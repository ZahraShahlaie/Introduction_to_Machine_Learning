



**یادگیری ماشین چیست و چه تفاوتی با برنامه‌نویسی سنتی دارد؟**

**پاسخ**: یادگیری ماشین شاخه‌ای از هوش مصنوعی است که به سیستم‌ها امکان می‌دهد از داده‌ها یاد بگیرند و عملکردشان را بدون برنامه‌نویسی صریح بهبود دهند. در برنامه‌نویسی سنتی، قوانین به‌صورت دستی کد می‌شوند، اما در یادگیری ماشین، مدل از داده‌ها الگوها را استخراج می‌کند.

---


**تعریف تام میچل از یادگیری ماشین چیست؟**

**پاسخ**: یک برنامه از تجربه $E$ نسبت به وظیفه $T$ و معیار عملکرد $P$ یاد می‌گیرد، اگر عملکردش در $T$، که با $P$ اندازه‌گیری می‌شود، با $E$ بهبود یابد.

---


**سوال:** در تعریف تام ام. میچل از یادگیری ماشین، سه‌گانه $(T, P, E)$ را توضیح دهید. چگونه این سه جزء با یکدیگر ارتباط برقرار می‌کنند تا نشان دهند که یک برنامه یاد می‌گیرد؟

**پاسخ:**

سه‌گانه $(T, P, E)$ اجزای اصلی یک مسئله یادگیری را تشکیل می‌دهند:

* **وظیفه (Task - T):** کاری که برنامه کامپیوتری باید انجام دهد.
* **معیار عملکرد (Performance Measure - P):** معیاری برای اندازه‌گیری میزان خوب بودن عملکرد برنامه در انجام وظیفه $T$.
* **تجربه (Experience - E):** داده‌ها یا اطلاعاتی که برنامه برای یادگیری از آن‌ها استفاده می‌کند.

**ارتباط:** یک برنامه یاد می‌گیرد اگر عملکرد آن در وظایف $T$، که با $P$ اندازه‌گیری می‌شود، با افزایش تجربه $E$ بهبود یابد. این بدان معناست که با مشاهده داده‌های بیشتر یا با تعاملات مکرر (تجربه)، برنامه باید بتواند وظیفه محوله را با کیفیت بالاتری (عملکرد بهتر) انجام دهد.

---
**چند کاربرد عملی یادگیری ماشین را نام ببرید.**

**پاسخ**: پیش‌بینی رفتار مشتریان، کنترل کیفیت کارخانه، تحلیل تصاویر پزشکی.

---

### چه نوع‌هایی از یادگیری ماشین وجود دارد؟

**پاسخ:**
یادگیری ماشین به سه نوع اصلی تقسیم می‌شود:

* **یادگیری نظارت‌شده:** مدل با استفاده از داده‌های برچسب‌دار (ورودی و خروجی) آموزش می‌بیند. مثلاً پیش‌بینی قیمت خانه بر اساس ویژگی‌هایی مانند متراژ و تعداد اتاق.
* **یادگیری بدون نظارت:** مدل با استفاده از داده‌های بدون برچسب برای کشف الگوها یا ساختارهای پنهان در داده‌ها آموزش می‌بیند. مثلاً خوشه‌بندی مشتریان برای بازاریابی هدفمند.
* **یادگیری تقویتی:** مدل از طریق آزمون و خطا و با دریافت پاداش یا جریمه یاد می‌گیرد. مثلاً آموزش یک ربات برای انجام وظایف خاص مانند حرکت در محیط.

---

**تفاوت بین یادگیری نظارت‌شده و بدون نظارت چیست؟**

**پاسخ**: در یادگیری نظارت‌شده، داده‌ها برچسب دارند (ورودی و خروجی مشخص)، اما در یادگیری بدون نظارت، داده‌ها بدون برچسب هستند و مدل الگوهای پنهان را کشف می‌کند.

---


### تفاوت بین supervised و unsupervised learning؟

**پاسخ**:
در **supervised learning** مدل با **برچسب‌های آموزشی** آموزش داده می‌شود، اما در **unsupervised learning** داده‌ها بدون برچسب هستند و مدل باید ساختار یا الگوهای پنهان در داده‌ها را کشف کند.

---

**یادگیری تحت نظارت چیست؟**

**پاسخ**: یادگیری با داده‌های برچسب‌دار که شامل ورودی ($x$) و خروجی ($y$) است برای پیش‌بینی خروجی‌های جدید.

---


**تفاوت رگرسیون و طبقه‌بندی چیست؟**

**پاسخ**: رگرسیون برای پیش‌بینی مقادیر پیوسته (مثل قیمت) و طبقه‌بندی برای پیش‌بینی دسته‌های گسسته (مثل اسپم/غیراسپم) است.

---


**رگرسیون خطی چیست و چگونه کار می‌کند؟**

**پاسخ**: رگرسیون خطی مدلی است که رابطه خطی بین متغیرهای مستقل و وابسته را مدل‌سازی می‌کند. معادله آن به‌صورت زیر است:

$$
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_n x_n + \epsilon
$$

هدف کمینه کردن خطا با یافتن ضرایب بهینه است.
---

###  رگرسیون خطی؟

**پاسخ**:
**رگرسیون خطی** برای پیش‌بینی داده‌های پیوسته مانند قیمت‌ها، روندها و دما استفاده می‌شود.

---

### مدل ساده‌ای برای پیش‌بینی پیوسته چیست؟

**پاسخ**:
**رگرسیون خطی** یک مدل ساده برای پیش‌بینی **داده‌های پیوسته** است که رابطه‌ای خطی بین ورودی‌ها و خروجی برقرار می‌کند.

---

**فرمول فرضیه رگرسیون خطی چیست؟**

**پاسخ**:

$$
h_w(x) = w_0 + w_1x_1 + \dots + w_Dx_D = w^T x
$$

---

**معادله رگرسیون خطی را بنویسید و اجزای آن را توضیح دهید.**

**پاسخ**: معادله:

$$
y = \beta_0 + \beta_1 x_1 + \dots + \beta_n x_n + \epsilon
$$

* $y$: متغیر وابسته (هدف).
* $\beta_0$: عرض از مبدا.
* $\beta_i$: ضرایب ویژگی‌ها.
* $x_i$: متغیرهای مستقل (ویژگی‌ها).
* $\epsilon$: خطای مدل.

---

**نقش $w_0$ در رگرسیون خطی چیست؟**

**پاسخ**: $w_0$ بایاس است که امکان پیش‌بینی مقادیر غیرصفر را حتی در صورت صفر بودن ویژگی‌ها فراهم می‌کند.

---

**هدف اصلی رگرسیون خطی چیست؟**

**پاسخ**: کمینه کردن فاصله بین پیش‌بینی ($h_w(x)$) و مقدار واقعی ($y$).

---

**تابع هزینه چیست؟**

**پاسخ**: معیاری برای سنجش دقت مدل، مثل مجموع مربعات خطاها (SSE).

---

**تابع هزینه در رگرسیون خطی چیست و چگونه محاسبه می‌شود؟**

**پاسخ**: تابع هزینه معمولاً میانگین مربعات خطا (MSE) است:

$$
J(\beta) = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2
$$

که $y_i$ مقدار واقعی و $\hat{y}_i$ مقدار پیش‌بینی‌شده است.

---


**فرمول MSE چیست؟**

**پاسخ**:

$$
J(w) = \frac{1}{n} \sum_{i=1}^{n} (y^{(i)} - h_w(x^{(i)}))^2
$$

---

**چرا از MSE به‌عنوان تابع هزینه استفاده می‌شود؟**

**پاسخ**: چون خطاهای بزرگ را بیشتر جریمه می‌کند و محاسباتش ساده است.

---

**روش تحلیلی در رگرسیون خطی چیست؟**

**پاسخ**: استفاده از معادلات نرمال برای محاسبه مستقیم

$$
w = (X^T X)^{-1} X^T y
$$

---



**مزیت روش تحلیلی چیست؟**

**پاسخ**: دقیق است و نیازی به تکرار ندارد.

---

**محدودیت‌های روش معادلات نرمال چیست؟**

**پاسخ**: محاسبات سنگین برای داده‌های بزرگ و نیاز به معکوس‌پذیری $X^T X$.

---








**گرادیان نزولی چیست؟**

**پاسخ**: روشی عددی برای کمینه کردن تابع هزینه با به‌روزرسانی وزن‌ها در جهت مخالف گرادیان.

---

**فرمول به‌روزرسانی گرادیان نزولی چیست؟**

**پاسخ**:

$$
w_{t+1} = w_t - \eta \nabla J(w_t)
$$

---

**نرخ یادگیری ($\eta$) چیست؟**

**پاسخ**: پارامتری که اندازه قدم‌های به‌روزرسانی وزن‌ها را تعیین می‌کند.

---

**اگر نرخ یادگیری خیلی بزرگ باشد چه اتفاقی می‌افتد؟**

**پاسخ**: الگوریتم ممکن است واگرا شود و به نقطه بهینه نرسد.

---

**اگر نرخ یادگیری خیلی کوچک باشد چه می‌شود؟**

**پاسخ**: همگرایی کند می‌شود و زمان زیادی طول می‌کشد.

---

**تفاوت Batch GD و Stochastic GD چیست؟**

**پاسخ**: Batch GD از کل داده‌ها و Stochastic GD از یک نمونه در هر مرحله استفاده می‌کند.

---

**Mini-batch GD چیست؟**

**پاسخ**: استفاده از زیرمجموعه‌ای از داده‌ها برای به‌روزرسانی وزن‌ها، تعادل بین دقت و سرعت.

---

**چرا نرمال‌سازی داده‌ها در گرادیان نزولی مهم است؟**

**پاسخ**: باعث می‌شود گرادیان‌ها در مقیاس مشابه باشند و همگرایی سریع‌تر شود.

---

**رگرسیون چندجمله‌ای چیست؟**

**پاسخ**: مدلی که روابط غیرخطی را با استفاده از ویژگی‌های چندجمله‌ای مدل می‌کند.

---

**فرمول فرضیه رگرسیون چندجمله‌ای چیست؟**

**پاسخ**:

$$
h(x) = w_0 + w_1x + w_2x^2 + \dots + w_mx^m
$$

---



**مزیت رگرسیون چندجمله‌ای نسبت به رگرسیون خطی چیست؟**

**پاسخ**: توانایی مدل‌سازی روابط غیرخطی.

---

**چرا رگرسیون چندجمله‌ای ممکن است بیش‌برازش کند؟**

**پاسخ**: چون با افزایش درجه، مدل ممکن است نویز داده‌ها را هم یاد بگیرد.

---

**Underfitting چیست؟**

**پاسخ**: وقتی مدل بیش‌ازحد ساده است و نمی‌تواند الگوهای داده را خوب یاد بگیرد.

---

**Overfitting چیست؟**

**پاسخ**: وقتی مدل بیش‌ازحد پیچیده است و نویز داده‌ها را هم یاد می‌گیرد.

---


**چگونه می‌توان از بیش‌برازش جلوگیری کرد؟**

**پاسخ**: استفاده از تنظیم‌سازی (Regularization)، داده‌های اعتبارسنجی، و Cross-Validation.

---


**بیش‌برازش چیست و چگونه می‌توان از آن جلوگیری کرد؟**

**پاسخ**: بیش‌برازش زمانی رخ می‌دهد که مدل بیش از حد به داده‌های آموزشی وابسته شود و روی داده‌های جدید ضعیف عمل کند. برای جلوگیری: منظم‌سازی (ریج، لاسو)، افزایش داده، و اعتبارسنجی متقاطع.

---

---

### چگونه Overfitting را تشخیص دهیم؟

**پاسخ**:
**Overfitting** زمانی رخ می‌دهد که **خطای آموزش پایین** و **خطای تست بالا** باشد، زیرا مدل فقط به داده‌های آموزش مناسب شده است و توانایی تعمیم به داده‌های جدید را ندارد.

---

### راه‌های جلوگیری از Overfitting؟

**پاسخ**:
برای جلوگیری از **overfitting** می‌توان از روش‌هایی مانند:

* **Regularization**
* **Dropout**
* **استفاده از داده‌های بیشتر**
* **مدل ساده‌تر** استفاده کرد.

---



**تفاوت بین بیش‌برازش و کم‌برازش چیست؟**

**پاسخ**: بیش‌برازش: مدل بیش از حد به داده‌های آموزشی وابسته است و روی داده‌های جدید ضعیف عمل می‌کند.
کم‌برازش: مدل الگوهای داده‌های آموزشی را به‌خوبی یاد نمی‌گیرد و عملکرد ضعیفی دارد.

---

**داده‌های اعتبارسنجی چه نقشی دارند؟**

**پاسخ**: برای انتخاب مدلی که نه خیلی ساده و نه خیلی پیچیده باشد.
---

**چرا MSE خطاهای بزرگ را بیشتر جریمه می‌کند؟**

**پاسخ**: چون خطاها را به توان 2 می‌رساند، تأثیر خطاهای بزرگ بیشتر می‌شود.

---

**چه زمانی از Batch GD استفاده می‌کنیم؟**

**پاسخ**: وقتی داده‌ها کم باشند و دقت بالا مهم باشد.

---

**چه زمانی Stochastic GD مناسب است؟**

**پاسخ**: برای داده‌های بزرگ یا مسائل آنلاین که سرعت مهم است.

---

**مزیت Mini-batch GD چیست؟**

**پاسخ**: تعادل بین سرعت Stochastic GD و دقت Batch GD.

---

**چگونه نرخ یادگیری مناسب انتخاب می‌شود؟**

**پاسخ**: با آزمایش مقادیر مختلف یا استفاده از روش‌های تطبیقی مثل Adam.

---

**چرا $X^T X$ ممکن است معکوس‌پذیر نباشد؟**

**پاسخ**: به دلیل هم‌خطی ویژگی‌ها یا تعداد کم نمونه‌ها.

---

**گرادیان چیست؟**

**پاسخ**: مشتق تابع هزینه نسبت به پارامترها که جهت بهینه‌سازی را نشان می‌دهد.

---


**نقش بایاس در رگرسیون چیست؟**

**پاسخ**: امکان جابجایی مدل برای تطابق بهتر با داده‌ها.

---




**چرا نرمال‌سازی داده‌ها در رگرسیون خطی مهم است؟**

**پاسخ**: نرمال‌سازی مقیاس ویژگی‌ها را یکسان می‌کند تا تأثیر متغیرهای با مقیاس بزرگ‌تر بر مدل کاهش یابد و گرادیان کاهشی سریع‌تر همگرا شود.
---


**چگونه می‌توان مدل رگرسیون را ارزیابی کرد؟**

**پاسخ**: با معیارهایی مثل MSE، RMSE، یا $R^2$ روی داده‌های تست.

---

**تفاوت داده‌های آموزشی و اعتبارسنجی چیست؟**

**پاسخ**: داده‌های آموزشی برای یادگیری مدل و اعتبارسنجی برای ارزیابی آن استفاده می‌شوند.

---

**چگونه درجه مناسب در رگرسیون چندجمله‌ای انتخاب میشود؟**


**پاسخ**: با استفاده از داده‌های اعتبارسنجی و بررسی خطای تست.

---

**چرا رگرسیون خطی برای داده‌های غیرخطی مناسب نیست؟**

**پاسخ**: چون فرض می‌کند رابطه بین ورودی و خروجی خطی است.

---

**تفاوت MSE و RMSE چیست؟**

**پاسخ**: RMSE ریشه دوم MSE است و مقیاسش با داده‌ها یکسان است.



---




**گرادیان کاهشی چیست و چگونه در رگرسیون خطی استفاده می‌شود؟**

**پاسخ**: گرادیان کاهشی الگوریتمی برای کمینه کردن تابع هزینه است. در رگرسیون خطی، ضرایب مدل با به‌روزرسانی‌های تکراری در جهت کاهش گرادیان تابع هزینه تنظیم می‌شوند.

---
### گرادیان دیسنت چیست؟

**پاسخ**:
**گرادیان دیسنت** الگوریتمی برای **کمینه‌سازی تابع هزینه** است که در هر مرحله با استفاده از **گرادیان**، پارامترهای مدل به‌روز می‌شود.

---

### چه زمانی گرادیان دیسنت همگرا نمی‌شود؟

**پاسخ**:
گرادیان دیسنت ممکن است زمانی که **نرخ یادگیری** زیاد باشد یا تابع هزینه **غیرمحدب** باشد، همگرا نشود.

**تعمیم‌پذیری در یادگیری ماشین به چه معناست؟**

**پاسخ**: تعمیم‌پذیری توانایی مدل در عملکرد خوب روی داده‌های جدید و نادیده است، نه فقط داده‌های آموزشی.

---

**چگونه می‌توان تعمیم‌پذیری یک مدل را ارزیابی کرد؟**

**پاسخ**: با استفاده از مجموعه آزمون جداگانه، معیارهایی مانند MSE یا دقت، و روش‌هایی مانند اعتبارسنجی متقاطع.

---


### داده‌های پرت چگونه بر عملکرد رگرسیون خطی تأثیر می‌گذارند؟

**پاسخ**:
داده‌های پرت می‌توانند **ضرایب مدل** را به‌شدت تحت تأثیر قرار دهند، زیرا این داده‌ها ممکن است الگویی غلط برای مدل ایجاد کنند. در نتیجه، **خطای پیش‌بینی** افزایش می‌یابد و مدل ممکن است قادر به تعمیم درست به داده‌های جدید نباشد.

---

### چگونه می‌توان اثر داده‌های پرت را در رگرسیون خطی کاهش داد؟

**پاسخ**:
برای کاهش اثر داده‌های پرت می‌توان از **روش‌های قوی رگرسیون** (مثل رگرسیون قوی) استفاده کرد که در برابر داده‌های پرت مقاوم‌تر هستند، یا اینکه از **حذف داده‌های پرت** و **وزن‌دهی به داده‌ها** بهره برد تا تأثیر آن‌ها بر مدل کم شود.

---

### تفاوت بین واریانس و بایاس در یادگیری ماشین چیست؟

**پاسخ**:

* **بایاس**: خطای ناشی از ساده‌سازی بیش از حد مدل، که باعث می‌شود مدل نتواند الگوهای پیچیده‌تر داده‌ها را به‌درستی یاد بگیرد.
* **واریانس**: حساسیت مدل به تغییرات جزئی در داده‌های آموزشی، که ممکن است مدل را در برابر داده‌های جدید حساس و ضعیف کند.

---

### چگونه می‌توان تعادل بین واریانس و بایاس را برقرار کرد؟

**پاسخ**:
برای حفظ تعادل بین بایاس و واریانس، باید **مدلی با پیچیدگی مناسب** انتخاب کرد. استفاده از **منظم‌سازی**، **اعتبارسنجی متقاطع**، و دقت در انتخاب ویژگی‌ها می‌تواند به این تعادل کمک کند.

---

### مفهوم "نفرین ابعاد" چیست و چگونه بر مدل‌های یادگیری ماشین تأثیر می‌گذارد؟

**پاسخ**:
**نفرین ابعاد** به مشکلاتی اطلاق می‌شود که زمانی پیش می‌آید که تعداد ویژگی‌ها (ابعاد داده‌ها) بسیار زیاد می‌شود. افزایش ابعاد باعث **کاهش تعمیم‌پذیری** مدل، افزایش پیچیدگی، و نیاز به داده‌های بیشتر می‌شود.



### تفاوت بین رگرسیون خطی ساده و چندگانه چیست؟

**پاسخ**:
**رگرسیون خطی ساده** تنها یک متغیر مستقل دارد، در حالی که **رگرسیون چندگانه** چندین متغیر مستقل را همزمان مدل می‌کند و روابط پیچیده‌تری را تحلیل می‌کند.

---

### چرا فرض خطی بودن در رگرسیون خطی مهم است؟

**پاسخ**:
رگرسیون خطی فرض می‌کند که رابطه بین متغیرهای ورودی و خروجی **خطی** است. اگر این فرض نقض شود، مدل نمی‌تواند روابط پیچیده‌تر داده‌ها را به درستی شبیه‌سازی کند و عملکرد ضعیفی خواهد داشت.

---

### اگر رابطه بین متغیرها غیرخطی باشد، چه باید کرد؟

**پاسخ**:
در صورت غیرخطی بودن رابطه بین متغیرها، می‌توان از **تبدیل ویژگی‌ها** (مانند افزودن توان‌ها یا لگاریتم‌ها) یا **مدل‌های غیرخطی** (مانند رگرسیون چندجمله‌ای یا درخت تصمیم) استفاده کرد.

---

### مفهوم "تابع احتمال" در رگرسیون احتمالی چیست؟

**پاسخ**:
**تابع احتمال** در رگرسیون احتمالی، توزیع احتمال پیش‌بینی‌ها را توصیف می‌کند. به‌عنوان مثال، در رگرسیون خطی، فرض می‌شود که خطای پیش‌بینی‌ها از توزیع نرمال با میانگین صفر و واریانس معین پیروی می‌کند.

---

### چگونه می‌توان مدل رگرسیون خطی را ارزیابی کرد؟

**پاسخ**:
برای ارزیابی مدل رگرسیون خطی از معیارهایی مانند **MSE** (میانگین مربعات خطا)، **RMSE** (ریشه میانگین مربعات خطا)، و **\$R^2\$** استفاده می‌شود. همچنین، بررسی **نمودارهای باقی‌مانده** می‌تواند به ارزیابی تطابق مدل با داده‌های واقعی کمک کند.

---

### تفاوت بین MSE و RMSE چیست؟

**پاسخ**:
**RMSE** (ریشه میانگین مربعات خطا) از **MSE** (میانگین مربعات خطا) به‌صورت ریشه دوم محاسبه می‌شود:
$\text{RMSE} = \sqrt{\frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2 }$
و مقیاس آن با داده‌های اصلی هم‌خوانی دارد، که تفسیر آن را برای های عملی ساده‌تر می‌کند.

---

### مفهوم "انحراف معیار" در رگرسیون احتمالی چیست؟

**پاسخ**:
**انحراف معیار** در رگرسیون احتمالی میزان پراکندگی توزیع پیش‌بینی‌ها را نشان می‌دهد و به‌عنوان معیاری برای سنجش **عدم قطعیت** پیش‌بینی‌ها مورد استفاده قرار می‌گیرد.

---

### چگونه می‌توان توزیع پیش‌بینی‌ها را در رگرسیون احتمالی تحلیل کرد؟

**پاسخ**:
برای تحلیل توزیع پیش‌بینی‌ها، می‌توان به **میانگین**، **واریانس**، و **بازه‌های اطمینان** توجه کرد. این بازه‌ها می‌توانند عدم قطعیت پیش‌بینی‌ها را به‌طور دقیق‌تری مشخص کنند.

---

### چرا داده‌های آموزشی باید نماینده داده‌های واقعی باشند؟

**پاسخ**:
اگر داده‌های آموزشی نماینده‌ی داده‌های واقعی نباشند، مدل ممکن است **الگوهای غلط** یاد بگیرد و در **داده‌های جدید** عملکرد ضعیفی داشته باشد. بنابراین، برای **تعادل و تعمیم‌پذیری بهتر**، داده‌های آموزشی باید نماینده‌ای از دنیای واقعی باشند.

---

### مفهوم "افزایش داده" چیست و چگونه به تعمیم‌پذیری کمک می‌کند؟

**پاسخ**:
**افزایش داده** فرآیند تولید داده‌های مصنوعی است که با تغییرات در داده‌های اصلی (مانند چرخش یا تغییر مقیاس تصاویر) انجام می‌شود. این کار باعث افزایش تنوع داده‌ها و **جلوگیری از بیش‌برازش** می‌شود و در نتیجه **تعمیمن‌پذیری مدل** را بهبود می‌بخشد.

---

### تفاوت بین مدل‌های پارامتری و غیرپارامتری چیست؟

**پاسخ**:
مدل‌های **پارامتری** (مثل رگرسیون خطی) تعداد محدودی پارامتر دارند، در حالی که مدل‌های **غیرپارامتری** (مثل KNN) ساختار منعطف‌تری دارند و می‌توانند پیچیدگی بیشتری را مدل کنند.

---
البته! در اینجا نسخه بدون شماره‌ها آمده است:

---

### تفاوت مدل خطی و مدل غیرخطی چیست؟

**پاسخ**:
مدل‌های **خطی** خروجی را به‌صورت ترکیب خطی از ورودی‌ها تولید می‌کنند (مثال: $y = \beta_0 + \beta_1 x_1 + \dots + \beta_n x_n$)، در حالی که مدل‌های **غیرخطی** قادرند روابط پیچیده‌تری بین ورودی‌ها و خروجی‌ها را مدل کنند (مثال: شبکه‌های عصبی، رگرسیون چندجمله‌ای، یا درخت‌های تصمیم).

---

### چرا از Polynomial Regression استفاده می‌شود؟

**پاسخ**:
**Polynomial Regression** برای مدل‌سازی **روابط غیرخطی** میان متغیرهای ورودی و خروجی به کار می‌رود. این روش به وسیله افزودن توان‌های مختلف به ویژگی‌ها، قادر است الگوهای پیچیده‌تری از داده‌ها را شبیه‌سازی کند.

---

### Regularization چگونه از overfitting جلوگیری می‌کند؟

**پاسخ**:
**Regularization** با اضافه کردن جریمه به وزن‌ها، مدل را مجبور می‌کند که ویژگی‌های مهم‌تر را انتخاب کرده و از پیچیدگی زیاد خودداری کند. این کار باعث جلوگیری از **بیش‌برازش (overfitting)** و بهبود **تعمیم‌پذیری** مدل می‌شود.

---

### مفهوم Early Stopping چیست؟

**پاسخ**:
**Early Stopping** یک تکنیک است که آموزش مدل را زمانی متوقف می‌کند که عملکرد آن بر روی داده‌های اعتبارسنجی شروع به بدتر شدن کند. این کار برای جلوگیری از بیش‌برازش و کاهش زمان آموزش مفید است.

---

### چه تفاوتی بین Validation و Test Set وجود دارد؟

**پاسخ**:
**Validation Set** برای تنظیم مدل، انتخاب بهترین هایپرپارامترها و جلوگیری از بیش‌برازش استفاده می‌شود، در حالی که **Test Set** برای ارزیابی نهایی و بررسی کارایی واقعی مدل استفاده می‌شود.

---

### تفاوت Ridge و Lasso چیست؟

**پاسخ**:
**Ridge** از جریمه $L_2$ استفاده می‌کند که به کاهش اندازه وزن‌ها کمک می‌کند، اما آن‌ها را به صفر نمی‌رساند. در مقابل، **Lasso** از جریمه $L_1$ استفاده می‌کند که برخی از وزن‌ها را به صفر می‌رساند و به انتخاب ویژگی‌های مهم کمک می‌کند.

---

### آیا L1 همیشه بهتر از L2 است؟

**پاسخ**:
نه، بسته به داده‌ها و هدف مدل، ممکن است **L2** عملکرد بهتری داشته باشد. **L1** بیشتر برای انتخاب ویژگی‌ها مفید است، در حالی که **L2** به مدل کمک می‌کند که ویژگی‌ها را با دقت بیشتر تنظیم کند.

---

### چرا از Cross-validation استفاده می‌کنیم؟

**پاسخ**:
**Cross-validation** برای ارزیابی عملکرد مدل روی نمونه‌های مختلف داده‌ها استفاده می‌شود و کمک می‌کند تا **واریانس ارزیابی** کاهش یابد و مدل به‌طور موثرتری تعمیم‌پذیر شود.

---

### چند نوع Cross-validation داریم؟

**پاسخ**:
چندین نوع **Cross-validation** وجود دارد، از جمله **K-Fold**, **Leave-One-Out**, و **Stratified K-Fold** که هر کدام بسته به نوع داده‌ها و هدف مدل استفاده می‌شود.

---

### مزایای استفاده از K-Fold Cross-validation چیست؟

**پاسخ**:
**K-Fold Cross-validation** مزایایی از جمله **استفاده مؤثر از داده‌ها** و **ارزیابی پایدارتر** عملکرد مدل بر روی مجموعه‌های مختلف داده‌ها را فراهم می‌آورد، که به تعمیم‌پذیری بهتر مدل کمک می‌کند.

---

### سوالات تحلیلی/ریاضی:

**چرا تابع MSE مشتق‌پذیر است و MAE نه؟**

**پاسخ**:
**MSE** (میانگین مربعات خطا) تابعی مربعی است که در تمام نقاط مشتق‌پذیر است، اما **MAE** (میانگین مطلق خطا) در نقطه صفر مشتق ندارد، زیرا به صورت خطی و بدون انحنا است.

---

**چرا در MLE فرض می‌کنیم نویز نرمال است؟**

**پاسخ**:
فرض نرمال بودن نویز به دلیل **قضیه حد مرکزی** است که می‌گوید ترکیب نویز ناشی از فرآیندهای مختلف معمولاً توزیع نرمال دارد. این فرض در بسیاری از پدیده‌های طبیعی درست است.

---

**در رگرسیون احتمالاتی چرا log-likelihood را بیشینه می‌کنیم؟**

**پاسخ**:
در **رگرسیون احتمالاتی**، بیشینه کردن **log-likelihood** معادل کمینه‌سازی **SSE** (مجموع مربعات خطا) است و پیاده‌سازی آن از لحاظ ریاضی راحت‌تر است.

---

**چرا Bias² و Variance جمع می‌شوند؟**

**پاسخ**:
**Bias²** و **Variance** دو منبع اصلی خطای کلی مدل هستند. **Bias** به خطای ناشی از فرضیات غلط مدل و **Variance** به حساسیت مدل به تغییرات داده‌های آموزشی اشاره دارد. خطای کلی مدل برابر با مجموع این دو است.

---

**چگونه Bias بالا را کاهش دهیم؟**

**پاسخ**:
برای کاهش **Bias**، می‌توان از **مدل‌های پیچیده‌تر** یا **افزایش ویژگی‌ها** استفاده کرد تا مدل قادر باشد الگوهای پیچیده‌تر داده‌ها را یاد بگیرد.

---

**چگونه Variance بالا را کاهش دهیم؟**

**پاسخ**:
برای کاهش **Variance**، می‌توان از **Regularization**، **استفاده از داده‌های بیشتر**، یا **مدل‌های ساده‌تر** استفاده کرد تا مدل کمتر به داده‌های آموزشی حساس باشد.

---

**تعریف دقیق Noise در Bias-Variance چیست؟**

**پاسخ**:
**Noise** بخشی از خطاست که به‌دلیل تصادفی بودن داده‌ها ایجاد می‌شود و قابل کاهش نیست. این خطا از طبیعت داده‌ها ناشی می‌شود و نمی‌توان آن را حذف کرد.

---

**چرا از Root Mean Squared Error استفاده می‌کنیم؟**

**پاسخ**:
**RMSE** (ریشه میانگین مربعات خطا) به دلیل اینکه با واحد‌های خروجی مدل یکسان است، تفسیر راحت‌تری دارد. همچنین این معیار خطاهای بزرگ را بیشتر جریمه می‌کند که به مدل کمک می‌کند تا دقت بیشتری در پیش‌بینی‌ها داشته باشد.

---

حتما! در اینجا نسخه به سبک مشابه شما آمده است:

---

### تفاوت Bias و Variance چیست؟

**پاسخ**:
**Bias** خطای ناشی از **ساده بودن مدل** است که مدل نمی‌تواند الگوهای پیچیده داده‌ها را به درستی شبیه‌سازی کند.
**Variance** حساسیت مدل به **تغییرات داده‌های آموزشی** است که ممکن است باعث شود مدل به داده‌های جدید تعمیم نپذیرد.

---

### چه زمانی از Regularization استفاده می‌کنیم؟

**پاسخ**:
**Regularization** زمانی استفاده می‌شود که مدل دچار **overfitting** شود و نیاز به **کاهش پیچیدگی** مدل باشد، تا از یادگیری نویز و جزئیات غیرضروری جلوگیری شود.

---

### تفاوت L1 و L2 چیست؟

**پاسخ**:
**L1 Regularization** (Lasso) ویژگی‌ها را به **صفر** می‌رساند و باعث **sparsity** می‌شود (ویژگی‌های غیرمفید حذف می‌شوند).
**L2 Regularization** (Ridge) وزن‌ها را کوچک می‌کند، اما آن‌ها را به صفر نمی‌رساند.


---

### تعریف MSE؟

**پاسخ**:
**MSE** یا **میانگین مربعات خطا**، میانگین مربعات اختلاف بین **پیش‌بینی‌ها** و **مقدار واقعی** است.

---

### تفاوت MAE و MSE؟

**پاسخ**:
**MAE** (میانگین مطلق خطا) خطاها را به‌صورت خطی اندازه‌گیری می‌کند، در حالی که **MSE** (میانگین مربعات خطا) خطاهای بزرگ‌تر را بیشتر جریمه می‌کند.

---



---

### Early Stopping چیست؟

**پاسخ**:
**Early Stopping** متوقف کردن آموزش مدل قبل از **overfitting** است، با مانیتور کردن **خطای اعتبارسنجی** برای جلوگیری از یادگیری بیش از حد.

---

### Batch size در آموزش چه تأثیری دارد؟

**پاسخ**:
**Batch size** بر **نوسان گرادیان**، **حافظه** و **سرعت یادگیری** تأثیر دارد. اندازه‌های بزرگ‌تر ممکن است منجر به **یادگیری پایدارتر** شوند، اما نیاز به حافظه بیشتری دارند.

---

### در رگرسیون چه فرضی در مورد نویز داریم؟

**پاسخ**:
در رگرسیون معمولاً فرض می‌کنیم که **نویز** از **توزیع نرمال** با **میانگین صفر** و واریانس ثابت پیروی می‌کند.

---

### تعریف log-likelihood؟

**پاسخ**:
**Log-likelihood** لگاریتم تابع **درست‌نمایی** است که به دلیل خواص ریاضیاتی، مشتق‌گیری و محاسبه آن را ساده‌تر می‌کند.

---

### چرا log-likelihood را بیشتر از likelihood استفاده می‌کنیم؟

**پاسخ**:
چون **log-likelihood** باعث می‌شود که ضرب‌ها به **جمع** تبدیل شوند و **مشتق‌گیری** را ساده‌تر می‌کند.

---

### چرا مدل‌های پیچیده overfit می‌کنند؟

**پاسخ**:
مدل‌های پیچیده قادرند حتی **نویز** داده را یاد بگیرند، که باعث می‌شود نتوانند **داده‌های جدید** را به خوبی تعمیم دهند و دچار **overfitting** شوند.

---

### چه زمانی underfitting داریم؟

**پاسخ**:
**Underfitting** زمانی اتفاق می‌افتد که مدل **ساده** باشد و نتواند **الگوهای پیچیده داده‌ها** را به درستی یاد بگیرد.

---

### آیا کاهش MSE همیشه خوب است؟

**پاسخ**:
نه، کاهش **MSE** بر روی داده‌های آموزش می‌تواند باعث **overfitting** شود، اگر مدل نتواند به خوبی **داده‌های تست** را پیش‌بینی کند.

---

بله، درست متوجه شدم. برای بهتر نمایش دادن فرمول‌ها، به این صورت بازنویسی می‌کنم:

---

### تفاوت بین مدل Discriminative و Generative چیست؟

**پاسخ کامل**:
**مدل‌های Discriminative** به طور مستقیم تابع شرطی $p(y|x)$ را یاد می‌گیرند، که هدف آن تشخیص مرزهای بین کلاس‌ها است. مثالی از این مدل‌ها، **رگرسیون لجستیک** است.
**مدل‌های Generative** توزیع مشترک $p(x,y)$ یا $p(x|y)$ و $p(y)$ را مدل می‌کنند، به این معنی که مدل علاوه بر یادگیری مرز بین کلاس‌ها، ویژگی‌های کلاس‌ها را نیز یاد می‌گیرد. مثالی از این مدل‌ها، **Naive Bayes** است.
در اکثر مسائل یادگیری ماشین، **مدل‌های Discriminative** ترجیح داده می‌شوند، زیرا معمولاً دقت بالاتری دارند.

---

### هدف از Cross-Validation چیست و چرا مهم است؟

**پاسخ کامل**:
**Cross-validation** یک روش برای ارزیابی عملکرد مدل به شکلی مستقل از **داده‌های آموزش و تست** است.
در **K-Fold Cross-Validation**، داده‌ها به K قسمت تقسیم می‌شوند. مدل بر روی K-1 قسمت آموزش داده می‌شود و سپس روی قسمت باقی‌مانده اعتبارسنجی می‌شود.
این روش کمک می‌کند که از **Overfitting** جلوگیری کنیم و **مقدار بهینه‌ی λ یا درجه‌ی مدل** را انتخاب کنیم.

---

### اگر داده‌ها نویزدار باشند، چه مشکلی برای مدل یادگیری پیش می‌آید؟

**پاسخ کامل**:
وجود **نویز** در داده‌ها باعث می‌شود مدل نتواند رابطه واقعی بین ویژگی‌ها و خروجی‌ها را به درستی یاد بگیرد. اگر مدل بیش از حد پیچیده باشد، ممکن است نویز را نیز یاد بگیرد و به **Overfitting** دچار شود.
برای کاهش این مشکل، می‌توان از روش‌های زیر استفاده کرد:

* **Regularization** (برای جلوگیری از پیچیده شدن بیش از حد مدل)
* **مدل ساده‌تر** (که امکان یادگیری رابطه‌های اصلی را فراهم می‌کند)
* **جمع‌آوری داده‌های بیشتر** (برای بهبود کیفیت مدل)

---

### چرا MSE نسبت به خطاهای بزرگ حساس‌تر است؟

**پاسخ کامل**:
چون در **MSE** از مربع خطاها استفاده می‌شود، خطاهای بزرگ بیش از حد **تقویت** می‌شوند. به عبارت دیگر، هرچه خطا بزرگ‌تر باشد، تأثیر بیشتری بر **MSE** دارد.
فرمول MSE به صورت زیر است:

$$
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$

این ویژگی باعث می‌شود که اگر داده‌های شما شامل **outlier** (داده‌های پرت) باشند، MSE ممکن است نمایانگر عملکرد واقعی مدل نباشد. در این شرایط، استفاده از **MAE** یا **Huber Loss** ممکن است مناسب‌تر باشد.

---

### چه زمانی استفاده از MAE به جای MSE منطقی‌تر است؟

**پاسخ کامل**:
**MAE** (میانگین قدرمطلق خطاها) زمانی بهتر است که داده‌ها شامل **outlier** باشند، زیرا MAE خطاها را به صورت **خطی** جریمه می‌کند و برخلاف **MSE** که به شدت از **outlier** تأثیر می‌گیرد، کمتر به خطاهای بزرگ حساس است.
در نتیجه، MAE برای داده‌هایی که دارای داده‌های پرت هستند، بهتر عمل می‌کند و ممکن است نمایانگر عملکرد واقعی‌تر مدل باشد.

---

البته! این هم نسخه بدون شماره:

---

### در scikit-learn چطور یک مدل Ridge می‌سازید؟

**پاسخ کامل**:
برای ساخت یک مدل **Ridge** در scikit-learn، باید از کلاس `Ridge` استفاده کنید و پارامتر `alpha` را تنظیم کنید که میزان regularization را تعیین می‌کند. سپس می‌توانید مدل را با داده‌های آموزشی آموزش دهید:

```python
from sklearn.linear_model import Ridge
model = Ridge(alpha=1.0)  # مقدار alpha را می‌توان برای تنظیم regularization تغییر داد
model.fit(X_train, y_train)
```

---

### چگونه می‌توان λ بهینه را پیدا کرد؟

**پاسخ کامل**:
برای پیدا کردن **λ بهینه** (که همان **regularization parameter** است)، می‌توان از روش‌هایی مثل **Grid Search** یا **Cross-validation** استفاده کرد. این روش‌ها به شما کمک می‌کنند تا مقدار بهترین λ را از بین یک مجموعه از مقادیر انتخابی پیدا کنید.

---

### اگر مدل شما در تست بد عمل می‌کند ولی در آموزش عالی است، چه مشکلی وجود دارد؟

**پاسخ کامل**:
این رفتار نشان‌دهنده **Overfitting** است. یعنی مدل شما بیش از حد به داده‌های آموزشی تطبیق پیدا کرده و توانایی تعمیم به داده‌های جدید را ندارد.

---

### اگر مدل ساده‌ای دارید و خطا هم بالا است، چه کاری باید بکنید؟

**پاسخ کامل**:
اگر مدل شما ساده است و خطای بالایی دارد، باید **مدل پیچیده‌تری** انتخاب کنید یا **ویژگی‌های جدید** به مدل اضافه کنید تا قدرت پیش‌بینی آن افزایش یابد.

---

### در یادگیری ماشین، چه نوع تابع خطا برای طبقه‌بندی استفاده می‌شود؟

**پاسخ کامل**:
برای مسائل **طبقه‌بندی**، معمولاً از تابع **Cross-entropy loss** استفاده می‌شود که اختلاف بین پیش‌بینی مدل و مقادیر واقعی را اندازه‌گیری می‌کند.

---

### اگر تابع هزینه به‌صورت غیرمحدب باشد چه مشکلی ایجاد می‌شود؟

**پاسخ کامل**:
اگر تابع هزینه به‌صورت **غیرمحدب** باشد، ممکن است الگوریتم به جای رسیدن به مینیمم سراسری، در **مینیمم محلی** گیر کند و نتایج بهینه‌ای به دست نیاید.

---

### چه زمانی از مدل‌های non-parametric استفاده می‌کنیم؟

**پاسخ کامل**:
مدل‌های **non-parametric** زمانی استفاده می‌شوند که نمی‌خواهیم هیچ فرض خاصی در مورد **توزیع داده‌ها** اعمال کنیم. این مدل‌ها می‌توانند از داده‌های خود برای ساخت مدل بدون نیاز به فرض‌های اولیه استفاده کنند.

---

### مزایای مدل‌های احتمالاتی نسبت به مدل‌های قطعی چیست؟

**پاسخ کامل**:
**مدل‌های احتمالاتی** قابلیت مدل‌سازی **عدم قطعیت** را دارند و می‌توانند **توزیع‌های احتمال** برای خروجی‌ها پیش‌بینی کنند. این ویژگی در مقایسه با مدل‌های قطعی که تنها یک پیش‌بینی واحد ارائه می‌دهند، مفیدتر است.

---

### در چه شرایطی Regularization به مدل آسیب می‌زند؟

**پاسخ کامل**:
اگر مقدار **λ** در **Regularization** بسیار بزرگ باشد، می‌تواند مدل را بیش از حد محدود کند و باعث **underfitting** شود، یعنی مدل قادر به یادگیری الگوهای داده‌ها نباشد.

---

### چرا استفاده زیاد از ویژگی‌ها ممکن است عملکرد مدل را کاهش دهد؟

**پاسخ کامل**:
**افزایش تعداد ویژگی‌ها** می‌تواند باعث **curse of dimensionality** شود، به این معنا که با افزایش ابعاد داده، **واریانس** مدل نیز افزایش می‌یابد و کارایی آن کاهش می‌یابد.

---

### در کدام شرایط dropout مؤثرتر از L2 است؟

**پاسخ کامل**:
در **شبکه‌های عصبی عمیق** که دارای **لایه‌های زیاد** هستند، استفاده از **Dropout** می‌تواند موثرتر از **L2 Regularization** باشد. Dropout به مدل کمک می‌کند تا از یادگیری بیش از حد وابستگی‌ها بین ویژگی‌ها جلوگیری کند.

---

### اگر مدل شما دچار high variance است، چه راهکارهایی دارید؟

**پاسخ کامل**:
برای کاهش **high variance**، می‌توان از روش‌های زیر استفاده کرد:

* **استفاده از داده‌های بیشتر** برای آموزش مدل
* **Regularization** برای کاهش پیچیدگی مدل
* **ساده‌سازی مدل** یا استفاده از مدل‌های کم‌پیچیده‌تر

---

حتماً! این هم نسخه جدید به سبک مشابه:

---

### مدل خطی چگونه می‌تواند با داده‌های غیرخطی کار کند؟

**پاسخ کامل:**
مدل‌های خطی می‌توانند با داده‌های غیرخطی کار کنند از طریق **پیش‌پردازش ویژگی‌ها (Feature Engineering)** یا **بسط ویژگی‌ها (Polynomial Features)** که فضای ویژگی‌های داده را به یک فضای خطی‌تر تبدیل می‌کند. به این ترتیب، مدل همچنان خطی باقی می‌ماند اما در فضای جدیدی که ویژگی‌های پیچیده‌تری دارد، عمل می‌کند.

مثال:

```python
from sklearn.preprocessing import PolynomialFeatures
poly = PolynomialFeatures(degree=2)
X_poly = poly.fit_transform(X_train)
```

---

### در تفسیر Root Mean Squared Error، چرا گفتیم واحد آن با خروجی برابر است؟

**پاسخ کامل:**
چون **RMSE** برابر است با:

$$
RMSE = \sqrt{MSE}
$$

از آنجایی که **MSE** واحدی به شکل **(خروجی)^2** دارد، با گرفتن ریشه دوم از آن، واحد **RMSE** با واحد خروجی یکسان می‌شود. این ویژگی باعث می‌شود که **RMSE** تفسیر‌پذیرتر باشد و بگوییم "مدل به طور میانگین ۲ درجه خطا دارد."

---

### چه ارتباطی بین Maximum Likelihood و Least Squares وجود دارد؟

**پاسخ کامل:**
اگر فرض کنیم که نویز در مدل ما **نرمال** و با **واریانس ثابت** است، آنگاه **بیشینه‌سازی تابع درست‌نمایی (Maximum Likelihood)** معادل **کمینه‌سازی SSE (Sum of Squared Errors)** خواهد بود. به عبارت دیگر:

$$
\text{argmax}_{w} \log L(w) \equiv \text{argmin}_{w} \sum (y_i - f(x_i))^2
$$

این پیوند بین **آمار** و **یادگیری ماشین** یکی از دلایل محبوبیت مدل‌های رگرسیون خطی است.

---

### اگر مدل‌تان Bias بالا دارد، چه اقداماتی انجام می‌دهید؟

**پاسخ کامل:**
مدلی که **Bias بالا** دارد، معمولاً به دلیل سادگی زیادش قادر به یادگیری روابط پیچیده داده‌ها نیست. برای کاهش **Bias** می‌توان از روش‌های زیر استفاده کرد:

* **افزایش پیچیدگی مدل** (مثلاً استفاده از درجه بالاتر در رگرسیون چندجمله‌ای)
* **اضافه کردن ویژگی‌های جدید** به داده‌ها
* **استفاده از مدل‌های غیرخطی** مانند درخت تصمیم یا شبکه عصبی که قادر به مدل‌سازی روابط پیچیده‌تری هستند.

---

### اگر مدل‌تان Variance بالا دارد، چگونه با آن مقابله می‌کنید؟

**پاسخ کامل:**
مدل‌هایی با **Variance بالا** به تغییرات داده‌های آموزشی حساس هستند و معمولاً به **Overfitting** منجر می‌شوند. برای مقابله با این مشکل، می‌توان از روش‌های زیر استفاده کرد:

* **استفاده از Regularization** مانند **Ridge** یا **Lasso** که مدل را از پیچیده شدن بیش از حد باز می‌دارد.
* **افزایش حجم داده آموزشی** برای کاهش حساسیت مدل به داده‌های خاص.
* **ساده‌تر کردن مدل** (مثلاً کاهش درجه رگرسیون چندجمله‌ای).
* **استفاده از Cross-validation** برای ارزیابی مدل روی داده‌های مختلف و جلوگیری از overfitting.

---

حتماً! این هم نسخه جدید به سبک مشابه:

---

### مدل خطی چگونه می‌تواند با داده‌های غیرخطی کار کند؟

**پاسخ کامل:**
مدل‌های خطی می‌توانند با داده‌های غیرخطی کار کنند از طریق **پیش‌پردازش ویژگی‌ها (Feature Engineering)** یا **بسط ویژگی‌ها (Polynomial Features)** که فضای ویژگی‌های داده را به یک فضای خطی‌تر تبدیل می‌کند. به این ترتیب، مدل همچنان خطی باقی می‌ماند اما در فضای جدیدی که ویژگی‌های پیچیده‌تری دارد، عمل می‌کند.

مثال:

```python
from sklearn.preprocessing import PolynomialFeatures
poly = PolynomialFeatures(degree=2)
X_poly = poly.fit_transform(X_train)
```

---

### در تفسیر Root Mean Squared Error، چرا گفتیم واحد آن با خروجی برابر است؟

**پاسخ کامل:**
چون **RMSE** برابر است با:

$$
RMSE = \sqrt{MSE}
$$

از آنجایی که **MSE** واحدی به شکل **(خروجی)^2** دارد، با گرفتن ریشه دوم از آن، واحد **RMSE** با واحد خروجی یکسان می‌شود. این ویژگی باعث می‌شود که **RMSE** تفسیر‌پذیرتر باشد و بگوییم "مدل به طور میانگین ۲ درجه خطا دارد."

---

### چه ارتباطی بین Maximum Likelihood و Least Squares وجود دارد؟

**پاسخ کامل:**
اگر فرض کنیم که نویز در مدل ما **نرمال** و با **واریانس ثابت** است، آنگاه **بیشینه‌سازی تابع درست‌نمایی (Maximum Likelihood)** معادل **کمینه‌سازی SSE (Sum of Squared Errors)** خواهد بود. به عبارت دیگر:

$$
\text{argmax}_{w} \log L(w) \equiv \text{argmin}_{w} \sum (y_i - f(x_i))^2
$$

این پیوند بین **آمار** و **یادگیری ماشین** یکی از دلایل محبوبیت مدل‌های رگرسیون خطی است.

---
---
---
---
---

---

**منظور از Regularization چیست؟**

**پاسخ**:  برای جلوگیری از پیچیدگی بیش‌ازحد مدل.

---

**تفاوت L1 و L2 Regularization چیست؟**

**پاسخ**: L1 وزن‌ها را به صفر می‌رساند (انتخاب ویژگی)، L2 وزن‌ها را کوچک می‌کند.


---


**چگونه می‌توان هم‌خطی ویژگی‌ها را تشخیص داد؟**

**پاسخ**: با محاسبه ماتریس همبستگی یا تحلیل VIF (Variance Inflation Factor).

---

**Cross-Validation چیست؟**

**پاسخ**: تکنیکی برای ارزیابی مدل با تقسیم داده‌ها به چندین زیرمجموعه.

---

---
---


### اگر مدل‌تان Bias بالا دارد، چه اقداماتی انجام می‌دهید؟

**پاسخ کامل:**
مدلی که **Bias بالا** دارد، معمولاً به دلیل سادگی زیادش قادر به یادگیری روابط پیچیده داده‌ها نیست. برای کاهش **Bias** می‌توان از روش‌های زیر استفاده کرد:

* **افزایش پیچیدگی مدل** (مثلاً استفاده از درجه بالاتر در رگرسیون چندجمله‌ای)
* **اضافه کردن ویژگی‌های جدید** به داده‌ها
* **استفاده از مدل‌های غیرخطی** مانند درخت تصمیم یا شبکه عصبی که قادر به مدل‌سازی روابط پیچیده‌تری هستند.

---

### اگر مدل‌تان Variance بالا دارد، چگونه با آن مقابله می‌کنید؟

**پاسخ کامل:**
مدل‌هایی با **Variance بالا** به تغییرات داده‌های آموزشی حساس هستند و معمولاً به **Overfitting** منجر می‌شوند. برای مقابله با این مشکل، می‌توان از روش‌های زیر استفاده کرد:

* **استفاده از Regularization** مانند **Ridge** یا **Lasso** که مدل را از پیچیده شدن بیش از حد باز می‌دارد.
* **افزایش حجم داده آموزشی** برای کاهش حساسیت مدل به داده‌های خاص.
* **ساده‌تر کردن مدل** (مثلاً کاهش درجه رگرسیون چندجمله‌ای).
* **استفاده از Cross-validation** برای ارزیابی مدل روی داده‌های مختلف و جلوگیری از overfitting.

---

بله، این هم نسخه بازنویسی شده به سبک مشابه:

---

---

### رگرسیون خطی چیست؟

**پاسخ:**
رگرسیون خطی یک مدل پایه‌ای در یادگیری ماشین است که برای مدل‌سازی روابط خطی میان متغیرها به کار می‌رود.

---

### رگرسیون خطی چگونه کار می‌کند؟

**پاسخ:**
رگرسیون خطی مدلی است که رابطه‌ای خطی میان متغیرهای مستقل (ویژگی‌ها) و متغیر وابسته (هدف) برقرار می‌کند. این مدل به صورت زیر تعریف می‌شود:

$$
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_n x_n + \epsilon
$$

که در آن \$\beta\_0\$ عرض از مبدا، \$\beta\_i\$ ضرایب مدل، \$x\_i\$ ویژگی‌ها، و \$\epsilon\$ خطای مدل است. هدف یافتن مقادیر بهینه \$\beta\_i\$ است که خطای پیش‌بینی را کمینه کند.

---

### رگرسیون خطی در چه مواردی استفاده می‌شود؟

**پاسخ:**
رگرسیون خطی برای پیش‌بینی مقادیر عددی در مسائلی مانند:

* پیش‌بینی فروش محصولات بر اساس بودجه تبلیغات.
* تخمین مصرف انرژی یک ساختمان بر اساس دما و اندازه.
* تحلیل روابط اقتصادی، مانند تأثیر نرخ بهره بر رشد اقتصادی.

برای بهبود دقت مدل، می‌توان از تکنیک‌هایی مانند نرمال‌سازی داده‌ها، انتخاب ویژگی‌های مناسب و استفاده از روش‌های منظم‌سازی (مانند رگرسیون ریج یا لاسو) استفاده کرد.

---

### چه مشکلاتی در استفاده از رگرسیون خطی ممکن است پیش بیاید؟

**پاسخ:**
چند مشکل اصلی عبارت‌اند از:

* **بیش‌برازش (Overfitting):** مدل ممکن است به‌طور دقیق داده‌های آموزشی را یاد بگیرد اما در داده‌های جدید عملکرد ضعیفی داشته باشد.
* **فرض خطی بودن:** اگر رابطه بین متغیرها غیرخطی باشد، رگرسیون خطی قادر به مدل‌سازی دقیق نخواهد بود.
* **حساسیت به داده‌های پرت:** داده‌های پرت می‌توانند ضرایب مدل را به‌شدت تحت تأثیر قرار دهند.

---

### چرا تعمیم‌پذیری در یادگیری ماشین مهم است؟

**پاسخ:**
**تعمیم‌پذیری** به این معناست که مدل فقط به داده‌های آموزشی وابسته نباشد، بلکه قادر باشد روی داده‌های جدید (داده‌های آزمون) نیز به‌خوبی عمل کند. هدف اصلی یادگیری ماشین، ساخت مدل‌هایی است که الگوهای عمومی را از داده‌ها استخراج کنند و نه اینکه فقط داده‌های آموزشی را حفظ کنند. اگر مدل نتواند به‌خوبی تعمیم دهد، ممکن است دچار **بیش‌برازش** یا **کم‌برازش** شود.

---

### رگولاریزاسیون چگونه از بیش‌برازش جلوگیری می‌کند و انواع رایج رگولاریزاسیون کدامند؟

**پاسخ:**
**رگولاریزاسیون** تکنیکی است که با اضافه کردن جریمه‌ای به تابع هزینه، پیچیدگی مدل را محدود کرده و از **بیش‌برازش (Overfitting)** جلوگیری می‌کند. این کار باعث می‌شود که وزن‌های مدل از اندازه‌های بزرگ دور شوند و مدل نتواند به نویز داده‌های آموزشی وابسته شود.

**انواع رایج رگولاریزاسیون:**

* **L1 Regularization (Lasso):** در این نوع، تابع هزینه شامل جمع مطلق وزن‌ها می‌شود:

  $$
  J(w) = \text{MSE} + \lambda \sum_{i=1}^{n} |w_i|
  $$

  که باعث می‌شود برخی از وزن‌ها به صفر برسند و در نتیجه مدل به **انتخاب ویژگی** کمک کند.

* **L2 Regularization (Ridge):** در این نوع، تابع هزینه شامل مربع وزن‌ها می‌شود:

  $$
  J(w) = \text{MSE} + \lambda \sum_{i=1}^{n} w_i^2
  $$

  این روش باعث می‌شود که وزن‌ها کوچک بمانند، اما به صفر نمی‌رسند. **Ridge** معمولاً برای **کاهش پیچیدگی مدل** و جلوگیری از ایجاد مدل‌های پیچیده‌تر استفاده می‌شود.

هر دو روش وابسته به **هایپرپارامتر λ** هستند که میزان جریمه به وزن‌ها را تنظیم می‌کند.

---

بله، در اینجا نسخه بازنویسی شده به سبک مشابه:

---

### چگونه می‌توان مدل‌های پیچیده را برای جلوگیری از بیش‌براش تنظیم کرد؟

**پاسخ:**
برای جلوگیری از **بیش‌براش** در مدل‌های پیچیده، می‌توان از استراتژی‌های زیر استفاده کرد:

1. **رگولاریزاسیون:**
   همانطور که در سوالات قبلی ذکر شد، اضافه کردن جریمه به وزن‌ها (با استفاده از **L1** یا **L2** رگولاریزاسیون) باعث می‌شود که مدل نتواند به جزئیات نویزی داده‌های آموزشی وابسته شود.

2. **کاهش پیچیدگی مدل:**
   کاهش تعداد ویژگی‌ها یا پارامترهای مدل می‌تواند از پیچیدگی بیش از حد جلوگیری کند. به عنوان مثال، استفاده از **پرسپترون‌های ساده‌تر** یا **شبکه‌های عصبی با تعداد لایه‌های کمتر** می‌تواند مدل را ساده‌تر کند.

3. **افزایش داده‌ها:**
   مدل‌ها معمولاً هنگامی که داده‌های بیشتری برای آموزش دارند، بهتر عمل می‌کنند. **افزایش داده‌ها** به کاهش خطر بیش‌براش کمک می‌کند.

4. **انتخاب ویژگی‌ها:**
   استفاده از تکنیک‌های **انتخاب ویژگی‌های مرتبط** و حذف ویژگی‌های غیرمفید یا نویزی می‌تواند پیچیدگی مدل را کاهش دهد و از مدل‌سازی جزئیات غیرضروری جلوگیری کند.

---

### چرا باید از **مجموع مربعات خطا (SSE)** به عنوان تابع هزینه استفاده کنیم و چرا این معیار در رگرسیون خطی پرکاربرد است؟

**پاسخ:**
**مجموع مربعات خطا (SSE)** به دلیل ویژگی‌های خاص خود یکی از معیارهای پرکاربرد در رگرسیون خطی است:

* **سادگی و شفافیت:**
  SSE، تفاوت بین مقادیر واقعی و پیش‌بینی شده را محاسبه کرده و آن را مربع می‌کند تا از تأثیر تفاوت‌های بزرگتر جلوگیری شود. این کار باعث می‌شود پیش‌بینی‌های نادرست بزرگ‌تر جریمه بیشتری داشته باشند.

* **قابلیت بهینه‌سازی آسان:**
  SSE به راحتی قابل بهینه‌سازی است. با استفاده از الگوریتم‌های بهینه‌سازی مبتنی بر **گرادیان نزولی**، می‌توان این تابع هزینه را کمینه کرد.

* **ارتباط با MLE:**
  همانطور که قبلاً اشاره شد، کمینه‌سازی **SSE** معادل **بیشینه‌سازی log-likelihood** در رگرسیون احتمالی است. از این منظر آماری، استفاده از SSE در رگرسیون خطی کاملاً منطقی است.

---

### آیا همیشه از رگرسیون خطی برای مدل‌سازی داده‌ها استفاده می‌کنیم؟ چه زمانی باید به روش‌های دیگری فکر کنیم؟

**پاسخ:**
رگرسیون خطی معمولاً زمانی مفید است که رابطه بین ورودی‌ها و خروجی‌ها تقریباً خطی باشد. اما اگر رابطه‌ها **غیرخطی** باشند، رگرسیون خطی ممکن است به **کم‌براش** یا **بیش‌براش** منجر شود.

در این شرایط، می‌توان از روش‌های دیگر استفاده کرد:

* **رگرسیون غیرخطی:**
  استفاده از مدل‌های رگرسیونی که می‌توانند روابط غیرخطی را مدل‌سازی کنند.

* **درخت‌های تصمیم (Decision Trees):**
  برای مدل‌سازی روابط پیچیده‌تر از **درخت‌های تصمیم** استفاده می‌شود که قادرند داده‌ها را به شکل غیرخطی تقسیم کنند.

* **شبکه‌های عصبی (Neural Networks):**
  این مدل‌ها قادرند روابط پیچیده و غیرخطی بین ورودی‌ها و خروجی‌ها را یاد بگیرند و برای داده‌های پیچیده مناسب‌تر هستند.

---

### چرا برای ارزیابی عملکرد مدل‌های یادگیری ماشین، استفاده از مجموعه تست (Test Set) جدا از مجموعه آموزشی (Training Set) ضروری است؟

**پاسخ:**
استفاده از **مجموعه تست** جداگانه از **مجموعه آموزشی** برای ارزیابی مدل ضروری است زیرا هدف اصلی یادگیری ماشین، ارزیابی توانایی مدل در تعمیم دادن به داده‌های جدید است. اگر داده‌های تست در فرآیند آموزش به کار روند، مدل ممکن است فقط داده‌های خاص مجموعه تست را حفظ کند و به خوبی بر روی داده‌های جدید عمل نکند. بنابراین، استفاده از مجموعه تست برای سنجش عملکرد مدل بر روی داده‌های **غیرمشاهده‌شده** و **ناشناخته** بسیار مهم است.

---

### **Bias-Variance Tradeoff** چیست و چگونه می‌توان آن را در انتخاب مدل‌های یادگیری ماشین به کار برد؟

**پاسخ:**
**Bias-Variance Tradeoff** به چالشی اشاره دارد که باید بین **بایاس (Bias)** و **واریانس (Variance)** تعادل برقرار کرد:

* **بایاس بالا:**
  نشان‌دهنده مدل‌های ساده‌ای است که قادر به مدل‌سازی پیچیدگی‌های داده‌ها نیستند و معمولاً منجر به **کم‌براش** می‌شوند.

* **واریانس بالا:**
  نشان‌دهنده مدل‌هایی است که به شدت به داده‌های آموزشی وابسته هستند و نمی‌توانند به خوبی بر روی داده‌های جدید تعمیم یابند. این موضوع به **بیش‌براش** مدل منجر می‌شود.

برای دستیابی به بهترین عملکرد، باید پیچیدگی مدل را به نحوی تنظیم کرد که بایاس و واریانس به طور متعادل به حداقل برسند.

---

بله، در اینجا ادامه‌ی پاسخ‌ها به سبک مشابه:

---

### **Regularization** چه نقشی در بهبود تعمیم‌پذیری مدل‌ها دارد و چرا در بسیاری از مدل‌ها از آن استفاده می‌شود؟

**پاسخ:**
**رگولاریزاسیون** یک تکنیک است که برای کاهش **بیش‌براش** و جلوگیری از پیچیدگی‌های زیاد در مدل‌ها به کار می‌رود. با افزودن یک جریمه به تابع هزینه، رگولاریزیشن می‌تواند مدل را به سمت استفاده از وزن‌های کوچکتر سوق دهد که این امر موجب کاهش پیچیدگی مدل و بهبود توانایی آن در تعمیم به داده‌های جدید می‌شود.
در رگرسیون L2 (Ridge) و L1 (Lasso)، این تکنیک می‌تواند باعث کاهش حساسیت مدل به نویز داده‌ها و جلوگیری از **بیش‌براش** شود.

---

### چه تفاوت‌هایی بین رگولاریزاسیون L1 و L2 وجود دارد و چگونه می‌توان از آن‌ها برای کنترل پیچیدگی مدل استفاده کرد؟

**پاسخ:**

* **رگولاریزاسیون L1 (Lasso):**
  این نوع رگولاریزیشن از جریمه‌ای برای جمع قدرمطلق وزن‌ها استفاده می‌کند. ویژگی خاص آن این است که می‌تواند برخی از وزن‌ها را به صفر برساند، و در نتیجه ویژگی‌هایی که کمتر مفید هستند از مدل حذف می‌شوند. این ویژگی برای **انتخاب ویژگی** مفید است.

* **رگولاریزاسیون L2 (Ridge):**
  در این روش، جریمه‌ای برای جمع مربعات وزن‌ها اعمال می‌شود که وزن‌ها را به صفر نمی‌رساند، بلکه آنها را به طور یکنواخت کاهش می‌دهد. این کار باعث می‌شود که مدل نسبت به تغییرات کوچک حساسیت کمتری داشته باشد و از **بیش‌براش** جلوگیری کند.

در هر دو نوع رگولاریزیشن، پارامتر **λ** (لامبدا) نقش کلیدی دارد و می‌تواند میزان پیچیدگی مدل را کنترل کند.

---

### چگونه می‌توان فهمید که مدل دچار **بیش‌براش** (Overfitting) یا **کم‌براش** (Underfitting) شده است؟

**پاسخ:**

* **بیش‌براش (Overfitting):**
  مدل به شدت به داده‌های آموزشی وابسته است و جزئیات کوچک و نویز داده‌ها را مدل می‌کند. در این حالت، خطای آموزش پایین است، اما خطای تست به طور قابل توجهی بالاتر است.

* **کم‌براش (Underfitting):**
  مدل به اندازه کافی پیچیده نیست و نمی‌تواند الگوهای موجود در داده‌ها را به خوبی مدل کند. در این حالت، خطای آموزش و تست هر دو بالا هستند و تقریباً مشابه یکدیگرند.

برای تشخیص این مشکلات، می‌توان عملکرد مدل را روی داده‌های آموزشی و تست مقایسه کرد. اگر تفاوت زیاد بین خطای آموزش و تست وجود داشته باشد، مدل دچار **بیش‌براش** است. اگر خطا در هر دو مجموعه بالا باشد، مدل **کم‌براش** است.

---

### **کراس-ولیدیشن (Cross-Validation)** چیست و چرا در ارزیابی عملکرد مدل‌ها مهم است؟

**پاسخ:**
**کراس-ولیدیشن** یک تکنیک برای ارزیابی مدل است که داده‌ها را به \$k\$ بخش تقسیم می‌کند. در هر دور، یک بخش به عنوان مجموعه تست و بقیه به عنوان مجموعه آموزش استفاده می‌شود. این فرآیند برای \$k\$ دور تکرار می‌شود و میانگین نتایج به دست آمده، عملکرد مدل را ارزیابی می‌کند.
کراس-ولیدیشن به جلوگیری از **بیش‌براش** کمک می‌کند و باعث می‌شود که مدل بر روی داده‌های جدید آزمایش شود، بدون اینکه تحت تأثیر نحوه تقسیم داده‌ها قرار گیرد.

---

### چگونه **N-fold Cross-Validation** می‌تواند به ارزیابی بهتر مدل کمک کند؟

**پاسخ:**
در **N-fold Cross-Validation**، داده‌ها به \$N\$ بخش تقسیم می‌شوند و هر بخش به نوبت به عنوان مجموعه تست و بقیه بخش‌ها به عنوان مجموعه آموزش استفاده می‌شوند. این فرآیند \$N\$ بار تکرار می‌شود.
مزیت این روش این است که **تمام داده‌ها** به طور یکسان به عنوان داده‌های آموزش و تست استفاده می‌شوند، که موجب افزایش دقت و کاهش واریانس ارزیابی می‌شود و احتمال تصادفی بودن نتایج را کاهش می‌دهد.

---

### چرا باید **بهینه‌سازی مدل** (Model Tuning) را با دقت انجام داد و چه عواملی باید در نظر گرفته شود؟

**پاسخ:**
**بهینه‌سازی مدل** به منظور دستیابی به بهترین عملکرد در داده‌های جدید ضروری است. انتخاب صحیح پارامترها و ویژگی‌ها برای مدل می‌تواند تأثیر زیادی بر عملکرد آن داشته باشد.
عوامل اصلی در بهینه‌سازی مدل شامل:

* **انتخاب مدل مناسب** برای نوع داده‌ها و پیچیدگی آن.
* **تنظیم هایپرپارامترها** (مانند اندازه لایه‌های شبکه عصبی یا مقدار λ در رگولاریزیشن).
* **استفاده از تکنیک‌های رگولاریزاسیون** برای جلوگیری از **بیش‌براش**.

هر یک از این عوامل می‌توانند تأثیر زیادی بر **دقت** و **توانایی تعمیم مدل** داشته باشند.

---

---

**سوال:** در رگرسیون خطی، چرا مدل ممکن است در برابر داده‌های جدید **ناتوان** باشد حتی اگر خطای آموزش بسیار کم باشد؟

**پاسخ:**
اگر مدل دارای **بیش‌براش** باشد (یعنی خطای آموزش بسیار کم و خطای تست بالا باشد)، احتمالاً مدل دچار پیچیدگی اضافی شده است که باعث شده است به جای یادگیری الگوهای عمومی، تنها به جزئیات و نویز داده‌های آموزشی توجه کند. در این حالت، مدل به داده‌های جدید تعمیم خوبی نخواهد داشت، زیرا توانایی آن در تشخیص الگوهای واقعی کاهش یافته است. این اتفاق معمولاً در مدل‌های پیچیده‌تر مانند **رگرسیون چندجمله‌ای با درجه بالا** یا **شبکه‌های عصبی با تعداد زیاد لایه‌ها** رخ می‌دهد که می‌توانند بیش از حد به داده‌های آموزشی فیت شوند.

---

**سوال:** چگونه می‌توان از **K-fold Cross Validation** برای ارزیابی عملکرد یک مدل یادگیری ماشین استفاده کرد؟

**پاسخ:**
در **K-fold Cross Validation**، داده‌ها به \$K\$ قسمت تقسیم می‌شوند. در هر دور، یکی از این بخش‌ها به عنوان **مجموعه تست** و باقی‌مانده به عنوان **مجموعه آموزشی** استفاده می‌شود. این فرآیند به تعداد \$K\$ بار تکرار می‌شود، بنابراین هر نمونه داده حداقل یک بار به عنوان داده تست مورد استفاده قرار می‌گیرد. نتیجه عملکرد مدل، میانگین خطای به دست آمده از هر \$K\$ تکرار است. این روش باعث می‌شود که مدل به طور جامع‌تری ارزیابی شود و از تأثیرات تصادفی تقسیم‌بندی داده‌ها جلوگیری شود. این روش به کاهش واریانس ارزیابی مدل کمک کرده و مطمئن می‌شود که مدل در داده‌های جدید به خوبی عمل می‌کند.

---

**سوال:** چه عواملی می‌تواند باعث شود که **خطای آموزش** پایین باشد ولی **خطای تست** بالا باشد؟

**پاسخ:**
این وضعیت معمولاً نشان‌دهنده **بیش‌براش** است. عوامل مختلفی می‌توانند باعث این مشکل شوند:

* **مدل پیچیده** با تعداد زیاد پارامتر که قادر به یادگیری جزئیات و نویزهای داده‌های آموزشی است.
* **پیش‌پردازش نامناسب** داده‌ها، مانند نرمال‌سازی ناقص یا ویژگی‌های غیرضروری که به مدل اضافه می‌شوند.
* **استفاده از مدل‌هایی که بیش از حد به داده‌های آموزشی وابسته هستند** (مثل رگرسیون چندجمله‌ای با درجه بالا).

در چنین شرایطی، مدل در برابر داده‌های جدید عملکرد ضعیفی دارد چون نمی‌تواند الگوهای عمومی را یاد بگیرد و تنها به خصوصیات خاص داده‌های آموزشی توجه می‌کند.

---

**سوال:** **MSE** (میانگین مربعات خطا) و **RMSE** (ریشه میانگین مربعات خطا) چه تفاوت‌هایی دارند و در ارزیابی مدل‌ها کدام یک بهتر است؟

**پاسخ:**
**MSE** (Mean Squared Error) میانگین مربعات خطاها را محاسبه می‌کند. این معیار نشان‌دهنده متوسط تفاوت‌های مربعی بین پیش‌بینی‌ها و مقادیر واقعی است.
**RMSE** (Root Mean Squared Error) ریشه مربع **MSE** است و به واحدهای داده نزدیک‌تر است. RMSE برای مدل‌هایی که نیاز به درک تفاوت‌های واقعی در واحدهای داده دارند، مفیدتر است.

اگرچه هر دو معیار اطلاعات مشابهی ارائه می‌دهند، **RMSE** برای تحلیل‌های خاص که نیاز به تفکیک تفاوت‌های خطا در مقیاس واقعی دارند، مناسب‌تر است.

---

اینجا نسخه کامل و بدون شماره‌ی سوالات و فرمول‌ها:

---

### پارامتر λ در Regularization چه نقشی دارد؟

**پاسخ:**
پارامتر λ میزان تاثیر ترم Regularization را کنترل می‌کند:

* اگر λ خیلی بزرگ باشد → مدل بیش‌ازحد ساده می‌شود (Underfitting)
* اگر λ خیلی کوچک باشد → مدل آزادانه وزن‌ها را انتخاب می‌کند (Overfitting)

انتخاب مناسب λ باعث رسیدن به **مدلی متعادل بین دقت و سادگی** می‌شود.

---

### در مدل رگرسیون با دیدگاه احتمالاتی، چرا از توزیع نرمال برای نویز استفاده می‌شود؟

**پاسخ:**
توزیع نرمال به‌دلیل خواص ریاضی مناسب (تقارن، مشتق‌پذیری) و قضیه حد مرکزی انتخاب می‌شود. فرض می‌کنیم:

$$
y = f(x; w) + \epsilon,\ \ \epsilon \sim \mathcal{N}(0, \sigma^2)
$$

این فرض باعث می‌شود تخمین پارامترها با روش **Maximum Likelihood Estimation** به ساده‌سازی تابع هزینه منجر شود (معادل MSE).

---

### چگونه نشان می‌دهیم که **Maximizing Log-Likelihood** معادل **Minimizing MSE** است؟

**پاسخ:**
اگر نویز نرمال با میانگین صفر و واریانس σ² فرض شود، تابع لگاریتم درست‌نمایی به شکل زیر درمی‌آید:

$$
\log L = -\frac{1}{2\sigma^2} \sum (y_i - f(x_i;w))^2 + \text{const}
$$

با حذف ثابت‌ها، بیشینه‌سازی log-likelihood معادل کمینه‌سازی **Sum of Squared Errors** (MSE) می‌شود.

---

### چه زمانی از Polynomial Regression استفاده می‌کنیم و خطر آن چیست؟

**پاسخ:**
وقتی رابطه‌ی بین ورودی و خروجی **غیرخطی** است، از رگرسیون چندجمله‌ای استفاده می‌کنیم.
خطر آن در این است که **درجه بالا → Overfitting** چون مدل می‌تواند به راحتی روی نویز داده آموزش هم منطبق شود.

---

### تعریف دقیق Expected Test Error چیست؟

**پاسخ:**
Expected Test Error یعنی میانگین خطای مدل روی داده‌های جدیدی که از همان توزیع \$p(x,y)\$ استخراج شده‌اند:

$$
J(w) = \mathbb{E}_{(x,y) \sim p}[(y - h_w(x))^2]
$$

از آنجا که توزیع اصلی را نداریم، این مقدار با داده‌های تست تخمین زده می‌شود.

---

### Root Mean Squared Error (RMSE) چه تفاوتی با MSE دارد و چه زمانی استفاده می‌شود؟

**پاسخ:**

* **MSE** فقط میانگین مربعات خطا را گزارش می‌کند و واحد آن مربع واحد خروجی است.
* **RMSE** ریشه‌ی MSE است و واحد آن مثل خروجی اصلی است.

مثلاً اگر داریم قیمت خانه‌ها را پیش‌بینی می‌کنیم، RMSE در واحد «تومان» خواهد بود و **قابل تفسیرتر** است. بنابراین RMSE اغلب برای گزارش به کاربران یا ارزیابی عملکرد کاربردی ترجیح داده می‌شود.

---

### چرا مدل‌های بسیار ساده (High Bias) حتی با داده زیاد هم عملکرد ضعیفی دارند؟

**پاسخ:**
مدل‌های ساده دارای فرضیات محدودکننده‌ای هستند. مثلاً در رگرسیون خطی، ما فرض می‌کنیم رابطه بین ورودی و خروجی خطی است. اگر واقعیت پیچیده‌تر باشد، حتی اگر **حجم داده زیاد باشد**، این مدل قادر به یادگیری آن نخواهد بود.
این خطای سیستماتیک را **Bias** می‌گویند. داده بیشتر نمی‌تواند فرض غلط مدل را جبران کند.

---

### آیا همیشه باید از مدل‌های پیچیده برای بهبود عملکرد استفاده کرد؟

**پاسخ:**
خیر! مدل پیچیده لزوماً بهتر نیست. پیچیدگی بالا اگر با داده ناکافی یا تنظیمات نامناسب همراه شود، **Overfitting** ایجاد می‌کند.
برعکس، مدل ساده با انتخاب ویژگی مناسب، Regularization و تنظیم پارامتر صحیح می‌تواند عملکرد بهتری از مدل پیچیده داشته باشد.
اصل طلایی: مدل باید **به اندازه‌ی لازم پیچیده باشد، نه بیشتر**.

---

### در چه شرایطی Regularization می‌تواند به مدل آسیب بزند؟

**پاسخ:**
اگر مقدار λ (ضریب Regularization) بیش از حد زیاد باشد، مدل بیش از حد ساده می‌شود. این اتفاق باعث **Underfitting** می‌شود، یعنی مدل نمی‌تواند حتی داده آموزش را به خوبی یاد بگیرد.
در نتیجه، هم Training Error و هم Test Error افزایش می‌یابند.
بنابراین، **تنظیم دقیق λ** با استفاده از Cross-validation بسیار حیاتی است.

---

اینجا نسخه اصلاح‌شده و بدون شماره و با فرمول‌های درست نمایش داده‌شده است:

---

### چگونه می‌توان به طور عملی و با استفاده از ارزیابی‌های مختلف، بهترین مدل را در رگرسیون انتخاب کرد؟

**پاسخ:**
برای انتخاب بهترین مدل در رگرسیون، می‌توان از ارزیابی‌های مختلفی استفاده کرد:

* **Cross-Validation:** اعتبارسنجی متقابل به کاهش واریانس ارزیابی کمک می‌کند و مدل‌ها را روی داده‌های مختلف می‌سنجد.
* **مجموعه تست:** ارزیابی مدل بر روی داده‌های دیده‌نشده برای سنجش قدرت تعمیم مدل ضروری است.
* **معیارهای ارزیابی:** از جمله **MSE** (میانگین مربعات خطا)، **RMSE** (ریشه میانگین مربعات خطا)، **R²** (ضریب تعیین) که میزان انطباق مدل با داده‌ها را نشان می‌دهند.
* **آزمون‌های آماری:** مانند آزمون‌های F و t برای بررسی میزان اعتبار پارامترهای مدل.

با مقایسه این معیارها، مدل‌هایی که کمترین خطا و بهترین تعمیم‌پذیری را دارند، انتخاب می‌شوند.

---

### چرا در مدل‌های پیچیده، به ویژه در مدل‌های یادگیری عمیق، معمولاً از تکنیک‌هایی مانند **Early Stopping** استفاده می‌شود؟

**پاسخ:**
در مدل‌های پیچیده و به ویژه در یادگیری عمیق، **Early Stopping** به منظور جلوگیری از **بیش‌براش** (Overfitting) استفاده می‌شود. این تکنیک مانع از ادامه آموزش مدل پس از رسیدن به نقطه‌ای می‌شود که عملکرد آن بر روی داده‌های تست شروع به افت کردن می‌کند، حتی اگر خطای آموزش همچنان کاهش یابد. به عبارت دیگر، در این روش، آموزش مدل قبل از اینکه به صورت کامل ادامه یابد، متوقف می‌شود تا از یادگیری جزئیات و نویزهای داده‌های آموزشی جلوگیری شود و مدل بتواند به بهترین عملکرد تعمیم‌پذیر برسد.

---

### چرا رگرسیون خطی در مواقعی که روابط پیچیده‌تری بین متغیرها وجود دارد، ممکن است نتیجه دقیقی ندهد؟

**پاسخ:**
رگرسیون خطی فرض می‌کند که رابطه بین متغیرهای ورودی و خروجی خطی است. این فرض ممکن است در بسیاری از موارد عملی صدق نکند. هنگامی که روابط پیچیده‌تری میان ورودی‌ها و خروجی وجود دارد (مثلاً روابط غیرخطی)، رگرسیون خطی قادر به مدل‌سازی این روابط نیست و باعث **کم‌براش** می‌شود. در این مواقع، مدل‌های پیچیده‌تری مانند **رگرسیون چندجمله‌ای** یا **شبکه‌های عصبی** که قابلیت مدل‌سازی روابط غیرخطی را دارند، می‌توانند عملکرد بهتری داشته باشند.

---

### در رگرسیون چندجمله‌ای، چرا استفاده از درجه‌های بسیار بالا (مانند \$M \geq 10\$) ممکن است منجر به از دست دادن قدرت تعمیم مدل شود؟

**پاسخ:**
در رگرسیون چندجمله‌ای با درجات بالا، مدل به طور فزاینده‌ای پیچیده می‌شود و سعی می‌کند به تمام نوسانات داده‌های آموزشی، حتی نویزهای تصادفی، واکنش نشان دهد. این پدیده منجر به **بیش‌براش** می‌شود، یعنی مدل به جای یادگیری الگوهای عمومی، به جزئیات و نویزهای موجود در داده‌ها فیت می‌شود. نتیجه این است که مدل عملکرد ضعیفی در برابر داده‌های جدید خواهد داشت، چرا که توانایی تعمیم به داده‌های دیده‌نشده کاهش می‌یابد.

---

### در رگرسیون خطی، چگونه می‌توان متوجه شد که مدل بیش از حد پیچیده یا ساده است؟

**پاسخ:**
برای ارزیابی پیچیدگی مدل در رگرسیون خطی، می‌توان به **خطای آموزش** و **خطای تست** نگاه کرد:

* اگر **خطای آموزش** و **خطای تست** هر دو بالا باشند، مدل **کم‌براش** است. این بدان معناست که مدل نتوانسته است رابطه واقعی موجود در داده‌ها را یاد بگیرد و نیاز به پیچیده‌تر شدن دارد.
* اگر **خطای آموزش** پایین و **خطای تست** بالا باشد، مدل **بیش‌براش** است. این یعنی مدل بیش از حد پیچیده است و به نویز داده‌های آموزشی فیت شده، که باعث عدم توانایی آن در تعمیم به داده‌های جدید می‌شود.

همچنین می‌توان از **اعتبارسنجی متقابل** و بررسی تغییرات **R²** برای ارزیابی بهتر پیچیدگی استفاده کرد.


---

### چه تفاوتی بین "Bagging" و "Boosting" در الگوریتم‌های یادگیری نظارت‌شده وجود دارد؟

**پاسخ:**

* **Bagging (Bootstrap Aggregating):**
  این تکنیک شامل آموزش چندین مدل بر روی زیرمجموعه‌های مختلف داده‌ها است که به طور تصادفی از داده‌های اصلی با جایگزینی نمونه‌برداری می‌شوند. پس از آموزش، پیش‌بینی‌ها از مدل‌های مختلف تجمیع می‌شوند (معمولاً به صورت متوسط برای رگرسیون یا رأی‌گیری برای طبقه‌بندی). این تکنیک بیشتر برای کاهش واریانس و جلوگیری از **بیش‌براش** استفاده می‌شود. الگوریتم **Random Forest** یکی از معروف‌ترین مثال‌های Bagging است.

* **Boosting:**
  در این روش، مدل‌ها به صورت ترتیبی آموزش داده می‌شوند و هر مدل جدید سعی می‌کند خطاهای مدل قبلی را اصلاح کند. مدل‌ها وزن‌دهی می‌شوند به طوری که مدل‌های بعدی توجه بیشتری به نمونه‌های اشتباه مدل‌های قبلی داشته باشند. این تکنیک بیشتر برای کاهش **بایاس** استفاده می‌شود و در نتیجه ممکن است منجر به **بیش‌براش** شود. الگوریتم‌های معروف Boosting شامل **AdaBoost** و **Gradient Boosting** هستند.

---

### چگونه می‌توان از تکنیک‌های رگولاریزاسیون برای مقابله با بیش‌براش استفاده کرد؟

**پاسخ:**
برای مقابله با **بیش‌براش** (Overfitting)، می‌توان از تکنیک‌های رگولاریزاسیون مانند **L1** (Lasso) و **L2** (Ridge) استفاده کرد:

* **L1 (Lasso) Regularization:** این رگولاریزاسیون به طور مؤثر برخی از ویژگی‌ها را به صفر می‌رساند، به طوری که آن‌ها از مدل حذف می‌شوند. این کار به انتخاب ویژگی‌ها و کاهش پیچیدگی مدل کمک می‌کند.
* **L2 (Ridge) Regularization:** این تکنیک وزن‌ها را کاهش می‌دهد، اما آن‌ها را به طور کامل صفر نمی‌کند. این باعث می‌شود مدل پیچیده‌تر شود ولی از **بیش‌براش** جلوگیری کند.

استفاده از این روش‌ها به طور مستقیم پیچیدگی مدل را کنترل کرده و به جلوگیری از فیت شدن بیش از حد به داده‌های آموزشی کمک می‌کند.

---

### در رگرسیون چندجمله‌ای، چگونه می‌توان از بیش‌براش جلوگیری کرد؟

**پاسخ:**
برای جلوگیری از **بیش‌براش** در رگرسیون چندجمله‌ای، می‌توان از تکنیک‌های مختلفی استفاده کرد:

* **رگولاریزاسیون (Regularization):** با اضافه کردن یک ترم جریمه به تابع هزینه (مانند **L2 regularization**)، می‌توان وزن‌های بزرگ را کاهش داده و پیچیدگی مدل را کنترل کرد. این کار باعث می‌شود که مدل از پیچیدگی اضافی که ممکن است منجر به بیش‌براش شود، جلوگیری کند.

* **انتخاب درجه بهینه:** به جای استفاده از درجات بالای زیاد (که ممکن است منجر به بیش‌براش شود)، باید از انتخاب دقتی درجه مدل استفاده کرد. این کار می‌تواند شامل استفاده از اعتبارسنجی متقابل (cross-validation) برای تعیین درجه مناسب باشد.

* **استفاده از مدل‌های ساده‌تر:** گاهی اوقات استفاده از مدل‌های ساده‌تر مانند **رگرسیون خطی** یا **رگرسیون چندجمله‌ای با درجات پایین** می‌تواند بهتر از مدل‌های پیچیده‌تر باشد که ممکن است بیش از حد به داده‌های آموزشی فیت شوند.

---

### چه تفاوت‌هایی بین مدل‌های رگرسیون خطی و رگرسیون لجستیک وجود دارد؟

**پاسخ:**

* **رگرسیون خطی:**
  این مدل برای پیش‌بینی یک متغیر هدف پیوسته استفاده می‌شود. در رگرسیون خطی، تابع فرضیه به صورت یک ترکیب خطی از ویژگی‌های ورودی است و هدف این است که تفاوت بین مقادیر پیش‌بینی شده و واقعی را کمینه کنیم.

* **رگرسیون لجستیک:**
  این مدل برای مسائل **طبقه‌بندی** استفاده می‌شود و به جای پیش‌بینی یک مقدار پیوسته، احتمال تعلق به یک کلاس خاص را پیش‌بینی می‌کند. رگرسیون لجستیک از تابع سیگموئید (sigmoid) برای تبدیل خروجی ترکیب خطی به یک مقدار در بازه 0 و 1 (احتمال) استفاده می‌کند.

تفاوت اصلی: رگرسیون خطی برای پیش‌بینی مقادیر پیوسته است، در حالی که رگرسیون لجستیک برای پیش‌بینی احتمالات و طبقه‌بندی داده‌ها به کلاس‌های مختلف به کار می‌رود.

---

### چه زمانی باید از رگرسیون لاسو (Lasso Regression) و رگرسیون ریج (Ridge Regression) استفاده کرد؟

**پاسخ:**

* **رگرسیون لاسو (Lasso):**
  این نوع رگولاریزاسیون از **L1 Regularization** استفاده می‌کند و می‌تواند به انتخاب ویژگی‌ها (Feature Selection) کمک کند. در شرایطی که تعداد زیادی ویژگی در داده‌ها وجود دارد و برخی از ویژگی‌ها ممکن است غیرمفید باشند، رگرسیون لاسو مفید است زیرا به ویژگی‌های غیرمفید وزن صفر می‌دهد.

* **رگرسیون ریج (Ridge):**
  رگرسیون ریج از **L2 Regularization** استفاده می‌کند و می‌تواند به کاهش پیچیدگی مدل کمک کند بدون اینکه ویژگی‌ها را به طور کامل حذف کند. این روش برای مدل‌هایی مناسب است که داده‌های با ویژگی‌های همبسته دارند و مدل می‌تواند از این ویژگی‌ها به طور همزمان استفاده کند.

انتخاب بین لاسو و ریج بستگی به نوع داده‌ها و نیاز به انتخاب ویژگی‌ها دارد. اگر می‌خواهید برخی ویژگی‌ها را حذف کنید، لاسو مناسب است؛ در غیر این صورت، ریج می‌تواند انتخاب بهتری باشد.

---

### در الگوریتم گرادیان دیسنت، چه مشکلی ممکن است ناشی از انتخاب نادرست نرخ یادگیری (Learning Rate) پیش آید؟

**پاسخ:**
در الگوریتم **گرادیان دیسنت**، نرخ یادگیری (η) نقش مهمی در فرآیند همگرایی دارد:

* **η بسیار کوچک:**
  وقتی نرخ یادگیری خیلی کوچک باشد، الگوریتم به آرامی پیش می‌رود و ممکن است زمان زیادی برای همگرایی نیاز داشته باشد. این می‌تواند موجب کند شدن روند بهینه‌سازی شود و در نهایت زمان زیادی را برای رسیدن به پاسخ نهایی مصرف کند.

* **η بسیار بزرگ:**
  اگر نرخ یادگیری بیش از حد بزرگ باشد، گرادیان دیسنت می‌تواند از مینیمم سراسری عبور کند (overshoot)، و به جای همگرایی به یک نقطه بهینه، از آن فاصله می‌گیرد. این ممکن است منجر به واگرایی (divergence) شود و الگوریتم نتایج دقیقی ارائه ندهد.

انتخاب یک نرخ یادگیری مناسب به مدل کمک می‌کند که سریع‌تر به مینیمم همگرا شود بدون اینکه به مشکل عبور از مینیمم یا کند شدن روند بر بخورد.

---

حتماً! در اینجا فرمول‌ها به درستی فرمت شده‌اند و مشکل خوانایی آن‌ها رفع شده است:


**سوال:** Contrastive Language-Image Pretraining (CLIP) به عنوان یک مثال از کاربردهای یادگیری ماشین مطرح شده است. توضیح دهید که CLIP چگونه متن و تصاویر را به هم متصل می‌کند و چه کاربردی دارد؟

**پاسخ:**

CLIP (Contrastive Language-Image Pretraining) یک مدل یادگیری ماشین است که برای **اتصال (Connecting)** متن و تصاویر طراحی شده است. این مدل با یادگیری یک فضای مشترک (joint embedding space) برای تصاویر و متن، می‌تواند درک کند که کدام متن با کدام تصویر مطابقت دارد.

**کاربرد:** این قابلیت به CLIP اجازه می‌دهد تا وظایف مختلفی را انجام دهد، مانند:

* جستجوی تصویری بر اساس توضیحات متنی (مثلاً پیدا کردن "گربه‌ای با کلاه قهوه‌ای" از میان تصاویر).
* طبقه‌بندی تصاویر بر اساس نام کلاس‌های متنی.
* تولید توضیحات متنی برای تصاویر (image captioning).

CLIP می‌تواند بدون آموزش مجدد بر روی داده‌های جدید، به طور موثر به وظایف مختلف تعمیم پیدا کند.

---

**سوال:** در یادگیری با نظارت، هدف تخمین یک تابع $f : \mathbb{R}^D \to \mathbb{R}$ است، به گونه‌ای که $y = f(x) + \epsilon$. نقش $\epsilon$ در این فرمول چیست؟

**پاسخ:**

در فرمول $y = f(x) + \epsilon$:

* $\epsilon$ نشان‌دهنده نویز (Noise) یا خطای غیرقابل توضیح در داده‌ها است.

این نویز شامل عواملی است که ناشناخته هستند یا توسط مدل قابل توضیح نیستند، مانند خطاهای اندازه‌گیری، عوامل تصادفی، یا متغیرهایی که در مدل گنجانده نشده‌اند.

**نقش $\epsilon$:** این است که نشان دهد خروجی واقعی $y$ فقط تابعی از $x$ نیست، بلکه شامل یک جزء تصادفی نیز می‌شود که مدل نمی‌تواند به طور کامل آن را پیش‌بینی کند. مدل تنها سعی می‌کند بهترین تقریب ممکن از تابع اصلی $f(x)$ را بیابد.

---

**سوال:** "مجموعه فرضیه (Hypothesis Set)" در یادگیری با نظارت چیست؟ چرا ما از یک "مجموعه" از فرضیه‌ها انتخاب می‌کنیم، نه اینکه مستقیماً تابع هدف ناشناخته را پیدا کنیم؟

**پاسخ:**

* **مجموعه فرضیه (Hypothesis Set - H):** مجموعه‌ای از توابع کاندیدا (یا "مدل‌های ممکن") $h : X \to Y$ است که الگوریتم یادگیری می‌تواند از میان آن‌ها انتخاب کند.

**چرا یک مجموعه؟** ما هرگز به طور کامل تابع هدف واقعی و ناشناخته ($f$) را نمی‌شناسیم. بنابراین، هدف ما یافتن بهترین تقریب ممکن ($g \approx f$) از میان یک مجموعه از توابع ممکن است. این مجموعه فرضیه، فضایی از مدل‌ها را تعریف می‌کند که الگوریتم می‌تواند در آن به جستجو بپردازد.

---

**سوال:** در مورد توابع هزینه، "خطای مربعات (Squared Error - SE)" چگونه برای یک نمونه واحد تعریف می‌شود؟ چرا این خطا به توان دو می‌رسد؟

**پاسخ:**

* **خطای مربعات (SE) برای یک نمونه واحد:**

  $$
  SE: (y^{(i)} - h(x^{(i)}; w))^2
  $$

  این خطا، تفاوت بین مقدار واقعی $y^{(i)}$ و مقدار پیش‌بینی شده $h(x^{(i)}; w)$ برای نمونه $i$-ام را نشان می‌دهد.

**چرا به توان دو می‌رسد؟**

* **مثبت کردن خطا:** توان دو، خطاهای مثبت و منفی را به مقادیر مثبت تبدیل می‌کند، بنابراین همه‌ی خطاها به صورت "ناقص بودن" مدل در نظر گرفته می‌شوند.
* **جریمه خطاهای بزرگ‌تر:** توان دو، خطاهای بزرگ‌تر را به شدت بیشتری جریمه می‌کند تا خطاهای کوچک‌تر. این باعث می‌شود مدل تلاش کند خطاهای قابل توجه را به حداقل برساند.

---

**سوال:** در مثال رگرسیون خطی تبلیغات تلویزیونی و فروش، پس از محاسبه مشتقات جزئی تابع هزینه و برابر صفر قرار دادن آن‌ها، به یک سیستم دو معادله خطی می‌رسیم. اهمیت حل این سیستم معادلات چیست؟

**پاسخ:**

اهمیت حل این سیستم معادلات این است که با حل آن‌ها، می‌توانیم مقادیر بهینه پارامترها ($w_0$ و $w_1$) را پیدا کنیم. این مقادیر بهینه، خط رگرسیونی را تعریف می‌کنند که تابع هزینه (SSE) را به حداقل می‌رساند و به بهترین شکل ممکن رابطه بین بودجه تبلیغات تلویزیونی و فروش را در داده‌های آموزشی مدل‌سازی می‌کند. این همان "راه‌حل تحلیلی" برای رگرسیون خطی تک‌متغیره است.

---

**سوال:** راه‌حل تحلیلی رگرسیون خطی (با استفاده از شبه معکوس) دارای پیچیدگی زمانی $O(n^3)$ است. این پیچیدگی زمانی چه معنایی برای کاربردهای "Big Data" دارد؟

**پاسخ:**

پیچیدگی زمانی $O(n^3)$ به این معناست که زمان لازم برای محاسبه راه‌حل تحلیلی با مکعب تعداد ابعاد (ویژگی‌ها) یا اندازه ماتریس متناسب است.

برای کاربردهای "Big Data"، که شامل مجموعه‌های داده با ابعاد (تعداد ویژگی‌ها) بسیار بالا می‌شوند، این پیچیدگی به معنای زمان محاسباتی بسیار طولانی و غیرعملی است.

به عنوان مثال، اگر تعداد ویژگی‌ها 10 برابر شود، زمان محاسبه 1000 برابر خواهد شد. این موضوع راه‌حل‌های تحلیلی را برای داده‌های بسیار بزرگ نامناسب می‌سازد.

---

**سوال:** توضیح دهید که چرا راه‌حل‌های تحلیلی برای رگرسیون خطی، برای سناریوهای "یادگیری آنلاین (Online Learning)" مناسب نیستند؟

**پاسخ:**

* **ماهیت یادگیری آنلاین:** در یادگیری آنلاین، داده‌ها به صورت جریان پیوسته و مداوم وارد می‌شوند. پیش‌بینی‌ها باید به صورت لحظه‌ای یا قبل از مشاهده تمام داده‌ها انجام شوند.

* **نیاز راه‌حل تحلیلی به تمام داده‌ها:** راه‌حل‌های تحلیلی برای محاسبه وزن‌های بهینه نیاز دارند که تمام داده‌ها از ابتدا موجود باشند. هر بار که داده‌های جدیدی اضافه می‌شوند، باید کل محاسبات (به ویژه معکوس کردن ماتریس) دوباره انجام شود که بسیار ناکارآمد است.

به همین دلیل، راه‌حل‌های تحلیلی برای سناریوهای یادگیری آنلاین که نیاز به به‌روزرسانی مدل به صورت تدریجی و با ورود داده‌های جدید دارند، مناسب نیستند.

---

**سوال:** گرادیان افزایشی (Gradient Ascent) چیست و چه تفاوتی با گرادیان دیسنت دارد؟ برای چه هدفی استفاده می‌شود؟

**پاسخ:**

* **گرادیان افزایشی:** نوعی الگوریتم بهینه‌سازی تکراری است که گام‌ها را متناسب با (مثبت) بردار گرادیان تابع در نقطه فعلی برمی‌دارد.

* **تفاوت با گرادیان دیسنت:** گرادیان دیسنت گام‌ها را در جهت منفی گرادیان برمی‌دارد تا تابع را کمینه کند. اما گرادیان افزایشی گام‌ها را در جهت مثبت گرادیان برمی‌دارد.

**هدف:** گرادیان افزایشی برای یافتن حداکثر محلی (local maximum


) یک تابع استفاده می‌شود.

---

**سوال:** در گرادیان دیسنت، اگر نرخ یادگیری ($\eta$) بسیار بزرگ باشد، چه مشکلاتی ممکن است پیش بیاید؟

**پاسخ:**

اگر نرخ یادگیری ($\eta$) بسیار بزرگ باشد، گرادیان دیسنت ممکن است با مشکلات زیر روبرو شود:

* **عبور از مینیمم (Overshoot):** مدل ممکن است در هر گام بیش از حد حرکت کند و از مینیمم عبور کند.
* **عدم همگرایی:** به دلیل پرش‌های بزرگ، ممکن است الگوریتم هرگز به مینیمم همگرا نشود و در اطراف آن نوسان کند.
* **واگرایی (Divergence):** در بدترین حالت، مقدار تابع هزینه ممکن است به جای کاهش، شروع به افزایش کند و الگوریتم از مینیمم دور شود.

---

حتماً! اینجا نسخه بهبود یافته و واضح‌تر از پاسخ‌های شما با فرمول‌ها و توضیحات مرتب‌شده است:

---

**۱. سوال: در اجزای یک مدل یادگیری (Solution Components - Learning Model)، "مجموعه فرضیه (Hypothesis Set)" و "الگوریتم یادگیری (Learning Algorithm)" چه نقشی دارند و چگونه با هم کار می‌کنند؟**

**پاسخ:**

* **مجموعه فرضیه (Hypothesis Set - H):** این مجموعه، توابع ممکن را که مدل می‌تواند برای تقریب تابع هدف واقعی انتخاب کند، تعریف می‌کند. هر $h(x,\theta)$ یک تابع کاندیدا است که با پارامترهای $\theta$ (پارامترهای یادگیری مسئله) مشخص می‌شود.

* **الگوریتم یادگیری (Learning Algorithm):** این الگوریتم مسئول یافتن بهترین مجموعه از پارامترها $\theta^*$ از فضای پارامتر $\Theta$ است به طوری که تابع $h(x,\theta^*)$ به بهترین شکل ممکن، تابع هدف واقعی $f(x)$ را تقریب بزند.

**همکاری:** این دو جزء با هم کار می‌کنند تا ورودی‌ها ($x$) را به خروجی‌ها ($y$) نگاشت کنند و خطای پیش‌بینی را به حداقل برسانند. $\theta^*$ همان بهترین پارامترها برای پیش‌بینی خروجی‌ها با استفاده از فرضیه انتخاب شده است.

---

**۲. سوال: چگونه توابع پایه (Basis Functions) به رگرسیون خطی کمک می‌کنند تا روابط غیرخطی را مدل کند؟**

**پاسخ:**

توابع پایه به ما اجازه می‌دهند تا ویژگی‌های اصلی را به یک فضای ویژگی جدید تبدیل کنیم. این تبدیل، ویژگی‌ها را به صورت غیرخطی نگاشت می‌کند (مثلاً $x$ به $x^2, x^3$ و غیره). سپس، رگرسیون خطی بر روی این بردارهای ویژگی تبدیل‌شده اعمال می‌شود. این رویکرد، سادگی و قابلیت تفسیر رگرسیون خطی را حفظ می‌کند، در حالی که انعطاف‌پذیری آن را برای مدل‌سازی روابط پیچیده و غیرخطی گسترش می‌دهد.

---

**۳. سوال: چرا در رگرسیون خطی چندمتغیره، فرمول راه‌حل تحلیلی از شبه معکوس (pseudo-inverse) ماتریس $X$ استفاده می‌کند؟**

**پاسخ:**

فرمول راه‌حل تحلیلی برای وزن‌ها در رگرسیون خطی چندمتغیره به صورت $w = (X^T X)^{-1} X^T y$ است. عبارت $(X^T X)^{-1} X^T$ را شبه معکوس ماتریس $X$ می‌نامند. ماتریس $X$ اغلب مربع نیست (تعداد نمونه‌ها با تعداد ویژگی‌ها برابر نیست) و بنابراین معکوس‌پذیر (invertible) نیست. شبه معکوس را می‌توان برای هر ماتریسی، صرف نظر از شکل آن، محاسبه کرد که این امکان را می‌دهد تا حتی در مواردی که ماتریس $X$ مربع یا معکوس‌پذیر نیست، راه‌حل تحلیلی را به دست آوریم.

---

**۴. سوال: چه محدودیت‌های عملی (Practical limitations) برای استفاده از راه‌حل تحلیلی در رگرسیون خطی وجود دارد که منجر به نیاز به روش‌های تکراری (Iterative methods) می‌شود؟**

**پاسخ:**

* **یادگیری آنلاین (Online learning):** در سناریوهایی که داده‌ها به صورت جریان پیوسته وارد می‌شوند و پیش‌بینی‌ها باید قبل از مشاهده تمام داده‌ها انجام شوند، راه‌حل‌های تحلیلی عملی نیستند زیرا نیاز دارند تمام داده‌ها از ابتدا موجود باشند.

* **عدم سازگاری با داده‌های جدید:** روش‌های تحلیلی بدون محاسبه مجدد کل راه‌حل، با داده‌های جدید سازگار نیستند.

---

**۵. سوال: چه تفاوتی بین گرادیان دیسنت دسته‌ای (Batch Gradient Descent) و گرادیان دیسنت تصادفی (Stochastic Gradient Descent - SGD) از نظر نحوه پردازش داده‌ها وجود دارد؟**

**پاسخ:**

* **Batch Gradient Descent:** در هر تکرار، تمام مجموعه آموزشی را پردازش می‌کند تا گرادیان را محاسبه و وزن‌ها را به‌روزرسانی کند.

* **Stochastic Gradient Descent (SGD):** در هر تکرار، تنها یک مثال آموزشی را پردازش می‌کند. پارامترهای مدل را به طور مکرر به‌روزرسانی می‌کند.

---

**۶. سوال: مزیت اصلی SGD نسبت به Batch Gradient Descent چیست؟ و چرا SGD ممکن است هرگز دقیقا به مینیمم همگرا نشود؟**

**پاسخ:**

* **مزیت اصلی:** اغلب SGD بسیار سریع‌تر از Batch gradient descent به مینیمم نزدیک می‌شود. این به دلیل به‌روزرسانی‌های مکررتر پارامترها است.

* **عدم همگرایی دقیق:** با این حال، SGD ممکن است هرگز دقیقا به مینیمم همگرا نشود، و پارامترها در اطراف مینیمم تابع هزینه نوسان خواهند کرد. این نوسان به دلیل ماهیت تصادفی به‌روزرسانی‌ها (بر اساس یک نمونه واحد) است. با این حال، در عمل، اکثر مقادیر نزدیک به مینیمم که SGD به آن‌ها می‌رسد، تقریب‌های منطقی خوبی برای مینیمم واقعی خواهند بود.

---

**۷. سوال: نرخ یادگیری ($\eta$) در گرادیان دیسنت چه نقشی دارد و انتخاب نادرست آن (بسیار کوچک یا بسیار بزرگ) چه پیامدهایی دارد؟**

**پاسخ:**

* **نقش $\eta$:** $\eta$ (نرخ یادگیری) اندازه گام‌هایی را که در هر تکرار برداشته می‌شود، تعیین می‌کند. این پارامتر، متناسب با منفی بردار گرادیان، وزن‌ها را به‌روزرسانی می‌کند.

* **$\eta$ بسیار کوچک:** گرادیان دیسنت می‌تواند بسیار کند باشد.

* **$\eta$ بسیار بزرگ:** گرادیان دیسنت می‌تواند از مینیمم عبور کند

  ---
  حتماً! اینجا نسخه بدون شماره سوالات:

---

**تفاوت بین **Training Error** و **Test Error** چیست و چرا Test Error مهم‌تر است؟**

**پاسخ:**

**Training Error**، خطای مدل روی داده‌های آموزش است، در حالی که **Test Error** خطا روی داده‌هایی است که مدل قبلاً ندیده است. مدل ممکن است روی داده آموزش عملکرد فوق‌العاده‌ای داشته باشد (حتی خطای صفر)، اما اگر روی داده جدید خطا بالا برود، نشان از **عدم تعمیم‌پذیری مناسب** دارد. هدف در یادگیری ماشین، **حداقل‌سازی Test Error** است.

---

**چگونه می‌توان تشخیص داد که مدل دچار **Overfitting** شده است؟**

**پاسخ:**

در **Overfitting**، مدل روی داده آموزش بسیار خوب عمل می‌کند ولی روی داده تست عملکرد بدی دارد. یعنی:

* **Training Error پایین**
* **Test Error بالا**

این اتفاق معمولاً زمانی رخ می‌دهد که مدل **بیش‌ازحد پیچیده** است یا ویژگی‌های زیادی دارد که باعث یادگیری نویز داده‌ها می‌شود.

---

**Underfitting** چیست و چه زمانی رخ می‌دهد؟

**پاسخ:**

**Underfitting** زمانی اتفاق می‌افتد که مدل آن‌قدر ساده است که حتی **داده آموزش را هم به خوبی یاد نمی‌گیرد**. در این حالت:

* **Training Error بالا**
* **Test Error بالا**

علت اصلی معمولاً ساده بودن مدل یا نداشتن ظرفیت کافی برای مدل‌سازی رابطه‌ی بین ویژگی‌ها و خروجی است.

---

**منظور از **Bias-Variance Tradeoff** چیست؟**

**پاسخ:**

در یادگیری ماشین، خطای تعمیم‌پذیری به سه جزء تقسیم می‌شود:

* **Bias**: خطای ناشی از ساده بودن مدل
* **Variance**: نوسان مدل نسبت به تغییر داده آموزش
* **Noise**: خطای ذاتی داده

**Tradeoff** یعنی افزایش پیچیدگی باعث کاهش **Bias** ولی افزایش **Variance** می‌شود. هنر طراحی مدل، رسیدن به **تعادل بهینه** بین این دو است.

---

**Regularization** چیست و چگونه از Overfitting جلوگیری می‌کند؟

**پاسخ:**

**Regularization** تکنیکی برای جلوگیری از **Overfitting** است. این کار با **اضافه کردن جریمه‌ای به وزن‌های بزرگ** در تابع هزینه انجام می‌شود:

* **L2 Regularization (Ridge):** جریمه با مجموع مربعات وزن‌ها:

  $$
  \text{Ridge:} \quad \lambda \sum_{i=1}^{n} w_i^2
  $$

* **L1 Regularization (Lasso):** جریمه با مجموع قدرمطلق وزن‌ها:

  $$
  \text{Lasso:} \quad \lambda \sum_{i=1}^{n} |w_i|
  $$

این جریمه مدل را مجبور به ساده‌سازی می‌کند و از پیچیده شدن بیش از حد مدل جلوگیری می‌کند.

---



---
---


**روش‌های منظم‌سازی مانند ریج و لاسو چگونه کار می‌کنند؟**

**پاسخ**: ریج با افزودن جریمه $L_2$:

$$
\lambda \sum \beta_i^2
$$

و لاسو با جریمه $L_1$:

$$
\lambda \sum |\beta_i|
$$

به تابع هزینه، پیچیدگی مدل را کاهش می‌دهند و از بیش‌برازش جلوگیری می‌کنند.

---

**اعتبارسنجی متقاطع چیست و چرا استفاده می‌شود؟**

**پاسخ**: اعتبارسنجی متقاطع (مانند k-fold) داده‌ها را به $k$ زیرمجموعه تقسیم می‌کند و مدل را $k$ بار آموزش و ارزیابی می‌کند تا عملکرد پایدار و تعمیم‌پذیری را بررسی کند.

---

**رگرسیون احتمالی چیست و چه تفاوتی با رگرسیون خطی دارد؟**

**پاسخ**: رگرسیون احتمالی توزیع احتمالی خروجی‌ها را مدل می‌کند، نه فقط یک مقدار دقیق. بر خلاف رگرسیون خطی، عدم قطعیت را نیز در نظر می‌گیرد.

---

**چرا مدل‌های احتمالی در پیش‌بینی‌های مالی مفید هستند؟**

**پاسخ**: مدل‌های احتمالی با ارائه توزیع احتمالات و عدم قطعیت، به تحلیل ریسک و تصمیم‌گیری در شرایط نامطمئن کمک می‌کنند.

---

**توزیع نرمال در رگرسیون احتمالی چه نقشی دارد؟**

**پاسخ**: توزیع نرمال اغلب برای مدل‌سازی خروجی‌ها یا خطاها استفاده می‌شود، زیرا بسیاری از پدیده‌ها در طبیعت از این توزیع پیروی می‌کنند.

---

**رگرسیون بیزی چیست و چگونه از آن استفاده می‌شود؟**

**پاسخ**: رگرسیون بیزی از اصول بیزی برای تخمین توزیع ضرایب استفاده می‌کند و با ترکیب دانش پیشین (prior) و داده‌ها، عدم قطعیت را مدل می‌کند.

---
بله، این هم نسخه بازنویسی شده به سبک بالا:

---

### چرا مدل‌های پیچیده با درجات بالای چندجمله‌ای (Polynomial Regression) معمولاً دچار Overfitting می‌شوند؟

**پاسخ**:
در رگرسیون چندجمله‌ای با درجات بالا، مدل قادر است دقیقاً با داده‌های آموزشی تطابق پیدا کند، از جمله **نویزهای تصادفی** که در داده‌ها وجود دارد. این انعطاف‌پذیری زیاد باعث می‌شود که مدل **الگوی کلی داده‌ها را درک نکند** و به جای آن، به جزئیات و نوسانات تصادفی پاسخ دهد. در نتیجه، مدل **عملکرد ضعیفی روی داده‌های جدید** خواهد داشت. برای جلوگیری از این مشکل می‌توان از روش‌هایی مانند **Regularization** یا کاهش درجه چندجمله‌ای استفاده کرد.

---

### در تفسیر Bias و Variance، چرا نمی‌توان هردو را هم‌زمان به حداقل رساند؟

**پاسخ**:
Bias و Variance دو مؤلفه متضاد هستند:

* مدل‌های ساده (مثلاً رگرسیون خطی) معمولاً **Bias بالا** دارند، زیرا قادر به یادگیری الگوهای پیچیده نیستند.
* مدل‌های پیچیده (مثلاً شبکه‌های عصبی عمیق یا رگرسیون چندجمله‌ای با درجه بالا) **Variance بالا** دارند، زیرا نسبت به تغییرات داده‌های آموزشی حساس هستند.

کاهش یکی از این دو معمولاً منجر به افزایش دیگری می‌شود. بنابراین، باید بین این دو یک **تعادل هوشمندانه** برقرار کرد که به آن **Bias-Variance Tradeoff** گفته می‌شود.

---

### چگونه می‌توان Generalization Error را در عمل تخمین زد؟

**پاسخ**:
گرچه **Generalization Error** (خطای واقعی مدل بر روی داده‌های دیده‌نشده) به‌صورت تئوری به شکل $\mathbb{E}_{p(x,y)}[(y - h(x))^2]$ تعریف می‌شود، در عمل می‌توان از **داده‌های تست مستقل** برای تخمین این خطا استفاده کرد. این مقدار را **Test Error** می‌نامیم که تقریب خوبی از **Generalization Error** است.

---

### Regularization چه تأثیری روی مقادیر وزن‌های مدل دارد؟

**پاسخ**:
در Regularization، با افزودن یک جریمه به تابع هزینه، مدل را از داشتن وزن‌های بزرگ بازمی‌داریم.

* **L2 Regularization (Ridge)**:

  * تابع جریمه: $\lambda \sum w_j^2$
  * این روش باعث می‌شود که وزن‌ها به‌طور پیوسته کاهش یابند و هیچ‌کدام به‌طور کامل صفر نمی‌شوند.
* **L1 Regularization (Lasso)**:

  * تابع جریمه: $\lambda \sum |w_j|$
  * در این روش، برخی وزن‌ها به‌کلی صفر می‌شوند که به **ویژگی‌گزینی (Feature Selection)** منجر می‌شود.

در هر دو روش، هدف اصلی **کاهش پیچیدگی مدل و افزایش تعمیم‌پذیری** است.

---

### چرا در MLE فرض می‌شود نویز از توزیع نرمال با میانگین صفر می‌آید؟

**پاسخ**:
این فرض دارای چند دلیل است:

1. **قضیه حد مرکزی**: بسیاری از نویزهای طبیعی ناشی از عوامل متعدد، توزیع نرمال دارند.
2. **سادگی ریاضیاتی**: توزیع نرمال مشتق‌پذیر و متقارن است و محاسبه log-likelihood آن ساده است.
3. **تحلیل آماری دقیق‌تر**: با فرض نرمال بودن نویز، کمینه کردن SSE معادل با بیشینه کردن Likelihood می‌شود.

اگر نویز واقعاً نرمال نباشد، مدل MLE ممکن است دچار خطا شود و باید از توزیع نویز دیگری استفاده کرد.

---

### تفاوت L1 و L2 Regularization در نتایج نهایی چیست؟

**پاسخ**:

* **L1 Regularization (Lasso)** تمایل دارد که **برخی وزن‌ها را به صفر برساند**، که این ویژگی به **ویژگی‌گزینی** (Feature Selection) منجر می‌شود.
* **L2 Regularization (Ridge)** وزن‌ها را کاهش می‌دهد اما به‌ندرت آن‌ها را به صفر می‌رساند. این کار مدل را نرم‌تر می‌کند و پیچیدگی آن را کاهش می‌دهد بدون حذف کامل ویژگی‌ها.

در مسائل با تعداد زیاد ویژگی‌ها (high-dimensional) اگر فرض کنیم که برخی ویژگی‌ها بی‌ارزش هستند، استفاده از **L1** مناسب‌تر است.

---


بله، این هم نسخه بازنویسی شده به سبک مشابه:

---

### مفهوم عدم قطعیت در رگرسیون احتمالی چیست؟

**پاسخ**:
عدم قطعیت در رگرسیون احتمالی نشان‌دهنده میزان اطمینان مدل به پیش‌بینی‌هایش است. به عبارت دیگر، مدل علاوه بر پیش‌بینی یک مقدار خاص، می‌تواند بازه اطمینان یا واریانس توزیع پیش‌بینی خود را نیز ارائه دهد. این مفهوم برای درک میزان دقت پیش‌بینی‌ها و محدودیت‌های مدل اهمیت دارد.

---


**تفاوت بین رگرسیون خطی و رگرسیون لجستیک چیست؟**

**پاسخ**: رگرسیون خطی برای پیش‌بینی مقادیر عددی (پیوسته) و رگرسیون لجستیک برای پیش‌بینی مقادیر دسته‌ای (مانند 0 و 1) استفاده می‌شود. رگرسیون لجستیک از تابع سیگموید برای مدل‌سازی احتمالات استفاده می‌کند.

---

**۱۵. سوال: تفاوت بین مدل‌های **Bagging** و **Boosting** در یادگیری جمعی (Ensemble Learning) چیست؟**

**پاسخ:**

* **Bagging (Bootstrap Aggregating):** در این روش، چندین مدل به طور مستقل و به صورت موازی بر روی زیرمجموعه‌های مختلف داده‌های آموزش (که به طور تصادفی و با جایگزینی انتخاب می‌شوند) آموزش داده می‌شوند. سپس، پیش‌بینی‌ها از مدل‌های مختلف تجمیع می‌شوند (معمولاً به صورت متوسط برای رگرسیون یا رأی‌گیری برای طبقه‌بندی). این روش معمولاً برای کاهش واریانس و جلوگیری از **بیش‌براش** استفاده می‌شود. نمونه معروف: **Random Forest**.

* **Boosting:** در این روش، مدل‌ها به صورت ترتیبی آموزش داده می‌شوند و هر مدل جدید سعی می‌کند خطاهای مدل قبلی را اصلاح کند. مدل‌های جدید به نقاطی که مدل قبلی اشتباه پیش‌بینی کرده است، وزن بیشتری می‌دهند. این تکنیک معمولاً برای کاهش **بایاس** استفاده می‌شود. Boosting می‌تواند عملکرد مدل را به طور قابل توجهی بهبود دهد، ولی در برخی موارد ممکن است به **بیش‌براش** منجر شود. نمونه معروف: **Gradient Boosting**.

**تفاوت اصلی:** **Bagging** مدل‌ها را به طور مستقل آموزش می‌دهد و هدف آن کاهش واریانس است، در حالی که **Boosting** مدل‌ها را به صورت ترتیبی آموزش می‌دهد و هدف آن کاهش بایاس است.

---

**۱۶. سوال: چگونه می‌توان از اعتبارسنجی متقابل (Cross-Validation) برای ارزیابی عملکرد مدل استفاده کرد؟**

**پاسخ:**

**اعتبارسنجی متقابل** یکی از تکنیک‌های اصلی برای ارزیابی عملکرد مدل‌های یادگیری است که برای جلوگیری از **بیش‌براش** و **کم‌براش** استفاده می‌شود. در این روش:

1. **داده‌ها به K بخش تقسیم می‌شوند:** مجموعه داده به $K$ بخش مساوی تقسیم می‌شود (معمولاً 5 یا 10).
2. **آموزش و ارزیابی مدل:** مدل $K$ بار آموزش داده می‌شود و هر بار یک بخش به عنوان داده‌های اعتبارسنجی استفاده می‌شود، در حالی که بقیه بخش‌ها برای آموزش مدل به کار می‌روند.
3. **میانگین نتایج:** پس از هر دور از ارزیابی، نتایج (مانند دقت، خطا، $R^2$) محاسبه شده و میانگین نتایج به عنوان ارزیابی نهایی مدل انتخاب می‌شود.

این روش به طور موثری عملکرد مدل را بر اساس داده‌های مختلف ارزیابی کرده و از انتخاب مدل‌هایی که ممکن است بر اساس تقسیم‌بندی‌های خاص داده بیش از حد بهینه شوند، جلوگیری می‌کند.

---

---

### مفهوم هم‌خطی (multicollinearity) چیست و چگونه می‌توان آن را تشخیص داد؟

**پاسخ**:
**هم‌خطی** زمانی رخ می‌دهد که ویژگی‌ها با یکدیگر همبستگی بالا دارند، که این می‌تواند باعث مشکلات در تخمین ضرایب مدل شود. برای تشخیص هم‌خطی می‌توان از **ماتریس همبستگی** یا محاسبه **VIF (عامل تورم واریانس)** استفاده کرد.

---

### رگرسیون ریج چگونه هم‌خطی را مدیریت می‌کند؟

**پاسخ**:
**رگرسیون ریج** با افزودن جریمه $L_2$ به تابع هزینه، تأثیر ویژگی‌های هم‌خطی را کاهش می‌دهد و از **رگرسیون پایدارتر** و با تعمیم‌پذیری بهتر برخوردار می‌شود:
$\lambda \sum \beta_i^2$

---
---

### روش‌های انتخاب ویژگی چیست و چرا مهم هستند؟

**پاسخ**:
روش‌های **انتخاب ویژگی** شامل **فیلترها**، **بسته‌بندی (wrapper)**، و **تعبیه‌شده (embedded)** هستند. این روش‌ها به انتخاب ویژگی‌های مرتبط برای مدل کمک می‌کنند و در نتیجه باعث کاهش پیچیدگی و بهبود تعمیم‌پذیری می‌شوند.

---
---






