# 📚 سوالات مصاحبه با توجه به این محتوا

در این بخش، ۵۰ سوال مصاحبه‌ای مرتبط با محتوای جلسه اول به همراه پاسخ‌های صحیح ارائه شده است. این سوالات برای آمادگی در مصاحبه‌های فنی طراحی شده‌اند.

1.  **یادگیری ماشین چیست؟**

   **پاسخ**: یادگیری ماشین شاخه‌ای از هوش مصنوعی است که به ماشین‌ها امکان می‌دهد از داده‌ها یاد بگیرند و عملکردشان را بدون برنامه‌نویسی صریح بهبود دهند.

2.  **تعریف تام میچل از یادگیری ماشین چیست؟**

 **پاسخ**: یک برنامه از تجربه $E$ نسبت به وظیفه $T$ و معیار عملکرد $P$ یاد می‌گیرد، اگر عملکردش در $T$， که با $P$ اندازه‌گیری می‌شود، با $E$ بهبود یابد.

3.  **چند کاربرد عملی یادگیری ماشین را نام ببرید.**

 **پاسخ**: پیش‌بینی رفتار مشتریان، کنترل کیفیت کارخانه، تحلیل تصاویر پزشکی.

4.  **یادگیری تحت نظارت چیست؟**

   **پاسخ**: یادگیری با داده‌های برچسب‌دار که شامل ورودی ($x$) و خروجی ($y$) است برای پیش‌بینی خروجی‌های جدید.

5.  **تفاوت رگرسیون و طبقه‌بندی چیست؟**

   **پاسخ**: رگرسیون برای پیش‌بینی مقادیر پیوسته (مثل قیمت) و طبقه‌بندی برای پیش‌بینی دسته‌های گسسته (مثل اسپم/غیراسپم) است.

6.  **رگرسیون خطی چه نوع مدلی است؟**

   **پاسخ**: مدلی که رابطه خطی بین ورودی‌ها و خروجی را با استفاده از بردار وزن‌ها ($w$) مدل می‌کند.

7.  **فرمول فرضیه رگرسیون خطی چیست؟**

   **پاسخ**: $h_w(x) = w_0 + w_1x_1 + \dots + w_Dx_D = w^T x$.

8.  **نقش $w_0$ در رگرسیون خطی چیست؟**

 **پاسخ**: $w_0$ بایاس است که امکان پیش‌بینی مقادیر غیرصفر را حتی در صورت صفر بودن ویژگی‌ها فراهم می‌کند.

9.  **هدف اصلی رگرسیون خطی چیست؟**

 **پاسخ**: کمینه کردن فاصله بین پیش‌بینی ($h_w(x)$) و مقدار واقعی ($y$).

10. **تابع هزینه چیست؟**

 **پاسخ**: معیاری برای سنجش دقت مدل، مثل مجموع مربعات خطاها (SSE).

11. **فرمول MSE چیست؟**

**پاسخ**: $J(w) = \frac{1}{n} \sum_{i=1}^{n} (y^{(i)} - h_w(x^{(i)}))^2$.

12. **چرا از MSE به‌عنوان تابع هزینه استفاده می‌شود؟**

 **پاسخ**: چون خطاهای بزرگ را بیشتر جریمه می‌کند و محاسباتش ساده است.

13. **روش تحلیلی در رگرسیون خطی چیست؟**

 **پاسخ**: استفاده از معادلات نرمال برای محاسبه مستقیم $w = (X^T X)^{-1} X^T y$.

14. **مزیت روش تحلیلی چیست؟**

 **پاسخ**: دقیق است و نیازی به تکرار ندارد.

15. **محدودیت‌های روش معادلات نرمال چیست؟**

 **پاسخ**: محاسبات سنگین برای داده‌های بزرگ و نیاز به معکوس‌پذیری $X^T X$.

16. **گرادیان نزولی چیست؟**

 **پاسخ**: روشی عددی برای کمینه کردن تابع هزینه با به‌روزرسانی وزن‌ها در جهت مخالف گرادیان.

17. **فرمول به‌روزرسانی گرادیان نزولی چیست؟**

   **پاسخ**: $w_{t+1} = w_t - \eta \nabla J(w_t)$.

18. **نرخ یادگیری ($\eta$) چیست؟**

**پاسخ**: پارامتری که اندازه قدم‌های به‌روزرسانی وزن‌ها را تعیین می‌کند.

19. **اگر نرخ یادگیری خیلی بزرگ باشد چه اتفاقی می‌افتد؟**

 **پاسخ**: الگوریتم ممکن است واگرا شود و به نقطه بهینه نرسد.

20. **اگر نرخ یادگیری خیلی کوچک باشد چه می‌شود؟**

 **پاسخ**: همگرایی کند می‌شود و زمان زیادی طول می‌کشد.

21. **تفاوت Batch GD و Stochastic GD چیست؟**

 **پاسخ**: Batch GD از کل داده‌ها و Stochastic GD از یک نمونه در هر مرحله استفاده می‌کند.

22. **Mini-batch GD چیست؟**

**پاسخ**: استفاده از زیرمجموعه‌ای از داده‌ها برای به‌روزرسانی وزن‌ها، تعادل بین دقت و سرعت.

23. **چرا نرمال‌سازی داده‌ها در گرادیان نزولی مهم است؟**

**پاسخ**: باعث می‌شود گرادیان‌ها در مقیاس مشابه باشند و همگرایی سریع‌تر شود.

24. **رگرسیون چندجمله‌ای چیست؟**

   **پاسخ**: مدلی که روابط غیرخطی را با استفاده از ویژگی‌های چندجمله‌ای مدل می‌کند.

25. **فرمول فرضیه رگرسیون چندجمله‌ای چیست؟**

 **پاسخ**: $h(x) = w_0 + w_1x + w_2x^2 + \dots + w_mx^m$.

26. **مزیت رگرسیون چندجمله‌ای نسبت به رگرسیون خطی چیست؟**

 **پاسخ**: توانایی مدل‌سازی روابط غیرخطی.

27. **چرا رگرسیون چندجمله‌ای ممکن است بیش‌برازش کند؟**

**پاسخ**: چون با افزایش درجه، مدل ممکن است نویز داده‌ها را هم یاد بگیرد.

28. **Underfitting چیست؟**
 **پاسخ**: وقتی مدل بیش‌ازحد ساده است و نمی‌تواند الگوهای داده را خوب یاد بگیرد.

29. **Overfitting چیست؟**

**پاسخ**: وقتی مدل بیش‌ازحد پیچیده است و نویز داده‌ها را هم یاد می‌گیرد.

30. **چگونه می‌توان از بیش‌برازش جلوگیری کرد؟**

**پاسخ**: استفاده از تنظیم‌سازی (Regularization)، داده‌های اعتبارسنجی، و Cross-Validation.

31. **داده‌های اعتبارسنجی چه نقشی دارند؟**

**پاسخ**: برای انتخاب مدلی که نه خیلی ساده و نه خیلی پیچیده باشد.

32. **منظور از Regularization چیست؟**

 **پاسخ**: افزودن جریمه به تابع هزینه برای جلوگیری از پیچیدگی بیش‌ازحد مدل.

33. **تفاوت L1 و L2 Regularization چیست؟**

**پاسخ**: L1 وزن‌ها را به صفر می‌رساند (انتخاب ویژگی)، L2 وزن‌ها را کوچک می‌کند.

34. **چرا MSE خطاهای بزرگ را بیشتر جریمه می‌کند؟**

 **پاسخ**: چون خطاها را به توان 2 می‌رساند، تأثیر خطاهای بزرگ بیشتر می‌شود.

35. **چه زمانی از Batch GD استفاده می‌کنیم؟**

 **پاسخ**: وقتی داده‌ها کم باشند و دقت بالا مهم باشد.

36. **چه زمانی Stochastic GD مناسب است؟**

**پاسخ**: برای داده‌های بزرگ یا مسائل آنلاین که سرعت مهم است.

37. **مزیت Mini-batch GD چیست؟**

 **پاسخ**: تعادل بین سرعت Stochastic GD و دقت Batch GD.

38. **چگونه نرخ یادگیری مناسب انتخاب می‌شود؟**

 **پاسخ**: با آزمایش مقادیر مختلف یا استفاده از روش‌های تطبیقی مثل Adam.

39. **چرا $X^T X$ ممکن است معکوس‌پذیر نباشد؟**

 **پاسخ**: به دلیل هم‌خطی ویژگی‌ها یا تعداد کم نمونه‌ها.

40. **گرادیان چیست؟**

  **پاسخ**: مشتق تابع هزینه نسبت به پارامترها که جهت بهینه‌سازی را نشان می‌دهد.

41. **تفاوت گرادیان نزولی و نیوتن چیست؟**

 **پاسخ**: نیوتن از اطلاعات مرتبه دوم (هسین) استفاده می‌کند و پیچیده‌تر است.

42. **نقش بایاس در رگرسیون چیست؟**

 **پاسخ**: امکان جابجایی مدل برای تطابق بهتر با داده‌ها.

43. **چگونه می‌توان هم‌خطی ویژگی‌ها را تشخیص داد؟**

 **پاسخ**: با محاسبه ماتریس همبستگی یا تحلیل VIF (Variance Inflation Factor).

44. **چرا داده‌ها را نرمال‌سازی می‌کنیم؟**

 **پاسخ**: برای یکسان‌سازی مقیاس ویژگی‌ها و بهبود همگرایی.

45. **Cross-Validation چیست؟**

 **پاسخ**: تکنیکی برای ارزیابی مدل با تقسیم داده‌ها به چندین زیرمجموعه.

46. **تفاوت داده‌های آموزشی و اعتبارسنجی چیست؟**

 **پاسخ**: داده‌های آموزشی برای یادگیری مدل و اعتبارسنجی برای ارزیابی آن استفاده می‌شوند.

47. **چگونه درجه مناسب در رگرسیون چندجمله‌ای انتخاب می‌شود؟**

 **پاسخ**: با استفاده از داده‌های اعتبارسنجی و بررسی خطای تست.

48. **چرا رگرسیون خطی برای داده‌های غیرخطی مناسب نیست؟**

**پاسخ**: چون فرض می‌کند رابطه بین ورودی و خروجی خطی است.

49. **تفاوت MSE و RMSE چیست؟**

**پاسخ**: RMSE ریشه دوم MSE است و مقیاسش با داده‌ها یکسان است.

50. **چگونه می‌توان مدل رگرسیون را ارزیابی کرد؟**

 **پاسخ**: با معیارهایی مثل MSE، RMSE، یا $R^2$ روی داده‌های تست.

---
# پاسخ به سؤالات مصاحبه‌ای یادگیری ماشین

این سند شامل پاسخ‌های دقیق و مختصر به 50 سؤالم مصاحبه‌ای در حوزه یادگیری ماشین، رگرسیون خطی، تعمیم‌پذیری، و رگرسیون احتمالی است. پاسخ‌ها برای آمادگی در مصاحبه‌های فنی طراحی شده‌اند و به زبان ساده و حرفه‌ای ارائه شده‌اند. فرمول‌ها با استفاده از سینتکس استاندارد LaTeX نوشته شده‌اند تا در محیط‌های Markdown به‌درستی نمایش داده شوند.

## سؤالات و پاسخ‌ها

1. **یادگیری ماشین چیست و چه تفاوتی با برنامه‌نویسی سنتی دارد؟**  
   یادگیری ماشین شاخه‌ای از هوش مصنوعی است که به سیستم‌ها امکان می‌دهد از داده‌ها یاد بگیرند و بدون برنامه‌ریزی صریح، عملکرد خود را بهبود دهند. در برنامه‌نویسی سنتی، قوانین به‌صورت دستی کد می‌شوند، اما در یادگیری ماشین، مدل از داده‌ها الگوها را استخراج می‌کند.

2. **سه نوع اصلی یادگیری ماشین را نام ببرید و برای هر کدام مثالی ارائه دهید.**  
   - **یادگیری نظارت‌شده**: پیش‌بینی قیمت خانه با داده‌های برچسب‌دار (متراژ، قیمت).  
   - **یادگیری بدون نظارت**: خوشه‌بندی مشتریان برای بازاریابی هدفمند.  
   - **یادگیری تقویتی**: آموزش ربات برای حرکت در迷宫 با پاداش و جریمه.

3. **تفاوت بین یادگیری نظارت‌شده و بدون نظارت چیست؟**  
   در یادگیری نظارت‌شده، داده‌ها برچسب دارند (ورودی و خروجی مشخص)، اما در یادگیری بدون نظارت، داده‌ها بدون برچسب هستند و مدل الگوهای پنهان را کشف می‌کند.

4. **رگرسیون خطی چیست و چگونه کار می‌کند؟**  
   رگرسیون خطی مدلی است که رابطه خطی بین متغیرهای مستقل و وابسته را مدل‌سازی می‌کند. معادله آن به‌صورت زیر است:  
   $$ y = \beta_0 + \beta_1 x_1 + \dots + \beta_n x_n + \epsilon $$  
   هدف کمینه کردن خطا با یافتن ضرایب بهینه است.

5. **معادله رگرسیون خطی را بنویسید و اجزای آن را توضیح دهید.**  
   معادله:  
   $$ y = \beta_0 + \beta_1 x_1 + \dots + \beta_n x_n + \epsilon $$  
   - $y$: متغیر وابسته (هدف).  
   - $\beta_0$: عرض از مبدا.  
   - $\beta_i$: ضرایب ویژگی‌ها.  
   - $x_i$: متغیرهای مستقل (ویژگی‌ها).  
   - $\epsilon$: خطای مدل.

6. **چرا نرمال‌سازی داده‌ها در رگرسیون خطی مهم است؟**  
   نرمال‌سازی مقیاس ویژگی‌ها را یکسان می‌کند تا تأثیر متغیرهای با مقیاس بزرگ‌تر بر مدل کاهش یابد و گرادیان کاهشی سریع‌تر همگرا شود.

7. **بیش‌برازش چیست و چگونه می‌توان از آن جلوگیری کرد؟**  
   بیش‌برازش زمانی رخ می‌دهد که مدل بیش از حد به داده‌های آموزشی وابسته شود و روی داده‌های جدید ضعیف عمل کند. برای جلوگیری: منظم‌سازی (ریج، لاسو)، افزایش داده، و اعتبارسنجی متقاطع.

8. **تفاوت بین رگرسیون خطی و رگرسیون لجستیک چیست؟**  
   رگرسیون خطی برای پیش‌بینی مقادیر عددی (پیوسته) و رگرسیون لجستیک برای پیش‌بینی مقادیر دسته‌ای (مانند 0 و 1) استفاده می‌شود. رگرسیون لجستیک از تابع سیگموید برای مدل‌سازی احتمالات استفاده می‌کند.

9. **تابع هزینه در رگرسیون خطی چیست و چگونه محاسبه می‌شود؟**  
   تابع هزینه معمولاً میانگین مربعات خطا (MSE) است:  
   $$ J(\beta) = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2 $$  
   که $y_i$ مقدار واقعی و $\hat{y}_i$ مقدار پیش‌بینی‌شده است.

10. **گرادیان کاهشی چیست و چگونه در رگرسیون خطی استفاده می‌شود؟**  
    گرادیان کاهشی الگوریتمی برای کمینه کردن تابع هزینه است. در رگرسیون خطی، ضرایب مدل با به‌روزرسانی‌های تکراری در جهت کاهش گرادیان تابع هزینه تنظیم می‌شوند.

11. **تعمیم‌پذیری در یادگیری ماشین به چه معناست؟**  
    تعمیم‌پذیری توانایی مدل در عملکرد خوب روی داده‌های جدید و نادیده است، نه فقط داده‌های آموزشی.

12. **چگونه می‌توان تعمیم‌پذیری یک مدل را ارزیابی کرد؟**  
    با استفاده از مجموعه آزمون جداگانه، معیارهایی مانند MSE یا دقت، و روش‌هایی مانند اعتبارسنجی متقاطع.

13. **تفاوت بین بیش‌برازش و کم‌برازش چیست؟**  
    بیش‌برازش: مدل بیش از حد به داده‌های آموزشی وابسته است و روی داده‌های جدید ضعیف عمل می‌کند.  
    کم‌برازش: مدل الگوهای داده‌های آموزشی را به‌خوبی یاد نمی‌گیرد و عملکرد ضعیفی دارد.

14. **روش‌های منظم‌سازی مانند ریج و لاسو چگونه کار می‌کنند؟**  
    ریج با افزودن جریمه $L_2$:  
    $$ \lambda \sum \beta_i^2 $$  
    و لاسو با جریمه $L_1$:  
    $$ \lambda \sum |\beta_i| $$  
    به تابع هزینه، پیچیدگی مدل را کاهش می‌دهند و از بیش‌برازش جلوگیری می‌کنند.

15. **اعتبارسنجی متقاطع چیست و چرا استفاده می‌شود؟**  
    اعتبارسنجی متقاطع (مانند k-fold) داده‌ها را به k زیرمجموعه تقسیم می‌کند و مدل را k بار آموزش و ارزیابی می‌کند تا عملکرد پایدار و تعمیم‌پذیری را بررسی کند.

16. **رگرسیون احتمالی چیست و چه تفاوتی با رگرسیون خطی دارد؟**  
    رگرسیون احتمالی توزیع احتمالی خروجی‌ها را مدل می‌کند، نه فقط یک مقدار دقیق. بر خلاف رگرسیون خطی، عدم قطعیت را نیز در نظر می‌گیرد.

17. **چرا مدل‌های احتمالی در پیش‌بینی‌های مالی مفید هستند؟**  
    مدل‌های احتمالی با ارائه توزیع احتمالات و عدم قطعیت، به تحلیل ریسک و تصمیم‌گیری در شرایط نامطمئن کمک می‌کنند.

18. **توزیع نرمال در رگرسیون احتمالی چه نقشی دارد؟**  
    توزیع نرمال اغلب برای مدل‌سازی خروجی‌ها یا خطاها استفاده می‌شود، زیرا بسیاری از پدیده‌ها در طبیعت از این توزیع پیروی می‌کنند.

19. **رگرسیون بیزی چیست و چگونه از آن استفاده می‌شود؟**  
    رگرسیون بیزی از اصول بیزی برای تخمین توزیع ضرایب استفاده می‌کند و با ترکیب دانش پیشین (prior) و داده‌ها، عدم قطعیت را مدل می‌کند.

20. **مفهوم عدم قطعیت در رگرسیون احتمالی چیست؟**  
    عدم قطعیت نشان‌دهنده میزان اطمینان مدل به پیش‌بینی‌هایش است، مانند بازه اطمینان یا واریانس توزیع پیش‌بینی.

21. **داده‌های پرت چگونه بر عملکرد رگرسیون خطی تأثیر می‌گذارند؟**  
    داده‌های پرت می‌توانند ضرایب مدل را به‌شدت تغییر دهند و خطای پیش‌بینی را افزایش دهند.

22. **چگونه می‌توان اثر داده‌های پرت را در رگرسیون خطی کاهش داد؟**  
    با استفاده از روش‌های قوی (robust regression)، حذف داده‌های پرت، یا اعمال وزن‌دهی به داده‌ها.

23. **تفاوت بین واریانس و بایاس در یادگیری ماشین چیست؟**  
    بایاس: خطای ناشی از ساده‌سازی بیش از حد مدل.  
    واریانس: حساسیت مدل به تغییرات کوچک در داده‌های آموزشی.

24. **چگونه می‌توان تعادل بین واریانس و بایاس را برقرار کرد؟**  
    با انتخاب مدل با پیچیدگی مناسب، استفاده از منظم‌سازی، و ارزیابی با اعتبارسنجی متقاطع.

25. **مفهوم "نفرین ابعاد" چیست و چگونه بر مدل‌های یادگیری ماشین تأثیر می‌گذارد؟**  
    نفرین ابعاد به مشکلات ناشی از تعداد زیاد ویژگی‌ها اشاره دارد که باعث افزایش پیچیدگی و کاهش تعمیم‌پذیری می‌شود.

26. **روش‌های انتخاب ویژگی چیست و چرا مهم هستند؟**  
    روش‌هایی مانند فیلتر، بسته‌بندی (wrapper)، و تعبیه‌شده (embedded) برای انتخاب ویژگی‌های مرتبط استفاده می‌شوند تا پیچیدگی کاهش یابد و تعمیم‌پذیری بهبود یابد.

27. **تفاوت بین رگرسیون خطی ساده و چندگانه چیست؟**  
    رگرسیون خطی ساده یک متغیر مستقل دارد، اما رگرسیون چندگانه چندین متغیر مستقل را مدل می‌کند.

28. **چرا فرض خطی بودن در رگرسیون خطی مهم است؟**  
    رگرسیون خطی فرض می‌کند رابطه بین متغیرها خطی است. اگر این فرض نقض شود، مدل دقت کافی نخواهد داشت.

29. **اگر رابطه بین متغیرها غیرخطی باشد، چه باید کرد؟**  
    از تبدیل ویژگی‌ها (مانند افزودن توان‌ها)، مدل‌های غیرخطی (مانند رگرسیون پلی‌نومیال)، یا الگوریتم‌های دیگر (مانند درخت تصمیم) استفاده کنید.

30. **مفهوم هم‌خطی (multicollinearity) چیست و چگونه می‌توان آن را تشخیص داد؟**  
    هم‌خطی زمانی رخ می‌دهد که ویژگی‌ها با هم همبستگی قوی داشته باشند. با محاسبه VIF (عامل تورم واریانس) یا ماتریس همبستگی تشخیص داده می‌شود.

31. **رگرسیون ریج چگونه هم‌خطی را مدیریت می‌کند؟**  
    رگرسیون ریج با افزودن جریمه $L_2$:  
    $$ \lambda \sum \beta_i^2 $$  
    به تابع هزینه، تأثیر ویژگی‌های هم‌خطی را کاهش می‌دهد.

32. **مفهوم "تابع احتمال" در رگرسیون احتمالی چیست؟**  
    تابع احتمال توزیع خروجی‌ها را توصیف می‌کند، مانند توزیع نرمال برای پیش‌بینی‌های پیوسته.

33. **چگونه می‌توان مدل رگرسیون خطی را ارزیابی کرد؟**  
    با معیارهایی مانند MSE، RMSE، $R^2$ و بررسی نمودارهای باقی‌مانده (residual plots).

34. **معیارهای ارزیابی مانند MSE و $R^2$ چیست؟**  
    - **MSE**: میانگین مربعات خطاها، معیاری برای دقت پیش‌بینی:  
      $$ \text{MSE} = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2 $$  
    - **$R^2$**: درصدی از واریانس داده‌ها که توسط مدل توضیح داده می‌شود:  
      $$ R^2 = 1 - \frac{\sum (y_i - \hat{y}_i)^2}{\sum (y_i - \bar{y})^2} $$

35. **تفاوت بین MSE و RMSE چیست؟**  
    RMSE ریشه دوم MSE است:  
    $$ \text{RMSE} = \sqrt{\frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2} $$  
    و مقیاس آن با داده‌های اصلی هم‌خوانی دارد، بنابراین تفسیر آن آسان‌تر است.

36. **مفهوم "انحراف معیار" در رگرسیون احتمالی چیست؟**  
    انحراف معیار میزان پراکندگی توزیع پیش‌بینی‌ها را نشان می‌دهد و معیاری برای عدم قطعیت است.

37. **چگونه می‌توان توزیع پیش‌بینی‌ها را در رگرسیون احتمالی تحلیل کرد؟**  
    با بررسی میانگین، واریانس، و بازه‌های اطمینان توزیع پیش‌بینی‌شده (مانند توزیع نرمال).

38. **چرا داده‌های آموزشی باید نماینده داده‌های واقعی باشند؟**  
    اگر داده‌های آموزشی نماینده نباشند، مدل الگوهای نادرست یاد می‌گیرد و تعمیم‌پذیری ضعیفی خواهد داشت.

39. **مفهوم "افزایش داده" چیست و چگونه به تعمیم‌پذیری کمک می‌کند؟**  
    افزایش داده با ایجاد داده‌های مصنوعی (مانند چرخش تصاویر) تنوع داده‌ها را افزایش می‌دهد و از بیش‌برازش جلوگیری می‌کند.

40. **تفاوت بین مدل‌های پارامتری و غیرپارامتری چیست؟**  
    مدل‌های پارامتری (مانند رگرسیون خطی) تعداد محدودی پارامتر دارند، اما مدل‌های غیرپارامتری (مانند KNN) ساختار انعطاف‌پذیرتری دارند.

41. **رگرسیون خطی یک مدل پارامتری است یا غیرپارامتری؟ چرا؟**  
    پارامتری است، زیرا تعداد محدودی پارامتر (ضرایب $\beta_i$) دارد و فرض خطی بودن را اعمال می‌کند.

42. **مفهوم "حداکثر درست‌نمایی" در رگرسیون احتمالی چیست؟**  
    حداکثر درست‌نمایی روشی است برای یافتن پارامترهایی که احتمال مشاهده داده‌ها را بیشینه می‌کنند.

43. **چگونه می‌توان مدل رگرسیون را برای داده‌های نامتوازن تنظیم کرد؟**  
    با استفاده از روش‌هایی مانند وزن‌دهی به داده‌ها، نمونه‌برداری مجدد (oversampling/undersampling)، یا مدل‌های قوی.

44. **مفهوم "گرادیان کاهشی تصادفی" چیست؟**  
    گرادیان کاهشی تصادفی (SGD) ضرایب مدل را با استفاده از یک نمونه تصادفی در هر مرحله به‌روزرسانی می‌کند تا محاسبات سریع‌تر شود.

45. **تفاوت بین یادگیری برخط و یادگیری دسته‌ای چیست؟**  
    یادگیری برخط مدل را با هر نمونه داده به‌روزرسانی می‌کند، اما یادگیری دسته‌ای از کل داده‌ها به‌صورت یکجا استفاده می‌کند.

46. **چگونه می‌توان مدل رگرسیون را برای داده‌های زمانی بهبود داد؟**  
    با افزودن ویژگی‌های زمانی (مانند تأخیر)، استفاده از مدل‌های سری زمانی (مانند ARIMA)، یا شبکه‌های بازگشتی.

47. **مفهوم "رگرسیون قوی" چیست و در چه مواردی استفاده می‌شود؟**  
    رگرسیون قوی روشی است که تأثیر داده‌های پرت را کاهش می‌دهد، مانند استفاده از تابع هزینه Huber، و در داده‌های پرنویز کاربرد دارد.

48. **چرا مدل‌های احتمالی در پزشکی کاربرد دارند؟**  
    مدل‌های احتمالی با ارائه عدم قطعیت، به پزشکان کمک می‌کنند تا ریسک‌ها و احتمالات بیماری‌ها را بهتر ارزیابی کنند.

49. **چگونه می‌توان مدل رگرسیون را برای پیش‌بینی‌های چندمتغیره گسترش داد؟**  
    با استفاده از رگرسیون چندمتغیره که چندین متغیر وابسته را به‌صورت همزمان مدل می‌کند.

50. **تفاوت بین پیش‌بینی نقطه‌ای و پیش‌بینی بازه‌ای چیست؟**  
    پیش‌بینی نقطه‌ای یک مقدار دقیق ارائه می‌دهد (مانند 500)، اما پیش‌بینی بازه‌ای یک بازه اطمینان (مانند 450-550) با سطح اطمینان مشخص می‌دهد.

## توضیحات تکمیلی
- تمام فرمول‌ها با استفاده از سینتکس استاندارد LaTeX نوشته شده‌اند تا در محیط‌های Markdown مانند GitHub یا Obsidian به‌درستی نمایش داده شوند.
- پاسخ‌ها به‌گونه‌ای طراحی شده‌اند که کوتاه، دقیق، و قابل‌فهم باشند و برای مصاحبه‌های فنی مناسب باشند.
- برای نمایش صحیح فرمول‌ها، اطمینان حاصل کنید که نمایشگر Markdown شما از LaTeX پشتیبانی می‌کند (مانند استفاده از MathJax).
- اگر نیاز به توضیحات مفصل‌تر یا افزودن مثال‌های عملی دارید، لطفاً اطلاع دهید.

### **6. منابع**

1.  کریستوفر ام. بیشاپ، *تشخیص الگو و یادگیری ماشین*.
2.  مهرداد سلیمانی باغشا، *یادگیری ماشین*.
3.  اندرو انگ و تنسور ما، *یادداشت‌های درس CS229*.
4.  تام میچل، *یادگیری ماشین*.
5.  یاسر ابومصطفی، مالک مگدون-اسماعیل و هسینگ-تی لین، *یادگیری از داده‌ها: دوره کوتاه*.
