📘 **جزوه آموزشی درس یادگیری ماشین (CE 40717)**
**موضوع: رگرسیون لجستیک (Logistic Regression)**
**تاریخ: ۵ اکتبر ۲۰۲۴**
**مدرس: دکتر علی شریفی‌زارچی**
**تهیه و تنظیم: دانیال غریب (با ویرایش و تکمیل)**

---

### **۱. مقدمه: چرا رگرسیون لجستیک؟**

رگرسیون لجستیک (Logistic Regression - LR) یک الگوریتم یادگیری ماشین است که عمدتاً برای حل **مسائل طبقه‌بندی (Classification Problems)**، به‌ویژه **طبقه‌بندی دودویی (Binary Classification)**، کاربرد دارد. برخلاف **رگرسیون خطی (Linear Regression)** که یک مقدار پیوسته را پیش‌بینی می‌کند، رگرسیون لجستیک هدف دارد تا خروجی‌ای را در بازه‌ی [0, 1] تولید کند، که می‌تواند به عنوان **احتمال تعلق یک نمونه به کلاس "مثبت" (Positive Class)** تفسیر شود.

**توضیحات اضافه:**
تصور کن می‌خوای یک ایمیل رو تشخیص بدی که اسپم هست یا نه. یا مثلاً وقتی یک تراکنش آنلاین انجام می‌شه، می‌خوای بدونی کلاهبرداریه یا واقعی. یا حتی در پزشکی، می‌خوای تشخیص بدی تومور خوش‌خیمه یا بدخیم. این‌ها همه‌شون مثال‌های طبقه‌بندی دودویی هستن. یعنی خروجی فقط دو حالت داره: بله یا خیر (که معمولاً با 0 و 1 نشون داده می‌شه). رگرسیون لجستیک دقیقاً برای همین کار ساخته شده.

در این نوع مسائل، برچسب خروجی ($y$) معمولاً به صورت ${0, 1}$ تعریف می‌شود:
* $y=0$: "کلاس منفی" (Negative Class) – مثلاً تومور خوش‌خیم
* $y=1$: "کلاس مثبت" (Positive Class) – مثلاً تومور بدخیم

### **۲. چرا نمی‌توان از رگرسیون خطی برای طبقه‌بندی استفاده کرد؟**

استفاده از رگرسیون خطی برای مسائل طبقه‌بندی چالش‌هایی دارد:
* **خروجی‌های خارج از بازه [0,1]:** رگرسیون خطی می‌تواند مقادیری پیش‌بینی کند (مانند $h_\theta(x)$) که بزرگ‌تر از 1 یا کوچک‌تر از 0 باشند (مثلاً 1.2 یا -0.3). این مقادیر نمی‌توانند به عنوان احتمال تفسیر شوند، در حالی که در مسائل طبقه‌بندی، ما به دنبال تخمین احتمال هستیم.
* **حساسیت به داده‌های پرت (Outliers):** همانطور که در نمودار اندازه تومور نشان داده شده، افزودن یک نقطه‌ی داده‌ی پرت می‌تواند خط رگرسیون را به شدت تغییر دهد، که منجر به یک مرز تصمیم‌گیری نامناسب می‌شود. این موضوع نشان می‌دهد که رگرسیون خطی برای طبقه‌بندی به اندازه کافی **قوی (Robust)** نیست.

**توضیحات اضافه:**
فرض کن با رگرسیون خطی می‌خواییم اندازه تومور رو پیش‌بینی کنیم و بگیم تومور بدخیمه یا خوش‌خیم. اگه تومور خوش‌خیم بود (No) عدد 0 و اگه بدخیم بود (Yes) عدد 1 رو نشون بدیم. اگه یه خط راست رو به این داده‌ها فیت کنیم (مثل نمودار صفحه 5 PDF)، می‌تونیم بگیم اگه خروجی خط بالای 0.5 بود، 1 پیش‌بینی می‌کنیم و اگه کمتر بود، 0. حالا اگه یه تومور بدخیم خیلی بزرگتر از بقیه رو به داده‌ها اضافه کنیم (همون نقطه‌ی پرت قرمز در صفحه 6 PDF)، خط رگرسیون کج می‌شه و مرز 0.5 جابجا می‌شه. این یعنی مدل ما دیگه نمی‌تونه به درستی تشخیص بده، چون یک داده‌ی جدید خیلی روی تصمیم‌گیریش تأثیر گذاشته. این یه مشکل بزرگه. برای همین، ما به تابعی نیاز داریم که خروجی اون به طور ذاتی بین 0 و 1 باشه و بشه اونو به عنوان احتمال تفسیر کرد.

### **۳. تابع سیگموید (Sigmoid Function)**

برای اطمینان از اینکه خروجی مدل در بازه‌ی [0, 1] قرار می‌گیرد، از یک **تابع فعال‌سازی (Activation Function)** به نام **تابع سیگموید (Sigmoid Function)** یا **تابع لجستیک (Logistic Function)** استفاده می‌شود. این تابع به صورت زیر تعریف می‌شود:
$$\sigma(z) = \frac{1}{1 + e^{-z}}$$

**توضیحات اضافه:**
این تابع مثل یه "فیلتر" عمل می‌کنه. هر عددی، چه خیلی بزرگ و چه خیلی کوچک، بهش بدی، خروجی‌اش همیشه بین 0 و 1 خواهد بود.
* **خروجی در بازه [0,1]:** اگر $z$ خیلی بزرگ و مثبت باشه (مثلاً 6)، $\exp(-z)$ خیلی کوچک می‌شه و $\sigma(z)$ نزدیک به 1 می‌شه. اگر $z$ خیلی بزرگ و منفی باشه (مثلاً -6)، $\exp(-z)$ خیلی بزرگ می‌شه و $\sigma(z)$ نزدیک به 0 می‌شه. اگر $z=0$ باشه، $\exp(0)=1$ و $\sigma(0) = 1/(1+1) = 0.5$ می‌شه.
* **همواری (Smoothness):** یعنی نمودارش یهو بالا و پایین نمی‌ره.
* **قابلیت مشتق‌گیری (Differentiability):** این ویژگی خیلی مهمه چون برای "یادگیری" مدل از الگوریتم‌هایی مثل گرادیان دیسنت استفاده می‌کنیم که نیاز به مشتق دارن. مشتق تابع سیگموید هم خودش از جنس سیگمویده ( $\sigma'(z) = \sigma(z)(1-\sigma(z))$ ).
* **تفسیر احتمالاتی:** خروجی $\sigma(w^{\top}x)$ را می‌توان به عنوان **احتمال شرطی ($P(y=1|x,w)$)** تفسیر کرد، یعنی احتمال اینکه برچسب $y$ برابر 1 باشد، به شرط وجود ویژگی‌های $x$ و پارامترهای $w$.
    * $P(y=1|x,w) = \sigma(w^{\top}x)$
    * $P(y=0|x,w) = 1 - \sigma(w^{\top}x)$

**مثال:** اگر $\sigma(w^{\top}x) = 0.7$ باشد، به این معنی است که 70 درصد احتمال دارد که رویداد مورد نظر (مثلاً برد در یک بازی بسکتبال) اتفاق بیفتد.

### **۴. تابع تصمیم (Decision Function) در رگرسیون لجستیک**

در رگرسیون لجستیک، ما به دنبال یافتن بردار وزن $w$ هستیم که **احتمال پسین (Posterior Probability)** $P(y=1|x)$ را پیش‌بینی کند.
تابع تصمیم در رگرسیون لجستیک به صورت ترکیب تابع سیگموید با ترکیب خطی ویژگی‌ها ($w^{\top}x$) تعریف می‌شود:
$$h(x) = \sigma(w^{\top}x)$$
که $x$ بردار ویژگی‌ها و $w$ بردار وزن‌هاست.

**قاعده‌ی تصمیم‌گیری:**
* اگر $h(x) \geq 0.5$ باشد، مدل $y=1$ را پیش‌بینی می‌کند.
* اگر $h(x) < 0.5$ باشد، مدل $y=0$ را پیش‌بینی می‌کند.

### **۵. سطح تصمیم (Decision Surface / Decision Boundary)**

**سطح تصمیم** یا **مرز تصمیم (Decision Boundary)** ناحیه‌ای در فضای مسئله است که خروجی یک طبقه‌بندی‌کننده مبهم است، یعنی مدل با اطمینان برابر، تعلق نمونه به هر یک از کلاس‌ها را پیش‌بینی می‌کند. در طبقه‌بندی دودویی، این مرز جایی است که احتمال تعلق یک نمونه به کلاس $y=0$ و $y=1$ برابر است:
$$\sigma(w^{\top}x) = 0.5$$
از آنجایی که $\sigma(z) = 0.5$ زمانی رخ می‌دهد که $z=0$ باشد، می‌توان نتیجه گرفت که مرز تصمیم زمانی ایجاد می‌شود که:
$$w^{\top}x = 0$$
این معادله یک **هایپرپلین (Hyperplane)** را در فضای ویژگی‌ها تعریف می‌کند. بنابراین، مرز تصمیم‌گیری در رگرسیون لجستیک به طور پیش‌فرض **خطی (Linear)** است.

**نکات مهم:**
* **ابعاد مرز تصمیم:** هایپرپلین مرز تصمیم همیشه یک بعد کمتر از فضای ویژگی‌ها دارد.
* **مرزهای تصمیم غیرخطی:** اگر از **نگاشت ویژگی‌ها (Feature Mapping)** استفاده کنیم و **ترم‌های مرتبه بالاتر (Higher-order terms)** را به بردار ویژگی‌ها اضافه کنیم (مثلاً $x_1^2, x_2^2, x_1 x_2$ و...)， می‌توان مرزهای تصمیم‌گیری **غیرخطی (Non-linear Decision Boundaries)** را نیز یاد گرفت.

**توضیحات اضافه:**
مرز تصمیم مثل یک خط (در فضای دو بعدی) یا یک صفحه (در فضای سه بعدی) عمل می‌کنه که فضای داده رو به دو قسمت تقسیم می‌کنه. یک سمت برای کلاس 0 و سمت دیگه برای کلاس 1.
**مثال مرز خطی:** در صفحه 18 PDF، می‌بینی که یه خط صاف (خط سیاه) دو دسته‌ی داده (دایره‌ها و ضربدرها) رو از هم جدا کرده. این خط همون مرز تصمیمه.
**نکات مهم:**
* **ابعاد مرز تصمیم:** هایپرپلین مرز تصمیم همیشه یک بعد کمتر از فضای ویژگی‌ها دارد. مثلاً اگه داده‌هات دوتا ویژگی داشته باشن (مثل $x_1$ و $x_2$)، مرز تصمیم یه خطه. اگه سه تا ویژگی داشته باشن، مرز تصمیم یه صفحه است.
* **مرزهای تصمیم غیرخطی:** اگه بخوایم مرزهای تصمیم پیچیده‌تر و غیرخطی داشته باشیم (مثلاً یه دایره یا منحنی)، می‌تونیم ویژگی‌های جدیدی بسازیم. مثلاً به جای فقط $x_1$ و $x_2$، می‌تونیم $x_1^2$، $x_2^2$ یا $x_1x_2$ رو هم به عنوان ویژگی‌های جدید به مدل بدیم. این کار باعث می‌شه $w^{\top}x = 0$ همچنان خطی باشه اما در فضای ویژگی‌های جدید! در فضای اصلی، مرز غیرخطی دیده می‌شه (مثلاً همون دایره در صفحه 19 PDF).

### **۶. برآورد بیشینه درست‌نمایی (Maximum Likelihood Estimation - MLE)**

هدف در رگرسیون لجستیک، یافتن بردار وزن $w$ است که **احتمال پسین (Posterior Probability)** تمام نمونه‌های آموزشی را حداکثر کند. این کار از طریق روش **حداکثر درست‌نمایی شرطی (Maximum Conditional Log Likelihood)** انجام می‌شود.

**توضیحات اضافه:**
این بخش، قلب یادگیری در رگرسیون لجستیکه. MLE یه روش آماریه برای پیدا کردن "بهترین" پارامترها (اینجا $w$) برای یک مدل، طوری که مدل ما، داده‌هایی که دیدیم رو "بهترین" حالت ممکن توضیح بده.
**فرمول احتمال یک نمونه:**
از آنجایی که $y^{(i)}$ در طبقه‌بندی دودویی یا 0 است یا 1، می‌توانیم احتمال $P(y^{(i)}|x^{(i)},w)$ را به شکل فشرده زیر بنویسیم:
$$P(y^{(i)}|x^{(i)},w) = \sigma(w^{\top}x^{(i)})^{y^{(i)}} (1 - \sigma(w^{\top}x^{(i)}))^{(1-y^{(i)})}$$
* **اگه $y^{(i)}=1$ باشه:** (یعنی نمونه واقعاً از کلاس مثبت بود) ترم اول $(\sigma(w^{\top}x^{(i)}))^{1}$ فعال می‌شه و ترم دوم $(1 - \sigma(w^{\top}x^{(i)}))^{0}$ که برابر 1 می‌شه، خنثی می‌شه. پس احتمال میشه $\sigma(w^{\top}x^{(i)})$.
* **اگه $y^{(i)}=0$ باشه:** (یعنی نمونه واقعاً از کلاس منفی بود) ترم دوم فعال می‌شه و ترم اول خنثی. پس احتمال میشه $(1 - \sigma(w^{\top}x^{(i)}))$.

**تابع درست‌نمایی (Likelihood Function):**
تابع درست‌نمایی برای کل مجموعه داده (با فرض استقلال نمونه‌ها از یکدیگر) به صورت حاصل‌ضرب احتمال هر نمونه تعریف می‌شود:
$$L(w) = \prod_{i=1}^{n} P(y^{(i)}|x^{(i)},w)$$
**توضیحات اضافه:**
این $L(w)$ بهمون میگه چقدر "احتمال" داره که این مجموعه داده‌ی آموزشی که دیدیم، با توجه به پارامترهای $w$ ما، اتفاق افتاده باشه. ما می‌خوایم این احتمال رو بیشینه کنیم.

**تابع لگاریتم درست‌نمایی (Log-Likelihood Function):**
برای سادگی محاسبات (به دلیل تبدیل ضرب به جمع که مشتق‌گیری رو راحت‌تر می‌کنه) و حفظ ویژگی‌های بهینه‌سازی (زیرا تابع $\log$ تابعی صعودی است و بیشینه‌سازی $L(w)$ معادل بیشینه‌سازی $\log L(w)$ است)، از لگاریتم تابع درست‌نمایی استفاده می‌شود:
$$\hat{w} = \arg \max_{w} \log \prod_{i=1}^{n} P(y^{(i)}|x^{(i)},w)$$
$$\log L(w) = \sum_{i=1}^{n} \log P(y^{(i)}|x^{(i)},w) = \sum_{i=1}^{n} \left[ y^{(i)}\log(\sigma(w^{\top}x^{(i)})) + (1-y^{(i)})\log(1-\sigma(w^{\top}x^{(i)})) \right]$$

### **۷. تابع هزینه (Cost Function) و مشتق آن**

در یادگیری ماشین، معمولاً هدف **کمینه‌سازی (Minimization)** یک تابع هزینه است. از آنجایی که MLE به دنبال **بیشینه‌سازی (Maximization)** تابع لگاریتم درست‌نمایی است، تابع هزینه $J(w)$ را به عنوان **منفی لگاریتم درست‌نمایی (Negative Log-Likelihood)** تعریف می‌کنیم:
$$J(w) = - \sum_{i=1}^{n} \left[ y^{(i)}\log(\sigma(w^{\top}x^{(i)})) + (1-y^{(i)})\log(1-\sigma(w^{\top}x^{(i)})) \right]$$
این تابع هزینه، با نام **Binary Cross-Entropy Loss** نیز شناخته می‌شود.

**توضیحات اضافه:**
این تابع بهمون میگه که مدل ما چقدر "اشتباه" کرده. هرچی این مقدار کمتر باشه، مدل ما بهتره.
**مثال تصویری (صفحه 26 PDF):**
* **خط آبی (اگر $y=1$ باشد):** اگر نمونه واقعی $y=1$ باشه، و مدل ما $0.16$ رو پیش‌بینی کنه، خطا خیلی بالاست (چون خیلی از 1 دوریم). ولی اگه $0.8$ پیش‌بینی کنه، خطا کمه.
* **خط زرد (اگر $y=0$ باشد):** اگر نمونه واقعی $y=0$ باشه، و مدل ما $0.16$ رو پیش‌بینی کنه، خطا خیلی کمه (چون به 0 نزدیکیم). ولی اگه $0.8$ پیش‌بینی کنه، خطا بالاست.

**ویژگی‌های تابع هزینه $J(w)$:**
* **محدب (Convex):** تابع هزینه رگرسیون لجستیک، یک تابع محدب است. این ویژگی بسیار مهم است زیرا تضمین می‌کند که الگوریتم‌های بهینه‌سازی مبتنی بر گرادیان (مانند گرادیان دیسنت) به یک **بهینه سراسری (Global Optimum)** همگرا می‌شوند و در بهینه‌های محلی (Local Optima) گیر نمی‌کنند.
* **قابلیت اثبات محدب بودن:** محدب بودن تابع از طریق مشتق دوم آن قابل اثبات است.

**مقایسه با Zero-One Loss:**
تابع هزینه Binary Cross-Entropy (که در رگرسیون لجستیک استفاده می‌شود) برخلاف **Zero-One Loss** (که اگر پیش‌بینی صحیح باشد 0 و در غیر این صورت 1 است)، یک تابع هموار است و میزان "اشتباه بودن" پیش‌بینی را با مقدار احتمال خروجی مرتبط می‌کند. این ویژگی به الگوریتم بهینه‌سازی اجازه می‌دهد تا به آرامی به سمت راه‌حل بهینه حرکت کند.

### **۸. گرادیان دیسنت (Gradient Descent) برای رگرسیون لجستیک**

از آنجایی که برای $J(w)$ راه‌حل تحلیلی (Closed-form solution) برای $\nabla_w J(w) = 0$ وجود ندارد، از الگوریتم‌های بهینه‌سازی تکراری مانند **گرادیان دیسنت (Gradient Descent)** برای یافتن $w$ بهینه استفاده می‌شود.

**توضیحات اضافه:**
گرادیان دیسنت مثل اینه که شما روی یه تپه ایستادی و می‌خوای بری پایین‌ترین نقطه‌ی دره. هر قدمی که برمی‌داری، در جهتیه که تپه بیشترین شیب رو به سمت پایین داره. اینجا هم، "دره" همون تابع هزینه‌س و ما می‌خوایم به کمترین مقدارش برسیم. "شیب" همون گرادیانه.
**قاعده‌ی به‌روزرسانی (Update Rule):**
$$w^{t+1} = w^t - \eta \nabla_w J(w^t)$$
که $w^t$ وزن‌ها در قدم $t$، $w^{t+1}$ وزن‌ها در قدم بعدی و $\eta$ **نرخ یادگیری (Learning Rate)** است. نرخ یادگیری تعیین می‌کنه که در هر قدم چقدر بزرگ حرکت کنیم.

**گرادیان تابع هزینه $J(w)$:**
با محاسبه مشتق تابع هزینه نسبت به $w$، گرادیان زیر به‌دست می‌آید:
$$\nabla_w J(w) = \sum_{i=1}^{n} (\sigma(w^{\top}x^{(i)}) - y^{(i)}) x^{(i)}$$

**توضیحات اضافه:**
این فرمول بهمون میگه که چطوری وزن‌ها رو تغییر بدیم. $( \sigma(w^{\top}x^{(i)}) - y^{(i)})$ همون "خطا" یا "تفاوت" بین پیش‌بینی مدل ($\sigma(w^{\top}x^{(i)})$) و مقدار واقعی ($y^{(i)}$) برای هر داده است. این خطا رو در خود ویژگی‌های $x^{(i)}$ ضرب می‌کنیم تا بفهمیم کدوم ویژگی‌ها بیشتر باعث این خطا شدن و باید وزن اون‌ها رو تغییر بدیم.

**مقایسه با گرادیان رگرسیون خطی:**
جالب است که گرادیان رگرسیون لجستیک شباهت زیادی به گرادیان **مجموع مربعات خطا (Sum of Squared Errors - SSE)** در رگرسیون خطی دارد:
* **رگرسیون لجستیک:** $\nabla_w J(w) = \sum_{i=1}^{n} (\sigma(w^{\top}x^{(i)}) - y^{(i)}) x^{(i)}$
* **رگرسیون خطی:** $\nabla_w J(w) = \sum_{i=1}^{n} (w^{\top}x^{(i)} - y^{(i)}) x^{(i)}$

تفاوت اصلی در این است که در رگرسیون لجستیک، به جای استفاده مستقیم از $w^{\top}x^{(i)}$ (که می‌تونه هر عددی باشه)، از خروجی تابع سیگموید ($\sigma(w^{\top}x^{(i)})$) استفاده می‌شود، که آن را به یک احتمال نگاشت می‌کند.

### **۹. رگرسیون لجستیک چندکلاسه (Multi-class Logistic Regression) یا Softmax Regression**

هنگامی که بیش از دو کلاس (K > 2) وجود دارد و هر نمونه تنها به یک کلاس تعلق دارد، از تعمیم رگرسیون لجستیک با نام **Softmax Regression** استفاده می‌شود.

**توضیحات اضافه:**
فرض کن دیگه نمی‌خوای فقط بگی اسپم هست یا نیست. می‌خوای بگی ایمیل مربوط به "فروش" هست، "پشتیبانی" هست، "تبلیغات" هست یا "شخصی". اینجا چهار تا کلاس داری. Softmax Regression برای اینجور مواقع به کار می‌ره.

**تابع Softmax:**
برای هر کلاس $k$， تابع Softmax احتمال تعلق نمونه $x$ به آن کلاس را ($P(y=k|x,W)$) پیش‌بینی می‌کند. این تابع به صورت زیر تعریف می‌شود:
$$ \sigma_k(x;W) = P(y=k|x) = \frac{\exp(w_k^{\top}x)}{\sum_{j=1}^{K} \exp(w_j^{\top}x)} $$
که $w_k$ بردار وزن مخصوص کلاس $k$ است.

**توضیحات اضافه:**
* برای هر کلاس (مثلاً کلاس 1، کلاس 2، ... کلاس K)، یه بردار وزن ($w_k$) داریم.
* هر بردار وزن در ویژگی‌های $x$ ضرب می‌شه ($w_k^{\top}x$) و یه عدد به دست میاد.
* بعد از تابع نمایی (exp) استفاده می‌کنیم تا اعداد مثبت بشن.
* در نهایت، هر کدوم از این اعداد نمایی شده رو تقسیم بر "مجموع" تمام اعداد نمایی شده می‌کنیم تا مطمئن بشیم که خروجی‌ها بین 0 و 1 باشن و مجموعشون 1 بشه.

**ویژگی‌های تابع Softmax:**
* **خروجی احتمالاتی:** مجموع احتمالات برای تمام کلاس‌ها برابر 1 است، یعنی $\sum_{k=1}^{K} P(y=k|x) = 1$. (یعنی مطمئنیم که نمونه به یکی از کلاس‌ها تعلق داره)
* **همواری و مشتق‌پذیری:** همانند سیگموید، Softmax یک تابع هموار و مشتق‌پذیر است.
* **برجسته کردن حداکثر:** این تابع به طور هموار احتمال مربوط به کلاس با بالاترین امتیاز ($w_k^{\top}x$) را برجسته می‌کند، در حالی که احتمال سایر کلاس‌ها را کاهش می‌دهد. (مثلاً اگه یه کلاس امتیاز خیلی بالاتری داشته باشه، احتمال اون نزدیک 1 و بقیه نزدیک 0 می‌شن).
* **پشتیبانی از مقادیر منفی:** به دلیل استفاده از تابع نمایی ($\exp$), Softmax می‌تواند ورودی‌های منفی را نیز به خوبی مدیریت کند.

**قاعده‌ی تصمیم‌گیری در Softmax Regression:**
برای یک ورودی جدید $x$， کلاسی انتخاب می‌شود که $\sigma_k(x;W)$ را حداکثر کند:
$$ \alpha(x) = \arg \max_{k=1,...,K} \sigma_k(x;W) $$

**تابع هزینه (Cost Function) برای Softmax Regression:**
تابع هزینه برای Softmax Regression نیز به عنوان منفی لگاریتم درست‌نمایی تعریف می‌شود و به آن **Cross-Entropy Loss (چندکلاسه)** می‌گویند:
$$ J(W) = - \sum_{i=1}^{n} \sum_{k=1}^{K} y_k^{(i)} \log(\sigma_k(x^{(i)};W)) $$
که $y_k^{(i)}$ یک مقدار باینری است (1 اگر نمونه $i$ به کلاس $k$ تعلق داشته باشد و 0 در غیر این صورت، **One-of-K encoding**).

**توضیحات اضافه:**
* **W:** اینجا $W$ یک ماتریس از تمام بردارهای وزن $w_k$ برای هر کلاس است ($W = [w_1, w_2, ..., w_K]$).
* **One-of-K encoding:** یعنی اگه مثلاً 4 تا کلاس داریم و نمونه‌ی $i$ به کلاس سوم تعلق داره، برچسب $y^{(i)}$ به صورت $[0, 0, 1, 0]^T$ نشون داده می‌شه. اینجوری فقط ترم مربوط به کلاس صحیح در تابع هزینه تاثیر می‌ذاره.

**گرادیان تابع هزینه برای Softmax Regression:**
$$ \nabla_{w_j} J(W) = \sum_{i=1}^{n} (\sigma_j(x^{(i)};W) - y_j^{(i)}) x^{(i)} $$
که $w_j^t$ بردار وزن برای کلاس $j$ در تکرار $t$-ام است.

### **۱۰. دیدگاه احتمالاتی در طبقه‌بندی: مدل‌های Generative در مقابل Discriminative**

در مسائل طبقه‌بندی، می‌توانیم مدل‌ها را از دو دیدگاه اصلی بررسی کنیم:

#### **الف) مدل‌های Generative (مولد)**
* **نحوه‌ی یادگیری:** این مدل‌ها ابتدا **توزیع توام (Joint Probability Distribution)** $P(x,y)$ را یاد می‌گیرند. به عبارت دیگر، آن‌ها توزیع‌های احتمالاتی $P(x|C_k)$ (**احتمال شرطی کلاس یا Likelihood**) و $P(C_k)$ (**احتمال پیشین کلاس یا Prior**) را برای هر کلاس $C_k$ برآورد می‌کنند.
* **پیش‌بینی:** سپس با استفاده از **قانون بیز (Bayes' Theorem)**، احتمال پسین $P(C_k|x)$ را محاسبه می‌کنند:
    $$ P(C_k|x) = \frac{P(x|C_k)P(C_k)}{\sum_{j=1}^{K}P(x|C_j)P(C_j)} $$
    و در نهایت کلاسی انتخاب می‌شود که بالاترین $P(C_k|x)$ را داشته باشد.
* **کاربردها:** مدل‌های مولد علاوه بر طبقه‌بندی، می‌توانند برای **تولید داده‌های جدید (Generate new data)** نیز استفاده شوند، زیرا توزیع کامل داده‌ها را یاد گرفته‌اند.
* **مثال:** **Naive Bayes** یک مثال از مدل Generative است.

**توضیحات اضافه:**
این مدل‌ها اول یاد می‌گیرن که داده‌های هر کلاس (مثلاً ویژگی‌های تومور خوش‌خیم) چطوری "توزیع" شدن. بعد یاد می‌گیرن که هر کلاس (خوش‌خیم یا بدخیم) به خودی خود چقدر رایجه. بعداً اگه یه داده‌ی جدید ببینن، با استفاده از قانون بیز محاسبه می‌کنن که چقدر محتمله این داده به هر کلاس تعلق داشته باشه و اونو به کلاسی که محتمل‌تره، اختصاص می‌دن. مثل این می‌مونه که اول یاد می‌گیرن چه شکلی‌اند آدم‌های قد بلند، چه شکلی‌اند آدم‌های کوتاه. بعدش یه آدم جدید می‌بینن، می‌گن این چقدر شبیه آدم‌های قد بلنده؟ چقدر شبیه آدم‌های کوتاهه؟

#### **ب) مدل‌های Discriminative (تمایزی)**
* **نحوه‌ی یادگیری:** این مدل‌ها مستقیماً **توزیع احتمال شرطی (Conditional Probability Distribution)** $P(y|x)$ را یاد می‌گیرند. به عبارت دیگر، آن‌ها مرزی را در فضای ویژگی‌ها یاد می‌گیرند که بهترین تفکیک را بین کلاس‌ها ایجاد می‌کند.
* **پیش‌بینی:** کلاسی انتخاب می‌شود که $P(C_k|x)$ آن از سایر کلاس‌ها بیشتر باشد.
* **کاربردها:** تمرکز اصلی این مدل‌ها بر دقت طبقه‌بندی است و معمولاً برای تولید داده استفاده نمی‌شوند.
* **مثال:** **رگرسیون لجستیک (Logistic Regression)** یک مثال بارز از مدل Discriminative است. این مدل مستقیماً احتمال $P(y=1|x)$ را با استفاده از تابع سیگموید ($\sigma(w^{\top}x)$) تخمین می‌زند.

**توضیحات اضافه:**
این مدل‌ها مستقیم روی مرز بین کلاس‌ها تمرکز می‌کنن. دیگه براشون مهم نیست که هر کلاس به تنهایی چه توزیعی داره، فقط می‌خوان بدونن چطوری بهترین خط جداکننده رو پیدا کنن. مثل این می‌مونه که یهو بگن خطی بکشید که آدم‌های قد بلند رو از کوتاه جدا کنه، بدون اینکه نیاز باشه دقیقاً بدونن توزیع قد آدم‌ها چیه.

**خلاصه‌ی مقایسه:**
| ویژگی | مدل‌های Generative (مولد) | مدل‌های Discriminative (تمایزی) |
| :--------------- | :------------------------------------------------------------- | :------------------------------------------------------- |
| هدف یادگیری | $P(x,y)$ (توزیع توام) | $P(y|x)$ (توزیع شرطی) |
| نحوه پیش‌بینی | محاسبه $P(y|x)$ با قانون بیز از $P(x|y)$ و $P(y)$ | مستقیم مدل‌سازی $P(y|x)$ |
| کاربرد دیگر | تولید داده‌های جدید | تمرکز بر طبقه‌بندی |
| مثال‌ها | Naive Bayes, Gaussian Discriminant Analysis | Logistic Regression, Support Vector Machine (SVM) |

---

### **خلاصه‌ی رگرسیون لجستیک (LR Summary)**

* **طبقه‌بندی‌کننده خطی:** رگرسیون لجستیک یک طبقه‌بندی‌کننده خطی است (مگر اینکه از نگاشت ویژگی‌های غیرخطی استفاده شود).
* **بهینه‌سازی با MLE:** مسئله بهینه‌سازی LR از طریق روش بیشینه درست‌نمایی (Maximum Likelihood Estimation) فرمول‌بندی می‌شود.
* **عدم وجود راه‌حل تحلیلی:** هیچ راه‌حل تحلیلی (Closed-form solution) برای مسئله بهینه‌سازی آن وجود ندارد.
* **تابع هزینه محدب:** با این حال، تابع هزینه آن (Cross-Entropy Loss) محدب است، که به این معنی است که الگوریتم‌های گرادیان دیسنت می‌توانند به یک بهینه سراسری همگرا شوند.

---
**منابع:**
* M. Soleymani Baghshah, "Machine learning." Lecture slides.
* A. Ng, "Ml-005, lecture 6." Lecture slides.
* C. M. Bishop, Pattern Recognition and Machine Learning. Information Science and Statistics, New York, NY: Springer, 1 ed., Aug. 2006.
* S. Fidler, "Csc411." Lecture slides.
* A. Ng and T. Ma, CS229 Lecture Notes. Updated June 11, 2023.

---

میخوام تو این فایل همه سایتا رو حذف کنی و به هر متن یا پاراگراف در خط اولش قرار بدی با شمارنده 1 تا هرجا ک رف 
[cite_start]ینی هر پاراگراف از خط اول [cite:1] [cite_start]از اون قسمت ب بعد دیگه رو همون خط نباشه [cite:2] 
در پایان باید تمام cite_start حذف و تمامی cite:number در جای خود باشند 
لطفا فقط کد مارک داون را بده
