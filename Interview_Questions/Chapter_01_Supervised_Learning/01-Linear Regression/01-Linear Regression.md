# 📘 جزوه کامل یادگیری ماشین: رگرسیون خطی، تعمیم‌پذیری و رگرسیون احتمالی

**از فایل اصلی : دکتر علی شریفی‌زارچی منتشر شده درتاریخ: ۲۱ سپتامبر ۲۰۲۴**

---

### **1. مقدمه (Introduction)**

این بخش به تعریف بنیادی یادگیری ماشین می‌پردازد و مثال‌هایی از کاربردهای آن در دنیای واقعی ارائه می‌دهد.

#### **1.1. تعریف یادگیری ماشین (Definition of Machine Learning (ML))**

یادگیری ماشین به عنوان حوزه‌ای از مطالعه تعریف می‌شود که کامپیوترها را قادر می‌سازد تا بدون برنامه‌ریزی صریح و گام‌به‌گام، از داده‌ها یاد بگیرند. این حوزه شامل ساخت الگوریتم‌هایی است که الگوها را از داده‌ها تعمیم می‌دهند و بر پیش‌بینی نتایج، طبقه‌بندی، یا کشف ساختارهای پنهان تمرکز دارند.

**تعریف تام ام. میچل (Tom M. Mitchell's Definition of Machine Learning):**
یکی از تعاریف مشهور یادگیری ماشین از تام ام. میچل است: "یک برنامه کامپیوتری گفته می‌شود که از تجربه $E$ نسبت به یک دسته از وظایف $T$ و معیار عملکرد $P$ یاد می‌گیرد، اگر عملکرد آن در وظاییم $T$， که با $P$ اندازه‌گیری می‌شود، با تجربه $E$ بهبود یابد."
به طور خلاصه، مسئله یادگیری می‌تواند به صورت سه‌گانه $(T, P, E)$ تعریف شود.
* **وظیفه (Task - T):** کاری که مدل باید انجام دهد، مثلاً پیش‌بینی قیمت خانه.
* **معیار عملکرد (Performance Measure - P):** روشی برای سنجش کیفیت انجام وظیفه، مثلاً دقت پیش‌بینی.
* **تجربه (Experience - E):** داده‌هایی که مدل برای یادگیری از آن‌ها استفاده می‌کند.
هدف اصلی یادگیری ماشین، توسعه مدل‌هایی است که بر اساس داده‌های گذشته، پیش‌بینی‌های دقیقی انجام دهند.

**توضیحات تکمیلی:**
این تعریف، هسته اصلی یادگیری ماشین را بیان می‌کند. یعنی کامپیوتر خودش یاد می‌گیرد، نه اینکه ما خط به خط به او بگوییم چه کند. مثلاً برای پیش‌بینی قیمت خانه، کامپیوتر از داده‌های خانه‌های فروخته شده قبلی (تجربه E) یاد می‌گیرد که قیمت‌ها (وظیفه T) را پیش‌بینی کند، و هرچه بهتر پیش‌بینی کند (معیار عملکرد P)، یعنی بهتر یاد گرفته است.

#### **1.2. مثال‌های کاربرد یادگیری ماشین (Example Usage of ML)**

یادگیری ماشین کاربردهای گسترده‌ای در دنیای واقعی دارد:

* تشخیص اخبار جعلی (Fake News Detection): یک مسئله طبقه‌بندی.
* پیش‌بینی قیمت خانه (Predicting House Prices): یک مسئله رگرسیون. مثال‌ها نشان می‌دهند که چگونه یادگیری ماشین می‌تواند با استفاده از داده‌های تاریخی (مانند مساحت زندگی و قیمت خانه)، روابط بین ویژگی‌ها را بیاموزد.
* ماشین‌های خودران (Self-driving cars): نیاز به تصمیم‌گیری لحظه‌ای دارند.
* برنامه‌های کاربردی در حوزه‌های مختلف: مالی، بهداشت و درمان، رباتیک و ...
* مثال تأیید متقاضی (Applicant Approval): بر اساس فرم درخواست متقاضی (سن، جنسیت، حقوق سالانه، سابقه اقامت و کار، بدهی فعلی)، خروجی نهایی می‌تواند تأیید یا رد درخواست باشد.

**توضیحات تکمیلی:**
این مثال‌ها نشان می‌دهند که ML چقدر متنوع است. از پیش‌بینی یک عدد (مثل قیمت خونه) گرفته تا تصمیم‌گیری (قبول یا رد یک درخواست) یا حتی کارهای پیچیده‌ای مثل رانندگی خودرو.

#### **1.3. پارادایم‌های یادگیری ماشین (Paradigms of ML)**

یادگیری ماشین به چند پارادایم اصلی تقسیم می‌شود:

* **یادگیری با نظارت (Supervised Learning):** در این نوع یادگیری، هدف پیش‌بینی یک متغیر هدف است که مثال‌های آن (داده‌های برچسب‌دار) را از قبل مشاهده کرده‌ایم. (مثل رگرسیون و طبقه‌بندی).
* **یادگیری بدون نظارت (Unsupervised Learning):** در اینجا، هدف کشف ساختارها و الگوهای پنهان در داده‌های مشاهده شده است، بدون اینکه برچسب‌های خروجی از قبل مشخص باشند. مثال: بخش‌بندی مشتریان (Customer Segmentation) یا خوشه‌بندی اخبار.
* **یادگیری تقویتی (Reinforcement Learning):** در این پارادایم، عامل یادگیرنده بازخورد جزئی و غیرمستقیم دریافت می‌کند و هیچ راهنمایی صریحی وجود ندارد. عامل برای دنباله‌ای از حرکات، پاداش دریافت می‌کند تا یک "سیاست" (policy) و توابع سودمندی را بیاموزد.
* **سایر پارادایم‌ها:** یادگیری نیمه‌نظارتی (Semi-supervised learning)، یادگیری فعال (Active Learning)، یادگیری آنلاین (Online learning) و ...

**توضیحات تکمیلی:**
این بخش، انواع اصلی یادگیری ماشین را معرفی می‌کند. یادگیری با نظارت مثل معلمی است که پاسخ‌های درست را می‌گوید. یادگیری بدون نظارت مثل کشف الگو در مجموعه‌ای از چیزها بدون هیچ راهنمایی است. یادگیری تقویتی مثل تربیت یک حیوان خانگی با پاداش و تنبیه است.

---

### **2. یادگیری با نظارت (Supervised Learning)**

این بخش به جزئیات یادگیری با نظارت می‌پردازد، که شامل رگرسیون و طبقه‌بندی است.

#### **2.1. تعریف یادگیری با نظارت (Definition):**

یادگیری با نظارت شکلی از یادگیری ماشین است که در آن مدل از داده‌های برچسب‌دار $\{(x_{i}, y_{i})\}$ یاد می‌گیرد تا یک خروجی $y$ را با داشتن ورودی $x$ پیش‌بینی کند.

هدف: تخمین یک تابع $f: \mathbb{R}^{D} \to \mathbb{R}$ به گونه‌ای که $y = f(x) + \epsilon$ باشد، که $\epsilon$ نشان‌دهنده نویز است.

#### **2.2. اجزای یادگیری (با نظارت) (Components of Supervised Learning)**

هر مسئله یادگیری با نظارت شامل اجزای زیر است:

* **تابع هدف ناشناخته ($f:\mathfrak{X} \to \mathfrak{Y}$):** تابع واقعی و پنهانی که رابطه بین ورودی و خروجی را توصیف می‌کند. $\mathfrak{X}$ فضای ورودی و $\mathfrak{Y}$ فضای خروجی است.
* **داده‌های آموزشی ($(x_{1}, y_{1}), (x_{2}, y_{2}), \dots, (x_{N}, y_{N})$):** مجموعه‌ای از مثال‌های ورودی و خروجی که برای آموزش مدل استفاده می‌شوند.
* **مجموعه فرضیه (Hypothesis Set - $\mathcal{H}$):** مجموعه‌ای از توابع کاندیدا ($h$) که مدل از میان آن‌ها، تابعی را برای تقریب تابع هدف واقعی انتخاب می‌کند.
* **الگوریتم یادگیری (Learning Algorithm):** روشی که برای انتخاب بهترین تابع ($g \approx f$) از مجموعه فرضیه استفاده می‌شود.

**توضیحات تکمیلی:**
مثل این است که شما می‌خواهید یک معادله (تابع هدف ناشناخته) را حدس بزنید. به جای اینکه مستقیم معادله را بدانید، چند نقطه از آن را به شما می‌دهند (داده‌های آموزشی). شما یک سری فرمول (مجموعه فرضیه) را امتحان می‌کنید و یک روش (الگوریتم یادگیری) برای پیدا کردن بهترین فرمول از بین آن‌ها انتخاب می‌کنید. نتیجه نهایی، همان "فرضیه نهایی" شماست.

#### **2.3. یادگیری با نظارت: رگرسیون در مقابل طبقه‌بندی (Regression vs. Classification)**

یادگیری با نظارت به دو دسته اصلی تقسیم می‌شود:

* **رگرسیون (Regression):** پیش‌بینی یک متغیر هدف پیوسته (continuous target variable)، مثلاً $y \in [0,1]$ یا هر عدد حقیقی دیگر (مانند قیمت خانه).
* **طبقه‌بندی (Classification):** پیش‌بینی یک متغیر هدف گسسته (discrete target variable)، مثلاً $y \in \{1, 2, \dots, C\}$ (مانند تشخیص اسپم/غیر اسپم).

#### **2.4. اجزای راه‌حل - مدل یادگیری (Solution Components - Learning Model)**

مدل یادگیری شامل دو جزء اصلی است که با هم کار می‌کنند:

* **مجموعه فرضیه (Hypothesis Set - $\mathcal{H}$):** این مجموعه، توابع ممکن را که مدل می‌تواند یاد بگیرد، تعریف می‌کند. این توابع به صورت $h(x, \theta)$ نمایش داده می‌شوند، که در آن $\theta$ پارامترهای یادگیری مسئله هستند.
* **الگوریتم یادگیری (Learning Algorithm):** این الگوریتم مسئول یافتن بهترین مجموعه از پارامترها ($\theta^{*}$) است به طوری که تابع $h(x, \theta^{*})$ به تابع هدف واقعی $f(x)$ نزدیک شود.

این دو جزء با هم کار می‌کنند تا ورودی‌ها ($x$) را به خروجی‌ها ($y$) نگاشت کنند و خطای پیش‌بینی را به حداقل برسانند. $\theta^{*}$ همان بهترین پارامترها برای پیش‌بینی خروجی‌ها با استفاده از فرضیه انتخاب شده است.

#### **3.5. مروری بر فضای فرضیه (Hypothesis Space Overview)**

* **فرضیه (Hypothesis - h):** به یک نگاشت از فضای ورودی ($\mathfrak{X}$) به فضای خروجی ($\mathfrak{Y}$) اشاره دارد.
* **فرضیه رگرسیون خطی (Linear Regression Hypothesis):** در رگرسیون خطی، فرضیه به صورت یک ترکیب خطی از ویژگی‌های ورودی است: $h_{w}(x) = w_{0} + w_{1}x_{1} + \dots + w_{D}x_{D} = w^{\top}x$.
* **بردار ورودی $x$:** برای سهولت محاسبات (قرار دادن $w_{0}$ در ضرب ماتریسی)، بردار ورودی معمولاً به صورت $x = [x_{0} = 1, x_{1}, x_{2}, \dots, x_{D}]$ تعریف می‌شود.
* **بردار پارامتر (وزن) $w$:** شامل وزن مربوط به بایاس و وزن‌های هر ویژگی است: $w = [w_{0}, w_{1}, w_{2}, \dots, w_{D}]$.

#### **3.6. نمایش فرضیه خطی (Linear Hypothesis Representation)**

فضای فرضیه خطی، ساده‌ترین شکل یک مدل رگرسیون است که در آن خروجی به صورت یک ترکیب خطی از ویژگی‌های ورودی بیان می‌شود.

**مثال‌های فرضیه خطی:**

* **تک متغیره (Single Variable):** $h_{w}(x) = w_{0} + w_{1}x$. (مثلاً پیش‌بینی قیمت خانه بر اساس تنها یک ویژگی مانند مساحت).
* **چند متغیره (Multivariate):** $h_{w}(x) = w_{0} + w_{1}x_{1} + w_{2}x_{2} + \dots + w_{D}x_{D}$. (مثلاً پیش‌بینی قیمت خانه بر اساس چندین ویژگی مانند مساحت، تعداد اتاق، موقعیت مکانی).

---

### **4. بهینه‌سازی (Optimization)**

این بخش به چگونگی یافتن بهترین پارامترهای مدل می‌پردازد تا مدل بتواند بهترین پیش‌بینی‌ها را انجام دهد.

#### **4.1. درک توابع هزینه (Understanding Cost Functions)**

در فضای فرضیه، ما یک تابع $h(x;w)$ را برای تقریب رابطه واقعی بین ورودی $x$ و خروجی $y$ انتخاب می‌کنیم.

هدف: کمینه‌سازی تفاوت بین مقادیر پیش‌بینی‌شده $h(x)$ و مقادیر واقعی $y$.

این تفاوت با استفاده از توابع هزینه (Cost Functions) اندازه‌گیری می‌شود. توابع هزینه به ما در انتخاب فرضیه بهینه کمک می‌کنند.

#### **4.2. تابع هزینه چیست؟ (What is a Cost Function?)**

تابع هزینه میزان خوبیِ تطابق فرضیه $h(x;w)$ با داده‌های آموزشی را اندازه‌گیری می‌کند.

در مسائل رگرسیون، رایج‌ترین تابع خطا، خطای مربعات (Squared Error - SE) است: $SE: (y^{(i)} - h(x^{(i)}; w))^2$.

تابع هزینه باید تمام پیش‌بینی‌ها را اندازه‌گیری کند. بنابراین، یک انتخاب رایج، مجموع مربعات خطا (Sum of Squared Errors - SSE) است: $J(w) = \sum_{i=1}^{N} (y^{(i)} - h(x^{(i)}; w))^2$.

هدف: کمینه‌سازی تابع هزینه برای یافتن بهترین پارامترهای $w$.

#### **4.3. SSE: مجموع مربعات خطا (Sum of Squared Errors)**

SSE به دلیل سادگی و قابلیت مشتق‌پذیری، به طور گسترده‌ای استفاده می‌شود.

به صورت شهودی، SSE نشان‌دهنده فاصله مربعی بین مقادیر پیش‌بینی‌شده و واقعی است.

SSE خطاهای بزرگ‌تر را به شدت بیشتری جریمه می‌کند تا خطاهای کوچک‌تر (به دلیل عملیات مربع).

برای رگرسیون خطی، SSE را می‌توان به صورت ماتریسی نوشت: $SSE = \sum_{i=1}^{N} (y^{(i)} - w^{\top}x^{(i)})^2$.

**توضیحات تکمیلی:**
SSE مثل این است که برای هر نقطه، اختلاف بین پیش‌بینی مدل و مقدار واقعی را حساب کنید، آن را به توان دو برسانید تا مثبت شود و خطاهای بزرگ‌تر بیشتر تنبیه شوند، و بعد همه‌ی این مربع‌ها را با هم جمع کنید. هدف کم کردن این عدد است.

#### **4.4. الگوریتم یادگیری (The Learning Algorithm)**

هدف: انتخاب وزن‌ها ($w$) به گونه‌ای که تابع هزینه $J(w)$ کمینه شود.

رویکرد: الگوریتم یادگیری در واقع فرآیند بهینه‌سازی تابع هزینه است.

شرط لازم برای پارامترهای بهینه: با گرفتن مشتق تابع هزینه نسبت به هر وزن ($w_i$) و برابر قرار دادن آن‌ها با صفر.

پارامترهای بهترین فرضیه برای مجموعه آموزشی: $w^{*} = \arg\min_{w} J(w)$.

#### **4.5. بهینه‌سازی تابع هزینه: تک‌متغیره (Cost function optimization: univariate)**

برای رگرسیون خطی تک‌متغیره ($J(w) = \sum_{i=1}^{n} (y^{(i)} - w_{0} - w_{1}x^{(i)})^2$)، شرایط لازم برای یافتن مقادیر پارامتر بهینه عبارتند از:

$\frac{\partial J(w)}{\partial w_{0}} = 0$

$\frac{\partial J(w)}{\partial w_{1}} = 0$

این دو معادله، یک سیستم از 2 معادله خطی را تشکیل می‌دهند. با حل این سیستم، می‌توان مقادیر بهینه $w_0$ و $w_1$ را به دست آورد.

**مثال رگرسیون خطی: تبلیغات تلویزیونی و فروش (TV Advertising and Sales)**
این یک مثال واقعی است که نشان می‌دهد چگونه کسب‌وکارها می‌توانند از رگرسیون خطی برای تصمیم‌گیری در مورد بودجه‌های بازاریابی استفاده کنند.

در این مسئله، میزان بودجه تبلیغات تلویزیونی به عنوان ورودی $x$ و فروش مربوطه به عنوان خروجی $y$ در نظر گرفته می‌شود.

با اعمال شرایط لازم برای پارامترهای بهینه، دو معادله خطی به دست می‌آید که با حل آن‌ها می‌توان $w_0$ و $w_1$ را پیدا کرد (مثلاً $w_1 \approx 0.052$ و $w_0 \approx 8.18$).

#### **4.6. بهینه‌سازی تابع هزینه: چندمتغیره (Cost function optimization: multivariate)**

برای رگرسیون خطی چندمتغیره، تابع هزینه SSE به صورت: $J(w) = \sum_{i=1}^{n} (y^{(i)} - h_{w}(x^{(i)}))^2 = \sum_{i=1}^{n} (y^{(i)} - w^{\top}x^{(i)})^2$ است.

برای سهولت کار، مسئله را به فرم ماتریسی می‌نویم:
* ماتریس ویژگی‌ها $X$ (که ستون اول آن برای بایاس، همگی 1 هستند).
* بردار وزن $w$.
* بردار خروجی $y$.

با استفاده از فرم‌های ماتریسی، تابع هزینه را می‌توان به صورت: $J(w) = ||y-Xw||_2^2$ بازنویسی کرد. (این نشان‌دهنده نرم اقلیدسی (L2 norm) بردار خطا است).

با گرفتن مشتق تابع هزینه نسبت به $w$ و برابر قرار دادن آن با صفر، می‌توان راه‌حل تحلیلی را به دست آورد:

$\nabla_{w}J(w) = -2X^{\top}(y-Xw)$

$\nabla_{w}J(w) = 0 \Rightarrow X^{\top}Xw = X^{\top}y \Rightarrow w=(X^{\top}X)^{-1}X^{\top}y$

#### **4.7. راه‌حل تحلیلی: چندمتغیره (Analytical solution: multivariate)**

عبارت $(X^{\top}X)^{-1}X^{\top}$ را شبه معکوس (pseudo-inverse) ماتریس $X$ می‌نامند.

ماتریس $X$ معمولاً مربع نیست و بنابراین معکوس‌پذیر (invertible) نیست. اما شبه معکوس را می‌توان برای هر ماتریسی، صرف نظر از شکل آن، محاسبه کرد.

#### **4.8. محدودیت‌های محاسباتی راه‌حل تحلیلی (Computational limitations of analytical solution)**

* **مقیاس‌پذیری (Scalability):** راه‌حل‌های تحلیلی برای مجموعه‌های داده بسیار بزرگ به خوبی مقیاس‌پذیر نیستند و برای کاربردهای Big Data غیرعملی هستند.
* **یافتن معکوس یک ماتریس:** ساده‌ترین راه برای یافتن معکوس یک ماتریس، حذف گاوسی است که دارای پیچیدگی زمانی $O(n^3)$ است. روش‌های دیگر مانند تجزیه LU نیز پیچیدگی $O(n^3)$ دارند، اما پایدارتر هستند.
* **روش‌های عددی (Numerical methods):** برای ماتریس‌های بزرگ و پراکنده (sparse)، روش‌های تکراری مانند گرادیان مزدوج (Conjugate Gradient) کارآمدتر هستند.

#### **4.9. محدودیت‌های عملی راه‌حل تحلیلی (Practical limitations of analytical solution)**

* **یادگیری آنلاین (Online learning):** در سناریوهایی که داده‌ها به صورت جریان پیوسته وارد می‌شوند و پیش‌بینی‌ها باید قبل از مشاهده تمام داده‌ها انجام شوند، راه‌حل‌های تحلیلی عملی نیستند.
* **عدم سازگاری با داده‌های جدید:** روش‌های تحلیلی بدون محاسبه مجدد کل راه‌حل، با داده‌های جدید سازگار نیستند.

#### **4.10. بهینه‌سازی تابع هزینه (Cost function optimization: Iterative approach)**

رویکرد دیگر: از یک حدس اولیه ($w^0$) شروع کرده و به طور تکراری ($w^t$ به $w^{t+1}$) وزن‌ها را تغییر می‌دهیم تا $J(w)$ کمینه شود تا به یک حداقل برسیم.

این رویکرد اساس الگوریتم گرادیان دیسنت (Gradient Descent) است.

#### **4.11. گرادیان دیسنت (Gradient Descent)**

* **قاعده به‌روزرسانی (Update Rule):** در هر گام، وزن‌ها به اندازه‌ی متناسب با منفی بردار گرادیان تابع در نقطه فعلی ($w^t$) تغییر می‌کنند: $w^{t+1}=w^{t}-\eta\nabla J(w^{t})$.
* **جهت حرکت:** $J(w)$ زمانی سریع‌ترین کاهش را دارد که در جهت منفی گرادیان حرکت کنیم.
* **فرض:** $J(w)$ در همسایگی $w^t$ تعریف شده و مشتق‌پذیر باشد.
* **گرادیان افزایشی (Gradient Ascent):** از گرادیان مثبت برای یافتن یک حداکثر محلی (local maximum) استفاده می‌کند.
* **هدف:** ادامه یافتن $w^{*} = \arg\min_{w} J(w)$.
* اگر $\eta$ (نرخ یادگیری) به اندازه کافی کوچک باشد، آنگاه $J(w^{t+1}) \leq J(w^{t})$ تضمین می‌شود.
* $\eta$ می‌تواند در هر تکرار به صورت $\eta_t$ تغییر کند (نرخ یادگیری تطبیقی).

**توضیحات تکمیلی:**
گرادیان دیسنت مثل اینه که شما روی یک تپه ایستادید و می‌خواهید به پایین‌ترین نقطه (دره) برسید. در هر قدم، به سمتی می‌روید که شیب تپه بیشترین نزول را داشته باشد. "گرادیان" همان جهت شیب تپه است. $\eta$ هم اندازه قدم شماست.

#### **4.12. معایب گرادیان دیسنت (Gradient descent disadvantages)**

* **مشکل مینیمم‌های محلی (Local minima problem):** اگر تابع هزینه غیرمحدب (non-convex) باشد، گرادیان دیسنت ممکن است در یک مینیمم محلی گیر کند و به مینیمم سراسری (global minimum) نرسد.
* با این حال، زمانی که $J$ محدب (convex) باشد، تمام مینیمم‌های محلی نیز مینیمم‌های سراسری هستند، بنابراین گرادیان دیسنت می‌تواند به راه‌حل سراسری همگرا شود. (در رگرسیون خطی با SSE، تابع هزینه محدب است).

#### **4.13. نرخ یادگیری ($\eta$) و به‌روزرسانی وزن‌ها (Weight Update Rule)**

* **قاعده به‌روزرسانی وزن‌ها:** $w^{t+1} = w^{t} + \eta \sum_{i=1}^{n} (y^{(i)} - w^{\top}x^{(i)})x^{(i)}$.
* $\eta$ بسیار کوچک: گرادیان دیسنت می‌تواند بسیار کند باشد.
* $\eta$ بسیار بزرگ: گرادیان دیسنت ممکن است از مینیمم عبور کند (overshoot)، نتواند همگرا شود، یا حتی واگرا شود. (تصاویر صفحات 52 تا 60 PDF این رفتار را به خوبی نشان می‌دهند).

#### **4.14. انواع گرادیان دیسنت (Variants of gradient descent)**

* **Batch gradient descent:** تمام مجموعه آموزشی را در یک تکرار پردازش می‌کند.
    * می‌تواند از نظر محاسباتی برای مجموعه‌های داده بزرگ پرهزینه و برای برخی کاربردها (مانند یادگیری آنلاین) غیرممکن باشد.
* **Mini-batch gradient descent:** زیرمجموعه‌های کوچک و تصادفی (مینی-بچ‌ها) از مجموعه آموزشی را در هر تکرار پردازش می‌کند.
    * بین کارایی گرادیان دسته‌ای و به‌روزرسانی‌های مکرر SGD تعادل برقرار می‌کند.
* **Stochastic gradient descent (SGD):** تنها یک مثال آموزشی را در هر تکرار پردازش می‌کند.
    * پارامترهای مدل را به طور مکرر به‌روزرسانی می‌کند که می‌تواند منجر به همگرایی سریع‌تر شود.
* **مثال: رگرسیون خطی با تابع هزینه SSE:** $w^{t+1} = w^{t} + \eta(y^{(i)} - w^{\top}x^{(i)})x^{(i)}$ (که $x^{(i)}$ مشاهده $i$-ام است).

* **یادگیری آنلاین با SGD:** اغلب SGD بسیار سریع‌تر از Batch gradient descent به مینیمم نزدیک می‌شود.
    * با این حال، ممکن است هرگز دقیقاً به مینیمم همگرا نشود و پارامترها در اطراف مینیمم نوسان کنند.
    * در عمل، اکثر مقادیر نزدیک به مینیمم، تقریب‌های منطقی خوبی برای مینیمم واقعی خواهند بود.

---

### **5. رگرسیون چندجمله‌ای (Polynomial Regression)**

این بخش به چگونگی تعمیم رگرسیون خطی برای مدل‌سازی روابط غیرخطی می‌پردازد.

#### **5.1. محدودیت‌های رگرسیون خطی (Limitations of linear regression)**

ممکن است بهترین خط برازش شده، همچنان با الگوی واقعی نمونه‌ها فاصله زیادی داشته باشد.

یک خط نمی‌تواند برای تعمیم روی نمونه‌های نویزی که الگوی غیرخطی دارند (مانند نمودار در صفحه 66 PDF) مناسب باشد.

#### **5.2. فراتر از رگرسیون خطی (Beyond Linear Regression)**

* **چگونه می‌توان رگرسیون خطی را برای مدل‌سازی روابط غیرخطی گسترش داد؟**
* **تبدیل داده با استفاده از توابع پایه (Basis Functions):**
    * توابع پایه به ما اجازه می‌دهند ویژگی‌های اصلی را به یک فضای ویژگی جدید تبدیل کنیم.
    * توابع پایه رایج شامل توابع چندجمله‌ای و گاوسی هستند.
* **یادگیری یک رگرسیون خطی بر روی ویژگی‌های تبدیل‌شده:**
    * با اعمال رگرسیون خطی بر روی بردارهای ویژگی تبدیل‌شده، می‌توانیم روابط پیچیده و غیرخطی را مدل‌سازی کنیم.
    * این رویکرد سادگی و قابلیت تفسیر رگرسیون خطی را حفظ می‌کند، در حالی که انعطاف‌پذیری آن را گسترش می‌دهد.

* **مثال (صفحه 69 PDF):** تبدیل یک دایره نویزی (که خطی نیست) به فضایی که در آن با رگرسیون خطی قابل مدل‌سازی است (با تغییر پایه‌های $[1,x,y]$ به $[1,x^2,y^2]$).

#### **5.3. رگرسیون چندجمله‌ای: تک‌متغیره (Polynomial regression: Univariate)**

**فرضیه رگرسیون چندجمله‌ای:** یک رگرسیون مرتبه $m$ (Degree $m$ regression) به صورت:

$h(x;w)=w_{0}+w_{1}x^{1}+ \dots +w_{m-1}x^{m-1}+w_{m}x^{m}$

**هدف:** برازش یک چندجمله‌ای از درجه $m$ به نقاط داده.

**نماینده ماتریسی (صفحه 71 PDF):** مشابه رگرسیون خطی تک‌متغیره، می‌توان ماتریس $X'$ را ساخت که شامل قدرت‌های مختلف $x$ (تا $m$) باشد، و بردار وزن $w$ و بردار خروجی $y$.

#### **5.4. راه‌حل تحلیلی رگرسیون چندجمله‌ای: تک‌متغیره (Polynomial regression analytical solution: Univariate)**

با بازنویسی تابع هزینه SSE با استفاده از فرم ماتریسی، داریم: $J(w)=||y-X'w||_2^2$.

**راه‌حل تحلیلی:** رگرسیون چندجمله‌ای نیز دارای یک راه‌حل تحلیلی (closed-form solution) است: $\hat{w}=(X'^{\top}X')^{-1}X'^{\top}y$.

#### **5.5. آموزش و اعتبارسنجی (Training and Validation)**

برای تمایز بهتر بین رگرسیون خطی و رگرسیون چندجمله‌ای، نشان خواهیم داد که مدل خطی نمی‌تواند به خوبی تعمیم پیدا کند.

نمونه‌ها به دو زیرمجموعه تقسیم می‌شوند: **مجموعه داده آموزش (Train dataset)** که برای آموزش مدل رگرسیون استفاده می‌شود، و **مجموعه داده اعتبارسنجی (Validation dataset)** که برای یافتن بهترین مدل رگرسیون برای یک کاربرد استفاده می‌شود.

اگر یک مدل بتواند به خوبی در مجموعه اعتبارسنجی تعمیم پیدا کند، کاندیدای خوبی خواهد بود.

#### **5.6. مثال رگرسیون چندجمله‌ای (Polynomial regression: example)**

با استفاده از نمونه‌های نویزی نشان داده شده در صفحه 74 PDF، می‌توان رگرسیون خطی و رگرسیون درجه دوم (Quadratic Regression) را برازش داد.

برازش هر دو رگرسیون درجه دوم و خطی، قدرت رگرسیون چندجمله‌ای را در تعمیم برای الگوهای پیچیده‌تر نشان می‌دهد. مدل درجه دوم (منحنی) به وضوح بهتر از مدل خطی (خط راست) برازش پیدا می‌کند و تعمیم‌پذیری بهتری دارد.
