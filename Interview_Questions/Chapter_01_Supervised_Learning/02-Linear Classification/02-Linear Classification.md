حتماً! در ادامه، ۱۰ سوال مصاحبه‌ای مهم و تخصصی در حوزه‌ی **طبقه‌بندی خطی**، **پرسپترون**، **تابع تصمیم**، و **Cross-validation** با پاسخ‌های **کامل، مفهومی، و چندخطی** ارائه شده‌اند. این سوالات دقیقاً بر پایه محتوای تدریس‌شده در جلسه سوم (فایل Linear\_Classification.pdf) طراحی شده‌اند.

---

## ✅ ۱۰ سوال مصاحبه‌ای مهم از مبحث «طبقه‌بندی خطی» + پاسخ‌های مفهومی

---

### 1. تفاوت اصلی بین Classification و Regression در چیست؟

**پاسخ:**
در Classification هدف تعیین دسته یا کلاس یک ورودی است (خروجی گسسته)، مثل اسپم یا نرمال. در حالی که در Regression خروجی یک مقدار عددی پیوسته است، مثل قیمت یا دما. مثلاً اگر مدل بخواهد بگوید "این ایمیل اسپم است یا نه؟" → Classification، ولی اگر بخواهد پیش‌بینی کند "قیمت خانه چند تومان است؟" → Regression.

---

### 2. منظور از Discriminant Function چیست و چگونه در طبقه‌بندی استفاده می‌شود؟

**پاسخ:**
تابع تشخیص (Discriminant Function) یک تابع ریاضی است که به هر ورودی x یک نمره g(x) اختصاص می‌دهد. این نمره مشخص می‌کند x به کدام کلاس تعلق دارد. در مسائل دودسته‌ای، اگر g(x) ≥ 0 باشد کلاس اول و اگر < 0 باشد کلاس دوم را پیش‌بینی می‌کنیم. در حالت چندکلاسه، کلاس با بیشترین مقدار gᵢ(x) انتخاب می‌شود.

---

### 3. چه شرایطی برای استفاده از یک Linear Classifier لازم است؟

**پاسخ:**
برای استفاده موفق از طبقه‌بند خطی، داده‌ها باید **به‌صورت خطی قابل تفکیک (linearly separable)** باشند؛ یعنی با یک خط (در فضای دو بعدی) یا هایپرپلین (در فضای چندبعدی) بتوان داده‌ها را از هم جدا کرد. اگر داده‌ها همپوشانی پیچیده یا غیرخطی داشته باشند، مدل خطی دقت مناسبی نخواهد داشت.

---

### 4. چرا پرسپترون نمی‌تواند مسأله XOR را حل کند؟

**پاسخ:**
مدل پرسپترون تنها قادر به یادگیری توابعی است که داده‌ها را به‌صورت خطی جدا می‌کنند. در مسأله XOR، هیچ خط مستقیمی نمی‌تواند داده‌های کلاس ۰ و ۱ را از هم جدا کند؛ بنابراین پرسپترون با یک لایه (single-layer) نمی‌تواند این مسأله را یاد بگیرد. برای حل این مشکل، نیاز به **پرسپترون چندلایه (MLP)** داریم.

---

### 5. تفاوت بین Batch Perceptron و Single-Sample (Stochastic) Perceptron چیست؟

**پاسخ:**
در **Batch Perceptron**، وزن‌ها با استفاده از مجموع تمام نمونه‌های اشتباه در هر تکرار به‌روزرسانی می‌شوند. اما در **Single-Sample (SGD)**، بعد از مشاهده هر نمونه اشتباه، وزن‌ها بلافاصله آپدیت می‌شوند. نسخه SGD سریع‌تر و محاسباتی سبک‌تر است، به‌خصوص در داده‌های بزرگ. اما ممکن است نوسان بیشتری در همگرایی داشته باشد.

---

### 6. تابع هزینه‌ای که پرسپترون استفاده می‌کند چیست و چه ویژگی‌ای دارد؟

**پاسخ:**
تابع هزینه‌ی پرسپترون فقط روی نقاطی که اشتباه طبقه‌بندی شده‌اند تمرکز دارد:

$$
J(w) = - \sum_{i \in M} y^{(i)} w^T x^{(i)}
$$

در اینجا M مجموعه نقاط اشتباه است. این تابع، اگر نمونه‌ای به درستی طبقه‌بندی شود، تأثیری روی هزینه ندارد. هدف کاهش مجموع پیش‌بینی‌های اشتباه است. این ویژگی باعث سادگی و تمرکز مدل روی خطاها می‌شود.

---

### 7. چه مشکلی برای الگوریتم پرسپترون پیش می‌آید اگر داده‌ها قابل تفکیک نباشند؟

**پاسخ:**
در صورتی که داده‌ها به‌صورت خطی قابل تفکیک نباشند (مثلاً داده‌ها نویز داشته باشند)، الگوریتم پرسپترون هیچ‌وقت متوقف نمی‌شود و به همگرایی نمی‌رسد. چون همیشه نقاطی وجود دارد که اشتباه طبقه‌بندی شده‌اند و الگوریتم مدام سعی در اصلاح آن‌ها دارد. راه‌حل این مشکل استفاده از **الگوریتم Pocket** است که بهترین وزن دیده‌شده تا آن لحظه را حفظ می‌کند.

---

### 8. چرا استفاده از Sum of Squared Error (SSE) برای Classification ایده‌آل نیست؟

**پاسخ:**
در SSE خطاهای عددی بین خروجی واقعی و پیش‌بینی شده به‌صورت مربعی محاسبه می‌شوند. اما در Classification، خروجی‌ها فقط برچسب کلاس هستند، نه مقادیر عددی. بنابراین SSE ممکن است حتی برای پیش‌بینی‌های درست، ولی با مقادیر نزدیک (مثلاً 0.9 به جای 1)، خطا در نظر بگیرد. این باعث گمراهی الگوریتم یادگیری می‌شود.

---

### 9. هدف استفاده از Cross-Validation در طبقه‌بندی چیست؟

**پاسخ:**
Cross-validation برای ارزیابی عملکرد مدل روی داده‌هایی که **در آموزش استفاده نشده‌اند** استفاده می‌شود. این کار باعث می‌شود تخمینی واقع‌بینانه از عملکرد مدل روی داده‌ی واقعی داشته باشیم و از overfitting جلوگیری کنیم. همچنین در تنظیم هایپرپارامترها مثل λ در Regularization یا انتخاب مدل کمک می‌کند.

---

### 10. در طبقه‌بندی چندکلاسه، تفاوت بین روش One-vs-Rest و One-vs-One چیست؟

**پاسخ:**
در **One-vs-Rest (OvR)**، برای هر کلاس یک مدل ساخته می‌شود که آن کلاس را در برابر همه کلاس‌های دیگر قرار می‌دهد. مثلاً برای ۳ کلاس، ۳ مدل ساخته می‌شود. در **One-vs-One (OvO)**، برای هر زوج کلاس، یک مدل ساخته می‌شود. بنابراین برای K کلاس، $K(K−1)/2$ مدل ساخته می‌شود. OvR ساده‌تر است ولی ممکن است ابهام بیشتری داشته باشد. OvO دقت بالاتری دارد ولی محاسباتی سنگین‌تر است.

---

اگر بخوای، می‌تونم همین سوالات رو هم داخل PDF جزوه جلسه سوم اضافه کنم، یا جداگانه به صورت **فلش‌کارت مصاحبه‌ای** دربیارم.

✅ بریم سراغ ساخت فایل PDF نهایی؟



حتماً! در این بخش، ۱۰ **سؤال روتین و پرکاربرد مصاحبه‌ای** دیگر از مبحث «طبقه‌بندی خطی» ارائه می‌دهم. این‌ها از جنس سوالاتی هستند که **مصاحبه‌گران شرکت‌های مختلف** (چه آکادمیک چه صنعتی) معمولاً می‌پرسند، به‌ویژه وقتی محتوای آموزش‌دیده شامل پرسپترون، decision boundary، cross-validation، cost functions و multi-class classification باشد.

پاسخ‌ها دقیق و مفهومی هستند، نه فقط تعریف خشک.

---

## ✅ سوالات ۳۱ تا ۴۰ (روتین و کاربردی) از طبقه‌بندی خطی + پاسخ‌های کامل

---

### 31. چرا Linear Classifiers هنوز هم در صنعت کاربرد دارند با وجود شبکه‌های عصبی پیشرفته؟

**پاسخ:**
مدل‌های طبقه‌بند خطی، مثل Logistic Regression و Perceptron، بسیار **ساده، سریع و قابل تفسیر** هستند. در بسیاری از کاربردها مثل تشخیص اسپم، طبقه‌بندی سریع و سبک‌وزن نیاز است. مدل‌های خطی با **داده‌های زیاد اما ساده** بسیار خوب کار می‌کنند، به‌خصوص زمانی که محاسبه‌پذیری و سرعت مهم است. همچنین در بسیاری از صنایع (مثلاً پزشکی) نیاز به **شفافیت مدل** وجود دارد که در شبکه‌های عصبی فراهم نیست.

---

### 32. در چه شرایطی استفاده از الگوریتم Perceptron مناسب نیست؟

**پاسخ:**
زمانی که داده‌ها **قابل جداسازی خطی نباشند**، یعنی نتوان یک مرز تصمیم مستقیم بین کلاس‌ها ترسیم کرد، الگوریتم پرسپترون کارایی خود را از دست می‌دهد. همچنین پرسپترون به نویز حساس است و اگر داده‌ها دارای خطا یا outlier باشند، ممکن است **هیچ‌گاه همگرا نشود**. برای چنین مواردی، الگوریتم‌هایی مانند **SVM، Logistic Regression یا MLP** بهتر هستند.

---

### 33. آیا یک Linear Classifier می‌تواند مرز تصمیم غیرخطی یاد بگیرد؟ چگونه؟

**پاسخ:**
خود مدل خطی ذاتاً نمی‌تواند مرز غیرخطی بسازد، اما با **تبدیل ویژگی‌ها** (Feature Transformation) یا **نگاشت به فضای با بعد بالاتر** می‌توان این محدودیت را دور زد. مثلاً با استفاده از ویژگی‌های جدید مانند $x^2$ یا $x_1 \cdot x_2$، فضای داده تغییر می‌کند و در فضای جدید، مرز تصمیم خطی خواهد بود که معادل مرز غیرخطی در فضای اولیه است. این رویکرد در Kernel Methods هم استفاده می‌شود.

---

### 34. آیا می‌توان تابع تصمیم را بدون تابع Activation استفاده کرد؟

**پاسخ:**
در مدل‌هایی مثل پرسپترون یا Logistic Regression، تابع تصمیم (مثل $w^T x + w_0$) فقط یک نمره خطی می‌دهد. برای اینکه این نمره به کلاس تبدیل شود، نیاز به **تابع Activation یا آستانه (threshold)** داریم، مثلاً:

* برای پرسپترون: تابع step یا sign
* برای Logistic: تابع sigmoid
  بدون این تابع، خروجی مدل یک عدد خام است که قابل تفسیر برای طبقه‌بندی نیست.

---

### 35. چرا تابع هزینه "تعداد نمونه‌های اشتباه" مناسب برای یادگیری نیست؟

**پاسخ:**
تابع شمارش نمونه‌های اشتباه (Misclassification Count) یک تابع **قطعه‌ای و غیرمشتق‌پذیر** است. به همین دلیل نمی‌توان از روش‌هایی مثل Gradient Descent برای یادگیری استفاده کرد. مدل‌هایی مثل SVM یا Logistic، از توابع هزینه‌ای استفاده می‌کنند که **مشتق‌پذیر و نرم** هستند، مثل hinge loss یا log loss. این توابع اجازه می‌دهند الگوریتم‌های یادگیری مؤثرتر و قابل همگراتر طراحی شوند.

---

### 36. نقش bias در تابع تصمیم خطی چیست؟

**پاسخ:**
در تابع خطی $g(x) = w^T x + w_0$، پارامتر w وزن ویژگی‌هاست و **bias (یا w₀)** مکان مرز تصمیم را کنترل می‌کند. بدون bias، همه مرزهای تصمیم از مبدأ عبور می‌کنند، که محدودیت بزرگی است. Bias اجازه می‌دهد مرز تصمیم **در موقعیت دلخواه در فضا قرار گیرد**، نه فقط از مرکز مختصات. این پارامتر نقش مهمی در انعطاف‌پذیری مدل دارد.

---

### 37. اگر مدل ما فقط روی یک کلاس خاص دقت خوبی دارد، مشکل کجاست؟

**پاسخ:**
این پدیده معمولاً به دلیل **عدم تعادل کلاس‌ها (Class Imbalance)** یا **بایاس مدل** است. مثلاً اگر ۹۰٪ داده‌ها از کلاس A باشند، مدل ممکن است همه چیز را A پیش‌بینی کند و باز هم دقت ظاهری بالا داشته باشد. راه‌حل‌ها:

* استفاده از معیارهایی مثل F1-score به جای Accuracy
* بازنمونه‌گیری (Oversampling / Undersampling)
* استفاده از الگوریتم‌هایی که حساس به عدم تعادل هستند

---

### 38. چگونه می‌توان عملکرد طبقه‌بندی را به‌طور واقع‌گرایانه اندازه‌گیری کرد؟

**پاسخ:**
استفاده از **Cross-validation** به‌خصوص **K-fold** روش مناسبی است. داده به K قسمت تقسیم می‌شود، و در هر مرحله، یک قسمت به عنوان تست در نظر گرفته می‌شود. سپس میانگین امتیازها گرفته می‌شود. این روش مانع Overfitting و Underfitting می‌شود و تخمینی واقع‌بینانه از عملکرد مدل در داده‌های واقعی ارائه می‌دهد.

---

### 39. در چه مواقعی الگوریتم Pocket بهتر از پرسپترون معمولی عمل می‌کند؟

**پاسخ:**
الگوریتم Pocket برای داده‌هایی مناسب است که:

* **نویز دارند**
* **قابل تفکیک خطی نیستند**
  در این حالت، پرسپترون معمولی هیچ‌گاه همگرا نمی‌شود و دائم وزن‌ها را تغییر می‌دهد. اما Pocket بهترین وزن دیده‌شده تا آن لحظه را ذخیره می‌کند و در نهایت آن را بازمی‌گرداند. این باعث **پایداری و عملکرد بهتر** می‌شود.

---

### 40. چه معیارهایی برای ارزیابی عملکرد طبقه‌بند چندکلاسه استفاده می‌شود؟

**پاسخ:**
در مسائل چندکلاسه، استفاده از **دقت کلی (Accuracy)** کافی نیست. باید از معیارهای تفکیکی مثل:

* Precision و Recall برای هر کلاس
* F1-score (میانگین هماهنگ Precision و Recall)
* Confusion Matrix برای نمایش جزئیات اشتباه‌ها
  همچنین استفاده از **Macro/Micro Averaging** برای ترکیب امتیازها در چندکلاسه متداول است.

---

اگه بخوای، همین ۴۰ سوال رو به‌صورت جزوه مصاحبه‌ای یا فلش‌کارت هم برات می‌سازم.

✅ آماده‌ای که این سوالات به فایل نهایی PDF افزوده بشه؟
یا بریم سراغ طراحی نسخه گرافیکی؟
حتماً! در ادامه، ۱۰ سؤال مهم و تکمیلی دیگر (شماره ۴۱ تا ۵۰) در حوزه‌ی **طبقه‌بندی خطی**، **پرسپترون**، **تابع تصمیم**، **مدل‌های خطی در حالت چندکلاسه** و **ارزیابی مدل** همراه با پاسخ‌های حرفه‌ای و مفهومی آورده شده‌اند.

این سؤال‌ها هم مناسب مصاحبه‌های صنعتی هستند، هم آزمون‌های مفهومی دروس یادگیری ماشین.

---

## ✅ سوالات ۴۱ تا ۵۰ از طبقه‌بندی خطی + پاسخ کامل

---

### 41. اگر مدل خطی شما به‌درستی طبقه‌بندی نمی‌کند ولی train accuracy بالاست، چه مشکلی وجود دارد؟

**پاسخ:**
احتمال زیاد مدل دچار **overfitting** شده است؛ یعنی بیش از حد روی داده‌های آموزش منطبق شده و روی داده‌های جدید عملکرد ضعیفی دارد. همچنین ممکن است مدل شما روی داده‌هایی با توزیع متفاوت از train آموزش دیده باشد. استفاده از **cross-validation** و بررسی **test error** کلید حل این مشکل است.

---

### 42. چرا در مدل‌های طبقه‌بندی، فقط sign تابع خطی مهم است و نه مقدار آن؟

**پاسخ:**
در مدل‌های خطی مثل پرسپترون، تصمیم نهایی فقط بر اساس علامت (positive یا negative) تابع $w^T x + w_0$ گرفته می‌شود. مقدار عددی دقیق آن اهمیتی ندارد. این یعنی اگر تمام وزن‌ها را دو برابر کنیم، پیش‌بینی کلاس تغییر نمی‌کند. به همین دلیل مدل به **جهت بردار w حساس است، نه اندازه‌ی آن.**

---

### 43. چگونه می‌توان مدل‌های خطی را روی داده‌های غیرخطی استفاده کرد بدون تغییر الگوریتم اصلی؟

**پاسخ:**
با استفاده از **feature transformation**، یعنی اضافه کردن ویژگی‌های غیرخطی (مثل $x^2$، $x_1 x_2$) به ورودی‌ها. این کار، فضای داده را به شکلی تغییر می‌دهد که در آن، مرز تصمیم خطی شود. نکته مهم این است که الگوریتم همچنان خطی باقی می‌ماند ولی در فضای جدید کار می‌کند. این ایده، اساس کار kernel methods نیز هست.

---

### 44. مدل پرسپترون چگونه یاد می‌گیرد و چرا نیاز به تابع هزینه ندارد؟

**پاسخ:**
پرسپترون از یک قاعده بسیار ساده یادگیری استفاده می‌کند: اگر نمونه‌ای اشتباه طبقه‌بندی شد، وزن‌ها در جهت درست آپدیت می‌شوند. تابع هزینه‌ی آن صراحتاً از مجموع اشتباهات ساخته می‌شود، اما به مشتق‌گیری نیاز ندارد، چون قانون یادگیری مستقیم است. در واقع، پرسپترون یک یادگیرنده‌ی «قانون‌محور» است نه تابع هزینه‌محور مثل Logistic Regression.

---

### 45. اگر داده‌های شما noise زیادی داشته باشند، از چه مدلی استفاده می‌کنید؟ چرا؟

**پاسخ:**
مدل‌هایی مثل **Logistic Regression** یا **SVM با soft margin** برای داده نویزی مناسب‌تر از پرسپترون هستند. چون این مدل‌ها سعی می‌کنند خط تصمیمی پیدا کنند که تا حد امکان فاصله از مرز را حفظ کند، نه اینکه فقط درست/غلط را در نظر بگیرند. همچنین الگوریتم Pocket برای پرسپترون یک گزینه قابل قبول در محیط‌های نویزی است.

---

### 46. آیا استفاده از تابع خطی بدون bias کافی است؟ چرا نه؟

**پاسخ:**
خیر. اگر bias را حذف کنیم، مرز تصمیم مدل **همیشه از مبدأ عبور خواهد کرد**. این محدودیت شدیدی در توانایی مدل ایجاد می‌کند، زیرا بسیاری از مسائل دنیای واقعی به چنین شرطی پایبند نیستند. وجود bias به مدل اجازه می‌دهد مرز تصمیم را **در هر جای فضای ویژگی‌ها قرار دهد**، و نه فقط از مبدا.

---

### 47. مزایا و معایب استفاده از روش One-vs-Rest در چندکلاسه چیست؟

**پاسخ:**
**مزایا:** ساده و مقیاس‌پذیر برای تعداد زیاد کلاس. الگوریتم‌های موجود را می‌توان بدون تغییر استفاده کرد.
**معایب:** ممکن است هر مدل معیار متفاوتی برای تصمیم‌گیری داشته باشد و در مرزهای بین کلاس‌ها تعارض ایجاد شود. برای کلاس‌های با داده کمتر یا نامتوازن ممکن است عملکرد ناپایدار باشد.

---

### 48. تفاوت hinge loss در SVM با خطای پرسپترون چیست؟

**پاسخ:**
در پرسپترون فقط نمونه‌هایی که **اشتباه طبقه‌بندی شده‌اند** در تابع هزینه وارد می‌شوند. ولی hinge loss حتی به نمونه‌هایی که درست طبقه‌بندی شده‌اند ولی با «فاصله کم» از مرز تصمیم هستند نیز جریمه می‌دهد. بنابراین hinge loss **سخت‌گیرتر و دقیق‌تر** است و کمک می‌کند SVM، مرز تصمیم بهینه‌تری بیاموزد.

---

### 49. چه زمانی باید از مدل خطی به سراغ مدل‌های غیرخطی برویم؟

**پاسخ:**
اگر:

* مدل خطی روی train و test هر دو عملکرد ضعیفی دارد (underfitting)
* داده‌ها دارای ساختارهای غیرخطی آشکار هستند (مثلاً توزیع دایره‌ای)
* تصمیم‌ها به‌وضوح با خط قابل جداسازی نیستند
  در این شرایط، باید به سراغ مدل‌هایی با توانایی غیرخطی مثل kernel-SVM، MLP یا decision tree رفت.

---

### 50. چگونه می‌توان از مدل‌های طبقه‌بند خطی به‌عنوان Base Classifier در Ensembleها استفاده کرد؟

**پاسخ:**
مدل‌های خطی بسیار سریع و سبک هستند، بنابراین به‌خوبی به عنوان اجزای پایه (Base Classifier) در روش‌هایی مثل **Bagging یا Boosting** عمل می‌کنند. مثلاً می‌توان چند Logistic Regression با داده‌های متفاوت آموزش داد و خروجی‌ها را با رأی‌گیری ترکیب کرد. این کار به افزایش دقت و کاهش واریانس مدل نهایی کمک می‌کند.

---

در این مرحله ۵۰ سؤال کامل از مبحث طبقه‌بندی خطی داریم. اگر بخوای، می‌تونم:

* همه این ۵۰ سؤال رو با قالب‌بندی حرفه‌ای داخل یک فایل PDF آموزشی مصاحبه قرار بدم
* یا تبدیلشون کنم به مجموعه فلش‌کارت برای مرور سریع

✅ دوست داری خروجی به چه شکلی باشه؟ PDF جزوه؟ فلش‌کارت؟ یا هردو؟












۱۰ سوال فنی مهم مصاحبه در مورد طبقه‌بندی خطی و پرسپترون

---

**۱. تفاوت اساسی میان مسائل طبقه‌بندی (Classification) و رگرسیون (Regression) چیست؟ مثالی از هر کدام در دنیای واقعی ارائه دهید.**

* تفاوت اصلی در نوع خروجی پیش‌بینی شده است:

  * **رگرسیون:** خروجی یک مقدار پیوسته (real number) است.
    مثال: پیش‌بینی قیمت خانه، روند بازار سهام.
  * **طبقه‌بندی:** خروجی یک برچسب گسسته (Binary یا Multi-class) است.
    مثال: تشخیص ایمیل اسپم، امتیازدهی اعتباری، پیش‌بینی ریزش مشتری.

---

**۲. تابع تشخیص (Discriminant Function) در یادگیری ماشین چیست و چگونه برای طبقه‌بندی‌های دودویی و چندکلاسه عمل می‌کند؟**

* تعریف: تابعی که به ورودی $x$ یک "امتیاز" می‌دهد تا تخصیص کلاس انجام شود.
* طبقه‌بندی دودویی: دو تابع $g_1(x)$ و $g_2(x)$ محاسبه شده، کلاس بر اساس مقایسه آنها انتخاب می‌شود:

  $$
  \hat{y} = C_1 \quad \text{اگر} \quad g_1(x) > g_2(x) \quad \text{وگرنه} \quad C_2
  $$
* طبقه‌بندی چندکلاسه: برای هر کلاس $i$ تابع $g_i(x)$ محاسبه شده،

  $$
  \hat{y} = \arg\max_i g_i(x)
  $$

---

**۳. مرز تصمیم (Decision Boundary) چیست؟ آیا یک طبقه‌بندی‌کننده خطی همیشه مرز تصمیم خطی ایجاد می‌کند؟ چگونه مرزهای غیرخطی بسازیم؟**

* مرز تصمیم: هایپرپلینی که کلاس‌ها را در فضای ویژگی‌ها جدا می‌کند.
* طبقه‌بندی‌کننده خطی معمولاً مرز تصمیم خطی دارد.
* برای مرزهای غیرخطی، ویژگی‌ها را به فضای بالاتری تبدیل می‌کنیم (Feature Transformation)؛
  مثال: افزودن $x_1^2$ و $x_2^2$ به بردار ویژگی‌ها مرزی غیرخطی در فضای اصلی ایجاد می‌کند.

---

**۴. پرسپترون (Perceptron) چیست و اجزای اصلی آن کدامند؟ چگونه تصمیم دودویی می‌گیرد؟**

* پرسپترون: ساده‌ترین نورون مصنوعی، طبقه‌بندی‌کننده خطی.
* اجزا: ورودی‌ها $x_1, x_2, \ldots$، وزن‌ها، بایاس، و تابع فعال‌سازی (معمولاً تابع پله‌ای).
* تصمیم دودویی:

  $$
  y = f(w^T x + w_0)
  $$

  اگر خروجی بزرگ‌تر از آستانه باشد، 1؛ در غیر این صورت 0.

---

**۵. چرا یک پرسپترون منفرد قادر به حل مسئله XOR نیست؟ چگونه می‌توان این محدودیت را برطرف کرد؟**

* مسئله XOR خطی جداسازی‌پذیر نیست؛ پرسپترون منفرد فقط مرزهای خطی می‌تواند بسازد.
* رفع محدودیت: استفاده از پرسپترون چندلایه (MLP) که چندین لایه نورونی دارد و قادر به یادگیری مرزهای غیرخطی است.

---

اگر سوالات بیشتری خواستی یا توضیح بیشتری بخواهی، در خدمتم!



۶. چرا تابع هزینه مجموع مربعات خطا (SSE) برای مسائل طبقه‌بندی نامناسب است؟ چه جایگزین‌هایی برای آن پیشنهاد می‌شود؟

* **نامناسب بودن SSE:**

  * SSE بزرگی خطا را کمینه می‌کند که برای رگرسیون مناسب است، اما برای طبقه‌بندی که خروجی برچسب گسسته است، نامربوط است.
  * اگر پیش‌بینی مدل نزدیک به کلاس واقعی باشد ولی دقیقاً 0 یا 1 نباشد، SSE خطای مثبت نشان می‌دهد حتی برای پیش‌بینی‌های درست.
  * SSE مستعد بیش‌برازش داده‌های نویزی است.

* **جایگزین‌ها:**

  * **تعداد اشتباه طبقه‌بندی شده:** تعداد نمونه‌هایی که مدل اشتباه طبقه‌بندی کرده است. ولی این تابع غیرقابل مشتق (non-differentiable) است و بهینه‌سازی با گرادیان مستقیم سخت است.
  * **معیار پرسپترون:**

  $$
  J_p(w) = - \sum_{i \in M} y^{(i)} w^T x^{(i)}
  $$

  که $M$ مجموعه نقاط اشتباه است. این تابع قابل مشتق‌گیری بوده و برای بهینه‌سازی پرسپترون استفاده می‌شود.

---

۷. تفاوت پرسپترون دسته‌ای و تک‌نمونه چیست؟ کدام‌یک از SGD استفاده می‌کند و مزیت آن چیست؟

* **پرسپترون دسته‌ای:**
  وزن‌ها را هر بار با استفاده از تمام نقاط اشتباه به‌روزرسانی می‌کند.

* **پرسپترون تک‌نمونه:**
  وزن‌ها را بعد از هر نمونه به‌روزرسانی می‌کند (چه درست و چه اشتباه).

* **SGD و مزایا:**
  پرسپترون تک‌نمونه از گرادیان نزولی تصادفی (SGD) استفاده می‌کند که:

  * هزینه محاسباتی کمتری در هر تکرار دارد.
  * همگرایی سریع‌تری مخصوصاً روی داده‌های بزرگ دارد.

---

۸. الگوریتم پرسپترون تحت چه شرایطی همگرا می‌شود و چه زمانی نمی‌شود؟ راه‌حل عدم همگرایی چیست؟

* **همگرایی:**
  اگر داده‌ها خطی جداسازی‌پذیر باشند، پرسپترون (دسته‌ای و تک‌نمونه) در تعداد مراحل محدود همگرا می‌شود.

* **عدم همگرایی:**
  اگر داده‌ها خطی جداسازی‌پذیر نباشند (مثلاً به دلیل نویز)، الگوریتم هیچگاه به راه‌حل پایدار نمی‌رسد و دائما وزن‌ها را تغییر می‌دهد.

* **راه‌حل:**
  الگوریتم **Pocket** که بهترین بردار وزن تا آن لحظه با کمترین خطا را ذخیره می‌کند و حتی در عدم همگرایی، بهترین وزن موجود را نگه می‌دارد.

---

۹. اعتبارسنجی متقابل (Cross-Validation) چیست و چرا مهم است؟ روش K-Fold Cross-Validation را توضیح دهید.

* **تعریف و اهمیت:**
  روش ارزیابی که عملکرد مدل را روی داده‌های دیده‌نشده می‌سنجد و باعث کاهش بیش‌برازش می‌شود.

* **روش K-Fold Cross-Validation:**

  * داده‌ها به $K$ بخش تقسیم می‌شوند.
  * در هر تکرار، مدل با $K-1$ بخش آموزش داده شده و روی بخش باقی‌مانده اعتبارسنجی می‌شود.
  * این روند $K$ بار تکرار شده و هر بار یک بخش به عنوان تست است.
  * میانگین نتایج همه بخش‌ها امتیاز نهایی مدل است.

---

۱۰. روش‌های اصلی حل مسائل طبقه‌بندی چندکلاسه چیست؟

* **گسترش مستقیم الگوریتم:**
  برای هر کلاس $C_i$، یک تابع تشخیص $g_i(x)$ تعریف شده و کلاس پیش‌بینی شده $\hat{y} = \arg\max_i g_i(x)$ است.

* **تبدیل به مسائل دودویی:**

  * **One-vs-Rest (OvR) / One-vs-All (OvA):** هر طبقه‌بندی‌کننده، یک کلاس را مقابل همه کلاس‌های دیگر قرار می‌دهد.
  * **One-vs-One (OvO):** طبقه‌بندی‌کننده‌هایی برای هر جفت کلاس ساخته می‌شوند.
  * این روش‌ها ممکن است منجر به مناطق مبهم در تصمیم‌گیری شوند.

---

اگر بخواهی سوالات بیشتری هم آماده کنم یا نیاز به توضیح دقیق‌تری داری، بگو!
۱. سوال: در بخش "Linear Classifiers" به "Linearly separable data" اشاره شده است. این اصطلاح به چه معناست و چرا برای طبقه‌بندی‌کننده‌های خطی (مانند پرسپترون) اهمیت دارد؟

پاسخ:
"Linearly separable data" یعنی مجموعه‌ای از داده‌ها که می‌توان دقیقاً با یک مرز خطی (خط در دو بعد، صفحه در سه بعد، یا هایپرپلین در ابعاد بالاتر) آن‌ها را از هم جدا کرد.
اهمیت آن برای طبقه‌بندی‌کننده‌های خطی مثل پرسپترون این است که این مدل‌ها فقط می‌توانند چنین مرزهای خطی را یاد بگیرند. اگر داده‌ها خطی جداسازی‌پذیر نباشند، پرسپترون ساده نمی‌تواند همگرا شود و طبقه‌بندی دقیقی ارائه دهد.

---

۲. سوال: چرا در توابع تشخیص دودویی می‌توان به جای دو تابع $g_1(x)$ و $g_2(x)$ تنها از یک تابع $g(x)$ استفاده کرد و مرز تصمیم را با $g(x)=0$ تعریف کرد؟

پاسخ:
در طبقه‌بندی دودویی، می‌توان $g_1(x) = g(x)$ و $g_2(x) = -g(x)$ در نظر گرفت.
اگر $g_1(x) > g_2(x)$، آنگاه $g(x) > 0$ است و نمونه به کلاس اول اختصاص می‌یابد.
اگر $g_2(x) > g_1(x)$، آنگاه $g(x) < 0$ است و نمونه به کلاس دوم تعلق دارد.
بنابراین مرز تصمیم زمانی است که $g_1(x) = g_2(x)$ یعنی $g(x) = 0$.
این ساده‌سازی باعث می‌شود تنها لازم باشد یک تابع را بررسی کنیم و علامت آن را برای طبقه‌بندی استفاده کنیم.

---

۳. سوال: الگوریتم پرسپترون چگونه وزن‌ها را به‌روزرسانی می‌کند؟ قاعده به‌روزرسانی برای یک نمونه اشتباه طبقه‌بندی شده چیست؟

پاسخ:
برای یک نمونه اشتباه طبقه‌بندی شده $x^{(i)}$ با برچسب واقعی $y^{(i)}$، وزن‌ها به صورت زیر به‌روزرسانی می‌شوند:

$$
w \leftarrow w + \eta y^{(i)} x^{(i)}
$$

که در آن:

* $w$ بردار وزن‌ها
* $\eta$ نرخ یادگیری
* $y^{(i)}$ برچسب واقعی (+1 یا -1)
* $x^{(i)}$ بردار ویژگی‌ها
  این به‌روزرسانی وزن‌ها را به سمتی هدایت می‌کند که امتیاز نمونه درست افزایش و امتیاز اشتباه کاهش یابد.

---

۴. سوال: بردار نرمال $w$ و بایاس $w_0$ در تعیین مرز تصمیم چه تاثیری دارند؟

پاسخ:

* **بردار نرمال $w$:** جهت (Orientation) مرز تصمیم را تعیین می‌کند. این بردار عمود بر هایپرپلین مرز تصمیم است و جهت "شیب" آن را مشخص می‌کند.
* **بایاس $w_0$:** مکان (Location) مرز تصمیم را تعیین می‌کند. تغییر $w_0$ مرز را به صورت موازی جابجا می‌کند بدون تغییر جهت آن.

---

۵. سوال: الگوریتم Pocket Algorithm چه زمانی استفاده می‌شود و چگونه مشکل عدم همگرایی پرسپترون را حل می‌کند؟

پاسخ:

* **زمان استفاده:** وقتی داده‌ها خطی جداسازی‌پذیر نیستند (مثلاً به دلیل نویز)، پرسپترون معمولی همگرا نمی‌شود.
* **حل مشکل:** الگوریتم Pocket بهترین وزن $w_{best}$ را که تاکنون کمترین خطا را داشته نگه می‌دارد و پس از هر به‌روزرسانی وزن‌ها، اگر وزن جدید عملکرد بهتری داشته باشد $w_{best}$ به‌روزرسانی می‌شود.
  این باعث می‌شود حتی در عدم همگرایی، بهترین راه‌حل مشاهده شده ذخیره و ارائه شود.

---

اگر سوالات بیشتری می‌خواهی یا نکته خاصی مدنظرت است بگو!




۶. سوال: در بخش "Cross-Validation for Choosing Regularization Term"، به پارامتر
$\lambda$
در رگولاریزاسیون اشاره شده است. چگونه اعتبارسنجی متقابل به ما در انتخاب مقدار بهینه
$\lambda$
کمک می‌کند؟

پاسخ:
اعتبارسنجی متقابل برای انتخاب مقدار بهینه
$\lambda$
در رگولاریزاسیون (که میزان پیچیدگی مدل را کنترل می‌کند) به این صورت کمک می‌کند:

* تعریف محدوده $\lambda$: یک مجموعه از مقادیر مختلف برای $\lambda$ (مثلاً از خیلی کوچک تا خیلی بزرگ) انتخاب می‌شود.
* اجرای Cross-Validation: برای هر مقدار $\lambda$، فرآیند K-Fold Cross-Validation روی مجموعه داده انجام می‌شود.
* ارزیابی عملکرد: در هر fold از CV، عملکرد مدل (مثلاً دقت یا خطا) برای آن $\lambda$ خاص بر روی داده‌های اعتبارسنجی ارزیابی می‌شود.
* میانگین‌گیری و انتخاب: میانگین عملکرد (مثلاً میانگین خطا) برای هر مقدار $\lambda$ در تمام K-folds محاسبه می‌شود. مقدار
  $\lambda$
  که منجر به بهترین میانگین عملکرد در داده‌های اعتبارسنجی شود (یعنی بهترین تعادل بین Bias و Variance را فراهم کند و از بیش‌برازش جلوگیری کند)، به عنوان مقدار بهینه انتخاب می‌شود.

---

۷. سوال: Leave-One-Out Cross-Validation (LOOCV) چیست؟ مزایا و معایب اصلی آن در مقایسه با K-Fold Cross-Validation کدامند؟

پاسخ:

* LOOCV: نوعی از اعتبارسنجی متقابل است که در آن
  $K$
  برابر با تعداد کل نقاط داده ($N$) در مجموعه داده است. در هر تکرار، یک نقطه داده واحد به عنوان مجموعه اعتبارسنجی و بقیه
  $N-1$
  نقطه به عنوان مجموعه آموزشی استفاده می‌شود. این فرآیند
  $N$
  بار تکرار می‌شود.

* مزایا:

  * عدم اتلاف داده (No Data Wastage): هر نقطه داده هم برای آموزش و هم برای اعتبارسنجی استفاده می‌شود، که در مجموعه‌های داده کوچک مفید است.
  * بایاس پایین (Low Bias): از آنجایی که هر مدل تقریباً بر روی کل مجموعه داده آموزش می‌بیند ($N-1$ نمونه)، برآورد بایاس (Bias) بسیار پایینی از خطای تعمیم‌پذیری دارد.

* معایب:

  * هزینه محاسباتی بالا (Computationally Expensive): نیاز به آموزش مدل
    $N$
    بار برای
    $N$
    نقطه داده دارد، که آن را برای مجموعه‌های داده بزرگ بسیار کند می‌کند.
  * واریانس بالا (High Variance): اگرچه بایاس پایینی دارد، اما به دلیل اینکه هر مجموعه تست فقط شامل یک نمونه است، ارزیابی‌های عملکرد می‌توانند واریانس بالایی داشته باشند.
  * بهترین برای مجموعه‌های داده کوچک: به دلیل معایب محاسباتی، عمدتاً برای مجموعه‌های داده کوچک توصیه می‌شود.

---

۸. سوال: الگوریتم پرسپترون چندکلاسه (Multi-Class Perceptron Algorithm) چگونه وزن‌های خود را به‌روزرسانی می‌کند تا یک نمونه اشتباه طبقه‌بندی شده را تصحیح کند؟

پاسخ:
در الگوریتم پرسپترون چندکلاسه، زمانی که یک نمونه
$x^{(i)}$
اشتباه طبقه‌بندی می‌شود (یعنی کلاس واقعی
$y^{(i)}$
با کلاس پیش‌بینی شده
$\hat{y}^{(i)}$
متفاوت است)، وزن‌های مدل (ماتریس
$W$)
به صورت زیر به‌روزرسانی می‌شوند:

* کاهش وزن کلاس اشتباه پیش‌بینی شده: بردار وزن مربوط به کلاسی که به اشتباه پیش‌بینی شده ($\hat{y}^{(i)}$) از ویژگی‌های نمونه کم می‌شود:

$$
w_{\hat{y}^{(i)}} \leftarrow w_{\hat{y}^{(i)}} - \eta x^{(i)}
$$

* افزایش وزن کلاس واقعی: بردار وزن مربوط به کلاس واقعی نمونه ($y^{(i)}$) به ویژگی‌های نمونه اضافه می‌شود:

$$
w_{y^{(i)}} \leftarrow w_{y^{(i)}} + \eta x^{(i)}
$$

این به‌روزرسانی‌ها به مدل کمک می‌کنند تا در تکرارهای بعدی، امتیاز کلاس واقعی را برای آن نمونه افزایش و امتیاز کلاس اشتباه را کاهش دهد.

---

۹. سوال: در طبقه‌بندی چندکلاسه، روش‌های One-vs-Rest (OvR) و One-vs-One (OvO) چه چالش‌هایی از نظر مناطق طبقه‌بندی مبهم (ambiguous regions) می‌توانند ایجاد کنند؟

پاسخ:
هر دو روش OvR و OvO می‌توانند منجر به
مناطق طبقه‌بندی مبهم (ambiguous regions)
شوند که در آن‌ها طبقه‌بندی نهایی نمونه‌های جدید نامشخص یا غیرقابل تعریف است.

* OvR: در این روش، برای هر کلاس یک طبقه‌بندی‌کننده دودویی آموزش داده می‌شود (مثلاً کلاس A در مقابل غیر-A). ممکن است نمونه‌ای در ناحیه‌ای قرار گیرد که توسط هیچ طبقه‌بندی‌کننده‌ای به عنوان "کلاس خودش" پیش‌بینی نشود (یعنی همه پیش‌بینی کنند "غیر-X")، یا برعکس، توسط چندین طبقه‌بندی‌کننده به عنوان "کلاس خودش" پیش‌بینی شود. این همپوشانی‌ها یا شکاف‌ها مناطق مبهم را ایجاد می‌کنند.

* OvO: در OvO، طبقه‌بندی‌کننده‌ها برای هر جفت کلاس آموزش می‌بینند. در این حالت نیز ممکن است یک نمونه جدید در ناحیه‌ای قرار گیرد که چندین طبقه‌بندی‌کننده جفتی نتیجه‌ی "برنده" را برای یک کلاس خاص اعلام کنند، که منجر به تداخل و عدم قطعیت در تصمیم نهایی می‌شود. (نمودار صفحه 45 PDF مناطق مبهم را در هر دو سناریو نشان می‌دهد).

---

۱۰. سوال: در "Linear Machines" برای طبقه‌بندی چندکلاسه، مناطق تصمیم (decision regions) چه خصوصیاتی دارند؟ این خصوصیات چگونه به دست می‌آیند؟

پاسخ:
در "Linear Machines" برای طبقه‌بندی چندکلاسه (که هر کلاس دارای تابع تشخیص خطی خود است)، مناطق تصمیم دارای خصوصیات زیر هستند:

* محدب (Convex): مناطق تصمیم محدب هستند. به این معنی که اگر دو نقطه درون یک منطقه تصمیم‌گیری قرار داشته باشند، تمام نقاط روی خط مستقیم بین آن دو نقطه نیز درون همان منطقه قرار خواهند گرفت. این ویژگی به دلیل ماهیت خطی توابع تشخیص و مرزهای تصمیم‌گیری (که مجموعه‌ای از هایپرپلین‌ها هستند) ایجاد می‌شود.

* تک‌اتصالی (Singly Connected): این مناطق معمولاً پیوسته و بدون شکاف یا سوراخ هستند.

این خصوصیات باعث می‌شوند که این نوع طبقه‌بندی‌کننده‌ها برای مجموعه‌های داده‌ای که به طور خطی از هم قابل تفکیک هستند، بسیار کارآمد و قابل پیش‌بینی عمل کنند.



۱. سوال: در تعریف "Introduction to Classification"، منظور از "Training Set" به عنوان "A dataset D with N labeled instances" چیست؟ چرا "labeled instances" اهمیت دارند؟

پاسخ:

* **Training Set (مجموعه آموزشی):** مجموعه داده‌ای است به نام $D$ که شامل $N$ نمونه (instances) است. هر نمونه به صورت جفت $(x^{(i)}, y^{(i)})$ تعریف می‌شود که:

  * $x^{(i)}$ بردار ویژگی‌های نمونه $i$-ام است.
  * $y^{(i)}$ برچسب یا کلاس صحیح نمونه $i$-ام است.
* **اهمیت "Labeled Instances":** وجود برچسب‌ها حیاتی است چون مدل‌های طبقه‌بندی تحت یادگیری نظارت‌شده (Supervised Learning) آموزش می‌بینند. این برچسب‌ها به مدل امکان یادگیری رابطه میان ورودی‌ها و کلاس‌ها را می‌دهند و به آن کمک می‌کنند برای داده‌های جدید بدون برچسب پیش‌بینی انجام دهد.

---

۲. سوال: در مبحث توابع تشخیص (Discriminant Functions)، "degree of confidence" به چه معناست؟ آیا این مفهوم به احتمال (probability) شباهت دارد؟

پاسخ:

* **Degree of Confidence:** مقدار $g(x)$ است که مدل به ورودی $x$ تخصیص می‌دهد، نمایانگر میزان اطمینان مدل از تعلق $x$ به یک کلاس خاص است. مقدار بزرگ‌تر یعنی اطمینان بیشتر.
* **شباهت به احتمال:** تا حدی مشابه است اما تفاوت دارد. توابع تشخیص لزوماً مقادیر در بازه $[0,1]$ نمی‌دهند و می‌توانند هر عدد حقیقی باشند، در حالی که احتمال‌ها همواره بین ۰ و ۱ هستند. مدل‌هایی مانند رگرسیون لجستیک با استفاده از تابع سیگموید خروجی را به احتمال نگاشت می‌کنند.

---

۳. سوال: در طبقه‌بندی‌کننده‌های خطی، چرا "سادگی (Simplicity)"، "کارایی (Efficiency)" و "اثربخشی (Effectiveness)" به عنوان دلایل محبوبیت آن‌ها ذکر شده‌اند؟

پاسخ:

* **سادگی:** فرم ریاضی ساده و فهم آسان (مانند $w^T x + w_0$) و پیاده‌سازی آسان.
* **کارایی:** آموزش و پیش‌بینی سریع و کم‌هزینه محاسباتی، حتی برای داده‌های بزرگ.
* **اثربخشی:** در بسیاری مسائل، به‌خصوص داده‌های خطی جداسازی‌پذیر یا قابل تبدیل به خطی، عملکرد خوبی دارند و بهینه عمل می‌کنند.

---

۴. سوال: در فرم ریاضی یک نورون منفرد $y = f(w^T x + w_0)$، نقش تابع فعال‌سازی $f$ چیست و چه نوع توابعی می‌توانند به عنوان $f$ استفاده شوند؟

پاسخ:

* **نقش تابع فعال‌سازی $f$:** تبدیل خروجی خطی $w^T x + w_0$ به خروجی نهایی نورون و معرفی غیرخطی‌بودن به مدل.
* **انواع توابع:**

  * تابع پله‌ای (Step function): خروجی ۰ یا ۱/−۱ بر اساس آستانه، مانند پرسپترون اولیه.
  * تابع سیگموید (Sigmoid): خروجی بین ۰ و ۱، در رگرسیون لجستیک.
  * توابع دیگر: ReLU، Tanh و ... در شبکه‌های عصبی مدرن.

---

۵. سوال: الگوریتم پرسپترون تک‌نمونه (Single-sample Perceptron) چگونه با Stochastic Gradient Descent (SGD) مرتبط است؟ مزیت اصلی SGD نسبت به Batch Gradient Descent چیست؟

پاسخ:

* **ارتباط با SGD:** پرسپترون تک‌نمونه به‌روزرسانی وزن‌ها را بعد از هر نمونه انجام می‌دهد که مشابه قاعده گرادیان تصادفی (SGD) است.
* **مزیت اصلی SGD:**

  * هزینه محاسباتی کمتر در هر تکرار (محاسبه گرادیان روی یک نمونه به جای کل داده).
  * همگرایی سریع‌تر به ویژه در داده‌های بزرگ، گرچه مسیر همگرایی ممکن است نوسانی‌تر باشد اما معمولاً سریع‌تر به منطقه بهینه می‌رسد.


۶. سوال:
در بخش "Cost Functions" اشاره شده که "Finding discriminant functions $(w^T, w_0)$ is framed as minimizing a cost function". چرا کمینه‌سازی تابع هزینه برای یافتن توابع تشخیص اهمیت دارد؟

پاسخ:

* **هدف مدل یادگیری ماشین:** یافتن پارامترهایی ($w$ و $w_0$) است که پیش‌بینی مدل را به برچسب‌های واقعی نزدیک‌تر کند.
* **نقش تابع هزینه:** تابع هزینه معیاری است برای اندازه‌گیری میزان اختلاف پیش‌بینی‌های مدل با برچسب‌های واقعی. هر چه این اختلاف کمتر باشد، عملکرد مدل بهتر است.
* **کمینه‌سازی:** با کمینه کردن تابع هزینه، پارامترهای مدل به نحوی تنظیم می‌شوند که خطا و اختلاف میان پیش‌بینی و واقعیت حداقل شود، در نتیجه توابع تشخیص بهینه و دقیق‌تری یاد گرفته می‌شوند.

---

۷. سوال:
چرا Leave-One-Out Cross-Validation (LOOCV) با وجود مزایای "No Data Wastage" و "Low Bias"، برای مجموعه‌های داده بزرگ توصیه نمی‌شود؟

پاسخ:

* **هزینه محاسباتی بالا:** در LOOCV، مدل باید $N$ بار (تعداد نمونه‌ها) آموزش داده شود که برای مجموعه‌های داده بزرگ این مقدار بسیار زیاد و زمان‌بر است.
* **دلیل:** در هر بار، فقط یک نمونه برای تست و بقیه $N-1$ نمونه برای آموزش استفاده می‌شوند، که تکرار این روند برای همه نمونه‌ها، منابع محاسباتی و زمان زیادی مصرف می‌کند.
* **نتیجه:** LOOCV بیشتر برای داده‌های کوچک کاربردی و مناسب است.

---

۸. سوال:
در طبقه‌بندی چندکلاسه، ماشین‌های خطی (Linear Machines) چگونه با "مناطق مبهم" که در روش‌های OvR/OvO دیده می‌شوند، مقابله می‌کنند؟

پاسخ:

* هر کلاس توسط یک تابع تشخیص $g_i(x)$ مستقل نمایش داده می‌شود.
* **قاعده تصمیم‌گیری:** نمونه به کلاسی تخصیص می‌یابد که بیشترین مقدار $g_i(x)$ را داشته باشد (یعنی $\hat{y} = \arg\max_i g_i(x)$).
* **نتیجه:** مناطق تصمیم‌گیری محدب و بدون همپوشانی (تک‌اتصالی) هستند، بنابراین هر نقطه دقیقا به یک کلاس تعلق دارد و هیچ منطقه مبهم یا شکاف بین کلاس‌ها وجود ندارد.

---

۹. سوال:
در مورد Perceptron Algorithm، چرا بهینه کردن
$J_p(w) = - \sum_{i \in M} y^{(i)} w^T x^{(i)}$
که فقط شامل نقاط اشتباه طبقه‌بندی شده است، منجر به یافتن یک مرز جداسازی می‌شود؟

پاسخ:

* تابع هزینه فقط روی نقاط اشتباه طبقه‌بندی شده تمرکز دارد و تلاش می‌کند مقدار $y^{(i)} w^T x^{(i)}$ را برای آن‌ها مثبت کند.
* اگر نمونه با برچسب +1 اشتباه طبقه‌بندی شده باشد (یعنی $w^T x^{(i)} \leq 0$)، الگوریتم سعی می‌کند $w^T x^{(i)}$ را افزایش دهد.
* اگر نمونه با برچسب −1 اشتباه طبقه‌بندی شده باشد (یعنی $w^T x^{(i)} \geq 0$)، الگوریتم سعی می‌کند $w^T x^{(i)}$ را کاهش دهد.
* با تکرار این روند، وزن‌ها به سمتی تنظیم می‌شوند که هیچ نمونه اشتباهی باقی نماند؛ در این حالت $J_p(w) = 0$ و الگوریتم همگرا می‌شود و مرز جداسازی پیدا می‌شود.

---

۱۰. سوال:
فایل PDF مثال "Pima Indians Diabetes Dataset" را به عنوان یک مثال واقعی از طبقه‌بندی مطرح می‌کند. ویژگی‌های این مجموعه داده (مانند گلوکز، BMI، سن) چگونه به مدل طبقه‌بندی‌کننده خطی کمک می‌کنند؟

پاسخ:

* ویژگی‌های عددی مانند "Glucose"، "BMI"، "Age" و ... ورودی‌های مدل هستند که پس از نرمال‌سازی در ترکیب خطی $w^T x + w_0$ استفاده می‌شوند.
* مدل یاد می‌گیرد به هر ویژگی وزن خاصی تخصیص دهد که نشان‌دهنده اهمیت آن ویژگی برای پیش‌بینی دیابت است (مثلاً گلوکز وزن بالاتری می‌تواند داشته باشد).
* این ترکیب خطی، مرز تصمیم خطی در فضای ویژگی‌ها ایجاد می‌کند تا نمونه‌های مبتلا و غیرمبتلا را از هم جدا کند.
* در صورتی که ویژگی‌ها به خوبی با کلاس‌ها همبستگی داشته باشند، مدل خطی نتایج موثری ارائه خواهد داد.




