حتماً! در ادامه، ۱۰ سوال مصاحبه‌ای مهم و تخصصی در حوزه‌ی **طبقه‌بندی خطی**، **پرسپترون**، **تابع تصمیم**، و **Cross-validation** با پاسخ‌های **کامل، مفهومی، و چندخطی** ارائه شده‌اند. این سوالات دقیقاً بر پایه محتوای تدریس‌شده در جلسه سوم (فایل Linear\_Classification.pdf) طراحی شده‌اند.

---

## ✅ ۱۰ سوال مصاحبه‌ای مهم از مبحث «طبقه‌بندی خطی» + پاسخ‌های مفهومی

---

### 1. تفاوت اصلی بین Classification و Regression در چیست؟

**پاسخ:**
در Classification هدف تعیین دسته یا کلاس یک ورودی است (خروجی گسسته)، مثل اسپم یا نرمال. در حالی که در Regression خروجی یک مقدار عددی پیوسته است، مثل قیمت یا دما. مثلاً اگر مدل بخواهد بگوید "این ایمیل اسپم است یا نه؟" → Classification، ولی اگر بخواهد پیش‌بینی کند "قیمت خانه چند تومان است؟" → Regression.

---

### 2. منظور از Discriminant Function چیست و چگونه در طبقه‌بندی استفاده می‌شود؟

**پاسخ:**
تابع تشخیص (Discriminant Function) یک تابع ریاضی است که به هر ورودی x یک نمره g(x) اختصاص می‌دهد. این نمره مشخص می‌کند x به کدام کلاس تعلق دارد. در مسائل دودسته‌ای، اگر g(x) ≥ 0 باشد کلاس اول و اگر < 0 باشد کلاس دوم را پیش‌بینی می‌کنیم. در حالت چندکلاسه، کلاس با بیشترین مقدار gᵢ(x) انتخاب می‌شود.

---

### 3. چه شرایطی برای استفاده از یک Linear Classifier لازم است؟

**پاسخ:**
برای استفاده موفق از طبقه‌بند خطی، داده‌ها باید **به‌صورت خطی قابل تفکیک (linearly separable)** باشند؛ یعنی با یک خط (در فضای دو بعدی) یا هایپرپلین (در فضای چندبعدی) بتوان داده‌ها را از هم جدا کرد. اگر داده‌ها همپوشانی پیچیده یا غیرخطی داشته باشند، مدل خطی دقت مناسبی نخواهد داشت.

---

### 4. چرا پرسپترون نمی‌تواند مسأله XOR را حل کند؟

**پاسخ:**
مدل پرسپترون تنها قادر به یادگیری توابعی است که داده‌ها را به‌صورت خطی جدا می‌کنند. در مسأله XOR، هیچ خط مستقیمی نمی‌تواند داده‌های کلاس ۰ و ۱ را از هم جدا کند؛ بنابراین پرسپترون با یک لایه (single-layer) نمی‌تواند این مسأله را یاد بگیرد. برای حل این مشکل، نیاز به **پرسپترون چندلایه (MLP)** داریم.

---

### 5. تفاوت بین Batch Perceptron و Single-Sample (Stochastic) Perceptron چیست؟

**پاسخ:**
در **Batch Perceptron**، وزن‌ها با استفاده از مجموع تمام نمونه‌های اشتباه در هر تکرار به‌روزرسانی می‌شوند. اما در **Single-Sample (SGD)**، بعد از مشاهده هر نمونه اشتباه، وزن‌ها بلافاصله آپدیت می‌شوند. نسخه SGD سریع‌تر و محاسباتی سبک‌تر است، به‌خصوص در داده‌های بزرگ. اما ممکن است نوسان بیشتری در همگرایی داشته باشد.

---

### 6. تابع هزینه‌ای که پرسپترون استفاده می‌کند چیست و چه ویژگی‌ای دارد؟

**پاسخ:**
تابع هزینه‌ی پرسپترون فقط روی نقاطی که اشتباه طبقه‌بندی شده‌اند تمرکز دارد:

$$
J(w) = - \sum_{i \in M} y^{(i)} w^T x^{(i)}
$$

در اینجا M مجموعه نقاط اشتباه است. این تابع، اگر نمونه‌ای به درستی طبقه‌بندی شود، تأثیری روی هزینه ندارد. هدف کاهش مجموع پیش‌بینی‌های اشتباه است. این ویژگی باعث سادگی و تمرکز مدل روی خطاها می‌شود.

---

### 7. چه مشکلی برای الگوریتم پرسپترون پیش می‌آید اگر داده‌ها قابل تفکیک نباشند؟

**پاسخ:**
در صورتی که داده‌ها به‌صورت خطی قابل تفکیک نباشند (مثلاً داده‌ها نویز داشته باشند)، الگوریتم پرسپترون هیچ‌وقت متوقف نمی‌شود و به همگرایی نمی‌رسد. چون همیشه نقاطی وجود دارد که اشتباه طبقه‌بندی شده‌اند و الگوریتم مدام سعی در اصلاح آن‌ها دارد. راه‌حل این مشکل استفاده از **الگوریتم Pocket** است که بهترین وزن دیده‌شده تا آن لحظه را حفظ می‌کند.

---

### 8. چرا استفاده از Sum of Squared Error (SSE) برای Classification ایده‌آل نیست؟

**پاسخ:**
در SSE خطاهای عددی بین خروجی واقعی و پیش‌بینی شده به‌صورت مربعی محاسبه می‌شوند. اما در Classification، خروجی‌ها فقط برچسب کلاس هستند، نه مقادیر عددی. بنابراین SSE ممکن است حتی برای پیش‌بینی‌های درست، ولی با مقادیر نزدیک (مثلاً 0.9 به جای 1)، خطا در نظر بگیرد. این باعث گمراهی الگوریتم یادگیری می‌شود.

---

### 9. هدف استفاده از Cross-Validation در طبقه‌بندی چیست؟

**پاسخ:**
Cross-validation برای ارزیابی عملکرد مدل روی داده‌هایی که **در آموزش استفاده نشده‌اند** استفاده می‌شود. این کار باعث می‌شود تخمینی واقع‌بینانه از عملکرد مدل روی داده‌ی واقعی داشته باشیم و از overfitting جلوگیری کنیم. همچنین در تنظیم هایپرپارامترها مثل λ در Regularization یا انتخاب مدل کمک می‌کند.

---

### 10. در طبقه‌بندی چندکلاسه، تفاوت بین روش One-vs-Rest و One-vs-One چیست؟

**پاسخ:**
در **One-vs-Rest (OvR)**، برای هر کلاس یک مدل ساخته می‌شود که آن کلاس را در برابر همه کلاس‌های دیگر قرار می‌دهد. مثلاً برای ۳ کلاس، ۳ مدل ساخته می‌شود. در **One-vs-One (OvO)**، برای هر زوج کلاس، یک مدل ساخته می‌شود. بنابراین برای K کلاس، $K(K−1)/2$ مدل ساخته می‌شود. OvR ساده‌تر است ولی ممکن است ابهام بیشتری داشته باشد. OvO دقت بالاتری دارد ولی محاسباتی سنگین‌تر است.

---

اگر بخوای، می‌تونم همین سوالات رو هم داخل PDF جزوه جلسه سوم اضافه کنم، یا جداگانه به صورت **فلش‌کارت مصاحبه‌ای** دربیارم.

✅ بریم سراغ ساخت فایل PDF نهایی؟



حتماً! در این بخش، ۱۰ **سؤال روتین و پرکاربرد مصاحبه‌ای** دیگر از مبحث «طبقه‌بندی خطی» ارائه می‌دهم. این‌ها از جنس سوالاتی هستند که **مصاحبه‌گران شرکت‌های مختلف** (چه آکادمیک چه صنعتی) معمولاً می‌پرسند، به‌ویژه وقتی محتوای آموزش‌دیده شامل پرسپترون، decision boundary، cross-validation، cost functions و multi-class classification باشد.

پاسخ‌ها دقیق و مفهومی هستند، نه فقط تعریف خشک.

---

## ✅ سوالات ۳۱ تا ۴۰ (روتین و کاربردی) از طبقه‌بندی خطی + پاسخ‌های کامل

---

### 31. چرا Linear Classifiers هنوز هم در صنعت کاربرد دارند با وجود شبکه‌های عصبی پیشرفته؟

**پاسخ:**
مدل‌های طبقه‌بند خطی، مثل Logistic Regression و Perceptron، بسیار **ساده، سریع و قابل تفسیر** هستند. در بسیاری از کاربردها مثل تشخیص اسپم، طبقه‌بندی سریع و سبک‌وزن نیاز است. مدل‌های خطی با **داده‌های زیاد اما ساده** بسیار خوب کار می‌کنند، به‌خصوص زمانی که محاسبه‌پذیری و سرعت مهم است. همچنین در بسیاری از صنایع (مثلاً پزشکی) نیاز به **شفافیت مدل** وجود دارد که در شبکه‌های عصبی فراهم نیست.

---

### 32. در چه شرایطی استفاده از الگوریتم Perceptron مناسب نیست؟

**پاسخ:**
زمانی که داده‌ها **قابل جداسازی خطی نباشند**، یعنی نتوان یک مرز تصمیم مستقیم بین کلاس‌ها ترسیم کرد، الگوریتم پرسپترون کارایی خود را از دست می‌دهد. همچنین پرسپترون به نویز حساس است و اگر داده‌ها دارای خطا یا outlier باشند، ممکن است **هیچ‌گاه همگرا نشود**. برای چنین مواردی، الگوریتم‌هایی مانند **SVM، Logistic Regression یا MLP** بهتر هستند.

---

### 33. آیا یک Linear Classifier می‌تواند مرز تصمیم غیرخطی یاد بگیرد؟ چگونه؟

**پاسخ:**
خود مدل خطی ذاتاً نمی‌تواند مرز غیرخطی بسازد، اما با **تبدیل ویژگی‌ها** (Feature Transformation) یا **نگاشت به فضای با بعد بالاتر** می‌توان این محدودیت را دور زد. مثلاً با استفاده از ویژگی‌های جدید مانند $x^2$ یا $x_1 \cdot x_2$، فضای داده تغییر می‌کند و در فضای جدید، مرز تصمیم خطی خواهد بود که معادل مرز غیرخطی در فضای اولیه است. این رویکرد در Kernel Methods هم استفاده می‌شود.

---

### 34. آیا می‌توان تابع تصمیم را بدون تابع Activation استفاده کرد؟

**پاسخ:**
در مدل‌هایی مثل پرسپترون یا Logistic Regression، تابع تصمیم (مثل $w^T x + w_0$) فقط یک نمره خطی می‌دهد. برای اینکه این نمره به کلاس تبدیل شود، نیاز به **تابع Activation یا آستانه (threshold)** داریم، مثلاً:

* برای پرسپترون: تابع step یا sign
* برای Logistic: تابع sigmoid
  بدون این تابع، خروجی مدل یک عدد خام است که قابل تفسیر برای طبقه‌بندی نیست.

---

### 35. چرا تابع هزینه "تعداد نمونه‌های اشتباه" مناسب برای یادگیری نیست؟

**پاسخ:**
تابع شمارش نمونه‌های اشتباه (Misclassification Count) یک تابع **قطعه‌ای و غیرمشتق‌پذیر** است. به همین دلیل نمی‌توان از روش‌هایی مثل Gradient Descent برای یادگیری استفاده کرد. مدل‌هایی مثل SVM یا Logistic، از توابع هزینه‌ای استفاده می‌کنند که **مشتق‌پذیر و نرم** هستند، مثل hinge loss یا log loss. این توابع اجازه می‌دهند الگوریتم‌های یادگیری مؤثرتر و قابل همگراتر طراحی شوند.

---

### 36. نقش bias در تابع تصمیم خطی چیست؟

**پاسخ:**
در تابع خطی $g(x) = w^T x + w_0$، پارامتر w وزن ویژگی‌هاست و **bias (یا w₀)** مکان مرز تصمیم را کنترل می‌کند. بدون bias، همه مرزهای تصمیم از مبدأ عبور می‌کنند، که محدودیت بزرگی است. Bias اجازه می‌دهد مرز تصمیم **در موقعیت دلخواه در فضا قرار گیرد**، نه فقط از مرکز مختصات. این پارامتر نقش مهمی در انعطاف‌پذیری مدل دارد.

---

### 37. اگر مدل ما فقط روی یک کلاس خاص دقت خوبی دارد، مشکل کجاست؟

**پاسخ:**
این پدیده معمولاً به دلیل **عدم تعادل کلاس‌ها (Class Imbalance)** یا **بایاس مدل** است. مثلاً اگر ۹۰٪ داده‌ها از کلاس A باشند، مدل ممکن است همه چیز را A پیش‌بینی کند و باز هم دقت ظاهری بالا داشته باشد. راه‌حل‌ها:

* استفاده از معیارهایی مثل F1-score به جای Accuracy
* بازنمونه‌گیری (Oversampling / Undersampling)
* استفاده از الگوریتم‌هایی که حساس به عدم تعادل هستند

---

### 38. چگونه می‌توان عملکرد طبقه‌بندی را به‌طور واقع‌گرایانه اندازه‌گیری کرد؟

**پاسخ:**
استفاده از **Cross-validation** به‌خصوص **K-fold** روش مناسبی است. داده به K قسمت تقسیم می‌شود، و در هر مرحله، یک قسمت به عنوان تست در نظر گرفته می‌شود. سپس میانگین امتیازها گرفته می‌شود. این روش مانع Overfitting و Underfitting می‌شود و تخمینی واقع‌بینانه از عملکرد مدل در داده‌های واقعی ارائه می‌دهد.

---

### 39. در چه مواقعی الگوریتم Pocket بهتر از پرسپترون معمولی عمل می‌کند؟

**پاسخ:**
الگوریتم Pocket برای داده‌هایی مناسب است که:

* **نویز دارند**
* **قابل تفکیک خطی نیستند**
  در این حالت، پرسپترون معمولی هیچ‌گاه همگرا نمی‌شود و دائم وزن‌ها را تغییر می‌دهد. اما Pocket بهترین وزن دیده‌شده تا آن لحظه را ذخیره می‌کند و در نهایت آن را بازمی‌گرداند. این باعث **پایداری و عملکرد بهتر** می‌شود.

---

### 40. چه معیارهایی برای ارزیابی عملکرد طبقه‌بند چندکلاسه استفاده می‌شود؟

**پاسخ:**
در مسائل چندکلاسه، استفاده از **دقت کلی (Accuracy)** کافی نیست. باید از معیارهای تفکیکی مثل:

* Precision و Recall برای هر کلاس
* F1-score (میانگین هماهنگ Precision و Recall)
* Confusion Matrix برای نمایش جزئیات اشتباه‌ها
  همچنین استفاده از **Macro/Micro Averaging** برای ترکیب امتیازها در چندکلاسه متداول است.

---

اگه بخوای، همین ۴۰ سوال رو به‌صورت جزوه مصاحبه‌ای یا فلش‌کارت هم برات می‌سازم.

✅ آماده‌ای که این سوالات به فایل نهایی PDF افزوده بشه؟
یا بریم سراغ طراحی نسخه گرافیکی؟
حتماً! در ادامه، ۱۰ سؤال مهم و تکمیلی دیگر (شماره ۴۱ تا ۵۰) در حوزه‌ی **طبقه‌بندی خطی**، **پرسپترون**، **تابع تصمیم**، **مدل‌های خطی در حالت چندکلاسه** و **ارزیابی مدل** همراه با پاسخ‌های حرفه‌ای و مفهومی آورده شده‌اند.

این سؤال‌ها هم مناسب مصاحبه‌های صنعتی هستند، هم آزمون‌های مفهومی دروس یادگیری ماشین.

---

## ✅ سوالات ۴۱ تا ۵۰ از طبقه‌بندی خطی + پاسخ کامل

---

### 41. اگر مدل خطی شما به‌درستی طبقه‌بندی نمی‌کند ولی train accuracy بالاست، چه مشکلی وجود دارد؟

**پاسخ:**
احتمال زیاد مدل دچار **overfitting** شده است؛ یعنی بیش از حد روی داده‌های آموزش منطبق شده و روی داده‌های جدید عملکرد ضعیفی دارد. همچنین ممکن است مدل شما روی داده‌هایی با توزیع متفاوت از train آموزش دیده باشد. استفاده از **cross-validation** و بررسی **test error** کلید حل این مشکل است.

---

### 42. چرا در مدل‌های طبقه‌بندی، فقط sign تابع خطی مهم است و نه مقدار آن؟

**پاسخ:**
در مدل‌های خطی مثل پرسپترون، تصمیم نهایی فقط بر اساس علامت (positive یا negative) تابع $w^T x + w_0$ گرفته می‌شود. مقدار عددی دقیق آن اهمیتی ندارد. این یعنی اگر تمام وزن‌ها را دو برابر کنیم، پیش‌بینی کلاس تغییر نمی‌کند. به همین دلیل مدل به **جهت بردار w حساس است، نه اندازه‌ی آن.**

---

### 43. چگونه می‌توان مدل‌های خطی را روی داده‌های غیرخطی استفاده کرد بدون تغییر الگوریتم اصلی؟

**پاسخ:**
با استفاده از **feature transformation**، یعنی اضافه کردن ویژگی‌های غیرخطی (مثل $x^2$، $x_1 x_2$) به ورودی‌ها. این کار، فضای داده را به شکلی تغییر می‌دهد که در آن، مرز تصمیم خطی شود. نکته مهم این است که الگوریتم همچنان خطی باقی می‌ماند ولی در فضای جدید کار می‌کند. این ایده، اساس کار kernel methods نیز هست.

---

### 44. مدل پرسپترون چگونه یاد می‌گیرد و چرا نیاز به تابع هزینه ندارد؟

**پاسخ:**
پرسپترون از یک قاعده بسیار ساده یادگیری استفاده می‌کند: اگر نمونه‌ای اشتباه طبقه‌بندی شد، وزن‌ها در جهت درست آپدیت می‌شوند. تابع هزینه‌ی آن صراحتاً از مجموع اشتباهات ساخته می‌شود، اما به مشتق‌گیری نیاز ندارد، چون قانون یادگیری مستقیم است. در واقع، پرسپترون یک یادگیرنده‌ی «قانون‌محور» است نه تابع هزینه‌محور مثل Logistic Regression.

---

### 45. اگر داده‌های شما noise زیادی داشته باشند، از چه مدلی استفاده می‌کنید؟ چرا؟

**پاسخ:**
مدل‌هایی مثل **Logistic Regression** یا **SVM با soft margin** برای داده نویزی مناسب‌تر از پرسپترون هستند. چون این مدل‌ها سعی می‌کنند خط تصمیمی پیدا کنند که تا حد امکان فاصله از مرز را حفظ کند، نه اینکه فقط درست/غلط را در نظر بگیرند. همچنین الگوریتم Pocket برای پرسپترون یک گزینه قابل قبول در محیط‌های نویزی است.

---

### 46. آیا استفاده از تابع خطی بدون bias کافی است؟ چرا نه؟

**پاسخ:**
خیر. اگر bias را حذف کنیم، مرز تصمیم مدل **همیشه از مبدأ عبور خواهد کرد**. این محدودیت شدیدی در توانایی مدل ایجاد می‌کند، زیرا بسیاری از مسائل دنیای واقعی به چنین شرطی پایبند نیستند. وجود bias به مدل اجازه می‌دهد مرز تصمیم را **در هر جای فضای ویژگی‌ها قرار دهد**، و نه فقط از مبدا.

---

### 47. مزایا و معایب استفاده از روش One-vs-Rest در چندکلاسه چیست؟

**پاسخ:**
**مزایا:** ساده و مقیاس‌پذیر برای تعداد زیاد کلاس. الگوریتم‌های موجود را می‌توان بدون تغییر استفاده کرد.
**معایب:** ممکن است هر مدل معیار متفاوتی برای تصمیم‌گیری داشته باشد و در مرزهای بین کلاس‌ها تعارض ایجاد شود. برای کلاس‌های با داده کمتر یا نامتوازن ممکن است عملکرد ناپایدار باشد.

---

### 48. تفاوت hinge loss در SVM با خطای پرسپترون چیست؟

**پاسخ:**
در پرسپترون فقط نمونه‌هایی که **اشتباه طبقه‌بندی شده‌اند** در تابع هزینه وارد می‌شوند. ولی hinge loss حتی به نمونه‌هایی که درست طبقه‌بندی شده‌اند ولی با «فاصله کم» از مرز تصمیم هستند نیز جریمه می‌دهد. بنابراین hinge loss **سخت‌گیرتر و دقیق‌تر** است و کمک می‌کند SVM، مرز تصمیم بهینه‌تری بیاموزد.

---

### 49. چه زمانی باید از مدل خطی به سراغ مدل‌های غیرخطی برویم؟

**پاسخ:**
اگر:

* مدل خطی روی train و test هر دو عملکرد ضعیفی دارد (underfitting)
* داده‌ها دارای ساختارهای غیرخطی آشکار هستند (مثلاً توزیع دایره‌ای)
* تصمیم‌ها به‌وضوح با خط قابل جداسازی نیستند
  در این شرایط، باید به سراغ مدل‌هایی با توانایی غیرخطی مثل kernel-SVM، MLP یا decision tree رفت.

---

### 50. چگونه می‌توان از مدل‌های طبقه‌بند خطی به‌عنوان Base Classifier در Ensembleها استفاده کرد؟

**پاسخ:**
مدل‌های خطی بسیار سریع و سبک هستند، بنابراین به‌خوبی به عنوان اجزای پایه (Base Classifier) در روش‌هایی مثل **Bagging یا Boosting** عمل می‌کنند. مثلاً می‌توان چند Logistic Regression با داده‌های متفاوت آموزش داد و خروجی‌ها را با رأی‌گیری ترکیب کرد. این کار به افزایش دقت و کاهش واریانس مدل نهایی کمک می‌کند.

---

در این مرحله ۵۰ سؤال کامل از مبحث طبقه‌بندی خطی داریم. اگر بخوای، می‌تونم:

* همه این ۵۰ سؤال رو با قالب‌بندی حرفه‌ای داخل یک فایل PDF آموزشی مصاحبه قرار بدم
* یا تبدیلشون کنم به مجموعه فلش‌کارت برای مرور سریع

✅ دوست داری خروجی به چه شکلی باشه؟ PDF جزوه؟ فلش‌کارت؟ یا هردو؟
