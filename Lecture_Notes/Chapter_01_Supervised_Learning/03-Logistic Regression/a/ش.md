๐ **ุฌุฒูู ุขููุฒุด ุฏุฑุณ ุงุฏฺฏุฑ ูุงุดู (CE 40717)**
**ููุถูุน: ุฑฺฏุฑุณูู ูุฌุณุชฺฉ (Logistic Regression)**
**ุชุงุฑุฎ: ต ุงฺฉุชุจุฑ ฒฐฒด**
**ูุฏุฑุณ: ุฏฺฉุชุฑ ุนู ุดุฑูโุฒุงุฑฺ**
**ุชูู ู ุชูุธู: ุฏุงูุงู ุบุฑุจ (ุจุง ูุฑุงุด ู ุชฺฉูู)**

---

### **ฑ. ููุฏูู: ฺุฑุง ุฑฺฏุฑุณูู ูุฌุณุชฺฉุ**

ุฑฺฏุฑุณูู ูุฌุณุชฺฉ (Logistic Regression - LR) ฺฉ ุงูฺฏูุฑุชู ุงุฏฺฏุฑ ูุงุดู ุงุณุช ฺฉู ุนูุฏุชุงู ุจุฑุง ุญู **ูุณุงุฆู ุทุจููโุจูุฏ (Classification Problems)**ุ ุจูโูฺู **ุทุจููโุจูุฏ ุฏูุฏู (Binary Classification)**ุ ฺฉุงุฑุจุฑุฏ ุฏุงุฑุฏ. ุจุฑุฎูุงู **ุฑฺฏุฑุณูู ุฎุท (Linear Regression)** ฺฉู ฺฉ ููุฏุงุฑ ูพูุณุชู ุฑุง ูพุดโุจู ูโฺฉูุฏุ ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ูุฏู ุฏุงุฑุฏ ุชุง ุฎุฑูุฌโุง ุฑุง ุฏุฑ ุจุงุฒูโ [0, 1] ุชููุฏ ฺฉูุฏุ ฺฉู ูโุชูุงูุฏ ุจู ุนููุงู **ุงุญุชูุงู ุชุนูู ฺฉ ููููู ุจู ฺฉูุงุณ "ูุซุจุช" (Positive Class)** ุชูุณุฑ ุดูุฏ.

**ุชูุถุญุงุช ุงุถุงูู:**
ุชุตูุฑ ฺฉู ูโุฎูุง ฺฉ ุงูู ุฑู ุชุดุฎุต ุจุฏ ฺฉู ุงุณูพู ูุณุช ุง ูู. ุง ูุซูุงู ููุช ฺฉ ุชุฑุงฺฉูุด ุขููุงู ุงูุฌุงู ูโุดูุ ูโุฎูุง ุจุฏูู ฺฉูุงูุจุฑุฏุงุฑู ุง ูุงูุน. ุง ุญุช ุฏุฑ ูพุฒุดฺฉุ ูโุฎูุง ุชุดุฎุต ุจุฏ ุชูููุฑ ุฎูุดโุฎูู ุง ุจุฏุฎู. ุงูโูุง ูููโุดูู ูุซุงูโูุง ุทุจููโุจูุฏ ุฏูุฏู ูุณุชู. ุนู ุฎุฑูุฌ ููุท ุฏู ุญุงูุช ุฏุงุฑู: ุจูู ุง ุฎุฑ (ฺฉู ูุนูููุงู ุจุง 0 ู 1 ูุดูู ุฏุงุฏู ูโุดู). ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ุฏููุงู ุจุฑุง ููู ฺฉุงุฑ ุณุงุฎุชู ุดุฏู.

ุฏุฑ ุงู ููุน ูุณุงุฆูุ ุจุฑฺุณุจ ุฎุฑูุฌ ($y$) ูุนูููุงู ุจู ุตูุฑุช ${0, 1}$ ุชุนุฑู ูโุดูุฏ:
* $y=0$: "ฺฉูุงุณ ููู" (Negative Class) โ ูุซูุงู ุชูููุฑ ุฎูุดโุฎู
* $y=1$: "ฺฉูุงุณ ูุซุจุช" (Positive Class) โ ูุซูุงู ุชูููุฑ ุจุฏุฎู

### **ฒ. ฺุฑุง ููโุชูุงู ุงุฒ ุฑฺฏุฑุณูู ุฎุท ุจุฑุง ุทุจููโุจูุฏ ุงุณุชูุงุฏู ฺฉุฑุฏุ**

ุงุณุชูุงุฏู ุงุฒ ุฑฺฏุฑุณูู ุฎุท ุจุฑุง ูุณุงุฆู ุทุจููโุจูุฏ ฺุงูุดโูุง ุฏุงุฑุฏ:
* **ุฎุฑูุฌโูุง ุฎุงุฑุฌ ุงุฒ ุจุงุฒู [0,1]:** ุฑฺฏุฑุณูู ุฎุท ูโุชูุงูุฏ ููุงุฏุฑ ูพุดโุจู ฺฉูุฏ (ูุงููุฏ $h_\theta(x)$) ฺฉู ุจุฒุฑฺฏโุชุฑ ุงุฒ 1 ุง ฺฉูฺฺฉโุชุฑ ุงุฒ 0 ุจุงุดูุฏ (ูุซูุงู 1.2 ุง -0.3). ุงู ููุงุฏุฑ ููโุชูุงููุฏ ุจู ุนููุงู ุงุญุชูุงู ุชูุณุฑ ุดููุฏุ ุฏุฑ ุญุงู ฺฉู ุฏุฑ ูุณุงุฆู ุทุจููโุจูุฏุ ูุง ุจู ุฏูุจุงู ุชุฎูู ุงุญุชูุงู ูุณุชู.
* **ุญุณุงุณุช ุจู ุฏุงุฏูโูุง ูพุฑุช (Outliers):** ููุงูุทูุฑ ฺฉู ุฏุฑ ูููุฏุงุฑ ุงูุฏุงุฒู ุชูููุฑ ูุดุงู ุฏุงุฏู ุดุฏูุ ุงูุฒูุฏู ฺฉ ููุทูโ ุฏุงุฏูโ ูพุฑุช ูโุชูุงูุฏ ุฎุท ุฑฺฏุฑุณูู ุฑุง ุจู ุดุฏุช ุชุบุฑ ุฏูุฏุ ฺฉู ููุฌุฑ ุจู ฺฉ ูุฑุฒ ุชุตููโฺฏุฑ ูุงููุงุณุจ ูโุดูุฏ. ุงู ููุถูุน ูุดุงู ูโุฏูุฏ ฺฉู ุฑฺฏุฑุณูู ุฎุท ุจุฑุง ุทุจููโุจูุฏ ุจู ุงูุฏุงุฒู ฺฉุงู **ูู (Robust)** ูุณุช.

**ุชูุถุญุงุช ุงุถุงูู:**
ูุฑุถ ฺฉู ุจุง ุฑฺฏุฑุณูู ุฎุท ูโุฎูุงู ุงูุฏุงุฒู ุชูููุฑ ุฑู ูพุดโุจู ฺฉูู ู ุจฺฏู ุชูููุฑ ุจุฏุฎูู ุง ุฎูุดโุฎู. ุงฺฏู ุชูููุฑ ุฎูุดโุฎู ุจูุฏ (No) ุนุฏุฏ 0 ู ุงฺฏู ุจุฏุฎู ุจูุฏ (Yes) ุนุฏุฏ 1 ุฑู ูุดูู ุจุฏู. ุงฺฏู ู ุฎุท ุฑุงุณุช ุฑู ุจู ุงู ุฏุงุฏูโูุง ูุช ฺฉูู (ูุซู ูููุฏุงุฑ ุตูุญู 5 PDF)ุ ูโุชููู ุจฺฏู ุงฺฏู ุฎุฑูุฌ ุฎุท ุจุงูุง 0.5 ุจูุฏุ 1 ูพุดโุจู ูโฺฉูู ู ุงฺฏู ฺฉูุชุฑ ุจูุฏุ 0. ุญุงูุง ุงฺฏู ู ุชูููุฑ ุจุฏุฎู ุฎู ุจุฒุฑฺฏุชุฑ ุงุฒ ุจูู ุฑู ุจู ุฏุงุฏูโูุง ุงุถุงูู ฺฉูู (ูููู ููุทูโ ูพุฑุช ูุฑูุฒ ุฏุฑ ุตูุญู 6 PDF)ุ ุฎุท ุฑฺฏุฑุณูู ฺฉุฌ ูโุดู ู ูุฑุฒ 0.5 ุฌุงุจุฌุง ูโุดู. ุงู ุนู ูุฏู ูุง ุฏฺฏู ููโุชููู ุจู ุฏุฑุณุช ุชุดุฎุต ุจุฏูุ ฺูู ฺฉ ุฏุงุฏูโ ุฌุฏุฏ ุฎู ุฑู ุชุตููโฺฏุฑุด ุชุฃุซุฑ ฺฏุฐุงุดุชู. ุงู ู ูุดฺฉู ุจุฒุฑฺฏู. ุจุฑุง ูููุ ูุง ุจู ุชุงุจุน ูุงุฒ ุฏุงุฑู ฺฉู ุฎุฑูุฌ ุงูู ุจู ุทูุฑ ุฐุงุช ุจู 0 ู 1 ุจุงุดู ู ุจุดู ุงููู ุจู ุนููุงู ุงุญุชูุงู ุชูุณุฑ ฺฉุฑุฏ.

### **ณ. ุชุงุจุน ุณฺฏููุฏ (Sigmoid Function)**

ุจุฑุง ุงุทููุงู ุงุฒ ุงูฺฉู ุฎุฑูุฌ ูุฏู ุฏุฑ ุจุงุฒูโ [0, 1] ูุฑุงุฑ ูโฺฏุฑุฏุ ุงุฒ ฺฉ **ุชุงุจุน ูุนุงูโุณุงุฒ (Activation Function)** ุจู ูุงู **ุชุงุจุน ุณฺฏููุฏ (Sigmoid Function)** ุง **ุชุงุจุน ูุฌุณุชฺฉ (Logistic Function)** ุงุณุชูุงุฏู ูโุดูุฏ. ุงู ุชุงุจุน ุจู ุตูุฑุช ุฒุฑ ุชุนุฑู ูโุดูุฏ:
$$\sigma(z) = \frac{1}{1 + e^{-z}}$$

**ุชูุถุญุงุช ุงุถุงูู:**
ุงู ุชุงุจุน ูุซู ู "ููุชุฑ" ุนูู ูโฺฉูู. ูุฑ ุนุฏุฏุ ฺู ุฎู ุจุฒุฑฺฏ ู ฺู ุฎู ฺฉูฺฺฉุ ุจูุด ุจุฏุ ุฎุฑูุฌโุงุด ููุดู ุจู 0 ู 1 ุฎูุงูุฏ ุจูุฏ.
* **ุฎุฑูุฌ ุฏุฑ ุจุงุฒู [0,1]:** ุงฺฏุฑ $z$ ุฎู ุจุฒุฑฺฏ ู ูุซุจุช ุจุงุดู (ูุซูุงู 6)ุ $\exp(-z)$ ุฎู ฺฉูฺฺฉ ูโุดู ู $\sigma(z)$ ูุฒุฏฺฉ ุจู 1 ูโุดู. ุงฺฏุฑ $z$ ุฎู ุจุฒุฑฺฏ ู ููู ุจุงุดู (ูุซูุงู -6)ุ $\exp(-z)$ ุฎู ุจุฒุฑฺฏ ูโุดู ู $\sigma(z)$ ูุฒุฏฺฉ ุจู 0 ูโุดู. ุงฺฏุฑ $z=0$ ุจุงุดูุ $\exp(0)=1$ ู $\sigma(0) = 1/(1+1) = 0.5$ ูโุดู.
* **ูููุงุฑ (Smoothness):** ุนู ูููุฏุงุฑุด ูู ุจุงูุง ู ูพุงู ููโุฑู.
* **ูุงุจูุช ูุดุชูโฺฏุฑ (Differentiability):** ุงู ูฺฺฏ ุฎู ูููู ฺูู ุจุฑุง "ุงุฏฺฏุฑ" ูุฏู ุงุฒ ุงูฺฏูุฑุชูโูุง ูุซู ฺฏุฑุงุฏุงู ุฏุณูุช ุงุณุชูุงุฏู ูโฺฉูู ฺฉู ูุงุฒ ุจู ูุดุชู ุฏุงุฑู. ูุดุชู ุชุงุจุน ุณฺฏููุฏ ูู ุฎูุฏุด ุงุฒ ุฌูุณ ุณฺฏููุฏู ( $\sigma'(z) = \sigma(z)(1-\sigma(z))$ ).
* **ุชูุณุฑ ุงุญุชูุงูุงุช:** ุฎุฑูุฌ $\sigma(w^{\top}x)$ ุฑุง ูโุชูุงู ุจู ุนููุงู **ุงุญุชูุงู ุดุฑุท ($P(y=1|x,w)$)** ุชูุณุฑ ฺฉุฑุฏุ ุนู ุงุญุชูุงู ุงูฺฉู ุจุฑฺุณุจ $y$ ุจุฑุงุจุฑ 1 ุจุงุดุฏุ ุจู ุดุฑุท ูุฌูุฏ ูฺฺฏโูุง $x$ ู ูพุงุฑุงูุชุฑูุง $w$.
    * $P(y=1|x,w) = \sigma(w^{\top}x)$
    * $P(y=0|x,w) = 1 - \sigma(w^{\top}x)$

**ูุซุงู:** ุงฺฏุฑ $\sigma(w^{\top}x) = 0.7$ ุจุงุดุฏุ ุจู ุงู ูุนู ุงุณุช ฺฉู 70 ุฏุฑุตุฏ ุงุญุชูุงู ุฏุงุฑุฏ ฺฉู ุฑูุฏุงุฏ ููุฑุฏ ูุธุฑ (ูุซูุงู ุจุฑุฏ ุฏุฑ ฺฉ ุจุงุฒ ุจุณฺฉุชุจุงู) ุงุชูุงู ุจูุชุฏ.

### **ด. ุชุงุจุน ุชุตูู (Decision Function) ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉ**

ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉุ ูุง ุจู ุฏูุจุงู ุงูุชู ุจุฑุฏุงุฑ ูุฒู $w$ ูุณุชู ฺฉู **ุงุญุชูุงู ูพุณู (Posterior Probability)** $P(y=1|x)$ ุฑุง ูพุดโุจู ฺฉูุฏ.
ุชุงุจุน ุชุตูู ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ุจู ุตูุฑุช ุชุฑฺฉุจ ุชุงุจุน ุณฺฏููุฏ ุจุง ุชุฑฺฉุจ ุฎุท ูฺฺฏโูุง ($w^{\top}x$) ุชุนุฑู ูโุดูุฏ:
$$h(x) = \sigma(w^{\top}x)$$
ฺฉู $x$ ุจุฑุฏุงุฑ ูฺฺฏโูุง ู $w$ ุจุฑุฏุงุฑ ูุฒูโูุงุณุช.

**ูุงุนุฏูโ ุชุตููโฺฏุฑ:**
* ุงฺฏุฑ $h(x) \geq 0.5$ ุจุงุดุฏุ ูุฏู $y=1$ ุฑุง ูพุดโุจู ูโฺฉูุฏ.
* ุงฺฏุฑ $h(x) < 0.5$ ุจุงุดุฏุ ูุฏู $y=0$ ุฑุง ูพุดโุจู ูโฺฉูุฏ.

### **ต. ุณุทุญ ุชุตูู (Decision Surface / Decision Boundary)**

**ุณุทุญ ุชุตูู** ุง **ูุฑุฒ ุชุตูู (Decision Boundary)** ูุงุญูโุง ุฏุฑ ูุถุง ูุณุฆูู ุงุณุช ฺฉู ุฎุฑูุฌ ฺฉ ุทุจููโุจูุฏโฺฉููุฏู ูุจูู ุงุณุชุ ุนู ูุฏู ุจุง ุงุทููุงู ุจุฑุงุจุฑุ ุชุนูู ููููู ุจู ูุฑ ฺฉ ุงุฒ ฺฉูุงุณโูุง ุฑุง ูพุดโุจู ูโฺฉูุฏ. ุฏุฑ ุทุจููโุจูุฏ ุฏูุฏูุ ุงู ูุฑุฒ ุฌุง ุงุณุช ฺฉู ุงุญุชูุงู ุชุนูู ฺฉ ููููู ุจู ฺฉูุงุณ $y=0$ ู $y=1$ ุจุฑุงุจุฑ ุงุณุช:
$$\sigma(w^{\top}x) = 0.5$$
ุงุฒ ุขูุฌุง ฺฉู $\sigma(z) = 0.5$ ุฒูุงู ุฑุฎ ูโุฏูุฏ ฺฉู $z=0$ ุจุงุดุฏุ ูโุชูุงู ูุชุฌู ฺฏุฑูุช ฺฉู ูุฑุฒ ุชุตูู ุฒูุงู ุงุฌุงุฏ ูโุดูุฏ ฺฉู:
$$w^{\top}x = 0$$
ุงู ูุนุงุฏูู ฺฉ **ูุงูพุฑูพูู (Hyperplane)** ุฑุง ุฏุฑ ูุถุง ูฺฺฏโูุง ุชุนุฑู ูโฺฉูุฏ. ุจูุงุจุฑุงูุ ูุฑุฒ ุชุตููโฺฏุฑ ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ุจู ุทูุฑ ูพุดโูุฑุถ **ุฎุท (Linear)** ุงุณุช.

**ูฺฉุงุช ููู:**
* **ุงุจุนุงุฏ ูุฑุฒ ุชุตูู:** ูุงูพุฑูพูู ูุฑุฒ ุชุตูู ููุดู ฺฉ ุจุนุฏ ฺฉูุชุฑ ุงุฒ ูุถุง ูฺฺฏโูุง ุฏุงุฑุฏ.
* **ูุฑุฒูุง ุชุตูู ุบุฑุฎุท:** ุงฺฏุฑ ุงุฒ **ูฺฏุงุดุช ูฺฺฏโูุง (Feature Mapping)** ุงุณุชูุงุฏู ฺฉูู ู **ุชุฑูโูุง ูุฑุชุจู ุจุงูุงุชุฑ (Higher-order terms)** ุฑุง ุจู ุจุฑุฏุงุฑ ูฺฺฏโูุง ุงุถุงูู ฺฉูู (ูุซูุงู $x_1^2, x_2^2, x_1 x_2$ ู...)๏ผ ูโุชูุงู ูุฑุฒูุง ุชุตููโฺฏุฑ **ุบุฑุฎุท (Non-linear Decision Boundaries)** ุฑุง ูุฒ ุงุฏ ฺฏุฑูุช.

**ุชูุถุญุงุช ุงุถุงูู:**
ูุฑุฒ ุชุตูู ูุซู ฺฉ ุฎุท (ุฏุฑ ูุถุง ุฏู ุจุนุฏ) ุง ฺฉ ุตูุญู (ุฏุฑ ูุถุง ุณู ุจุนุฏ) ุนูู ูโฺฉูู ฺฉู ูุถุง ุฏุงุฏู ุฑู ุจู ุฏู ูุณูุช ุชูุณู ูโฺฉูู. ฺฉ ุณูุช ุจุฑุง ฺฉูุงุณ 0 ู ุณูุช ุฏฺฏู ุจุฑุง ฺฉูุงุณ 1.
**ูุซุงู ูุฑุฒ ุฎุท:** ุฏุฑ ุตูุญู 18 PDFุ ูโุจู ฺฉู ู ุฎุท ุตุงู (ุฎุท ุณุงู) ุฏู ุฏุณุชูโ ุฏุงุฏู (ุฏุงุฑูโูุง ู ุถุฑุจุฏุฑูุง) ุฑู ุงุฒ ูู ุฌุฏุง ฺฉุฑุฏู. ุงู ุฎุท ูููู ูุฑุฒ ุชุตููู.
**ูฺฉุงุช ููู:**
* **ุงุจุนุงุฏ ูุฑุฒ ุชุตูู:** ูุงูพุฑูพูู ูุฑุฒ ุชุตูู ููุดู ฺฉ ุจุนุฏ ฺฉูุชุฑ ุงุฒ ูุถุง ูฺฺฏโูุง ุฏุงุฑุฏ. ูุซูุงู ุงฺฏู ุฏุงุฏูโูุงุช ุฏูุชุง ูฺฺฏ ุฏุงุดุชู ุจุงุดู (ูุซู $x_1$ ู $x_2$)ุ ูุฑุฒ ุชุตูู ู ุฎุทู. ุงฺฏู ุณู ุชุง ูฺฺฏ ุฏุงุดุชู ุจุงุดูุ ูุฑุฒ ุชุตูู ู ุตูุญู ุงุณุช.
* **ูุฑุฒูุง ุชุตูู ุบุฑุฎุท:** ุงฺฏู ุจุฎูุงู ูุฑุฒูุง ุชุตูู ูพฺุฏูโุชุฑ ู ุบุฑุฎุท ุฏุงุดุชู ุจุงุดู (ูุซูุงู ู ุฏุงุฑู ุง ููุญู)ุ ูโุชููู ูฺฺฏโูุง ุฌุฏุฏ ุจุณุงุฒู. ูุซูุงู ุจู ุฌุง ููุท $x_1$ ู $x_2$ุ ูโุชููู $x_1^2$ุ $x_2^2$ ุง $x_1x_2$ ุฑู ูู ุจู ุนููุงู ูฺฺฏโูุง ุฌุฏุฏ ุจู ูุฏู ุจุฏู. ุงู ฺฉุงุฑ ุจุงุนุซ ูโุดู $w^{\top}x = 0$ ููฺูุงู ุฎุท ุจุงุดู ุงูุง ุฏุฑ ูุถุง ูฺฺฏโูุง ุฌุฏุฏ! ุฏุฑ ูุถุง ุงุตูุ ูุฑุฒ ุบุฑุฎุท ุฏุฏู ูโุดู (ูุซูุงู ูููู ุฏุงุฑู ุฏุฑ ุตูุญู 19 PDF).

### **ถ. ุจุฑุขูุฑุฏ ุจุดูู ุฏุฑุณุชโููุง (Maximum Likelihood Estimation - MLE)**

ูุฏู ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉุ ุงูุชู ุจุฑุฏุงุฑ ูุฒู $w$ ุงุณุช ฺฉู **ุงุญุชูุงู ูพุณู (Posterior Probability)** ุชูุงู ูููููโูุง ุขููุฒุด ุฑุง ุญุฏุงฺฉุซุฑ ฺฉูุฏ. ุงู ฺฉุงุฑ ุงุฒ ุทุฑู ุฑูุด **ุญุฏุงฺฉุซุฑ ุฏุฑุณุชโููุง ุดุฑุท (Maximum Conditional Log Likelihood)** ุงูุฌุงู ูโุดูุฏ.

**ุชูุถุญุงุช ุงุถุงูู:**
ุงู ุจุฎุดุ ููุจ ุงุฏฺฏุฑ ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉู. MLE ู ุฑูุด ุขูุงุฑู ุจุฑุง ูพุฏุง ฺฉุฑุฏู "ุจูุชุฑู" ูพุงุฑุงูุชุฑูุง (ุงูุฌุง $w$) ุจุฑุง ฺฉ ูุฏูุ ุทูุฑ ฺฉู ูุฏู ูุงุ ุฏุงุฏูโูุง ฺฉู ุฏุฏู ุฑู "ุจูุชุฑู" ุญุงูุช ููฺฉู ุชูุถุญ ุจุฏู.
**ูุฑููู ุงุญุชูุงู ฺฉ ููููู:**
ุงุฒ ุขูุฌุง ฺฉู $y^{(i)}$ ุฏุฑ ุทุจููโุจูุฏ ุฏูุฏู ุง 0 ุงุณุช ุง 1ุ ูโุชูุงูู ุงุญุชูุงู $P(y^{(i)}|x^{(i)},w)$ ุฑุง ุจู ุดฺฉู ูุดุฑุฏู ุฒุฑ ุจููุณู:
$$P(y^{(i)}|x^{(i)},w) = \sigma(w^{\top}x^{(i)})^{y^{(i)}} (1 - \sigma(w^{\top}x^{(i)}))^{(1-y^{(i)})}$$
* **ุงฺฏู $y^{(i)}=1$ ุจุงุดู:** (ุนู ููููู ูุงูุนุงู ุงุฒ ฺฉูุงุณ ูุซุจุช ุจูุฏ) ุชุฑู ุงูู $(\sigma(w^{\top}x^{(i)}))^{1}$ ูุนุงู ูโุดู ู ุชุฑู ุฏูู $(1 - \sigma(w^{\top}x^{(i)}))^{0}$ ฺฉู ุจุฑุงุจุฑ 1 ูโุดูุ ุฎูุซ ูโุดู. ูพุณ ุงุญุชูุงู ูุดู $\sigma(w^{\top}x^{(i)})$.
* **ุงฺฏู $y^{(i)}=0$ ุจุงุดู:** (ุนู ููููู ูุงูุนุงู ุงุฒ ฺฉูุงุณ ููู ุจูุฏ) ุชุฑู ุฏูู ูุนุงู ูโุดู ู ุชุฑู ุงูู ุฎูุซ. ูพุณ ุงุญุชูุงู ูุดู $(1 - \sigma(w^{\top}x^{(i)}))$.

**ุชุงุจุน ุฏุฑุณุชโููุง (Likelihood Function):**
ุชุงุจุน ุฏุฑุณุชโููุง ุจุฑุง ฺฉู ูุฌููุนู ุฏุงุฏู (ุจุง ูุฑุถ ุงุณุชููุงู ูููููโูุง ุงุฒ ฺฉุฏฺฏุฑ) ุจู ุตูุฑุช ุญุงุตูโุถุฑุจ ุงุญุชูุงู ูุฑ ููููู ุชุนุฑู ูโุดูุฏ:
$$L(w) = \prod_{i=1}^{n} P(y^{(i)}|x^{(i)},w)$$
**ุชูุถุญุงุช ุงุถุงูู:**
ุงู $L(w)$ ุจูููู ูฺฏู ฺูุฏุฑ "ุงุญุชูุงู" ุฏุงุฑู ฺฉู ุงู ูุฌููุนู ุฏุงุฏูโ ุขููุฒุด ฺฉู ุฏุฏูุ ุจุง ุชูุฌู ุจู ูพุงุฑุงูุชุฑูุง $w$ ูุงุ ุงุชูุงู ุงูุชุงุฏู ุจุงุดู. ูุง ูโุฎูุงู ุงู ุงุญุชูุงู ุฑู ุจุดูู ฺฉูู.

**ุชุงุจุน ูฺฏุงุฑุชู ุฏุฑุณุชโููุง (Log-Likelihood Function):**
ุจุฑุง ุณุงุฏฺฏ ูุญุงุณุจุงุช (ุจู ุฏูู ุชุจุฏู ุถุฑุจ ุจู ุฌูุน ฺฉู ูุดุชูโฺฏุฑ ุฑู ุฑุงุญุชโุชุฑ ูโฺฉูู) ู ุญูุธ ูฺฺฏโูุง ุจูููโุณุงุฒ (ุฒุฑุง ุชุงุจุน $\log$ ุชุงุจุน ุตุนูุฏ ุงุณุช ู ุจุดููโุณุงุฒ $L(w)$ ูุนุงุฏู ุจุดููโุณุงุฒ $\log L(w)$ ุงุณุช)ุ ุงุฒ ูฺฏุงุฑุชู ุชุงุจุน ุฏุฑุณุชโููุง ุงุณุชูุงุฏู ูโุดูุฏ:
$$\hat{w} = \arg \max_{w} \log \prod_{i=1}^{n} P(y^{(i)}|x^{(i)},w)$$
$$\log L(w) = \sum_{i=1}^{n} \log P(y^{(i)}|x^{(i)},w) = \sum_{i=1}^{n} \left[ y^{(i)}\log(\sigma(w^{\top}x^{(i)})) + (1-y^{(i)})\log(1-\sigma(w^{\top}x^{(i)})) \right]$$

### **ท. ุชุงุจุน ูุฒูู (Cost Function) ู ูุดุชู ุขู**

ุฏุฑ ุงุฏฺฏุฑ ูุงุดูุ ูุนูููุงู ูุฏู **ฺฉูููโุณุงุฒ (Minimization)** ฺฉ ุชุงุจุน ูุฒูู ุงุณุช. ุงุฒ ุขูุฌุง ฺฉู MLE ุจู ุฏูุจุงู **ุจุดููโุณุงุฒ (Maximization)** ุชุงุจุน ูฺฏุงุฑุชู ุฏุฑุณุชโููุง ุงุณุชุ ุชุงุจุน ูุฒูู $J(w)$ ุฑุง ุจู ุนููุงู **ููู ูฺฏุงุฑุชู ุฏุฑุณุชโููุง (Negative Log-Likelihood)** ุชุนุฑู ูโฺฉูู:
$$J(w) = - \sum_{i=1}^{n} \left[ y^{(i)}\log(\sigma(w^{\top}x^{(i)})) + (1-y^{(i)})\log(1-\sigma(w^{\top}x^{(i)})) \right]$$
ุงู ุชุงุจุน ูุฒููุ ุจุง ูุงู **Binary Cross-Entropy Loss** ูุฒ ุดูุงุฎุชู ูโุดูุฏ.

**ุชูุถุญุงุช ุงุถุงูู:**
ุงู ุชุงุจุน ุจูููู ูฺฏู ฺฉู ูุฏู ูุง ฺูุฏุฑ "ุงุดุชุจุงู" ฺฉุฑุฏู. ูุฑฺ ุงู ููุฏุงุฑ ฺฉูุชุฑ ุจุงุดูุ ูุฏู ูุง ุจูุชุฑู.
**ูุซุงู ุชุตูุฑ (ุตูุญู 26 PDF):**
* **ุฎุท ุขุจ (ุงฺฏุฑ $y=1$ ุจุงุดุฏ):** ุงฺฏุฑ ููููู ูุงูุน $y=1$ ุจุงุดูุ ู ูุฏู ูุง $0.16$ ุฑู ูพุดโุจู ฺฉููุ ุฎุทุง ุฎู ุจุงูุงุณุช (ฺูู ุฎู ุงุฒ 1 ุฏูุฑู). ูู ุงฺฏู $0.8$ ูพุดโุจู ฺฉููุ ุฎุทุง ฺฉูู.
* **ุฎุท ุฒุฑุฏ (ุงฺฏุฑ $y=0$ ุจุงุดุฏ):** ุงฺฏุฑ ููููู ูุงูุน $y=0$ ุจุงุดูุ ู ูุฏู ูุง $0.16$ ุฑู ูพุดโุจู ฺฉููุ ุฎุทุง ุฎู ฺฉูู (ฺูู ุจู 0 ูุฒุฏฺฉู). ูู ุงฺฏู $0.8$ ูพุดโุจู ฺฉููุ ุฎุทุง ุจุงูุงุณุช.

**ูฺฺฏโูุง ุชุงุจุน ูุฒูู $J(w)$:**
* **ูุญุฏุจ (Convex):** ุชุงุจุน ูุฒูู ุฑฺฏุฑุณูู ูุฌุณุชฺฉุ ฺฉ ุชุงุจุน ูุญุฏุจ ุงุณุช. ุงู ูฺฺฏ ุจุณุงุฑ ููู ุงุณุช ุฒุฑุง ุชุถูู ูโฺฉูุฏ ฺฉู ุงูฺฏูุฑุชูโูุง ุจูููโุณุงุฒ ูุจุชู ุจุฑ ฺฏุฑุงุฏุงู (ูุงููุฏ ฺฏุฑุงุฏุงู ุฏุณูุช) ุจู ฺฉ **ุจููู ุณุฑุงุณุฑ (Global Optimum)** ููฺฏุฑุง ูโุดููุฏ ู ุฏุฑ ุจูููโูุง ูุญู (Local Optima) ฺฏุฑ ููโฺฉููุฏ.
* **ูุงุจูุช ุงุซุจุงุช ูุญุฏุจ ุจูุฏู:** ูุญุฏุจ ุจูุฏู ุชุงุจุน ุงุฒ ุทุฑู ูุดุชู ุฏูู ุขู ูุงุจู ุงุซุจุงุช ุงุณุช.

**ููุงุณู ุจุง Zero-One Loss:**
ุชุงุจุน ูุฒูู Binary Cross-Entropy (ฺฉู ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ุงุณุชูุงุฏู ูโุดูุฏ) ุจุฑุฎูุงู **Zero-One Loss** (ฺฉู ุงฺฏุฑ ูพุดโุจู ุตุญุญ ุจุงุดุฏ 0 ู ุฏุฑ ุบุฑ ุงู ุตูุฑุช 1 ุงุณุช)ุ ฺฉ ุชุงุจุน ูููุงุฑ ุงุณุช ู ูุฒุงู "ุงุดุชุจุงู ุจูุฏู" ูพุดโุจู ุฑุง ุจุง ููุฏุงุฑ ุงุญุชูุงู ุฎุฑูุฌ ูุฑุชุจุท ูโฺฉูุฏ. ุงู ูฺฺฏ ุจู ุงูฺฏูุฑุชู ุจูููโุณุงุฒ ุงุฌุงุฒู ูโุฏูุฏ ุชุง ุจู ุขุฑุงู ุจู ุณูุช ุฑุงูโุญู ุจููู ุญุฑฺฉุช ฺฉูุฏ.

### **ธ. ฺฏุฑุงุฏุงู ุฏุณูุช (Gradient Descent) ุจุฑุง ุฑฺฏุฑุณูู ูุฌุณุชฺฉ**

ุงุฒ ุขูุฌุง ฺฉู ุจุฑุง $J(w)$ ุฑุงูโุญู ุชุญูู (Closed-form solution) ุจุฑุง $\nabla_w J(w) = 0$ ูุฌูุฏ ูุฏุงุฑุฏุ ุงุฒ ุงูฺฏูุฑุชูโูุง ุจูููโุณุงุฒ ุชฺฉุฑุงุฑ ูุงููุฏ **ฺฏุฑุงุฏุงู ุฏุณูุช (Gradient Descent)** ุจุฑุง ุงูุชู $w$ ุจููู ุงุณุชูุงุฏู ูโุดูุฏ.

**ุชูุถุญุงุช ุงุถุงูู:**
ฺฏุฑุงุฏุงู ุฏุณูุช ูุซู ุงูู ฺฉู ุดูุง ุฑู ู ุชูพู ุงุณุชุงุฏ ู ูโุฎูุง ุจุฑ ูพุงูโุชุฑู ููุทูโ ุฏุฑู. ูุฑ ูุฏู ฺฉู ุจุฑูโุฏุงุฑุ ุฏุฑ ุฌูุชู ฺฉู ุชูพู ุจุดุชุฑู ุดุจ ุฑู ุจู ุณูุช ูพุงู ุฏุงุฑู. ุงูุฌุง ููุ "ุฏุฑู" ูููู ุชุงุจุน ูุฒููโุณ ู ูุง ูโุฎูุงู ุจู ฺฉูุชุฑู ููุฏุงุฑุด ุจุฑุณู. "ุดุจ" ูููู ฺฏุฑุงุฏุงูู.
**ูุงุนุฏูโ ุจูโุฑูุฒุฑุณุงู (Update Rule):**
$$w^{t+1} = w^t - \eta \nabla_w J(w^t)$$
ฺฉู $w^t$ ูุฒูโูุง ุฏุฑ ูุฏู $t$ุ $w^{t+1}$ ูุฒูโูุง ุฏุฑ ูุฏู ุจุนุฏ ู $\eta$ **ูุฑุฎ ุงุฏฺฏุฑ (Learning Rate)** ุงุณุช. ูุฑุฎ ุงุฏฺฏุฑ ุชุนู ูโฺฉูู ฺฉู ุฏุฑ ูุฑ ูุฏู ฺูุฏุฑ ุจุฒุฑฺฏ ุญุฑฺฉุช ฺฉูู.

**ฺฏุฑุงุฏุงู ุชุงุจุน ูุฒูู $J(w)$:**
ุจุง ูุญุงุณุจู ูุดุชู ุชุงุจุน ูุฒูู ูุณุจุช ุจู $w$ุ ฺฏุฑุงุฏุงู ุฒุฑ ุจูโุฏุณุช ูโุขุฏ:
$$\nabla_w J(w) = \sum_{i=1}^{n} (\sigma(w^{\top}x^{(i)}) - y^{(i)}) x^{(i)}$$

**ุชูุถุญุงุช ุงุถุงูู:**
ุงู ูุฑููู ุจูููู ูฺฏู ฺฉู ฺุทูุฑ ูุฒูโูุง ุฑู ุชุบุฑ ุจุฏู. $( \sigma(w^{\top}x^{(i)}) - y^{(i)})$ ูููู "ุฎุทุง" ุง "ุชูุงูุช" ุจู ูพุดโุจู ูุฏู ($\sigma(w^{\top}x^{(i)})$) ู ููุฏุงุฑ ูุงูุน ($y^{(i)}$) ุจุฑุง ูุฑ ุฏุงุฏู ุงุณุช. ุงู ุฎุทุง ุฑู ุฏุฑ ุฎูุฏ ูฺฺฏโูุง $x^{(i)}$ ุถุฑุจ ูโฺฉูู ุชุง ุจูููู ฺฉุฏูู ูฺฺฏโูุง ุจุดุชุฑ ุจุงุนุซ ุงู ุฎุทุง ุดุฏู ู ุจุงุฏ ูุฒู ุงููโูุง ุฑู ุชุบุฑ ุจุฏู.

**ููุงุณู ุจุง ฺฏุฑุงุฏุงู ุฑฺฏุฑุณูู ุฎุท:**
ุฌุงูุจ ุงุณุช ฺฉู ฺฏุฑุงุฏุงู ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ุดุจุงูุช ุฒุงุฏ ุจู ฺฏุฑุงุฏุงู **ูุฌููุน ูุฑุจุนุงุช ุฎุทุง (Sum of Squared Errors - SSE)** ุฏุฑ ุฑฺฏุฑุณูู ุฎุท ุฏุงุฑุฏ:
* **ุฑฺฏุฑุณูู ูุฌุณุชฺฉ:** $\nabla_w J(w) = \sum_{i=1}^{n} (\sigma(w^{\top}x^{(i)}) - y^{(i)}) x^{(i)}$
* **ุฑฺฏุฑุณูู ุฎุท:** $\nabla_w J(w) = \sum_{i=1}^{n} (w^{\top}x^{(i)} - y^{(i)}) x^{(i)}$

ุชูุงูุช ุงุตู ุฏุฑ ุงู ุงุณุช ฺฉู ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉุ ุจู ุฌุง ุงุณุชูุงุฏู ูุณุชูู ุงุฒ $w^{\top}x^{(i)}$ (ฺฉู ูโุชููู ูุฑ ุนุฏุฏ ุจุงุดู)ุ ุงุฒ ุฎุฑูุฌ ุชุงุจุน ุณฺฏููุฏ ($\sigma(w^{\top}x^{(i)})$) ุงุณุชูุงุฏู ูโุดูุฏุ ฺฉู ุขู ุฑุง ุจู ฺฉ ุงุญุชูุงู ูฺฏุงุดุช ูโฺฉูุฏ.

### **น. ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ฺูุฏฺฉูุงุณู (Multi-class Logistic Regression) ุง Softmax Regression**

ููฺฏุงู ฺฉู ุจุด ุงุฒ ุฏู ฺฉูุงุณ (K > 2) ูุฌูุฏ ุฏุงุฑุฏ ู ูุฑ ููููู ุชููุง ุจู ฺฉ ฺฉูุงุณ ุชุนูู ุฏุงุฑุฏุ ุงุฒ ุชุนูู ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ุจุง ูุงู **Softmax Regression** ุงุณุชูุงุฏู ูโุดูุฏ.

**ุชูุถุญุงุช ุงุถุงูู:**
ูุฑุถ ฺฉู ุฏฺฏู ููโุฎูุง ููุท ุจฺฏ ุงุณูพู ูุณุช ุง ูุณุช. ูโุฎูุง ุจฺฏ ุงูู ูุฑุจูุท ุจู "ูุฑูุด" ูุณุชุ "ูพุดุชุจุงู" ูุณุชุ "ุชุจูุบุงุช" ูุณุช ุง "ุดุฎุต". ุงูุฌุง ฺูุงุฑ ุชุง ฺฉูุงุณ ุฏุงุฑ. Softmax Regression ุจุฑุง ุงูุฌูุฑ ููุงูุน ุจู ฺฉุงุฑ ูโุฑู.

**ุชุงุจุน Softmax:**
ุจุฑุง ูุฑ ฺฉูุงุณ $k$๏ผ ุชุงุจุน Softmax ุงุญุชูุงู ุชุนูู ููููู $x$ ุจู ุขู ฺฉูุงุณ ุฑุง ($P(y=k|x,W)$) ูพุดโุจู ูโฺฉูุฏ. ุงู ุชุงุจุน ุจู ุตูุฑุช ุฒุฑ ุชุนุฑู ูโุดูุฏ:
$$ \sigma_k(x;W) = P(y=k|x) = \frac{\exp(w_k^{\top}x)}{\sum_{j=1}^{K} \exp(w_j^{\top}x)} $$
ฺฉู $w_k$ ุจุฑุฏุงุฑ ูุฒู ูุฎุตูุต ฺฉูุงุณ $k$ ุงุณุช.

**ุชูุถุญุงุช ุงุถุงูู:**
* ุจุฑุง ูุฑ ฺฉูุงุณ (ูุซูุงู ฺฉูุงุณ 1ุ ฺฉูุงุณ 2ุ ... ฺฉูุงุณ K)ุ ู ุจุฑุฏุงุฑ ูุฒู ($w_k$) ุฏุงุฑู.
* ูุฑ ุจุฑุฏุงุฑ ูุฒู ุฏุฑ ูฺฺฏโูุง $x$ ุถุฑุจ ูโุดู ($w_k^{\top}x$) ู ู ุนุฏุฏ ุจู ุฏุณุช ูุงุฏ.
* ุจุนุฏ ุงุฒ ุชุงุจุน ููุง (exp) ุงุณุชูุงุฏู ูโฺฉูู ุชุง ุงุนุฏุงุฏ ูุซุจุช ุจุดู.
* ุฏุฑ ููุงุชุ ูุฑ ฺฉุฏูู ุงุฒ ุงู ุงุนุฏุงุฏ ููุง ุดุฏู ุฑู ุชูุณู ุจุฑ "ูุฌููุน" ุชูุงู ุงุนุฏุงุฏ ููุง ุดุฏู ูโฺฉูู ุชุง ูุทูุฆู ุจุดู ฺฉู ุฎุฑูุฌโูุง ุจู 0 ู 1 ุจุงุดู ู ูุฌููุนุดูู 1 ุจุดู.

**ูฺฺฏโูุง ุชุงุจุน Softmax:**
* **ุฎุฑูุฌ ุงุญุชูุงูุงุช:** ูุฌููุน ุงุญุชูุงูุงุช ุจุฑุง ุชูุงู ฺฉูุงุณโูุง ุจุฑุงุจุฑ 1 ุงุณุชุ ุนู $\sum_{k=1}^{K} P(y=k|x) = 1$. (ุนู ูุทูุฆูู ฺฉู ููููู ุจู ฺฉ ุงุฒ ฺฉูุงุณโูุง ุชุนูู ุฏุงุฑู)
* **ูููุงุฑ ู ูุดุชูโูพุฐุฑ:** ููุงููุฏ ุณฺฏููุฏุ Softmax ฺฉ ุชุงุจุน ูููุงุฑ ู ูุดุชูโูพุฐุฑ ุงุณุช.
* **ุจุฑุฌุณุชู ฺฉุฑุฏู ุญุฏุงฺฉุซุฑ:** ุงู ุชุงุจุน ุจู ุทูุฑ ูููุงุฑ ุงุญุชูุงู ูุฑุจูุท ุจู ฺฉูุงุณ ุจุง ุจุงูุงุชุฑู ุงูุชุงุฒ ($w_k^{\top}x$) ุฑุง ุจุฑุฌุณุชู ูโฺฉูุฏุ ุฏุฑ ุญุงู ฺฉู ุงุญุชูุงู ุณุงุฑ ฺฉูุงุณโูุง ุฑุง ฺฉุงูุด ูโุฏูุฏ. (ูุซูุงู ุงฺฏู ู ฺฉูุงุณ ุงูุชุงุฒ ุฎู ุจุงูุงุชุฑ ุฏุงุดุชู ุจุงุดูุ ุงุญุชูุงู ุงูู ูุฒุฏฺฉ 1 ู ุจูู ูุฒุฏฺฉ 0 ูโุดู).
* **ูพุดุชุจุงู ุงุฒ ููุงุฏุฑ ููู:** ุจู ุฏูู ุงุณุชูุงุฏู ุงุฒ ุชุงุจุน ููุง ($\exp$), Softmax ูโุชูุงูุฏ ูุฑูุฏโูุง ููู ุฑุง ูุฒ ุจู ุฎูุจ ูุฏุฑุช ฺฉูุฏ.

**ูุงุนุฏูโ ุชุตููโฺฏุฑ ุฏุฑ Softmax Regression:**
ุจุฑุง ฺฉ ูุฑูุฏ ุฌุฏุฏ $x$๏ผ ฺฉูุงุณ ุงูุชุฎุงุจ ูโุดูุฏ ฺฉู $\sigma_k(x;W)$ ุฑุง ุญุฏุงฺฉุซุฑ ฺฉูุฏ:
$$ \alpha(x) = \arg \max_{k=1,...,K} \sigma_k(x;W) $$

**ุชุงุจุน ูุฒูู (Cost Function) ุจุฑุง Softmax Regression:**
ุชุงุจุน ูุฒูู ุจุฑุง Softmax Regression ูุฒ ุจู ุนููุงู ููู ูฺฏุงุฑุชู ุฏุฑุณุชโููุง ุชุนุฑู ูโุดูุฏ ู ุจู ุขู **Cross-Entropy Loss (ฺูุฏฺฉูุงุณู)** ูโฺฏููุฏ:
$$ J(W) = - \sum_{i=1}^{n} \sum_{k=1}^{K} y_k^{(i)} \log(\sigma_k(x^{(i)};W)) $$
ฺฉู $y_k^{(i)}$ ฺฉ ููุฏุงุฑ ุจุงูุฑ ุงุณุช (1 ุงฺฏุฑ ููููู $i$ ุจู ฺฉูุงุณ $k$ ุชุนูู ุฏุงุดุชู ุจุงุดุฏ ู 0 ุฏุฑ ุบุฑ ุงู ุตูุฑุชุ **One-of-K encoding**).

**ุชูุถุญุงุช ุงุถุงูู:**
* **W:** ุงูุฌุง $W$ ฺฉ ูุงุชุฑุณ ุงุฒ ุชูุงู ุจุฑุฏุงุฑูุง ูุฒู $w_k$ ุจุฑุง ูุฑ ฺฉูุงุณ ุงุณุช ($W = [w_1, w_2, ..., w_K]$).
* **One-of-K encoding:** ุนู ุงฺฏู ูุซูุงู 4 ุชุง ฺฉูุงุณ ุฏุงุฑู ู ูููููโ $i$ ุจู ฺฉูุงุณ ุณูู ุชุนูู ุฏุงุฑูุ ุจุฑฺุณุจ $y^{(i)}$ ุจู ุตูุฑุช $[0, 0, 1, 0]^T$ ูุดูู ุฏุงุฏู ูโุดู. ุงูุฌูุฑ ููุท ุชุฑู ูุฑุจูุท ุจู ฺฉูุงุณ ุตุญุญ ุฏุฑ ุชุงุจุน ูุฒูู ุชุงุซุฑ ูโุฐุงุฑู.

**ฺฏุฑุงุฏุงู ุชุงุจุน ูุฒูู ุจุฑุง Softmax Regression:**
$$ \nabla_{w_j} J(W) = \sum_{i=1}^{n} (\sigma_j(x^{(i)};W) - y_j^{(i)}) x^{(i)} $$
ฺฉู $w_j^t$ ุจุฑุฏุงุฑ ูุฒู ุจุฑุง ฺฉูุงุณ $j$ ุฏุฑ ุชฺฉุฑุงุฑ $t$-ุงู ุงุณุช.

### **ฑฐ. ุฏุฏฺฏุงู ุงุญุชูุงูุงุช ุฏุฑ ุทุจููโุจูุฏ: ูุฏูโูุง Generative ุฏุฑ ููุงุจู Discriminative**

ุฏุฑ ูุณุงุฆู ุทุจููโุจูุฏุ ูโุชูุงูู ูุฏูโูุง ุฑุง ุงุฒ ุฏู ุฏุฏฺฏุงู ุงุตู ุจุฑุฑุณ ฺฉูู:

#### **ุงูู) ูุฏูโูุง Generative (ูููุฏ)**
* **ูุญููโ ุงุฏฺฏุฑ:** ุงู ูุฏูโูุง ุงุจุชุฏุง **ุชูุฒุน ุชูุงู (Joint Probability Distribution)** $P(x,y)$ ุฑุง ุงุฏ ูโฺฏุฑูุฏ. ุจู ุนุจุงุฑุช ุฏฺฏุฑุ ุขูโูุง ุชูุฒุนโูุง ุงุญุชูุงูุงุช $P(x|C_k)$ (**ุงุญุชูุงู ุดุฑุท ฺฉูุงุณ ุง Likelihood**) ู $P(C_k)$ (**ุงุญุชูุงู ูพุดู ฺฉูุงุณ ุง Prior**) ุฑุง ุจุฑุง ูุฑ ฺฉูุงุณ $C_k$ ุจุฑุขูุฑุฏ ูโฺฉููุฏ.
* **ูพุดโุจู:** ุณูพุณ ุจุง ุงุณุชูุงุฏู ุงุฒ **ูุงููู ุจุฒ (Bayes' Theorem)**ุ ุงุญุชูุงู ูพุณู $P(C_k|x)$ ุฑุง ูุญุงุณุจู ูโฺฉููุฏ:
    $$ P(C_k|x) = \frac{P(x|C_k)P(C_k)}{\sum_{j=1}^{K}P(x|C_j)P(C_j)} $$
    ู ุฏุฑ ููุงุช ฺฉูุงุณ ุงูุชุฎุงุจ ูโุดูุฏ ฺฉู ุจุงูุงุชุฑู $P(C_k|x)$ ุฑุง ุฏุงุดุชู ุจุงุดุฏ.
* **ฺฉุงุฑุจุฑุฏูุง:** ูุฏูโูุง ูููุฏ ุนูุงูู ุจุฑ ุทุจููโุจูุฏุ ูโุชูุงููุฏ ุจุฑุง **ุชููุฏ ุฏุงุฏูโูุง ุฌุฏุฏ (Generate new data)** ูุฒ ุงุณุชูุงุฏู ุดููุฏุ ุฒุฑุง ุชูุฒุน ฺฉุงูู ุฏุงุฏูโูุง ุฑุง ุงุฏ ฺฏุฑูุชูโุงูุฏ.
* **ูุซุงู:** **Naive Bayes** ฺฉ ูุซุงู ุงุฒ ูุฏู Generative ุงุณุช.

**ุชูุถุญุงุช ุงุถุงูู:**
ุงู ูุฏูโูุง ุงูู ุงุฏ ูโฺฏุฑู ฺฉู ุฏุงุฏูโูุง ูุฑ ฺฉูุงุณ (ูุซูุงู ูฺฺฏโูุง ุชูููุฑ ุฎูุดโุฎู) ฺุทูุฑ "ุชูุฒุน" ุดุฏู. ุจุนุฏ ุงุฏ ูโฺฏุฑู ฺฉู ูุฑ ฺฉูุงุณ (ุฎูุดโุฎู ุง ุจุฏุฎู) ุจู ุฎูุฏ ุฎูุฏ ฺูุฏุฑ ุฑุงุฌู. ุจุนุฏุงู ุงฺฏู ู ุฏุงุฏูโ ุฌุฏุฏ ุจุจููุ ุจุง ุงุณุชูุงุฏู ุงุฒ ูุงููู ุจุฒ ูุญุงุณุจู ูโฺฉูู ฺฉู ฺูุฏุฑ ูุญุชููู ุงู ุฏุงุฏู ุจู ูุฑ ฺฉูุงุณ ุชุนูู ุฏุงุดุชู ุจุงุดู ู ุงููู ุจู ฺฉูุงุณ ฺฉู ูุญุชููโุชุฑูุ ุงุฎุชุตุงุต ูโุฏู. ูุซู ุงู ูโูููู ฺฉู ุงูู ุงุฏ ูโฺฏุฑู ฺู ุดฺฉูโุงูุฏ ุขุฏูโูุง ูุฏ ุจููุฏุ ฺู ุดฺฉูโุงูุฏ ุขุฏูโูุง ฺฉูุชุงู. ุจุนุฏุด ู ุขุฏู ุฌุฏุฏ ูโุจููุ ูโฺฏู ุงู ฺูุฏุฑ ุดุจู ุขุฏูโูุง ูุฏ ุจููุฏูุ ฺูุฏุฑ ุดุจู ุขุฏูโูุง ฺฉูุชุงููุ

#### **ุจ) ูุฏูโูุง Discriminative (ุชูุงุฒ)**
* **ูุญููโ ุงุฏฺฏุฑ:** ุงู ูุฏูโูุง ูุณุชููุงู **ุชูุฒุน ุงุญุชูุงู ุดุฑุท (Conditional Probability Distribution)** $P(y|x)$ ุฑุง ุงุฏ ูโฺฏุฑูุฏ. ุจู ุนุจุงุฑุช ุฏฺฏุฑุ ุขูโูุง ูุฑุฒ ุฑุง ุฏุฑ ูุถุง ูฺฺฏโูุง ุงุฏ ูโฺฏุฑูุฏ ฺฉู ุจูุชุฑู ุชูฺฉฺฉ ุฑุง ุจู ฺฉูุงุณโูุง ุงุฌุงุฏ ูโฺฉูุฏ.
* **ูพุดโุจู:** ฺฉูุงุณ ุงูุชุฎุงุจ ูโุดูุฏ ฺฉู $P(C_k|x)$ ุขู ุงุฒ ุณุงุฑ ฺฉูุงุณโูุง ุจุดุชุฑ ุจุงุดุฏ.
* **ฺฉุงุฑุจุฑุฏูุง:** ุชูุฑฺฉุฒ ุงุตู ุงู ูุฏูโูุง ุจุฑ ุฏูุช ุทุจููโุจูุฏ ุงุณุช ู ูุนูููุงู ุจุฑุง ุชููุฏ ุฏุงุฏู ุงุณุชูุงุฏู ููโุดููุฏ.
* **ูุซุงู:** **ุฑฺฏุฑุณูู ูุฌุณุชฺฉ (Logistic Regression)** ฺฉ ูุซุงู ุจุงุฑุฒ ุงุฒ ูุฏู Discriminative ุงุณุช. ุงู ูุฏู ูุณุชููุงู ุงุญุชูุงู $P(y=1|x)$ ุฑุง ุจุง ุงุณุชูุงุฏู ุงุฒ ุชุงุจุน ุณฺฏููุฏ ($\sigma(w^{\top}x)$) ุชุฎูู ูโุฒูุฏ.

**ุชูุถุญุงุช ุงุถุงูู:**
ุงู ูุฏูโูุง ูุณุชูู ุฑู ูุฑุฒ ุจู ฺฉูุงุณโูุง ุชูุฑฺฉุฒ ูโฺฉูู. ุฏฺฏู ุจุฑุงุดูู ููู ูุณุช ฺฉู ูุฑ ฺฉูุงุณ ุจู ุชููุง ฺู ุชูุฒุน ุฏุงุฑูุ ููุท ูโุฎูุงู ุจุฏููู ฺุทูุฑ ุจูุชุฑู ุฎุท ุฌุฏุงฺฉููุฏู ุฑู ูพุฏุง ฺฉูู. ูุซู ุงู ูโูููู ฺฉู ูู ุจฺฏู ุฎุท ุจฺฉุดุฏ ฺฉู ุขุฏูโูุง ูุฏ ุจููุฏ ุฑู ุงุฒ ฺฉูุชุงู ุฌุฏุง ฺฉููุ ุจุฏูู ุงูฺฉู ูุงุฒ ุจุงุดู ุฏููุงู ุจุฏููู ุชูุฒุน ูุฏ ุขุฏูโูุง ฺู.

**ุฎูุงุตูโ ููุงุณู:**
| ูฺฺฏ | ูุฏูโูุง Generative (ูููุฏ) | ูุฏูโูุง Discriminative (ุชูุงุฒ) |
| :--------------- | :------------------------------------------------------------- | :------------------------------------------------------- |
| ูุฏู ุงุฏฺฏุฑ | $P(x,y)$ (ุชูุฒุน ุชูุงู) | $P(y|x)$ (ุชูุฒุน ุดุฑุท) |
| ูุญูู ูพุดโุจู | ูุญุงุณุจู $P(y|x)$ ุจุง ูุงููู ุจุฒ ุงุฒ $P(x|y)$ ู $P(y)$ | ูุณุชูู ูุฏูโุณุงุฒ $P(y|x)$ |
| ฺฉุงุฑุจุฑุฏ ุฏฺฏุฑ | ุชููุฏ ุฏุงุฏูโูุง ุฌุฏุฏ | ุชูุฑฺฉุฒ ุจุฑ ุทุจููโุจูุฏ |
| ูุซุงูโูุง | Naive Bayes, Gaussian Discriminant Analysis | Logistic Regression, Support Vector Machine (SVM) |

---

### **ุฎูุงุตูโ ุฑฺฏุฑุณูู ูุฌุณุชฺฉ (LR Summary)**

* **ุทุจููโุจูุฏโฺฉููุฏู ุฎุท:** ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ฺฉ ุทุจููโุจูุฏโฺฉููุฏู ุฎุท ุงุณุช (ูฺฏุฑ ุงูฺฉู ุงุฒ ูฺฏุงุดุช ูฺฺฏโูุง ุบุฑุฎุท ุงุณุชูุงุฏู ุดูุฏ).
* **ุจูููโุณุงุฒ ุจุง MLE:** ูุณุฆูู ุจูููโุณุงุฒ LR ุงุฒ ุทุฑู ุฑูุด ุจุดูู ุฏุฑุณุชโููุง (Maximum Likelihood Estimation) ูุฑูููโุจูุฏ ูโุดูุฏ.
* **ุนุฏู ูุฌูุฏ ุฑุงูโุญู ุชุญูู:** ูฺ ุฑุงูโุญู ุชุญูู (Closed-form solution) ุจุฑุง ูุณุฆูู ุจูููโุณุงุฒ ุขู ูุฌูุฏ ูุฏุงุฑุฏ.
* **ุชุงุจุน ูุฒูู ูุญุฏุจ:** ุจุง ุงู ุญุงูุ ุชุงุจุน ูุฒูู ุขู (Cross-Entropy Loss) ูุญุฏุจ ุงุณุชุ ฺฉู ุจู ุงู ูุนู ุงุณุช ฺฉู ุงูฺฏูุฑุชูโูุง ฺฏุฑุงุฏุงู ุฏุณูุช ูโุชูุงููุฏ ุจู ฺฉ ุจููู ุณุฑุงุณุฑ ููฺฏุฑุง ุดููุฏ.

---
**ููุงุจุน:**
* M. Soleymani Baghshah, "Machine learning." Lecture slides.
* A. Ng, "Ml-005, lecture 6." Lecture slides.
* C. M. Bishop, Pattern Recognition and Machine Learning. Information Science and Statistics, New York, NY: Springer, 1 ed., Aug. 2006.
* S. Fidler, "Csc411." Lecture slides.
* A. Ng and T. Ma, CS229 Lecture Notes. Updated June 11, 2023.

---

ูุฎูุงู ุชู ุงู ูุงู ููู ุณุงุชุง ุฑู ุญุฐู ฺฉู ู ุจู ูุฑ ูุชู ุง ูพุงุฑุงฺฏุฑุงู ุฏุฑ ุฎุท ุงููุด ูุฑุงุฑ ุจุฏ ุจุง ุดูุงุฑูุฏู 1 ุชุง ูุฑุฌุง ฺฉ ุฑู 
[cite_start]ู ูุฑ ูพุงุฑุงฺฏุฑุงู ุงุฒ ุฎุท ุงูู [cite:1] [cite_start]ุงุฒ ุงูู ูุณูุช ุจ ุจุนุฏ ุฏฺฏู ุฑู ูููู ุฎุท ูุจุงุดู [cite:2] 
ุฏุฑ ูพุงุงู ุจุงุฏ ุชูุงู cite_start ุญุฐู ู ุชูุงู cite:number ุฏุฑ ุฌุง ุฎูุฏ ุจุงุดูุฏ 
ูุทูุง ููุท ฺฉุฏ ูุงุฑฺฉ ุฏุงูู ุฑุง ุจุฏู
