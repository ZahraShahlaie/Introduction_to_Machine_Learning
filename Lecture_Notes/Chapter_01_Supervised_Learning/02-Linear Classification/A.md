

📘 جزوه آموزشی درس یادگیری ماشین (CE 40717)

موضوع: طبقه‌بندی خطی (Linear Classification) و پرسپترون (Perceptron)

تاریخ: ۳۰ سپتامبر ۲۰۲۴

مدرس: دکتر علی شریفی‌زارچی
> 📚 Introduction to Classification
> 🧮 Discriminant Functions
> ➗ Linear Classifiers
> 🔁 Perceptron & Cost Functions
> ✅ Cross-validation
> 🔢 Multi-class Classification




---


 ## ۱. مقدمه‌ای بر طبقه‌بندی (Introduction to Classification)

تعریف:
در یادگیری ماشین، هدف طبقه‌بندی این است که:

 داده‌های ورودی (Training Set): یک مجموعه داده آموزشی
  $D$
  با
  $N$
  نمونه برچسب‌دار داریم:
  $D = \{ (x^{(i)}, y^{(i)}) \}_{i=1}^N$

 برچسب‌ها (Labels): هر
  $y^{(i)}$
  به یکی از
  $K$
  کلاس ممکن تعلق دارد:
  $y^{(i)} \in \{1, ..., K\}$

هدف نهایی: با دریافت یک ورودی جدید
  $x$
  آن را به یکی از
  $K$
  کلاس موجود تخصیص دهیم.

توضیحات اضافه:
تصور کنید یک کمد دارید و می‌خواهید لباس‌ها را بر اساس رنگ (قرمز، آبی، سبز) در قفسه‌های مختلف قرار دهید. اینجا رنگ لباس "برچسب" شماست و هر لباس جدیدی که می‌آید، باید به یکی از این قفسه‌ها (کلاس‌ها) برود. در یادگیری ماشین هم همین‌طور است؛ ما به مدل "آموزش" می‌دهیم که بر اساس ویژگی‌های ورودی، نمونه‌های جدید را به کلاس‌های صحیح اختصاص دهد.

مثال‌های واقعی:

* تشخیص اسپم ایمیل: ایمیل‌ها به دو دسته "اسپم" یا "اینباکس" طبقه‌بندی می‌شوند.
* تشخیص پزشکی: بر اساس علائم و نتایج آزمایش، بیماری‌ها (مانند دیابت) تشخیص داده می‌شوند.
* پیش‌بینی ریزش مشتری (Churn Prediction): پیش‌بینی اینکه آیا یک مشتری، خدمات شرکت را ترک خواهد کرد یا خیر.

مثال: مجموعه داده دیابت پیما ایندیانز (Pima Indians Diabetes Dataset):

* مسئله: پیش‌بینی اینکه آیا یک بیمار بر اساس داده‌های تشخیصی پزشکی (مانند تعداد دفعات بارداری، گلوکز، فشار خون، BMI، سن و...) دیابت دارد یا خیر.
* اهمیت: تشخیص زودهنگام دیابت برای درمان و مدیریت آن حیاتی است.

**طبقه‌بندی در مقابل رگرسیون (Classification vs. Regression):**

| جنبه          | رگرسیون خطی (Linear Regression)     | طبقه‌بندی خطی (Linear Classification)                    |
| :------------ | :---------------------------------- | :------------------------------------------------------- |
| نوع خروجی     | مقادیر پیوسته (اعداد حقیقی)         | برچسب‌های دودویی یا چندکلاسه (مثلاً -1/+1، A/B/C)        |
| موارد استفاده | پیش‌بینی قیمت خانه، روند بازار سهام | تشخیص اسپم ایمیل، امتیازدهی اعتباری، پیش‌بینی ریزش مشتری |

توضیحات اضافه:
فقط به یاد داشته باش که "رگرسیون" یعنی پیش‌بینی یک عدد (مثلاً قیمت خونه)، ولی "طبقه‌بندی" یعنی پیش‌بینی یک دسته یا گروه (مثلاً اینکه ایمیل اسپمه یا نه). مدل‌های خطی هم می‌تونن برای رگرسیون و هم برای طبقه‌بندی استفاده بشن، فقط نوع خروجی و روش یادگیری‌شون فرق می‌کنه.

---



## ۲. توابع تشخیص (Discriminant Functions)

**تعریف:**
تابع تشخیص، تابعی است که به یک بردار ورودی $x$ یک "امتیاز" تخصیص می‌دهد تا آن را به کلاس‌های مختلف طبقه‌بندی کند. این تابع، ورودی $x$ را به یک عدد حقیقی $g(x)$ نگاشت می‌کند که نشان‌دهنده درجه اطمینان مدل در تخصیص $x$ به یک کلاس خاص است.


**توضیحات اضافه:**
تصور کن داری میوه‌ها را دسته‌بندی می‌کنی. یک تابع تشخیص می‌تواند به هر میوه بر اساس رنگ، بو و اندازه، یک "امتیاز" بدهد. مثلاً اگر امتیاز بالای ۰.۷ باشد، می‌گویی این سیب است؛ اگر کمتر بود، ممکن است پرتقال باشد.



### چگونگی کارکرد:

**طبقه‌بندی دودویی (Binary Classification):**
برای دو کلاس $C_1$ و $C_2$، دو تابع $g_1(x)$ و $g_2(x)$ محاسبه می‌شوند. کلاس بر اساس مقایسه این دو تابع پیش‌بینی می‌شود:

$$
\hat{y} = \begin{cases} 
C_1 & \text{if } g_1(x) > g_2(x) \\
C_2 & \text{otherwise}
\end{cases}
$$



**حالت کلی (K-class Problems):**
برای مسائل با $K$ کلاس، تابع $g_i(x)$ برای هر کلاس $i$ محاسبه می‌شود. نمونه $x$ به کلاسی تخصیص داده می‌شود که بالاترین امتیاز را داشته باشد:

$$
\hat{y} = \arg\max_i g_i(x)
$$

---



## 3. مرز تصمیم (Decision Boundary)


 **تعریف:** یک هایپرپلین جداکننده است که کلاس‌های مختلف را در فضای ویژگی‌ها از هم جدا می‌کند. به آن "سطح تصمیم" (Decision Surface) نیز گفته می‌شود. ب عبارت دیگر مرز تصمیم همان سطحی است که فضای ورودی را به ناحیه‌هایی تقسیم می‌کند که هر کدام مربوط به یک کلاس هستند. 



 **مثال‌های بصری:**

  مرز تصمیم خطی دو بعدی (2D Linear Decision Boundary): یک خط صاف که دو دسته داده را از هم جدا می‌کند.

   مرز تصمیم غیرخطی دو بعدی (2D Non-linear Decision Boundary): یک منحنی که دو دسته داده را از هم جدا می‌کند.

  مرز تصمیم خطی سه بعدی (3D Linear Decision Boundary): یک صفحه که دو دسته داده را از هم جدا می‌کند.

   مرز تصمیم غیرخطی سه بعدی (3D Non-linear Decision Boundary): یک سطح منحنی که دو دسته داده را از هم جدا می‌کند.

  در فضای دو‌بعدی، این مرز یک خط است. در فضای سه‌بعدی یک صفحه و در فضای d-بعدی یک هایپرپلین (صفحه با d−1 بعد). نمونه‌های دو طرف این مرز به دو کلاس متفاوت تعلق دارند. در مدل‌های خطی، مرز تصمیم نیز خطی است.



### توابع تشخیص برای دو-دسته (Two-Category):

برای مسائل دو دسته‌ای، می‌توان تنها یک تابع
$g: \mathbb{R}^d \to \mathbb{R}$
پیدا کرد:

$$
g_1(x) = g(x)
$$

$$
g_2(x) = -g(x)
$$

مرز تصمیم:
$g(x) = 0$. (یعنی جایی که $g_1(x)$ و $g_2(x)$ برابر می‌شوند).


**توضیحات اضافه:**
وقتی می‌گوییم "مرز تصمیم"، منظورمان یک خط، یک صفحه یا یک سطح پیچیده‌تر است که فضای داده‌ها را به قسمت‌هایی تقسیم می‌کند. هر قسمت مربوط به یک کلاس است. اگر این مرز یک خط راست باشد (در دو بعد) یا یک صفحه صاف (در سه بعد)، به آن "خطی" می‌گوییم. اگر منحنی یا سطح پیچیده‌ای باشد، آن را "غیرخطی" می‌نامیم.

![decision_boundry](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/02-Linear%20Classification/images/decision%20boundry.png)


---



## ۳. طبقه‌بندی‌کننده‌های خطی (Linear Classifiers)

**تعریف:**
در طبقه‌بندی‌کننده‌های خطی، مرزهای تصمیم به صورت خطی در فضای $d$-بعدی ویژگی‌ها ($x \in \mathbb{R}^d$) یا خطی در یک مجموعه مشخص از توابع $x$ (توابع ویژگی) هستند.


### داده‌های جداسازی‌پذیر خطی (Linearly Separable Data):

نقاط داده‌ای که می‌توانند دقیقاً توسط یک مرز تصمیم‌گیری خطی از هم جدا شوند.

**توضیحات اضافه:**
خیلی از اوقات داده‌ها را می‌شود با یک خط راست از هم جدا کرد (مانند دایره‌ها و ضربدرها در شکل زیر). این داده‌ها "جداسازی‌پذیر خطی" هستند. طبقه‌بندی‌کننده‌های خطی محبوب هستند چون:
![14_pdf](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/02-Linear%20Classification/images/14_pdf.png)


* **سادگی (Simplicity):** پیاده‌سازی و درک آسان دارند.
* **کارایی (Efficiency):** از نظر محاسباتی کم‌هزینه هستند.
* **اثربخشی (Effectiveness):** با وجود سادگی، در بسیاری از مسائل واقعی عملکرد خوبی دارند.



### طبقه‌بندی دو-دسته (Two Category Classification):

یک تابع تشخیص خطی به صورت زیر تعریف می‌شود:

$$
g(x) = w^T x + w_0 = w_d \cdot x_d + \ldots + w_1 \cdot x_1 + w_0
$$

که در آن:

* $x = [x_1, \ldots, x_d]$ بردار ویژگی‌ها،
* $w = [w_1, \ldots, w_d]$ بردار وزن‌ها،
* و $w_0$ بایاس (bias) است.


### قاعده تصمیم:

$$
\hat{y} = 
\begin{cases}
C_1 & \text{if } w^T x + w_0 \geq 0 \\
C_2 & \text{otherwise}
\end{cases}
$$



### مرز تصمیم:

معادله مرز تصمیم برابر است با:

$$
w^T x + w_0 = 0
$$



### ویژگی‌های مرز تصمیم (هایپرپلین $H$):

* مرز تصمیم یک هایپرپلین $(d-1)$-بعدی $H$ در فضای ویژگی $d$-بعدی است.
* جهت هایپرپلین توسط بردار نرمال $\left[ \frac{w_1}{\|w\|}, \ldots, \frac{w_d}{\|w\|} \right]$ تعیین می‌شود.
* موقعیت هایپرپلین توسط $w_0$ تعیین می‌شود. (این تغییر در نمودارهای زیر که $w_0$ از 0 به 0.5 تغییر می‌کند، واضح است.)
* ![w0loc](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/02-Linear%20Classification/images/w0loc.png)


  ![des_1](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/02-Linear%20Classification/images/des%201.jpg)




---
### مرز تصمیم غیرخطی (Non-linear Decision Boundary):

* **تبدیل ویژگی (Feature Transformation):**
  برای ایجاد غیرخطی بودن، ویژگی‌ها به فضای با ابعاد بالاتر تبدیل می‌شوند. این تبدیل با استفاده از یک تابع غیرخطی $\phi(x)$ انجام می‌شود.

* **خطی در فضای تبدیل‌شده:**
  مرز تصمیم در فضای جدید (تبدیل‌شده) خطی می‌شود، اما در فضای اصلی $x$ غیرخطی است.


### مثال: ایجاد مرز تصمیم دایره‌ای

مرز تصمیم دایره‌ای مانند $-1 + x_1^2 + x_2^2 = 0$ با مشخصات زیر:

* ویژگی‌های اصلی:

  $$
  x = [x_1, x_2]
  $$

* تبدیل ویژگی:

  $$
  \phi(x) = [1, x_1, x_2, x_1^2, x_2^2, x_1 x_2]
  $$

* وزن‌ها:

  $$
  w = [w_0, w_1, \ldots, w_m] = [-1, 0, 0, 1, 1, 0]
  $$

* قاعده تصمیم:
  اگر $w^T \phi(x) \geq 0$ باشد، آنگاه $y = 1$؛ در غیر این صورت $y = -1$.



**توضیحات اضافه:**
این بخش بسیار مهم است. اگر داده‌ها با یک خط صاف از هم جدا نشوند (مانند مسئله XOR)، می‌توانی ویژگی‌های جدیدی از همان ویژگی‌های قدیمی بسازی. مثلاً اگر ویژگی‌ها $x_1$ و $x_2$ باشند، می‌توانی ویژگی‌های جدید $x_1^2$ و $x_2^2$ را نیز اضافه کنی. اکنون مرز تصمیم‌گیری در این فضای جدید با ابعاد بیشتر، خطی خواهد بود، اما اگر به آن از دید فضای اصلی نگاه کنی، می‌بینی که مرز تصمیم دیگر خطی نیست و ممکن است یک منحنی یا دایره باشد.
![nonlinear](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/02-Linear%20Classification/images/nonlinear.png)

---

### ۴. پرسپترون (Perceptron)

#### **پرسپترون چیست؟**

پرسپترون ساده‌ترین نوع نورون مصنوعی است که در یادگیری ماشین برای انجام وظایف طبقه‌بندی استفاده می‌شود.

#### **واحد ساختاری پایه (Basic Building Block)**

پرسپترون به عنوان ساده‌ترین نوع نورون مصنوعی، ورودی‌ها را به یک خروجی نگاشت می‌کند. این نگاشت از طریق یک ترکیب خطی و آستانه (Threshold) انجام می‌شود.
![perceptron](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/02-Linear%20Classification/images/perceptron.png)


#### **طبقه‌بندی‌کننده خطی**

پرسپترون خروجی را از یک ترکیب خطی از ورودی‌ها و وزن‌ها محاسبه کرده و با استفاده از آستانه‌ای خاص تصمیم می‌گیرد که آیا خروجی 1 است یا 0.

#### **تصمیم دودویی (Binary Decision)**

* اگر جمع وزن‌دار ورودی‌ها از آستانه بیشتر شود، خروجی 1 خواهد بود.
* در غیر این صورت، خروجی 0 خواهد بود.

#### **اجزا:**

* ورودی‌ها (Inputs)
* وزن‌ها (Weights)
* بایاس (Bias)
* تابع فعال‌سازی (Activation Function) - معمولاً از تابع پله‌ای (Step Function) یا سیگموید (Sigmoid) استفاده می‌شود.

#### **توضیح:**

پرسپترون مانند کوچک‌ترین واحد مغز انسان (نورون) عمل می‌کند. ورودی‌ها را دریافت می‌کند، هر کدام را در وزن مربوطه ضرب کرده و جمع می‌کند. سپس یک بایاس (مانند آستانه) به آن اضافه می‌کند و خروجی را از یک تابع فعال‌سازی عبور می‌دهد تا تصمیم نهایی (0 یا 1) را بگیرد.

#### **الهام‌گرفته از زیست‌شناسی:**

پرسپترون عملکرد اصلی نورون‌های بیولوژیکی مغز را تقلید می‌کند.

#### **نورون منفرد (Single Neuron):**

فرمول خروجی یک نورون منفرد به صورت زیر است:

$$
y = f(w^T x + w_0)
$$

که در آن:

* $x$ بردار ورودی،
* $w$ بردار وزن‌ها،
* $w_0$ بایاس،
* $f$ تابع فعال‌سازی (مثلاً تابع پله‌ای).
![active](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/02-Linear%20Classification/images/active.png)
![active2](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/02-Linear%20Classification/images/active2.jpg)

**محدودیت:** تنها قادر به حل مسائل **خطی قابل تفکیک** است، مثل AND و OR، اما نه XOR.
![xor](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/02-Linear%20Classification/images/xor.png)


xor تفکیک پذیر خطی نیس و نمیتوان با یک لابه پرسپترون ان را جدا کرد.
![fire](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/02-Linear%20Classification/images/fire.jpg)

![learn_no1](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/02-Linear%20Classification/images/learn%20no1.png)
![learn_no2](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/02-Linear%20Classification/images/learn%20no2.jpg)



### **به سمت مرزهای تصمیم‌گیری پیچیده‌تر (Multi-Layer Perceptron - MLP):**

#### **افزودن لایه‌ها برای پیچیدگی بیشتر:**

MLP شامل چندین لایه نورون است که می‌تواند توابع پیچیده‌تر را مدل‌سازی کند.

#### **لایه‌های جدید = مرزهای تصمیم جدید:**

هر لایه، مرزهای تصمیم جدیدی ایجاد می‌کند که باعث جداسازی داده‌های غیرخطی می‌شود.

#### **مثال ساختار دو لایه:**

* لایه ورودی → لایه پنهان (Hidden Layer) → لایه خروجی (Output Layer)

#### **لایه پنهان و تبدیل‌های غیرخطی:**

لایه پنهان تبدیل‌های غیرخطی را معرفی می‌کند که باعث می‌شود مدل قادر به یادگیری مرزهای پیچیده‌تری شود.

#### **توضیح:**

برای حل مسائل پیچیده‌تر مانند XOR، می‌توان چند پرسپترون را به صورت لایه‌ای به هم متصل کرد. این ساختار به نام **پرسپترون چندلایه (MLP)** یا **شبکه عصبی (Neural Network)** شناخته می‌شود. ترکیب لایه‌ها و غیرخطی بودن بین آن‌ها باعث می‌شود که مدل قادر به یادگیری مرزهای تصمیم‌گیری پیچیده و غیرخطی باشد.


---

**انتخاب تابع هزینه و تابع فعال‌سازی مناسب در مسائل دسته‌بندی**
پس از یادگیری ساختار مدل (معماری پرسپترون)، گام بعدی یافتن یک **تابع هزینه** مناسب است که بتوان آن را با الگوریتم‌های بهینه‌سازی مانند **گرادیان کاهشی (Gradient Descent)** بهینه کرد. هدف اصلی این تابع هزینه، نزدیک کردن خروجی مدل (پیش‌بینی $g_h$) به لیبل واقعی ($Y$) است. به عنوان مثال، اگر برای لیبل ۲ (مثلاً سگ) انتظار داریم $G_2$ از $G_1$ و $G_3$ بزرگ‌تر باشد.

---

### چرا **Sum Squared Error (SSE)** برای دسته‌بندی مناسب نیست؟

اولین تابعی که ممکن است به ذهن برسد، **خطای مجموع مربعات (Sum Squared Error - SSE)** است که در رگرسیون خطی استفاده می‌شود. SSE به صورت $(Y_h - Y)^2$ محاسبه می‌شود. با این حال، استفاده از SSE برای مسائل دسته‌بندی باینری (مثلاً ۰ و ۱) مشکلات جدی ایجاد می‌کند:

* **عدم تمایز قائل شدن بین درجات مختلف پیش‌بینی صحیح:** فرض کنید خروجی مدل $Y_h$ است که فقط علامت را نشان می‌دهد (مثلاً $Y_h = 1$ اگر ورودی سگ است و $Y_h = 0$ اگر گربه است).

  * اگر $Y=1$ (سگ) باشد و مدل $Y_h=1$ پیش‌بینی کند، خطا صفر است.
  * اما اگر سگ‌های "سگ‌تر" یا "خشن‌تر" داریم که مدل خروجی $Y_h=2$ (مثلاً) برای آن‌ها می‌دهد (یعنی "بیشتر سگ است")، با وجود اینکه این پیش‌بینی درست است و نشان می‌دهد که شیء واقعاً سگ است، SSE خطایی برابر $(2-1)^2 = 1$ تولید می‌کند. این خطا غیرمنطقی است زیرا مدل به درستی شیء را در کلاس "سگ" قرار داده است.
* **کشاندن مرز تصمیم‌گیری:** افزودن نقاط داده جدید که در یک کلاس قرار دارند (مثلاً کلاس ۱)، حتی اگر کاملاً در آن کلاس باشند و از مرز تصمیم‌گیری فاصله زیادی داشته باشند، باعث می‌شود مدل سعی کند مرز تصمیم‌گیری را به سمت این نقاط جدید حرکت دهد تا خطای آن‌ها را کاهش دهد. این امر به دلیل این است که SSE برای فاصله‌ی پیش‌بینی از لیبل واقعی مجازات می‌کند، حتی اگر پیش‌بینی در جهت درست باشد. این رفتار در مسائل دسته‌بندی نامطلوب است زیرا هدف اصلی تعیین صحیح کلاس است، نه مطابقت دقیق مقدار خروجی با لیبل.

این مشکلات باعث می‌شود که SSE یک **تابع هزینه بسیار نامناسب** برای مسائل دسته‌بندی باشد.
![sse_cost](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/02-Linear%20Classification/images/sse%20cost.png)


---

### جایگزینی برای Identity Activation Function و مشکلات آن: **Sign Function**

پرسپترون خام (بدون تابع فعال‌سازی) صرفاً $W^T X + W_0$ را محاسبه می‌کند که به نوعی از تابع فعال‌سازی **Identity (همانی)** استفاده می‌کند (یعنی خروجی همان ورودی است). برای بهبود این وضعیت در دسته‌بندی، می‌توانیم از یک تابع فعال‌سازی استفاده کنیم.

یکی از جایگزین‌های پیشنهادی، **تابع علامت (Sign Function)** است:

$$
\text{Sign}(x) = 
\begin{cases} 
-1 & \text{if } x < 0 \\
0 & \text{if } x = 0 \\
1 & \text{if } x > 0 
\end{cases}
$$

(گاهی اوقات برای دسته‌بندی باینری به جای -۱ و ۱، از ۰ و ۱ استفاده می‌شود).

**مزایای استفاده از Sign Function:**

* **ثبات در پیش‌بینی:** این تابع به درستی "درجه سگ بودن" را نادیده می‌گیرد و فقط برچسب را ارائه می‌دهد. اگر $X$ نمایانگر سگ باشد، چه "کمی سگ" باشد چه "خیلی سگ"، خروجی همواره ۱ (یا -۱ بسته به تعریف) خواهد بود. این یعنی برای سگ‌های "سگ‌تر" هم خطایی ایجاد نمی‌شود.
* **بهبود نسبت به Identity:** این تابع در مسائل دسته‌بندی عملکرد بسیار بهتری نسبت به Identity Function دارد.

**مشکل اساسی Sign Function:**

* **مشتق‌ناپذیری (Non-Differentiable):** تابع علامت در نقطه $X=0$ مشتق‌پذیر نیست و در بقیه نقاط نیز مشتق آن صفر است. این ویژگی یک مانع بزرگ برای استفاده از الگوریتم **گرادیان کاهشی (Gradient Descent)** است. گرادیان کاهشی برای بهینه‌سازی پارامترها به مشتق تابع هزینه نیاز دارد تا جهت کاهش خطا را پیدا کند. از آنجایی که Sign Function مشتق‌پذیر نیست، نمی‌توانیم از آن به عنوان یک تابع فعال‌سازی در مدل‌هایی که با گرادیان کاهشی آموزش می‌بینند، استفاده کنیم.
![sign](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/02-Linear%20Classification/images/sign.png)

---

### نتیجه‌گیری اولیه و گام بعدی

تابع **Sign Function** با وجود اینکه در مفهوم دسته‌بندی بهتر از SSE عمل می‌کند، به دلیل مشتق‌ناپذیری برای الگوریتم‌های مبتنی بر گرادیان مناسب نیست. بنابراین، ما به دنبال یک **تابع هزینه پرسپترونی (Perceptron Cost Function)** و یک تابع فعال‌سازی هستیم که:
۱. نسبتاً **صاف (Smooth)** باشد (مشتق‌پذیر باشد).
۲. بتواند به خوبی با الگوریتم گرادیان کاهشی بهینه‌سازی شود.

این نیاز ما را به سمت توابع فعال‌سازی نرم‌تر و توابع هزینه مناسب برای مسائل دسته‌بندی سوق می‌دهد که در ادامه مورد بحث قرار خواهند گرفت.

![smoother](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/02-Linear%20Classification/images/smoother.png)

---


** تابع هزینه پرسپترون (Perceptron Criterion)**
برای غلبه بر مشکلات توابع هزینه قبلی، معیار پرسپترون (Perceptron Criterion) معرفی می‌شود که به طور خاص بر نقاط اشتباه طبقه‌بندی شده (Misclassified Points) تمرکز می‌کند.
فرمول تابع هزینه پرسپترون (با در نظر گرفتن لیبل‌های $y^{(i)} \in \{-1,+1\}$):

$$
J_p(w) = - \sum_{i \in M} y^{(i)} w^T x^{(i)}
$$

که در آن $M$ مجموعه نقاطی است که به اشتباه طبقه‌بندی شده‌اند.

**هدف:** هدف این تابع، کمینه کردن ضرر با طبقه‌بندی صحیح تمام نقاط است. این تابع نسبت به تابع علامت، رفتار "هموارتری" دارد و بخش داخلی آن $y^{(i)} w^T x^{(i)}$ مشتق‌پذیر است.

**نحوه کار:**

1. مدل، پیش‌بینی‌هایی را برای تمام نمونه‌های آموزشی انجام می‌دهد.
2. نمونه‌هایی که به درستی پیش‌بینی شده‌اند، نادیده گرفته می‌شوند.
3. تنها برای نمونه‌هایی که به اشتباه پیش‌بینی شده‌اند (عضو مجموعه $M$)، مشتق تابع هزینه نسبت به پارامترها (وزن‌ها) محاسبه می‌شود.
4. سپس، با استفاده از گرادیان کاهشی، وزن‌ها به‌روزرسانی می‌شوند.

مشتق $J_p(w)$ نسبت به $w$ به صورت زیر است:

$$
\nabla_w J_p(w) = - \sum_{i \in M} y^{(i)} x^{(i)}
$$


![image](https://github.com/user-attachments/assets/77bfaeee-d5e7-46aa-b925-e8b8b523ab27)

![image](https://github.com/user-attachments/assets/6fefffb0-0633-4e8f-9421-d9270c54db25)
**۵. الگوریتم پرسپترون**
الگوریتم پرسپترون یک الگوریتم ساده برای دسته‌بندی دودویی (Binary Classification) است که دو کلاس را با یک مرز خطی از هم جدا می‌کند.

**الف. پرسپترون دسته‌ای (Batch Perceptron)**
پرسپترون دسته‌ای، بردار وزن را با استفاده از تمام نقاط اشتباه طبقه‌بندی شده در هر تکرار به‌روزرسانی می‌کند.
قاعده به‌روزرسانی گرادیان کاهشی:

$$
w \leftarrow w - \eta \nabla_w J_p(w)
$$

$$
w \leftarrow w - \eta \left( - \sum_{i \in M} y_i x_i \right) = w + \eta \sum_{i \in M} y_i x_i
$$

که در آن $\eta$ نرخ یادگیری (Learning Rate) است.
**نکته:** پرسپترون دسته‌ای برای داده‌های جداسازی‌پذیر خطی (Linearly Separable) در تعداد گام‌های متناهی همگرا (Converge) می‌شود.

**ب. پرسپترون تک نمونه‌ای (Single-sample Perceptron) یا SGD**
پرسپترون تک نمونه‌ای، بردار وزن را پس از پردازش هر نقطه داده به صورت جداگانه به‌روزرسانی می‌کند. این روش معادل گرادیان کاهشی تصادفی (Stochastic Gradient Descent - SGD) است.
قاعده به‌روزرسانی:

$$
w \leftarrow w + \eta y_i x_i
$$

(برای یک نمونه $i$ که اشتباه طبقه‌بندی شده است)

**مزایا:**

هزینه محاسباتی کمتر در هر تکرار: فقط یک نمونه در هر به‌روزرسانی استفاده می‌شود.

همگرایی سریع‌تر: به خصوص برای مجموعه داده‌های بزرگ.
  **نکته:** اگر داده‌های آموزشی جداسازی‌پذیر خطی باشند، پرسپترون تک نمونه‌ای نیز تضمین می‌کند که در تعداد متناهی از گام‌ها به راه‌حل می‌رسد.

مثال عملی اجرای پرسپترون نشان می‌دهد که چگونه یک خط تصمیم‌گیری (Decision Boundary) از یک وضعیت اولیه با خطای بالا شروع کرده و به تدریج با به‌روزرسانی وزن‌ها (بردار $w$) به سمت کاهش خطا و همگرایی حرکت می‌کند.

![changes](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/02-Linear%20Classification/images/changes.png)


---
**۶. همگرایی پرسپترون (Perceptron Convergence Theorem)**
قضیه مهم در مورد پرسپترون این است که برای داده‌هایی که جداسازی‌پذیر خطی (Linearly Separable) هستند، پرسپترون حتماً همگرا می‌شود و آموزش آن پایان می‌یابد.

**اثبات همگرایی:**
فرض کنید مجموعه داده‌ای داریم که به صورت خطی جداسازی‌پذیر است. یعنی می‌توان یک خط واقعی (Decision Boundary) به نام $w^*$ پیدا کرد که تمام نقاط را به درستی طبقه‌بندی می‌کند. همچنین فرض می‌کنیم یک مارجین (Margin) مثبت (فاصله نقاط از خط تصمیم‌گیری) وجود دارد.

بردار وزن اولیه: $w^{(1)}$ (همان $w_0$ در اسلاید) را به عنوان بردار صفر در نظر می‌گیریم.

**به‌روزرسانی:** در هر گام $t+1$، بردار وزن $w^{(t+1)}$ از $w^{(t)}$ با استفاده از یک نمونه اشتباه طبقه‌بندی شده $(x^{(i)}, y^{(i)})$ به صورت زیر به دست می‌آید (با در نظر گرفتن نرخ یادگیری $\eta = 1$ برای سادگی اثبات):

$$
w^{(t+1)} = w^{(t)} + y^{(i)} x^{(i)}
$$

هدف اثبات این است که ضرب داخلی $w^* \cdot w^{(t)}$ در هر مرحله افزایش می‌یابد و این افزایش حدی دارد.

$$
w^* \cdot w^{(t+1)} = w^* \cdot (w^{(t)} + y^{(i)} x^{(i)}) = w^* \cdot w^{(t)} + y^{(i)} (w^* \cdot x^{(i)})
$$

از آنجایی که $w^*$ به درستی تمام نقاط را طبقه‌بندی می‌کند، برای هر نقطه $x^{(i)}$، $y^{(i)} (w^* \cdot x^{(i)})$ همیشه مثبت و بزرگتر یا مساوی با یک مقدار ثابت (مارجین) است. یعنی،

$$
y^{(i)} (w^* \cdot x^{(i)}) \geq \gamma > 0
$$

برای یک $\gamma$ مثبت (که همان مارجین است).
پس:

$$
w^* \cdot w^{(t+1)} \geq w^* \cdot w^{(t)} + \gamma
$$

این نشان می‌دهد که مقدار $w^* \cdot w^{(t)}$ در هر گام به اندازه حداقل $\gamma$ افزایش می‌یابد. از طرفی، نورم (اندازه) $w^{(t+1)}$ نیز تحت کنترل است. می‌توان نشان داد که نورم $w^{(t)}$ نمی‌تواند تا ابد رشد کند.

$$
\| w^{(t+1)} \|^2 = \| w^{(t)} + y^{(i)} x^{(i)} \|^2 = \| w^{(t)} \|^2 + 2 y^{(i)} (w^{(t)} \cdot x^{(i)}) + \| y^{(i)} x^{(i)} \|^2 = \| w^{(t)} \|^2 + 2 y^{(i)} (w^{(t)} \cdot x^{(i)}) + \| x^{(i)} \|^2
$$

از آنجایی که $x^{(i)}$ اشتباه طبقه‌بندی شده است، $y^{(i)} (w^{(t)} \cdot x^{(i)}) < 0$. در نتیجه، رشد $\| w^{(t)} \|^2$ محدود است.
ترکیب این دو نابرابری (رشد خطی در دات پروداکت و رشد محدود در نورم) منجر به این می‌شود که تعداد به‌روزرسانی‌های لازم برای پرسپترون محدود باشد. به عبارت دیگر، $w^{(t)}$ به سمت $w^*$ نزدیک می‌شود تا زمانی که هیچ نقطه اشتباه طبقه‌بندی شده‌ای باقی نماند.
![proof1](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/02-Linear%20Classification/images/proof1.jpg)

![proof2](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/02-Linear%20Classification/images/proof2.jpg)

---

**مشکل برای داده‌های جداسازی‌ناپذیر خطی (Non-Linearly Separable Data):**
هنگامی که هیچ مرز تصمیم‌گیری خطی نمی‌تواند کلاس‌ها را به طور کامل از هم جدا کند (مثلاً به دلیل نویز یا ماهیت داده‌ها)، الگوریتم پرسپترون همگرا نمی‌شود. در این حالت، همیشه نقاطی وجود خواهند داشت که مدل قادر به طبقه‌بندی صحیح آن‌ها نیست. در نتیجه، الگوریتم به طور مداوم وزن‌ها را برای تصحیح نقاط اشتباه طبقه‌بندی شده تنظیم می‌کند و هرگز متوقف نمی‌شود.

برای حل این مشکل در داده‌های جداسازی‌ناپذیر خطی، از الگوریتم‌هایی مانند **Pocket Algorithm** استفاده می‌شود. این الگوریتم بهترین بردار وزن ($w$) را که تا آن لحظه بهترین عملکرد را داشته، "در جیب خود" نگه می‌دارد، حتی اگر بعدها به‌روزرسانی‌های بعدی منجر به عملکرد بدتر شوند.

**الگوریتم Pocket:**

1. مقداردهی اولیه $w$.
2. برای تعداد تکرار $T$:

   1. یک نمونه $x^{(i)}$ انتخاب کن.
   2. اگر $x^{(i)}$ اشتباه طبقه‌بندی شد:

      1. $w_{new} = w + \eta x^{(i)} y^{(i)}$
      2. اگر $E_{train}(w_{new}) < E_{train}(w)$ (یعنی خطای آموزش با $w_{new}$ کمتر از $w$ فعلی است):

         $$
         w = w_{new}
         $$
      3. (اختیاری: می‌توانیم بهترین $w$ را که تا کنون دیده‌ایم، جداگانه ذخیره کنیم، حتی اگر $w_{new}$ فعلی بدتر باشد.)
