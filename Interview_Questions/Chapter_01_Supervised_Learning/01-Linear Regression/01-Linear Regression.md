

۴. **سوال:** تعمیم‌پذیری یک مدل چگونه با انتخاب ویژگی‌ها و پیچیدگی مدل مرتبط است؟

**پاسخ:**

**تعمیم‌پذیری و انتخاب ویژگی‌ها:** انتخاب ویژگی‌ها به این معناست که مدل فقط ویژگی‌هایی را برای آموزش انتخاب می‌کند که اطلاعات ارزشمندی در مورد هدف پیش‌بینی ارائه می‌دهند. ویژگی‌های غیرضروری یا نویزی می‌توانند موجب کاهش تعمیم‌پذیری مدل شوند زیرا ممکن است مدل این ویژگی‌ها را به عنوان اطلاعات مفید یاد بگیرد که بر روی داده‌های جدید، عملکرد ضعیفی داشته باشد.

**تعمیم‌پذیری و پیچیدگی مدل:** پیچیدگی مدل به تعداد پارامترهای مدل و نحوه ارتباط آن‌ها با داده‌ها بستگی دارد. مدل‌های پیچیده‌تر (با تعداد پارامترهای بیشتر) ممکن است بتوانند دقیقاً روی داده‌های آموزشی برازش شوند، اما خطر **بیش‌برازش** وجود دارد. در مقابل، مدل‌های ساده‌تر ممکن است نتوانند پیچیدگی‌های موجود در داده‌ها را به درستی مدل کنند که به آن **کم‌برازش** گفته می‌شود.

به طور کلی، **انتخاب ویژگی‌های مناسب** و **انتخاب مدل مناسب** (با پیچیدگی مناسب) کلید تعمیم‌پذیری است. انتخاب ویژگی‌های مفید و پیچیدگی مدل به گونه‌ای که توانایی درک داده‌های واقعی را داشته باشد و در عین حال از بیش‌برازش جلوگیری کند، می‌تواند باعث بهبود تعمیم‌پذیری مدل شود.

---

۵. **سوال:** چه تفاوتی بین رگرسیون خطی و رگرسیون احتمالی وجود دارد؟ کدام یک از آن‌ها برای داده‌های نویزی مناسب‌تر است؟

**پاسخ:**

**رگرسیون خطی:** رگرسیون خطی یک مدل ریاضی ساده است که رابطه خطی بین ورودی‌ها و خروجی‌ها برقرار می‌کند. هدف این مدل کمینه کردن مجموع مربعات خطا (Sum of Squared Errors) است. در این مدل، فرض بر این است که تمامی داده‌ها دقیق و بدون نویز هستند.

**رگرسیون احتمالی:** در رگرسیون احتمالی، به جای فرض دقیق بودن داده‌ها، فرض می‌شود که خروجی‌ها دارای نویز هستند و این نویز از یک توزیع احتمال پیروی می‌کند (مانند توزیع نرمال). در این روش، هدف پیش‌بینی مقدار میانگین خروجی به شرط ورودی است و علاوه بر مدل‌سازی رابطه ورودی-خروجی، میزان **عدم قطعیت** پیش‌بینی نیز مدنظر قرار می‌گیرد.

**مناسب برای داده‌های نویزی:** رگرسیون احتمالی برای داده‌های نویزی مناسب‌تر است زیرا این مدل به طور صریح به وجود نویز در داده‌ها پرداخته و آن را در فرآیند یادگیری خود مدنظر قرار می‌دهد. در حالی که رگرسیون خطی بدون توجه به نویز ممکن است به بیش‌برازش دچار شود، رگرسیون احتمالی توانایی مقابله با نویز و کاهش تأثیر آن بر پیش‌بینی‌ها را دارد.

---

۶. **سوال:** توضیح دهید که مفهوم **بهینه‌سازی بیشینه درست‌نمایی (MLE)** چگونه در رگرسیون خطی به **کمینه‌سازی مجموع مربعات خطا (SSE)** تبدیل می‌شود؟

**پاسخ:**

**برآورد بیشینه درست‌نمایی (MLE)** روشی برای یافتن پارامترهای یک مدل است که احتمال وقوع داده‌های مشاهده‌شده را بیشینه می‌کند. در رگرسیون خطی، فرض بر این است که داده‌ها دارای نویز گاوسی هستند، یعنی تفاوت بین پیش‌بینی مدل و داده‌های واقعی به توزیع نرمال با میانگین صفر و واریانس $\sigma^2$ پیروی می‌کند.

تابع احتمال برای یک داده به صورت زیر است:

$$
p(y | x, w, \sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp \left( -\frac{(y - f(x; w))^2}{2 \sigma^2} \right)
$$

برای تخمین وزن‌های مدل $w$ با استفاده از **MLE**، ما می‌خواهیم تابع درست‌نمایی (likelihood) را بیشینه کنیم. اما معمولاً به دلیل راحتی محاسباتی، به جای بیشینه‌سازی تابع درست‌نمایی، از **لگاریتم درست‌نمایی (log-likelihood)** استفاده می‌کنیم.

تبدیل حاصل‌ضرب احتمال‌ها به جمع لگاریتمی، منجر به عبارت زیر می‌شود:

$$
\log L(Z; w, \sigma^2) \sim - \sum_{i=1}^{n} (y^{(i)} - f(x^{(i)}; w))^2
$$

که نشان‌دهنده **مجموع مربعات خطا (SSE)** است. بنابراین، در رگرسیون خطی، **بیشینه‌سازی درست‌نمایی** معادل **کمینه‌سازی مجموع مربعات خطا** است، چرا که بهینه‌سازی **log-likelihood** دقیقاً همان چیزی است که در رگرسیون خطی با کمینه‌سازی **SSE** انجام می‌دهیم.

---

۷. **سوال:** **رگولاریزاسیون** چگونه از بیش‌برازش جلوگیری می‌کند و انواع رایج رگولاریزاسیون کدامند؟

**پاسخ:**

**رگولاریزاسیون** تکنیکی است که با اضافه کردن یک جریمه به تابع هزینه، پیچیدگی مدل را کنترل کرده و از **بیش‌برازش (Overfitting)** جلوگیری می‌کند. این کار باعث می‌شود که وزن‌ها (parameters) مدل خیلی بزرگ نشوند و مدل نتواند به جزئیات و نویز داده‌های آموزشی وابسته شود.

**انواع رایج رگولاریزاسیون:**

* **L1 Regularization (Lasso):** در این نوع رگولاریزاسیون، تابع هزینه شامل جمع مطلق وزن‌ها می‌شود:

  $$
  J(w) = \text{MSE} + \lambda \sum_{i=1}^{n} |w_i|
  $$

  که باعث می‌شود برخی از وزن‌ها به صفر برسند و در نتیجه مدل به **انتخاب ویژگی** کمک کند.

* **L2 Regularization (Ridge):** در این نوع، تابع هزینه شامل مربع وزن‌ها می‌شود:

  $$
  J(w) = \text{MSE} + \lambda \sum_{i=1}^{n} w_i^2
  $$

  این کار باعث می‌شود که وزن‌ها کوچک بمانند، اما معمولاً به صفر نخواهند رسید. **Ridge** بیشتر برای **کاهش پیچیدگی مدل** و جلوگیری از مدل‌های خیلی پیچیده استفاده می‌شود.

هر دو روش به تنظیم کردن مقدار **هایپرپارامتر $\lambda$** بستگی دارند، که میزان جریمه‌ای که به وزن‌ها وارد می‌شود را تعیین می‌کند.

---

۸. **سوال:** چگونه می‌توان مدل‌های پیچیده را برای جلوگیری از بیش‌برازش تنظیم کرد؟

**پاسخ:**

برای جلوگیری از بیش‌برازش در مدل‌های پیچیده، چندین استراتژی می‌توان به کار برد:

1. **استفاده از رگولاریزاسیون:** همانطور که در سوالات قبلی گفته شد، اضافه کردن جریمه به وزن‌ها (با استفاده از **L1** یا **L2** رگولاریزاسیون) باعث می‌شود که مدل نتواند به جزئیات نویزی داده‌های آموزشی توجه کند.

2. **کاهش پیچیدگی مدل:** کاهش تعداد ویژگی‌ها یا تعداد پارامترهای مدل می‌تواند از پیچیدگی بیش از حد جلوگیری کند. به طور مثال، استفاده از **پرسپترون‌های ساده‌تر** یا **شبکه‌های عصبی با تعداد لایه‌های کمتر**.

3. **استفاده از داده‌های بیشتر:** مدل‌ها به طور کلی در صورتی که داده‌های بیشتری برای آموزش داشته باشند، به صورت مؤثرتری تعمیم پیدا می‌کنند. استفاده از **داده‌های بیشتر** به کاهش خطر بیش‌برازش کمک می‌کند.

4. **استفاده از تکنیک‌های انتخاب ویژگی:** **انتخاب ویژگی‌های مرتبط** و حذف ویژگی‌های غیرمفید یا نویزی می‌تواند کمک کند تا مدل پیچیدگی خود را کاهش دهد و فقط بر روی ویژگی‌های مهم تمرکز کند.

---

۹. **سوال:** چرا باید از **مجموع مربعات خطا (SSE)** به عنوان تابع هزینه استفاده کنیم و چرا این معیار در رگرسیون خطی پرکاربرد است؟

**پاسخ:**

**مجموع مربعات خطا (SSE)** به دلیل چندین ویژگی، به عنوان تابع هزینه‌ای محبوب در رگرسیون خطی شناخته می‌شود:

* **سادگی و شفافیت:** SSE، تفاوت بین مقادیر واقعی و پیش‌بینی شده را می‌سنجد و آن را مربع کرده تا از تأثیر تفاوت‌های بزرگتر جلوگیری شود. این کار باعث می‌شود که پیش‌بینی‌های نادرست بزرگ‌تر، جریمه بیشتری داشته باشند.
* **قابلیت بهینه‌سازی آسان:** به دلیل ویژگی مشتق‌پذیری و ساده بودن آن، به راحتی می‌توان از الگوریتم‌های بهینه‌سازی مبتنی بر گرادیان (مثل **گرادیان نزولی**) برای کمینه کردن این تابع استفاده کرد.
* \*\*ارتباط


با MLE:\*\* همانطور که در سوال‌های قبلی توضیح داده شد، کمینه‌سازی **SSE** معادل **بیشینه‌سازی log-likelihood** در رگرسیون احتمالی است، بنابراین از منظر آماری، استفاده از SSE به طور طبیعی در رگرسیون خطی منطقی است.

---

۱۰. **سوال:** آیا همیشه از رگرسیون خطی برای مدل‌سازی داده‌ها استفاده می‌کنیم؟ چه زمانی باید به روش‌های دیگری فکر کنیم؟

**پاسخ:**

رگرسیون خطی معمولاً زمانی مفید است که رابطه بین ورودی‌ها و خروجی‌ها تقریباً خطی باشد. با این حال، در صورت وجود **رابطه‌های غیرخطی**، استفاده از رگرسیون خطی ممکن است به **کم‌براش** یا **بیش‌براش** منجر شود.

در این شرایط، باید از روش‌های دیگر مانند:

* **رگرسیون غیرخطی**: استفاده از مدل‌های رگرسیونی که می‌توانند الگوهای غیرخطی را شبیه‌سازی کنند.
* **درخت‌های تصمیم (Decision Trees)**: برای مدل‌سازی روابط پیچیده‌تر با استفاده از تقسیم‌های غیرخطی.
* **شبکه‌های عصبی (Neural Networks)**: برای یادگیری روابط پیچیده‌تر و غیرخطی از ورودی‌ها به خروجی‌ها.

استفاده کرد.
۸. **سوال:** چرا برای ارزیابی عملکرد مدل‌های یادگیری ماشین، استفاده از مجموعه تست (Test Set) جدا از مجموعه آموزشی (Training Set) ضروری است؟

**پاسخ:**
استفاده از مجموعه تست جداگانه از مجموعه آموزشی ضروری است زیرا هدف نهایی یادگیری ماشین، ارزیابی توانایی مدل در تعمیم دادن به داده‌های جدید و ناشناخته است. اگر داده‌های تست در طول فرآیند آموزش مدل مورد استفاده قرار بگیرند، مدل ممکن است فقط داده‌های خاص مجموعه تست را حفظ کند و در نتیجه عملکرد واقعی آن بر روی داده‌های جدید به درستی ارزیابی نشود. بنابراین، مجموعه تست برای سنجش دقت مدل بر روی داده‌های غیرمشاهده‌شده ضروری است.

---

۹. **سوال:** **Bias-Variance Tradeoff** چیست و چگونه می‌توان آن را در انتخاب مدل‌های یادگیری ماشین به کار برد؟

**پاسخ:**
Bias-Variance Tradeoff به چالشی اشاره دارد که در آن باید بین **بایاس (Bias)** و **واریانس (Variance)** تعادل برقرار شود.

* **بایاس بالا** نشان‌دهنده مدل‌هایی است که فرض‌های ساده‌ای دارند و قادر به ثبت پیچیدگی‌های داده‌ها نیستند، که منجر به **کم‌براش شدن** مدل می‌شود.
* **واریانس بالا** نشان‌دهنده مدل‌هایی است که به شدت به داده‌های آموزشی وابسته هستند و نمی‌توانند به خوبی به داده‌های جدید تعمیم یابند، که منجر به **بیش‌براش شدن** مدل می‌شود.
  بنابراین، برای دستیابی به بهترین عملکرد مدل، باید پیچیدگی مدل را به نحوی انتخاب کرد که بایاس و واریانس به طور متعادل به حداقل برسند.

---

۱۰. **سوال:** **Regularization** چه نقشی در بهبود تعمیم‌پذیری مدل‌ها دارد و چرا در بسیاری از مدل‌ها از آن استفاده می‌شود؟

**پاسخ:**
رگولاریزاسیون یک تکنیک است که برای کاهش **بیش‌براش** و جلوگیری از پیچیدگی‌های زیاد در مدل‌ها استفاده می‌شود. با افزودن یک جریمه به تابع هزینه، رگولاریزاسیون می‌تواند مدل را به سمت استفاده از وزن‌های کوچکتر سوق دهد، که این امر موجب کاهش پیچیدگی مدل و بهبود توانایی آن در تعمیم می‌شود.
در رگرسیون L2 (Ridge) و L1 (Lasso) این تکنیک باعث می‌شود که مدل به داده‌های نویزدار کمتر حساس باشد و از **بیش‌براش** جلوگیری کند.

---

۱۱. **سوال:** چه تفاوت‌هایی بین رگولاریزاسیون L1 و L2 وجود دارد و چگونه می‌توان از آن‌ها برای کنترل پیچیدگی مدل استفاده کرد؟

**پاسخ:**

* **رگولاریزاسیون L1 (Lasso)**: این نوع رگولاریزاسیون، از جریمه‌ای برای جمع قدرمطلق وزن‌ها استفاده می‌کند. یکی از ویژگی‌های خاص آن این است که می‌تواند وزن‌ها را به صفر برساند، که در نتیجه باعث می‌شود برخی ویژگی‌ها از مدل حذف شوند. این ویژگی برای انجام **انتخاب ویژگی** مفید است.

* **رگولاریزاسیون L2 (Ridge)**: این نوع رگولاریزاسیون از جریمه‌ای برای جمع مربعات وزن‌ها استفاده می‌کند و نمی‌تواند وزن‌ها را به صفر برساند، بلکه آن‌ها را به طور یکنواخت کاهش می‌دهد. این امر منجر به **کمتر حساس شدن مدل به تغییرات کوچک** می‌شود و از **بیش‌براش** جلوگیری می‌کند.

در هر دو حالت، پارامتر **λ** (لامبدا) نقش کلیدی در تنظیم مقدار رگولاریزاسیون و پیچیدگی مدل دارد.

---

۱۲. **سوال:** چگونه می‌توان فهمید که مدل دچار **بیش‌براش** (Overfitting) یا **کم‌براش** (Underfitting) شده است؟

**پاسخ:**

* **بیش‌براش (Overfitting)**: در این حالت، مدل به شدت به داده‌های آموزشی وابسته است و به جزئیات کوچک و نویز داده‌ها می‌پردازد. نتیجه آن این است که خطای آموزش پایین است، اما خطای تست به طور قابل توجهی بالا است.

* **کم‌براش (Underfitting)**: در این حالت، مدل به اندازه کافی پیچیده نیست و نمی‌تواند الگوهای داده‌ها را به خوبی ثبت کند. در اینجا، خطای آموزش و تست هر دو بالا هستند و تقریباً مشابه یکدیگرند.

یکی از روش‌های تشخیص این مشکلات، ارزیابی عملکرد مدل بر روی داده‌های آموزش و تست است. اگر تفاوت قابل توجهی بین خطای آموزش و خطای تست وجود داشته باشد، احتمالاً مدل دچار **بیش‌براش** است. اگر خطای هر دو مجموعه بالا باشد، مدل **کم‌براش** است.

---

۱۳. **سوال:** **کراس-ولیدیشن (Cross-Validation)** چیست و چرا در ارزیابی عملکرد مدل‌ها مهم است؟

**پاسخ:**
کراس-ولیدیشن یک تکنیک برای ارزیابی عملکرد مدل است که داده‌ها را به $k$ بخش تقسیم می‌کند. در هر دور، یک بخش به عنوان مجموعه تست و باقی بخش‌ها به عنوان مجموعه آموزش استفاده می‌شوند. این فرآیند برای $k$ دور تکرار می‌شود و میانگین نتایج به دست آمده، ارزیابی نهایی مدل را تعیین می‌کند.
کراس-ولیدیشن به جلوگیری از **بیش‌براش** کمک می‌کند و باعث می‌شود که مدل بر روی داده‌های جدید، بدون تأثیر از نحوه تقسیم‌بندی داده‌ها، آزمایش شود.

---

۱۴. **سوال:** چگونه **N-fold Cross-Validation** می‌تواند به ارزیابی بهتر مدل کمک کند؟

**پاسخ:**
در **N-fold Cross-Validation**، داده‌ها به $N$ بخش تقسیم می‌شوند و هر بخش به طور نوبتی به عنوان مجموعه تست و باقی‌مانده به عنوان مجموعه آموزش استفاده می‌شود. این فرآیند $N$ بار تکرار می‌شود.
مزیت این روش این است که **تمام داده‌ها** به طور یکسان به عنوان داده‌های آموزش و تست استفاده می‌شوند، که موجب افزایش دقت و کاهش واریانس ارزیابی می‌شود. این روش همچنین احتمال تصادفی بودن ارزیابی مدل را کاهش می‌دهد.

---

۱۵. **سوال:** چرا باید **بهینه‌سازی مدل** (Model Tuning) را با دقت انجام داد و چه عواملی باید در نظر گرفته شود؟

**پاسخ:**
بهینه‌سازی مدل برای دستیابی به بهترین عملکرد ممکن در داده‌های جدید ضروری است. در این فرآیند، انتخاب صحیح پارامترها و ویژگی‌ها برای مدل می‌تواند تأثیر زیادی بر عملکرد آن داشته باشد. عوامل اصلی در بهینه‌سازی مدل شامل:

* **انتخاب مدل مناسب** بر اساس نوع داده و پیچیدگی آن.
* **تنظیم پارامترهای هایپر** (Hyperparameters) مانند اندازه‌ی لایه‌های شبکه عصبی یا مقدار λ در رگولاریزاسیون.
* **استفاده از تکنیک‌های رگولاریزاسیون** برای جلوگیری از بیش‌براش.

هر یک از این عوامل می‌توانند تأثیر زیادی بر **دقت** و **توانایی تعمیم مدل** داشته باشند.

---

این پرسش‌ها به شما کمک می‌کنند تا درک بهتری از مباحث تعمیم، رگرسیون احتمالی و تکنیک‌های مختلف یادگیری ماشین داشته باشید.




۱۶. **سوال:** در رگرسیون احتمالی، فرض توزیع گاوسی برای نویز چگونه به تحلیل مدل و تخمین‌های پارامتر کمک می‌کند؟

**پاسخ:**
فرض توزیع گاوسی برای نویز این امکان را می‌دهد که خطاهای مدل را به صورت احتمال‌پذیر مدل‌سازی کنیم. این فرض باعث می‌شود که بتوانیم از مفاهیم **برآورد بیشینه درست‌نمایی (MLE)** برای تخمین پارامترها استفاده کنیم. با فرض اینکه نویز به طور مستقل و با توزیع نرمال (میانگین صفر و واریانس ثابت) عمل می‌کند، می‌توانیم از موازنه احتمال برای تعیین بهترین پارامترهای مدل استفاده کنیم. این فرضیات همچنین باعث ساده‌تر شدن تحلیل و محاسبات مربوط به مدل می‌شوند و می‌توانند منجر به یافتن پارامترهای بهینه مدل شوند.

---

۱۷. **سوال:** در رگرسیون خطی، چگونه می‌توان با استفاده از MLE، مدل را طوری تنظیم کرد که کمینه‌سازی مجموع مربعات خطا (SSE) را انجام دهد؟

**پاسخ:**
در رگرسیون خطی، فرض می‌شود که نویز در داده‌ها از توزیع گاوسی پیروی می‌کند. در این صورت، تابع درست‌نمایی به صورت حاصل‌ضرب احتمالات تمام داده‌ها مدل‌سازی می‌شود. وقتی لگاریتم این درست‌نمایی گرفته می‌شود، به فرم **log-likelihood** تبدیل می‌شود که شامل جمع مربعات خطا است. این تبدیل به ما این امکان را می‌دهد که بیشینه‌سازی لگاریتم درست‌نمایی را معادل با کمینه‌سازی مجموع مربعات خطا (SSE) بدانیم. بنابراین، با استفاده از MLE و فرض گاوسی بودن نویز، مدل به طور طبیعی کمترین SSE را به دست می‌آورد.

---

۱۸. **سوال:** در رگرسیون خطی، اگر نویز از توزیع نرمال پیروی نکند، آیا هنوز می‌توان از MLE برای تخمین پارامترها استفاده کرد؟

**پاسخ:**
اگر نویز از توزیع نرمال پیروی نکند، استفاده از MLE برای تخمین پارامترها همچنان امکان‌پذیر است، اما باید فرض مناسب‌تری برای توزیع نویز انتخاب کرد. در چنین شرایطی، معمولاً از توزیع‌های دیگر مانند توزیع‌های **Exponential**، **Poisson** یا توزیع‌های دیگر استفاده می‌شود. هر توزیع احتمال باید در قالب مدل MLE گنجانده شود تا خطاها به درستی مدل‌سازی شوند. در این حالت، برآورد پارامترها ممکن است پیچیده‌تر شود و نیاز به محاسبات بیشتری داشته باشد.

---

۱۹. **سوال:** چه ارتباطی بین **log-likelihood** و **maximum a posteriori estimation (MAP)** در مدل‌های رگرسیون وجود دارد؟

**پاسخ:**
**MAP** (برآورد بیشینه‌ی پسا‌محتمل) مشابه **MLE** است، با این تفاوت که در **MAP** علاوه بر داده‌های مشاهده‌شده، یک **توزیع پیشین (Prior Distribution)** برای پارامترها نیز در نظر گرفته می‌شود. در **MLE**، پارامترها بر اساس بیشینه‌سازی تابع درست‌نمایی (likelihood) تخمین زده می‌شوند، در حالی که در **MAP**، پارامترها به گونه‌ای انتخاب می‌شوند که احتمال پسا‌محتمل آنها (حاصل‌ضرب درست‌نمایی و توزیع پیشین) بیشینه شود.
در صورتی که توزیع پیشین غیر‌مهم باشد یا به طور یکنواخت توزیع شود، **MAP** و **MLE** به نتایج مشابهی می‌رسند. به عبارت دیگر، اگر هیچ نوع توزیع پیشین مشخصی نداشته باشیم، **MAP** و **MLE** به یکدیگر معادل می‌شوند.

---

۲۰. **سوال:** در رگرسیون خطی، چرا مدل ممکن است در برابر داده‌های جدید **ناتوان** باشد حتی اگر خطای آموزش بسیار کم باشد؟

**پاسخ:**
اگر مدل دارای **بیش‌براش** باشد (یعنی خطای آموزش بسیار کم و خطای تست بالا باشد)، احتمالاً مدل دچار پیچیدگی اضافی شده است که باعث شده است به جای یادگیری الگوهای عمومی، تنها به جزئیات و نویز داده‌های آموزشی توجه کند. در این حالت، مدل به داده‌های جدید تعمیم خوبی نخواهد داشت، زیرا توانایی آن در تشخیص الگوهای واقعی کاهش یافته است. این اتفاق معمولاً در مدل‌های پیچیده‌تر مانند **رگرسیون چندجمله‌ای با درجه بالا** یا **شبکه‌های عصبی با تعداد زیاد لایه‌ها** رخ می‌دهد که می‌توانند بیش از حد به داده‌های آموزشی فیت شوند.

---

۲۱. **سوال:** چگونه می‌توان از **K-fold Cross Validation** برای ارزیابی عملکرد یک مدل یادگیری ماشین استفاده کرد؟

**پاسخ:**
در **K-fold Cross Validation**، داده‌ها به $K$ قسمت تقسیم می‌شوند. در هر دور، یکی از این بخش‌ها به عنوان **مجموعه تست** و باقی‌مانده به عنوان **مجموعه آموزشی** استفاده می‌شود. این فرآیند به تعداد $K$ بار تکرار می‌شود، بنابراین هر نمونه داده حداقل یک بار به عنوان داده تست مورد استفاده قرار می‌گیرد. نتیجه عملکرد مدل، میانگین خطای به دست آمده از هر $K$ تکرار است. این روش باعث می‌شود که مدل به طور جامع‌تری ارزیابی شود و از تأثیرات تصادفی تقسیم‌بندی داده‌ها جلوگیری شود. این روش به کاهش واریانس ارزیابی مدل کمک کرده و مطمئن می‌شود که مدل در داده‌های جدید به خوبی عمل می‌کند.

---

۲۲. **سوال:** چه عواملی می‌تواند باعث شود که **خطای آموزش** پایین باشد ولی **خطای تست** بالا باشد؟

**پاسخ:**
این وضعیت معمولاً نشان‌دهنده **بیش‌براش** است. عوامل مختلفی می‌توانند باعث این مشکل شوند:

* **مدل پیچیده** با تعداد زیاد پارامتر که قادر به یادگیری جزئیات و نویزهای داده‌های آموزشی است.
* **پیش‌پردازش نامناسب** داده‌ها، مانند نرمال‌سازی ناقص یا ویژگی‌های غیرضروری که به مدل اضافه می‌شوند.
* **استفاده از مدل‌هایی که بیش از حد به داده‌های آموزشی وابسته هستند** (مثل رگرسیون چندجمله‌ای با درجه بالا).

در چنین شرایطی، مدل در برابر داده‌های جدید عملکرد ضعیفی دارد چون نمی‌تواند الگوهای عمومی را یاد بگیرد و تنها به خصوصیات خاص داده‌های آموزشی توجه می‌کند.

---

۲۳. **سوال:** **MSE** (میانگین مربعات خطا) و **RMSE** (ریشه میانگین مربعات خطا) چه تفاوت‌هایی دارند و در ارزیابی مدل‌ها کدام یک بهتر است؟

**پاسخ:**
**MSE** (Mean Squared Error) میانگین مربعات خطاها را محاسبه می‌کند. این معیار نشان‌دهنده متوسط تفاوت‌های مربعی بین پیش‌بینی‌ها و مقادیر واقعی است.
**RMSE** (Root Mean Squared Error) ریشه مربع **MSE** است و به واحدهای داده نزدیک‌تر است. RMSE برای مدل‌هایی که نیاز به درک تفاوت‌های واقعی در واحدهای داده دارند، مفیدتر است.

اگرچه هر دو معیار اطلاعات مشابهی ارائه می‌دهند، **RMSE** برای تحلیل‌های خاص که نیاز به تفکیک تفاوت‌های خطا در مقیاس واقعی دارند، مناسب‌تر است.






**۳۱. سوال:**

**چگونه می‌توان به طور عملی و با استفاده از ارزیابی‌های مختلف، بهترین مدل را در رگرسیون انتخاب کرد؟**

**پاسخ:**
برای انتخاب بهترین مدل در رگرسیون، می‌توان از ارزیابی‌های مختلفی استفاده کرد:

* **Cross-Validation:** اعتبارسنجی متقابل به کاهش واریانس ارزیابی کمک می‌کند و مدل‌ها را روی داده‌های مختلف می‌سنجد.
* **مجموعه تست:** ارزیابی مدل بر روی داده‌های دیده‌نشده برای سنجش قدرت تعمیم مدل ضروری است.
* **معیارهای ارزیابی:** از جمله **MSE** (میانگین مربعات خطا)، **RMSE** (ریشه میانگین مربعات خطا)، **R²** (ضریب تعیین) که میزان انطباق مدل با داده‌ها را نشان می‌دهند.
* **آزمون‌های آماری:** مانند آزمون‌های F و t برای بررسی میزان اعتبار پارامترهای مدل.
  با مقایسه این معیارها، مدل‌هایی که کمترین خطا و بهترین تعمیم‌پذیری را دارند، انتخاب می‌شوند.

---

**۳۲. سوال:**

**چرا در مدل‌های پیچیده، به ویژه در مدل‌های یادگیری عمیق، معمولاً از تکنیک‌هایی مانند **Early Stopping** استفاده می‌شود؟**

**پاسخ:**
در مدل‌های پیچیده و به ویژه در یادگیری عمیق، **Early Stopping** به منظور جلوگیری از **بیش‌براش** (Overfitting) استفاده می‌شود. این تکنیک مانع از ادامه آموزش مدل پس از رسیدن به نقطه‌ای می‌شود که عملکرد آن بر روی داده‌های تست شروع به افت کردن می‌کند، حتی اگر خطای آموزش همچنان کاهش یابد. به عبارت دیگر، در این روش، آموزش مدل قبل از اینکه به صورت کامل ادامه یابد، متوقف می‌شود تا از یادگیری جزئیات و نویزهای داده‌های آموزشی جلوگیری شود و مدل بتواند به بهترین عملکرد تعمیم‌پذیر برسد.

---

**۳۳. سوال:**

**چرا رگرسیون خطی در مواقعی که روابط پیچیده‌تری بین متغیرها وجود دارد، ممکن است نتیجه دقیقی ندهد؟**

**پاسخ:**
رگرسیون خطی فرض می‌کند که رابطه بین متغیرهای ورودی و خروجی خطی است. این فرض ممکن است در بسیاری از موارد عملی صدق نکند. هنگامی که روابط پیچیده‌تری میان ورودی‌ها و خروجی وجود دارد (مثلاً روابط غیرخطی)، رگرسیون خطی قادر به مدل‌سازی این روابط نیست و باعث **کم‌براش** می‌شود. در این مواقع، مدل‌های پیچیده‌تری مانند **رگرسیون چندجمله‌ای** یا **شبکه‌های عصبی** که قابلیت مدل‌سازی روابط غیرخطی را دارند، می‌توانند عملکرد بهتری داشته باشند.

---

**۳۴. سوال:**

**در رگرسیون چندجمله‌ای، چرا استفاده از درجه‌های بسیار بالا (مانند $M \geq 10$) ممکن است منجر به از دست دادن قدرت تعمیم مدل شود؟**

**پاسخ:**
در رگرسیون چندجمله‌ای با درجات بالا، مدل به طور فزاینده‌ای پیچیده می‌شود و سعی می‌کند به تمام نوسانات داده‌های آموزشی، حتی نویزهای تصادفی، واکنش نشان دهد. این پدیده منجر به **بیش‌براش** می‌شود، یعنی مدل به جای یادگیری الگوهای عمومی، به جزئیات و نویزهای موجود در داده‌ها فیت می‌شود. نتیجه این است که مدل عملکرد ضعیفی در برابر داده‌های جدید خواهد داشت، چرا که توانایی تعمیم به داده‌های دیده‌نشده کاهش می‌یابد.

---

**۳۵. سوال:**

**در رگرسیون خطی، چگونه می‌توان متوجه شد که مدل بیش از حد پیچیده یا ساده است؟**

**پاسخ:**
برای ارزیابی پیچیدگی مدل در رگرسیون خطی، می‌توان به **خطای آموزش** و **خطای تست** نگاه کرد:

* اگر **خطای آموزش** و **خطای تست** هر دو بالا باشند، مدل **کم‌براش** است. این بدان معناست که مدل نتوانسته است رابطه واقعی موجود در داده‌ها را یاد بگیرد و نیاز به پیچیده‌تر شدن دارد.
* اگر **خطای آموزش** پایین و **خطای تست** بالا باشد، مدل **بیش‌براش** است. این یعنی مدل بیش از حد پیچیده است و به نویز داده‌های آموزشی فیت شده، که باعث عدم توانایی آن در تعمیم به داده‌های جدید می‌شود.

همچنین می‌توان از **اعتبارسنجی متقابل** و بررسی تغییرات **R²** برای ارزیابی بهتر پیچیدگی استفاده کرد.

---

**۳۶. سوال:**

**چه تفاوتی بین "Bagging" و "Boosting" در الگوریتم‌های یادگیری نظارت‌شده وجود دارد؟**

**پاسخ:**

* **Bagging (Bootstrap Aggregating):** این تکنیک شامل آموزش چندین مدل بر روی زیرمجموعه‌های مختلف داده‌ها است که به طور تصادفی از داده‌های اصلی با جایگزینی نمونه‌برداری می‌شوند. پس از آموزش، پیش‌بینی‌ها از مدل‌های مختلف تجمیع می‌شوند (معمولاً به صورت متوسط برای رگرسیون یا رأی‌گیری برای طبقه‌بندی). این تکنیک بیشتر برای کاهش واریانس و جلوگیری از **بیش‌براش** استفاده می‌شود. الگوریتم **Random Forest** یکی از معروف‌ترین مثال‌های Bagging است.

* **Boosting:** در این روش، مدل‌ها به صورت ترتیبی آموزش داده می‌شوند و هر مدل جدید سعی می‌کند خطاهای مدل قبلی را اصلاح کند. مدل‌ها وزن‌دهی می‌شوند به طوری که مدل‌های بعدی توجه بیشتری به نمونه‌های اشتباه مدل‌های قبلی داشته باشند. این تکنیک بیشتر برای کاهش **بایاس** استفاده می‌شود و در نتیجه ممکن است منجر به **بیش‌براش** شود. الگوریتم‌های معروف Boosting شامل **AdaBoost** و **Gradient Boosting** هستند.

---

**۳۷. سوال:**

**چگونه می‌توان از تکنیک‌های رگولاریزاسیون برای مقابله با بیش‌براش استفاده کرد؟**

**پاسخ:**
برای مقابله با **بیش‌براش** (Overfitting)، می‌توان از تکنیک‌های رگولاریزاسیون مانند **L1** (Lasso) و **L2** (Ridge) استفاده کرد:

* **L1 (Lasso) Regularization**: این رگولاریزاسیون به طور مؤثر برخی از ویژگی‌ها را به صفر می‌رساند، به طوری که آن‌ها از مدل حذف می‌شوند. این کار به انتخاب ویژگی‌ها و کاهش پیچیدگی مدل کمک می‌کند.
* **L2 (Ridge) Regularization**: این تکنیک وزن‌ها را کاهش می‌دهد، اما آن‌ها را به طور کامل صفر نمی‌کند. این باعث می‌شود مدل پیچیده‌تر شود ولی از **بیش‌براش** جلوگیری کند.

استفاده از این روش‌ها به طور مستقیم پیچیدگی مدل را کنترل کرده و به جلوگیری از فیت شدن بیش از حد به داده‌های آموزشی کمک می‌کند.
**۱۱. سوال:**

**در رگرسیون چندجمله‌ای، چگونه می‌توان از بیش‌براش جلوگیری کرد؟**

**پاسخ:**

برای جلوگیری از **بیش‌براش** در رگرسیون چندجمله‌ای، می‌توان از تکنیک‌های مختلفی استفاده کرد:

* **رگولاریزاسیون (Regularization):** با اضافه کردن یک ترم جریمه به تابع هزینه (مانند **L2 regularization**)، می‌توان وزن‌های بزرگ را کاهش داده و پیچیدگی مدل را کنترل کرد. این کار باعث می‌شود که مدل از پیچیدگی اضافی که ممکن است منجر به بیش‌براش شود، جلوگیری کند.

* **انتخاب درجه بهینه:** به جای استفاده از درجات بالای زیاد (که ممکن است منجر به بیش‌براش شود)، باید از انتخاب دقتی درجه مدل استفاده کرد. این کار می‌تواند شامل استفاده از اعتبارسنجی متقابل (cross-validation) برای تعیین درجه مناسب باشد.

* **استفاده از مدل‌های ساده‌تر:** گاهی اوقات استفاده از مدل‌های ساده‌تر مانند **رگرسیون خطی** یا **رگرسیون چندجمله‌ای با درجات پایین** می‌تواند بهتر از مدل‌های پیچیده‌تر باشد که ممکن است بیش از حد به داده‌های آموزشی فیت شوند.

---

**۱۲. سوال:**

**چه تفاوت‌هایی بین مدل‌های رگرسیون خطی و رگرسیون لجستیک وجود دارد؟**

**پاسخ:**

* **رگرسیون خطی:** این مدل برای پیش‌بینی یک متغیر هدف پیوسته استفاده می‌شود. در رگرسیون خطی، تابع فرضیه به صورت یک ترکیب خطی از ویژگی‌های ورودی است و هدف این است که تفاوت بین مقادیر پیش‌بینی شده و واقعی را کمینه کنیم.

* **رگرسیون لجستیک:** این مدل برای مسائل **طبقه‌بندی** استفاده می‌شود و به جای پیش‌بینی یک مقدار پیوسته، احتمال تعلق به یک کلاس خاص را پیش‌بینی می‌کند. رگرسیون لجستیک از تابع سیگموئید (sigmoid) برای تبدیل خروجی ترکیب خطی به یک مقدار در بازه 0 و 1 (احتمال) استفاده می‌کند.

تفاوت اصلی: رگرسیون خطی برای پیش‌بینی مقادیر پیوسته است، در حالی که رگرسیون لجستیک برای پیش‌بینی احتمالات و طبقه‌بندی داده‌ها به کلاس‌های مختلف به کار می‌رود.

---

**۱۳. سوال:**

**چه زمانی باید از رگرسیون لاسو (Lasso Regression) و رگرسیون ریج (Ridge Regression) استفاده کرد؟**

**پاسخ:**

* **رگرسیون لاسو (Lasso):** این نوع رگولاریزاسیون از **L1 Regularization** استفاده می‌کند و می‌تواند به انتخاب ویژگی‌ها (Feature Selection) کمک کند. در شرایطی که تعداد زیادی ویژگی در داده‌ها وجود دارد و برخی از ویژگی‌ها ممکن است غیرمفید باشند، رگرسیون لاسو مفید است زیرا به ویژگی‌های غیرمفید وزن صفر می‌دهد.

* **رگرسیون ریج (Ridge):** رگرسیون ریج از **L2 Regularization** استفاده می‌کند و می‌تواند به کاهش پیچیدگی مدل کمک کند بدون اینکه ویژگی‌ها را به طور کامل حذف کند. این روش برای مدل‌هایی مناسب است که داده‌های با ویژگی‌های همبسته دارند و مدل می‌تواند از این ویژگی‌ها به طور همزمان استفاده کند.

انتخاب بین لاسو و ریج بستگی به نوع داده‌ها و نیاز به انتخاب ویژگی‌ها دارد. اگر می‌خواهید برخی ویژگی‌ها را حذف کنید، لاسو مناسب است؛ در غیر این صورت، ریج می‌تواند انتخاب بهتری باشد.

---

**۱۴. سوال:**

**در الگوریتم گرادیان دیسنت، چه مشکلی ممکن است ناشی از انتخاب نادرست نرخ یادگیری (Learning Rate) پیش آید؟**

**پاسخ:**

در الگوریتم **گرادیان دیسنت**، نرخ یادگیری (η) نقش مهمی در فرآیند همگرایی دارد:

* **η بسیار کوچک:** وقتی نرخ یادگیری خیلی کوچک باشد، الگوریتم به آرامی پیش می‌رود و ممکن است زمان زیادی برای همگرایی نیاز داشته باشد. این می‌تواند موجب کند شدن روند بهینه‌سازی شود و در نهایت زمان زیادی را برای رسیدن به پاسخ نهایی مصرف کند.

* **η بسیار بزرگ:** اگر نرخ یادگیری بیش از حد بزرگ باشد، گرادیان دیسنت می‌تواند از مینیمم سراسری عبور کند (overshoot)، و به جای همگرایی به یک نقطه بهینه، از آن فاصله می‌گیرد. این ممکن است منجر به واگرایی (divergence) شود و الگوریتم نتایج دقیقی ارائه ندهد.

انتخاب یک نرخ یادگیری مناسب به مدل کمک می‌کند که سریع‌تر به مینیمم همگرا شود بدون اینکه به مشکل عبور از مینیمم یا کند شدن روند بر بخورد.

---

**۱۵. سوال:**

**تفاوت بین مدل‌های **Bagging** و **Boosting** در یادگیری جمعی (Ensemble Learning) چیست؟**

**پاسخ:**

* **Bagging (Bootstrap Aggregating):** در این روش، چندین مدل به طور مستقل و به صورت موازی بر روی زیرمجموعه‌های مختلف داده‌های آموزش (که به طور تصادفی و با جایگزینی انتخاب می‌شوند) آموزش داده می‌شوند. سپس، پیش‌بینی‌ها از مدل‌های مختلف تجمیع می‌شوند (معمولاً به صورت متوسط برای رگرسیون یا رأی‌گیری برای طبقه‌بندی). این روش معمولاً برای کاهش واریانس و جلوگیری از **بیش‌براش** استفاده می‌شود. نمونه معروف: **Random Forest**.

* **Boosting:** در این روش، مدل‌ها به صورت ترتیبی آموزش داده می‌شوند و هر مدل جدید سعی می‌کند خطاهای مدل قبلی را اصلاح کند. مدل‌های جدید به نقاطی که مدل قبلی اشتباه پیش‌بینی کرده است، وزن بیشتری می‌دهند. این تکنیک معمولاً برای کاهش **بایاس** استفاده می‌شود. Boosting می‌تواند عملکرد مدل را به طور قابل توجهی بهبود دهد، ولی در برخی موارد ممکن است به **بیش‌براش** منجر شود. نمونه معروف: **Gradient Boosting**.

تفاوت اصلی: **Bagging** مدل‌ها را به طور مستقل آموزش می‌دهد و هدف آن کاهش واریانس است، در حالی که **Boosting** مدل‌ها را به صورت ترتیبی آموزش می‌دهد و هدف آن کاهش بایاس است.

---

**۱۶. سوال:**

**چگونه می‌توان از اعتبارسنجی متقابل (Cross-Validation) برای ارزیابی عملکرد مدل استفاده کرد؟**

**پاسخ:**

**اعتبارسنجی متقابل** یکی از تکنیک‌های اصلی برای ارزیابی عملکرد مدل‌های یادگیری است که برای جلوگیری از **بیش‌براش** و **کم‌براش** استفاده می‌شود. در این روش:

1. **داده‌ها به K بخش تقسیم می‌شوند:** مجموعه داده به K بخش مساوی تقسیم می‌شود (معمولاً 5 یا 10).
2. **آموزش و ارزیابی مدل:** مدل K بار آموزش داده می‌شود و هر بار یک بخش به عنوان داده‌های اعتبارسنجی استفاده می‌شود، در حالی که بقیه بخش‌ها برای آموزش مدل به کار می‌روند.
3. **میانگین نتایج:** پس از هر دور از ارزیابی، نتایج (مانند دقت، خطا، R²) محاسبه شده و میانگین نتایج به عنوان ارزیابی نهایی مدل انتخاب می‌شود.

این روش به طور موثری عملکرد مدل را بر اساس داده‌های مختلف ارزیابی کرده و از انتخاب مدل‌هایی که ممکن است بر اساس تقسیم‌بندی‌های خاص داده بیش از حد بهینه شوند، جلوگیری می‌کند.



حتما، این هم پاسخ‌های دقیق شما بدون هیچ تغییری:

---

۱. **سوال: در اجزای یک مدل یادگیری (Solution Components - Learning Model)، "مجموعه فرضیه (Hypothesis Set)" و "الگوریتم یادگیری (Learning Algorithm)" چه نقشی دارند و چگونه با هم کار می‌کنند؟**

**پاسخ:**

* **مجموعه فرضیه (Hypothesis Set - H):** این مجموعه، توابع ممکن را که مدل می‌تواند برای تقریب تابع هدف واقعی انتخاب کند، تعریف می‌کند. هر $h(x,\theta)$ یک تابع کاندیدا است که با پارامترهای $\theta$ (پارامترهای یادگیری مسئله) مشخص می‌شود.

* **الگوریتم یادگیری (Learning Algorithm):** این الگوریتم مسئول یافتن بهترین مجموعه از پارامترها ($\theta^*$) از فضای پارامتر $\Theta$ است به طوری که تابع $h(x,\theta^*)$ به بهترین شکل ممکن، تابع هدف واقعی $f(x)$ را تقریب بزند.

**همکاری:** این دو جزء با هم کار می‌کنند تا ورودی‌ها ($x$) را به خروجی‌ها ($y$) نگاشت کنند و خطای پیش‌بینی را به حداقل برسانند. $\theta^*$ همان بهترین پارامترها برای پیش‌بینی خروجی‌ها با استفاده از فرضیه انتخاب شده است.

---

۲. **سوال: چگونه توابع پایه (Basis Functions) به رگرسیون خطی کمک می‌کنند تا روابط غیرخطی را مدل کند؟**

**پاسخ:**
توابع پایه به ما اجازه می‌دهند تا ویژگی‌های اصلی را به یک فضای ویژگی جدید تبدیل کنیم. این تبدیل، ویژگی‌ها را به صورت غیرخطی نگاشت می‌کند (مثلاً $x$ به $x^2, x^3$ و غیره). سپس، رگرسیون خطی بر روی این بردارهای ویژگی تبدیل‌شده اعمال می‌شود. این رویکرد، سادگی و قابلیت تفسیر رگرسیون خطی را حفظ می‌کند، در حالی که انعطاف‌پذیری آن را برای مدل‌سازی روابط پیچیده و غیرخطی گسترش می‌دهد.

---

۳. **سوال: چرا در رگرسیون خطی چندمتغیره، فرمول راه‌حل تحلیلی از شبه معکوس (pseudo-inverse) ماتریس $X$ استفاده می‌کند؟**

**پاسخ:**
فرمول راه‌حل تحلیلی برای وزن‌ها در رگرسیون خطی چندمتغیره به صورت $w = (X^T X)^{-1} X^T y$ است. عبارت $(X^T X)^{-1} X^T$ را شبه معکوس ماتریس $X$ می‌نامند. ماتریس $X$ اغلب مربع نیست (تعداد نمونه‌ها با تعداد ویژگی‌ها برابر نیست) و بنابراین معکوس‌پذیر (invertible) نیست. شبه معکوس را می‌توان برای هر ماتریسی، صرف نظر از شکل آن، محاسبه کرد که این امکان را می‌دهد تا حتی در مواردی که ماتریس $X$ مربع یا معکوس‌پذیر نیست، راه‌حل تحلیلی را به دست آوریم.

---

اگر نیاز به توضیح بیشتر دارید، خوشحال می‌شوم که کمک کنم!
حتما، این هم پاسخ‌های دقیق شما بدون هیچ تغییری:

---

۴. **سوال: چه محدودیت‌های عملی (Practical limitations) برای استفاده از راه‌حل تحلیلی در رگرسیون خطی وجود دارد که منجر به نیاز به روش‌های تکراری (Iterative methods) می‌شود؟**

**پاسخ:**

* **یادگیری آنلاین (Online learning):** در سناریوهایی که داده‌ها به صورت جریان پیوسته وارد می‌شوند و پیش‌بینی‌ها باید قبل از مشاهده تمام داده‌ها انجام شوند، راه‌حل‌های تحلیلی عملی نیستند زیرا نیاز دارند تمام داده‌ها از ابتدا موجود باشند.

* **عدم سازگاری با داده‌های جدید:** روش‌های تحلیلی بدون محاسبه مجدد کل راه‌حل، با داده‌های جدید سازگار نیستند.

---

۵. **سوال: چه تفاوتی بین گرادیان دیسنت دسته‌ای (Batch Gradient Descent) و گرادیان دیسنت تصادفی (Stochastic Gradient Descent - SGD) از نظر نحوه پردازش داده‌ها وجود دارد؟**

**پاسخ:**

* **Batch Gradient Descent:** در هر تکرار، تمام مجموعه آموزشی را پردازش می‌کند تا گرادیان را محاسبه و وزن‌ها را به‌روزرسانی کند.

* **Stochastic Gradient Descent (SGD):** در هر تکرار، تنها یک مثال آموزشی را پردازش می‌کند. پارامترهای مدل را به طور مکرر به‌روزرسانی می‌کند.

---

۶. **سوال: مزیت اصلی SGD نسبت به Batch Gradient Descent چیست؟ و چرا SGD ممکن است هرگز دقیقا به مینیمم همگرا نشود؟**

**پاسخ:**

* **مزیت اصلی:** اغلب SGD بسیار سریع‌تر از Batch gradient descent به مینیمم نزدیک می‌شود. این به دلیل به‌روزرسانی‌های مکررتر پارامترها است.

* **عدم همگرایی دقیق:** با این حال، SGD ممکن است هرگز دقیقا به مینیمم همگرا نشود، و پارامترها در اطراف مینیمم تابع هزینه نوسان خواهند کرد. این نوسان به دلیل ماهیت تصادفی به‌روزرسانی‌ها (بر اساس یک نمونه واحد) است. با این حال، در عمل، اکثر مقادیر نزدیک به مینیمم که SGD به آن‌ها می‌رسد، تقریب‌های منطقی خوبی برای مینیمم واقعی خواهند بود.

---

۷. **سوال: نرخ یادگیری ($\eta$) در گرادیان دیسنت چه نقشی دارد و انتخاب نادرست آن (بسیار کوچک یا بسیار بزرگ) چه پیامدهایی دارد؟**

**پاسخ:**

* **نقش $\eta$:** $\eta$ (نرخ یادگیری) اندازه گام‌هایی را که در هر تکرار برداشته می‌شود، تعیین می‌کند. این پارامتر، متناسب با منفی بردار گرادیان، وزن‌ها را به‌روزرسانی می‌کند.

* **$\eta$ بسیار کوچک:** گرادیان دیسنت می‌تواند بسیار کند باشد.

* **$\eta$ بسیار بزرگ:** گرادیان دیسنت می‌تواند از مینیمم عبور کند (overshoot). این ممکن است منجر به عدم همگرایی یا حتی واگرایی (diverge) الگوریتم شود.

---

۸. **سوال: توضیح دهید چرا SSE (مجموع مربعات خطا) "خطاهای بزرگ‌تر را به شدت بیشتری جریمه می‌کند"؟**

**پاسخ:**
SSE خطاهای بزرگ‌تر را به شدت بیشتری جریمه می‌کند به دلیل عملیات "مربع" (squared). وقتی تفاوت بین مقدار پیش‌بینی شده و واقعی بزرگ باشد، مربع کردن آن تفاوت، مقدار خطای بسیار بزرگتری را تولید می‌کند، در حالی که تفاوت‌های کوچک‌تر، خطاهای کوچکتری را تولید می‌کنند. این ویژگی باعث می‌شود مدل به شدت تلاش کند تا خطاهای بزرگ را کاهش دهد.

---

۹. **سوال: مفهوم "Online learning" در یادگیری ماشین چیست و چه ارتباطی با SGD دارد؟**

**پاسخ:**

* **Online learning (یادگیری آنلاین):** سناریویی است که در آن داده‌ها به صورت جریان پیوسته و مداوم وارد می‌شوند. پیش‌بینی‌ها باید به صورت لحظه‌ای یا قبل از مشاهده تمام داده‌ها انجام شوند.

* **ارتباط با SGD:** SGD به طور خاص برای یادگیری آنلاین مناسب است زیرا وزن‌ها را پس از پردازش هر یک از نمونه‌ها (یا Mini-batchها) به‌روزرسانی می‌کند. این امکان را می‌دهد تا مدل به طور مداوم با داده‌های جدید، بدون نیاز به پردازش کل مجموعه داده در هر بار، سازگار شود.

---

۱۰. **سوال: محدودیت اصلی رگرسیون خطی چیست و چگونه رگرسیون چندجمله‌ای این محدودیت را برطرف می‌کند؟**

**پاسخ:**

* **محدودیت اصلی رگرسیون خطی:** این است که تنها می‌تواند روابط خطی بین ویژگی‌های ورودی و خروجی را مدل‌سازی کند. اگر الگوی واقعی داده‌ها به وضوح غیرخطی باشد، رگرسیون خطی نمی‌تواند به خوبی تعمیم پیدا کند.

* **راه حل رگرسیون چندجمله‌ای:** رگرسیون چندجمله‌ای با استفاده از توابع پایه (Basis Functions)، این محدودیت را برطرف می‌کند. این توابع، ویژگی‌های اصلی را به یک فضای ویژگی جدید تبدیل می‌کنند که شامل قدرت‌های بالاتر ویژگی‌ها (مثلاً $x^2, x^3$) است. سپس، رگرسیون خطی بر روی این ویژگی‌های تبدیل‌شده اعمال می‌شود. این رویکرد، به مدل اجازه می‌دهد تا روابط پیچیده و غیرخطی را مدل‌سازی کند.

---

اگر نیاز به اصلاح یا توضیح بیشتر دارید، خوشحال می‌شوم که کمک کنم!
حتما، این هم پاسخ‌های دقیق شما بدون هیچ تغییری:

---

۱. **سوال: در تعریف تام ام. میچل از یادگیری ماشین، سه‌گانه $(T,P,E)$ را توضیح دهید. چگونه این سه جزء با یکدیگر ارتباط برقرار می‌کنند تا نشان دهند که یک برنامه یاد می‌گیرد؟**

**پاسخ:**

سه‌گانه $(T,P,E)$ اجزای اصلی یک مسئله یادگیری را تشکیل می‌دهند:

* **وظیفه (Task - T):** کاری که برنامه کامپیوتری باید انجام دهد.

* **معیار عملکرد (Performance Measure - P):** معیاری برای اندازه‌گیری میزان خوب بودن عملکرد برنامه در انجام وظیفه $T$.

* **تجربه (Experience - E):** داده‌ها یا اطلاعاتی که برنامه برای یادگیری از آن‌ها استفاده می‌کند.

**ارتباط:** یک برنامه یاد می‌گیرد اگر عملکرد آن در وظایف $T$، که با $P$ اندازه‌گیری می‌شود، با افزایش تجربه $E$ بهبود یابد. این بدان معناست که با مشاهده داده‌های بیشتر یا با تعاملات مکرر (تجربه)، برنامه باید بتواند وظیفه محوله را با کیفیت بالاتری (عملکرد بهتر) انجام دهد.

---

۲. **سوال: Contrastive Language-Image Pretraining (CLIP) به عنوان یک مثال از کاربردهای یادگیری ماشین مطرح شده است. توضیح دهید که CLIP چگونه متن و تصاویر را به هم متصل می‌کند و چه کاربردی دارد؟**

**پاسخ:**

CLIP (Contrastive Language-Image Pretraining) یک مدل یادگیری ماشین است که برای **اتصال (Connecting)** متن و تصاویر طراحی شده است. این مدل با یادگیری یک فضای مشترک (joint embedding space) برای تصاویر و متن، می‌تواند درک کند که کدام متن با کدام تصویر مطابقت دارد.

**کاربرد:** این قابلیت به CLIP اجازه می‌دهد تا وظایف مختلفی را انجام دهد، مانند:

* جستجوی تصویری بر اساس توضیحات متنی (مثلاً پیدا کردن "گربه‌ای با کلاه قهوه‌ای" از میان تصاویر).
* طبقه‌بندی تصاویر بر اساس نام کلاس‌های متنی.
* تولید توضیحات متنی برای تصاویر (image captioning).

CLIP می‌تواند بدون آموزش مجدد بر روی داده‌های جدید، به طور موثر به وظایف مختلف تعمیم پیدا کند.

---

۳. **سوال: در یادگیری با نظارت، هدف تخمین یک تابع $f : \mathbb{R}^D \to \mathbb{R}$ است، به گونه‌ای که $y = f(x) + \epsilon$. نقش $\epsilon$ در این فرمول چیست؟**

**پاسخ:**

در فرمول $y = f(x) + \epsilon$:

* $\epsilon$ نشان‌دهنده نویز (Noise) یا خطای غیرقابل توضیح در داده‌ها است.

این نویز شامل عواملی است که ناشناخته هستند یا توسط مدل قابل توضیح نیستند، مانند خطاهای اندازه‌گیری، عوامل تصادفی، یا متغیرهایی که در مدل گنجانده نشده‌اند.

**نقش $\epsilon$:** این است که نشان دهد خروجی واقعی $y$ فقط تابعی از $x$ نیست، بلکه شامل یک جزء تصادفی نیز می‌شود که مدل نمی‌تواند به طور کامل آن را پیش‌بینی کند. مدل تنها سعی می‌کند بهترین تقریب ممکن از تابع اصلی $f(x)$ را بیابد.

---

۴. **سوال: "مجموعه فرضیه (Hypothesis Set)" در یادگیری با نظارت چیست؟ چرا ما از یک "مجموعه" از فرضیه‌ها انتخاب می‌کنیم، نه اینکه مستقیماً تابع هدف ناشناخته را پیدا کنیم؟**

**پاسخ:**

* **مجموعه فرضیه (Hypothesis Set - H):** مجموعه‌ای از توابع کاندیدا (یا "مدل‌های ممکن") $h : X \to Y$ است که الگوریتم یادگیری می‌تواند از میان آن‌ها انتخاب کند.

**چرا یک مجموعه؟** ما هرگز به طور کامل تابع هدف واقعی و ناشناخته ($f$) را نمی‌شناسیم. بنابراین، هدف ما یافتن بهترین تقریب ممکن ($g \approx f$) از میان یک مجموعه از توابع ممکن است. این مجموعه فرضیه، فضایی از مدل‌ها را تعریف می‌کند که الگوریتم می‌تواند در آن به جستجو بپردازد.

---

۵. **سوال: در مورد توابع هزینه، "خطای مربعات (Squared Error - SE)" چگونه برای یک نمونه واحد تعریف می‌شود؟ چرا این خطا به توان دو می‌رسد؟**

**پاسخ:**

* **خطای مربعات (SE) برای یک نمونه واحد:**

  $$
  SE: (y^{(i)} - h(x^{(i)}; w))^2
  $$

  این خطا، تفاوت بین مقدار واقعی $y^{(i)}$ و مقدار پیش‌بینی شده $h(x^{(i)}; w)$ برای نمونه $i$-ام را نشان می‌دهد.

**چرا به توان دو می‌رسد؟**

* **مثبت کردن خطا:** توان دو، خطاهای مثبت و منفی را به مقادیر مثبت تبدیل می‌کند، بنابراین همه‌ی خطاها به صورت "ناقص بودن" مدل در نظر گرفته می‌شوند.

* **جریمه خطاهای بزرگ‌تر:** توان دو، خطاهای بزرگ‌تر را به شدت بیشتری جریمه می‌کند تا خطاهای کوچک‌تر. این باعث می‌شود مدل تلاش کند خطاهای قابل توجه را به حداقل برساند.

---

اگر به اصلاحات یا توضیحات بیشتری نیاز دارید، خوشحال می‌شوم که کمک کنم!
حتما، این هم پاسخ‌های دقیق شما بدون هیچ تغییری:

---

۶. **سوال: در مثال رگرسیون خطی تبلیغات تلویزیونی و فروش، پس از محاسبه مشتقات جزئی تابع هزینه و برابر صفر قرار دادن آن‌ها، به یک سیستم دو معادله خطی می‌رسیم. اهمیت حل این سیستم معادلات چیست؟**

**پاسخ:**

اهمیت حل این سیستم معادلات این است که با حل آن‌ها، می‌توانیم مقادیر بهینه پارامترها ($w_0$ و $w_1$) را پیدا کنیم. این مقادیر بهینه، خط رگرسیونی را تعریف می‌کنند که تابع هزینه (SSE) را به حداقل می‌رساند و به بهترین شکل ممکن رابطه بین بودجه تبلیغات تلویزیونی و فروش را در داده‌های آموزشی مدل‌سازی می‌کند. این همان "راه‌حل تحلیلی" برای رگرسیون خطی تک‌متغیره است.

---

۷. **سوال: راه‌حل تحلیلی رگرسیون خطی (با استفاده از شبه معکوس) دارای پیچیدگی زمانی $O(n^3)$ است. این پیچیدگی زمانی چه معنایی برای کاربردهای "Big Data" دارد؟**

**پاسخ:**

پیچیدگی زمانی $O(n^3)$ به این معناست که زمان لازم برای محاسبه راه‌حل تحلیلی با مکعب تعداد ابعاد (ویژگی‌ها) یا اندازه ماتریس متناسب است.

برای کاربردهای "Big Data"، که شامل مجموعه‌های داده با ابعاد (تعداد ویژگی‌ها) بسیار بالا می‌شوند، این پیچیدگی به معنای زمان محاسباتی بسیار طولانی و غیرعملی است.

به عنوان مثال، اگر تعداد ویژگی‌ها 10 برابر شود، زمان محاسبه 1000 برابر خواهد شد. این موضوع راه‌حل‌های تحلیلی را برای داده‌های بسیار بزرگ نامناسب می‌سازد.

---

۸. **سوال: توضیح دهید که چرا راه‌حل‌های تحلیلی برای رگرسیون خطی، برای سناریوهای "یادگیری آنلاین (Online Learning)" مناسب نیستند؟**

**پاسخ:**

* **ماهیت یادگیری آنلاین:** در یادگیری آنلاین، داده‌ها به صورت جریان پیوسته و مداوم وارد می‌شوند. پیش‌بینی‌ها باید به صورت لحظه‌ای یا قبل از مشاهده تمام داده‌ها انجام شوند.

* **نیاز راه‌حل تحلیلی به تمام داده‌ها:** راه‌حل‌های تحلیلی برای محاسبه وزن‌های بهینه نیاز دارند که تمام داده‌ها از ابتدا موجود باشند. هر بار که داده‌های جدیدی اضافه می‌شوند، باید کل محاسبات (به ویژه معکوس کردن ماتریس) دوباره انجام شود که بسیار ناکارآمد است.

به همین دلیل، راه‌حل‌های تحلیلی برای سناریوهای یادگیری آنلاین که نیاز به به‌روزرسانی مدل به صورت تدریجی و با ورود داده‌های جدید دارند، مناسب نیستند.

---

۹. **سوال: گرادیان افزایشی (Gradient Ascent) چیست و چه تفاوتی با گرادیان دیسنت دارد؟ برای چه هدفی استفاده می‌شود؟**

**پاسخ:**

* **گرادیان افزایشی:** نوعی الگوریتم بهینه‌سازی تکراری است که گام‌ها را متناسب با (مثبت) بردار گرادیان تابع در نقطه فعلی برمی‌دارد.

* **تفاوت با گرادیان دیسنت:** گرادیان دیسنت گام‌ها را در جهت منفی گرادیان برمی‌دارد تا تابع را کمینه کند. اما گرادیان افزایشی گام‌ها را در جهت مثبت گرادیان برمی‌دارد.

**هدف:** گرادیان افزایشی برای یافتن حداکثر محلی (local maximum) یک تابع استفاده می‌شود.

---

۱۰. **سوال: در گرادیان دیسنت، اگر نرخ یادگیری ($\eta$) بسیار بزرگ باشد، چه مشکلاتی ممکن است پیش بیاید؟**

**پاسخ:**

اگر نرخ یادگیری ($\eta$) بسیار بزرگ باشد، گرادیان دیسنت ممکن است با مشکلات زیر روبرو شود:

* **عبور از مینیمم (Overshoot):** مدل ممکن است در هر گام بیش از حد حرکت کند و از مینیمم عبور کند.

* **عدم همگرایی:** به دلیل پرش‌های بزرگ، ممکن است الگوریتم هرگز به مینیمم همگرا نشود و در اطراف آن نوسان کند.

* **واگرایی (Divergence):** در بدترین حالت، مقدار تابع هزینه ممکن است به جای کاهش، شروع به افزایش کند و الگوریتم از مینیمم دور شود.

---

اگر نیاز به اصلاح یا توضیح بیشتر دارید، خوشحال می‌شوم که کمک کنم!




















# 📚 سوالات مصاحبه با توجه به این محتوا

در این بخش، ۵۰ سوال مصاحبه‌ای مرتبط با محتوای جلسه اول به همراه پاسخ‌های صحیح ارائه شده است. این سوالات برای آمادگی در مصاحبه‌های فنی طراحی شده‌اند.

1.  **یادگیری ماشین چیست؟**

   **پاسخ**: یادگیری ماشین شاخه‌ای از هوش مصنوعی است که به ماشین‌ها امکان می‌دهد از داده‌ها یاد بگیرند و عملکردشان را بدون برنامه‌نویسی صریح بهبود دهند.

2.  **تعریف تام میچل از یادگیری ماشین چیست؟**

 **پاسخ**: یک برنامه از تجربه $E$ نسبت به وظیفه $T$ و معیار عملکرد $P$ یاد می‌گیرد، اگر عملکردش در $T$， که با $P$ اندازه‌گیری می‌شود، با $E$ بهبود یابد.

3.  **چند کاربرد عملی یادگیری ماشین را نام ببرید.**

 **پاسخ**: پیش‌بینی رفتار مشتریان، کنترل کیفیت کارخانه، تحلیل تصاویر پزشکی.

4.  **یادگیری تحت نظارت چیست؟**

   **پاسخ**: یادگیری با داده‌های برچسب‌دار که شامل ورودی ($x$) و خروجی ($y$) است برای پیش‌بینی خروجی‌های جدید.

5.  **تفاوت رگرسیون و طبقه‌بندی چیست؟**

   **پاسخ**: رگرسیون برای پیش‌بینی مقادیر پیوسته (مثل قیمت) و طبقه‌بندی برای پیش‌بینی دسته‌های گسسته (مثل اسپم/غیراسپم) است.

6.  **رگرسیون خطی چه نوع مدلی است؟**

   **پاسخ**: مدلی که رابطه خطی بین ورودی‌ها و خروجی را با استفاده از بردار وزن‌ها ($w$) مدل می‌کند.

7.  **فرمول فرضیه رگرسیون خطی چیست؟**

   **پاسخ**: $h_w(x) = w_0 + w_1x_1 + \dots + w_Dx_D = w^T x$.

8.  **نقش $w_0$ در رگرسیون خطی چیست؟**

 **پاسخ**: $w_0$ بایاس است که امکان پیش‌بینی مقادیر غیرصفر را حتی در صورت صفر بودن ویژگی‌ها فراهم می‌کند.

9.  **هدف اصلی رگرسیون خطی چیست؟**

 **پاسخ**: کمینه کردن فاصله بین پیش‌بینی ($h_w(x)$) و مقدار واقعی ($y$).

10. **تابع هزینه چیست؟**

 **پاسخ**: معیاری برای سنجش دقت مدل، مثل مجموع مربعات خطاها (SSE).

11. **فرمول MSE چیست؟**

**پاسخ**: $J(w) = \frac{1}{n} \sum_{i=1}^{n} (y^{(i)} - h_w(x^{(i)}))^2$.

12. **چرا از MSE به‌عنوان تابع هزینه استفاده می‌شود؟**

 **پاسخ**: چون خطاهای بزرگ را بیشتر جریمه می‌کند و محاسباتش ساده است.

13. **روش تحلیلی در رگرسیون خطی چیست؟**

 **پاسخ**: استفاده از معادلات نرمال برای محاسبه مستقیم $w = (X^T X)^{-1} X^T y$.

14. **مزیت روش تحلیلی چیست؟**

 **پاسخ**: دقیق است و نیازی به تکرار ندارد.

15. **محدودیت‌های روش معادلات نرمال چیست؟**

 **پاسخ**: محاسبات سنگین برای داده‌های بزرگ و نیاز به معکوس‌پذیری $X^T X$.

16. **گرادیان نزولی چیست؟**

 **پاسخ**: روشی عددی برای کمینه کردن تابع هزینه با به‌روزرسانی وزن‌ها در جهت مخالف گرادیان.

17. **فرمول به‌روزرسانی گرادیان نزولی چیست؟**

   **پاسخ**: $w_{t+1} = w_t - \eta \nabla J(w_t)$.

18. **نرخ یادگیری ($\eta$) چیست؟**

**پاسخ**: پارامتری که اندازه قدم‌های به‌روزرسانی وزن‌ها را تعیین می‌کند.

19. **اگر نرخ یادگیری خیلی بزرگ باشد چه اتفاقی می‌افتد؟**

 **پاسخ**: الگوریتم ممکن است واگرا شود و به نقطه بهینه نرسد.

20. **اگر نرخ یادگیری خیلی کوچک باشد چه می‌شود؟**

 **پاسخ**: همگرایی کند می‌شود و زمان زیادی طول می‌کشد.

21. **تفاوت Batch GD و Stochastic GD چیست؟**

 **پاسخ**: Batch GD از کل داده‌ها و Stochastic GD از یک نمونه در هر مرحله استفاده می‌کند.

22. **Mini-batch GD چیست؟**

**پاسخ**: استفاده از زیرمجموعه‌ای از داده‌ها برای به‌روزرسانی وزن‌ها، تعادل بین دقت و سرعت.

23. **چرا نرمال‌سازی داده‌ها در گرادیان نزولی مهم است؟**

**پاسخ**: باعث می‌شود گرادیان‌ها در مقیاس مشابه باشند و همگرایی سریع‌تر شود.

24. **رگرسیون چندجمله‌ای چیست؟**

   **پاسخ**: مدلی که روابط غیرخطی را با استفاده از ویژگی‌های چندجمله‌ای مدل می‌کند.

25. **فرمول فرضیه رگرسیون چندجمله‌ای چیست؟**

 **پاسخ**: $h(x) = w_0 + w_1x + w_2x^2 + \dots + w_mx^m$.

26. **مزیت رگرسیون چندجمله‌ای نسبت به رگرسیون خطی چیست؟**

 **پاسخ**: توانایی مدل‌سازی روابط غیرخطی.

27. **چرا رگرسیون چندجمله‌ای ممکن است بیش‌برازش کند؟**

**پاسخ**: چون با افزایش درجه، مدل ممکن است نویز داده‌ها را هم یاد بگیرد.

28. **Underfitting چیست؟**
 **پاسخ**: وقتی مدل بیش‌ازحد ساده است و نمی‌تواند الگوهای داده را خوب یاد بگیرد.

29. **Overfitting چیست؟**

**پاسخ**: وقتی مدل بیش‌ازحد پیچیده است و نویز داده‌ها را هم یاد می‌گیرد.

30. **چگونه می‌توان از بیش‌برازش جلوگیری کرد؟**

**پاسخ**: استفاده از تنظیم‌سازی (Regularization)، داده‌های اعتبارسنجی، و Cross-Validation.

31. **داده‌های اعتبارسنجی چه نقشی دارند؟**

**پاسخ**: برای انتخاب مدلی که نه خیلی ساده و نه خیلی پیچیده باشد.

32. **منظور از Regularization چیست؟**

 **پاسخ**: افزودن جریمه به تابع هزینه برای جلوگیری از پیچیدگی بیش‌ازحد مدل.

33. **تفاوت L1 و L2 Regularization چیست؟**

**پاسخ**: L1 وزن‌ها را به صفر می‌رساند (انتخاب ویژگی)، L2 وزن‌ها را کوچک می‌کند.

34. **چرا MSE خطاهای بزرگ را بیشتر جریمه می‌کند؟**

 **پاسخ**: چون خطاها را به توان 2 می‌رساند، تأثیر خطاهای بزرگ بیشتر می‌شود.

35. **چه زمانی از Batch GD استفاده می‌کنیم؟**

 **پاسخ**: وقتی داده‌ها کم باشند و دقت بالا مهم باشد.

36. **چه زمانی Stochastic GD مناسب است؟**

**پاسخ**: برای داده‌های بزرگ یا مسائل آنلاین که سرعت مهم است.

37. **مزیت Mini-batch GD چیست؟**

 **پاسخ**: تعادل بین سرعت Stochastic GD و دقت Batch GD.

38. **چگونه نرخ یادگیری مناسب انتخاب می‌شود؟**

 **پاسخ**: با آزمایش مقادیر مختلف یا استفاده از روش‌های تطبیقی مثل Adam.

39. **چرا $X^T X$ ممکن است معکوس‌پذیر نباشد؟**

 **پاسخ**: به دلیل هم‌خطی ویژگی‌ها یا تعداد کم نمونه‌ها.

40. **گرادیان چیست؟**

  **پاسخ**: مشتق تابع هزینه نسبت به پارامترها که جهت بهینه‌سازی را نشان می‌دهد.

41. **تفاوت گرادیان نزولی و نیوتن چیست؟**

 **پاسخ**: نیوتن از اطلاعات مرتبه دوم (هسین) استفاده می‌کند و پیچیده‌تر است.

42. **نقش بایاس در رگرسیون چیست؟**

 **پاسخ**: امکان جابجایی مدل برای تطابق بهتر با داده‌ها.

43. **چگونه می‌توان هم‌خطی ویژگی‌ها را تشخیص داد؟**

 **پاسخ**: با محاسبه ماتریس همبستگی یا تحلیل VIF (Variance Inflation Factor).

44. **چرا داده‌ها را نرمال‌سازی می‌کنیم؟**

 **پاسخ**: برای یکسان‌سازی مقیاس ویژگی‌ها و بهبود همگرایی.

45. **Cross-Validation چیست؟**

 **پاسخ**: تکنیکی برای ارزیابی مدل با تقسیم داده‌ها به چندین زیرمجموعه.

46. **تفاوت داده‌های آموزشی و اعتبارسنجی چیست؟**

 **پاسخ**: داده‌های آموزشی برای یادگیری مدل و اعتبارسنجی برای ارزیابی آن استفاده می‌شوند.

47. **چگونه درجه مناسب در رگرسیون چندجمله‌ای انتخاب می‌شود؟**

 **پاسخ**: با استفاده از داده‌های اعتبارسنجی و بررسی خطای تست.

48. **چرا رگرسیون خطی برای داده‌های غیرخطی مناسب نیست؟**

**پاسخ**: چون فرض می‌کند رابطه بین ورودی و خروجی خطی است.

49. **تفاوت MSE و RMSE چیست؟**

**پاسخ**: RMSE ریشه دوم MSE است و مقیاسش با داده‌ها یکسان است.

50. **چگونه می‌توان مدل رگرسیون را ارزیابی کرد؟**

 **پاسخ**: با معیارهایی مثل MSE، RMSE، یا $R^2$ روی داده‌های تست.

---
# 📚 سوالات مصاحبه با توجه به این محتوا

در این بخش، ۵۰ سوال مصاحبه‌ای مرتبط با محتوای جلسه اول به همراه پاسخ‌های صحیح ارائه شده است. این سوالات برای آمادگی در مصاحبه‌های فنی طراحی شده‌اند.

1.  **یادگیری ماشین چیست و چه تفاوتی با برنامه‌نویسی سنتی دارد؟**

    **پاسخ**: یادگیری ماشین شاخه‌ای از هوش مصنوعی است که به سیستم‌ها امکان می‌دهد از داده‌ها یاد بگیرند و عملکردشان را بدون برنامه‌نویسی صریح بهبود دهند. در برنامه‌نویسی سنتی، قوانین به‌صورت دستی کد می‌شوند، اما در یادگیری ماشین، مدل از داده‌ها الگوها را استخراج می‌کند.

2.  **سه نوع اصلی یادگیری ماشین را نام ببرید و برای هر کدام مثالی ارائه دهید.**

    **پاسخ**:
    * **یادگیری نظارت‌شده**: پیش‌بینی قیمت خانه با داده‌های برچسب‌دار (متراژ، قیمت).
    * **یادگیری بدون نظارت**: خوشه‌بندی مشتریان برای بازاریابی هدفمند.
    * **یادگیری تقویتی**: آموزش ربات برای حرکت در迷宫 با پاداش و جریمه.

3.  **تفاوت بین یادگیری نظارت‌شده و بدون نظارت چیست؟**

    **پاسخ**: در یادگیری نظارت‌شده، داده‌ها برچسب دارند (ورودی و خروجی مشخص)، اما در یادگیری بدون نظارت، داده‌ها بدون برچسب هستند و مدل الگوهای پنهان را کشف می‌کند.

4.  **رگرسیون خطی چیست و چگونه کار می‌کند؟**

    **پاسخ**: رگرسیون خطی مدلی است که رابطه خطی بین متغیرهای مستقل و وابسته را مدل‌سازی می‌کند. معادله آن به‌صورت زیر است:
    $$ y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_n x_n + \epsilon $$
    هدف کمینه کردن خطا با یافتن ضرایب بهینه است.

5.  **معادله رگرسیون خطی را بنویسید و اجزای آن را توضیح دهید.**

    **پاسخ**: معادله:
    $$ y = \beta_0 + \beta_1 x_1 + \dots + \beta_n x_n + \epsilon $$
    * $y$: متغیر وابسته (هدف).
    * $\beta_0$: عرض از مبدا.
    * $\beta_i$: ضرایب ویژگی‌ها.
    * $x_i$: متغیرهای مستقل (ویژگی‌ها).
    * $\epsilon$: خطای مدل.

6.  **چرا نرمال‌سازی داده‌ها در رگرسیون خطی مهم است؟**

    **پاسخ**: نرمال‌سازی مقیاس ویژگی‌ها را یکسان می‌کند تا تأثیر متغیرهای با مقیاس بزرگ‌تر بر مدل کاهش یابد و گرادیان کاهشی سریع‌تر همگرا شود.

7.  **بیش‌برازش چیست و چگونه می‌توان از آن جلوگیری کرد؟**

    **پاسخ**: بیش‌برازش زمانی رخ می‌دهد که مدل بیش از حد به داده‌های آموزشی وابسته شود و روی داده‌های جدید ضعیف عمل کند. برای جلوگیری: منظم‌سازی (ریج، لاسو)، افزایش داده، و اعتبارسنجی متقاطع.

8.  **تفاوت بین رگرسیون خطی و رگرسیون لجستیک چیست؟**

    **پاسخ**: رگرسیون خطی برای پیش‌بینی مقادیر عددی (پیوسته) و رگرسیون لجستیک برای پیش‌بینی مقادیر دسته‌ای (مانند 0 و 1) استفاده می‌شود. رگرسیون لجستیک از تابع سیگموید برای مدل‌سازی احتمالات استفاده می‌کند.

9.  **تابع هزینه در رگرسیون خطی چیست و چگونه محاسبه می‌شود؟**

    **پاسخ**: تابع هزینه معمولاً میانگین مربعات خطا (MSE) است:
    $$ J(\beta) = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2 $$
    که $y_i$ مقدار واقعی و $\hat{y}_i$ مقدار پیش‌بینی‌شده است.

10. **گرادیان کاهشی چیست و چگونه در رگرسیون خطی استفاده می‌شود؟**

    **پاسخ**: گرادیان کاهشی الگوریتمی برای کمینه کردن تابع هزینه است. در رگرسیون خطی، ضرایب مدل با به‌روزرسانی‌های تکراری در جهت کاهش گرادیان تابع هزینه تنظیم می‌شوند.

11. **تعمیم‌پذیری در یادگیری ماشین به چه معناست؟**

    **پاسخ**: تعمیم‌پذیری توانایی مدل در عملکرد خوب روی داده‌های جدید و نادیده است، نه فقط داده‌های آموزشی.

12. **چگونه می‌توان تعمیم‌پذیری یک مدل را ارزیابی کرد؟**

    **پاسخ**: با استفاده از مجموعه آزمون جداگانه، معیارهایی مانند MSE یا دقت، و روش‌هایی مانند اعتبارسنجی متقاطع.

13. **تفاوت بین بیش‌برازش و کم‌برازش چیست؟**

    **پاسخ**: بیش‌برازش: مدل بیش از حد به داده‌های آموزشی وابسته است و روی داده‌های جدید ضعیف عمل می‌کند.
    کم‌برازش: مدل الگوهای داده‌های آموزشی را به‌خوبی یاد نمی‌گیرد و عملکرد ضعیفی دارد.

14. **روش‌های منظم‌سازی مانند ریج و لاسو چگونه کار می‌کنند؟**

    **پاسخ**: ریج با افزودن جریمه $L_2$:
    $$ \lambda \sum \beta_i^2 $$
    و لاسو با جریمه $L_1$:
    $$ \lambda \sum |\beta_i| $$
    به تابع هزینه، پیچیدگی مدل را کاهش می‌دهند و از بیش‌برازش جلوگیری می‌کنند.

15. **اعتبارسنجی متقاطع چیست و چرا استفاده می‌شود؟**

    **پاسخ**: اعتبارسنجی متقاطع (مانند k-fold) داده‌ها را به k زیرمجموعه تقسیم می‌کند و مدل را k بار آموزش و ارزیابی می‌کند تا عملکرد پایدار و تعمیم‌پذیری را بررسی کند.

16. **رگرسیون احتمالی چیست و چه تفاوتی با رگرسیون خطی دارد؟**

    **پاسخ**: رگرسیون احتمالی توزیع احتمالی خروجی‌ها را مدل می‌کند، نه فقط یک مقدار دقیق. بر خلاف رگرسیون خطی، عدم قطعیت را نیز در نظر می‌گیرد.

17. **چرا مدل‌های احتمالی در پیش‌بینی‌های مالی مفید هستند؟**

    **پاسخ**: مدل‌های احتمالی با ارائه توزیع احتمالات و عدم قطعیت، به تحلیل ریسک و تصمیم‌گیری در شرایط نامطمئن کمک می‌کنند.

18. **توزیع نرمال در رگرسیون احتمالی چه نقشی دارد؟**

    **پاسخ**: توزیع نرمال اغلب برای مدل‌سازی خروجی‌ها یا خطاها استفاده می‌شود، زیرا بسیاری از پدیده‌ها در طبیعت از این توزیع پیروی می‌کنند.

19. **رگرسیون بیزی چیست و چگونه از آن استفاده می‌شود؟**

    **پاسخ**: رگرسیون بیزی از اصول بیزی برای تخمین توزیع ضرایب استفاده می‌کند و با ترکیب دانش پیشین (prior) و داده‌ها، عدم قطعیت را مدل می‌کند.

20. **مفهوم عدم قطعیت در رگرسیون احتمالی چیست؟**

    **پاسخ**: عدم قطعیت نشان‌دهنده میزان اطمینان مدل به پیش‌بینی‌هایش است، مانند بازه اطمینان یا واریانس توزیع پیش‌بینی.

21. **داده‌های پرت چگونه بر عملکرد رگرسیون خطی تأثیر می‌گذارند؟**

    **پاسخ**: داده‌های پرت می‌توانند ضرایب مدل را به‌شدت تغییر دهند و خطای پیش‌بینی را افزایش دهند.

22. **چگونه می‌توان اثر داده‌های پرت را در رگرسیون خطی کاهش داد؟**

    **پاسخ**: با استفاده از روش‌های قوی (robust regression)، حذف داده‌های پرت، یا اعمال وزن‌دهی به داده‌ها.

23. **تفاوت بین واریانس و بایاس در یادگیری ماشین چیست؟**

    **پاسخ**: بایاس: خطای ناشی از ساده‌سازی بیش از حد مدل.
    واریانس: حساسیت مدل به تغییرات کوچک در داده‌های آموزشی.

24. **چگونه می‌توان تعادل بین واریانس و بایاس را برقرار کرد؟**

    **پاسخ**: با انتخاب مدل با پیچیدگی مناسب، استفاده از منظم‌سازی، و ارزیابی با اعتبارسنجی متقاطع.

25. **مفهوم "نفرین ابعاد" چیست و چگونه بر مدل‌های یادگیری ماشین تأثیر می‌گذارد؟**

    **پاسخ**: نفرین ابعاد به مشکلات ناشی از تعداد زیاد ویژگی‌ها اشاره دارد که باعث افزایش پیچیدگی و کاهش تعمیم‌پذیری می‌شود.

26. **روش‌های انتخاب ویژگی چیست و چرا مهم هستند؟**

    **پاسخ**: روش‌هایی مانند فیلتر، بسته‌بندی (wrapper)، و تعبیه‌شده (embedded) برای انتخاب ویژگی‌های مرتبط استفاده می‌شوند تا پیچیدگی کاهش یابد و تعمیم‌پذیری بهبود یابد.

27. **تفاوت بین رگرسیون خطی ساده و چندگانه چیست؟**

    **پاسخ**: رگرسیون خطی ساده یک متغیر مستقل دارد، اما رگرسیون چندگانه چندین متغیر مستقل را مدل می‌کند.

28. **چرا فرض خطی بودن در رگرسیون خطی مهم است؟**

    **پاسخ**: رگرسیون خطی فرض می‌کند رابطه بین متغیرها خطی است. اگر این فرض نقض شود، مدل دقت کافی نخواهد داشت.

29. **اگر رابطه بین متغیرها غیرخطی باشد، چه باید کرد؟**

    **پاسخ**: از تبدیل ویژگی‌ها (مانند افزودن توان‌ها)، مدل‌های غیرخطی (مانند رگرسیون پلی‌نومیال)، یا الگوریتم‌های دیگر (مانند درخت تصمیم) استفاده کنید.

30. **مفهوم هم‌خطی (multicollinearity) چیست و چگونه می‌توان آن را تشخیص داد؟**

    **پاسخ**: هم‌خطی زمانی رخ می‌دهد که ویژگی‌ها با هم همبستگی قوی داشته باشند. با محاسبه VIF (عامل تورم واریانس) یا ماتریس همبستگی تشخیص داده می‌شود.

31. **رگرسیون ریج چگونه هم‌خطی را مدیریت می‌کند؟**

    **پاسخ**: رگرسیون ریج با افزودن جریمه $L_2$:
    $$ \lambda \sum \beta_i^2 $$
    به تابع هزینه، تأثیر ویژگی‌های هم‌خطی را کاهش می‌دهد.

32. **مفهوم "تابع احتمال" در رگرسیون احتمالی چیست؟**

    **پاسخ**: تابع احتمال توزیع خروجی‌ها را توصیف می‌کند، مانند توزیع نرمال برای پیش‌بینی‌های پیوسته.

33. **چگونه می‌توان مدل رگرسیون خطی را ارزیابی کرد؟**

    **پاسخ**: با معیارهایی مانند MSE، RMSE، $R^2$ و بررسی نمودارهای باقی‌مانده (residual plots).


35. **تفاوت بین MSE و RMSE چیست؟**

    **پاسخ**: RMSE ریشه دوم MSE است:
    $$ \text{RMSE} = \sqrt{\frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2 } $$
    و مقیاس آن با داده‌های اصلی هم‌خوانی دارد، بنابراین تفسیر آن آسان‌تر است.

36. **مفهوم "انحراف معیار" در رگرسیون احتمالی چیست؟**

    **پاسخ**: انحراف معیار میزان پراکندگی توزیع پیش‌بینی‌ها را نشان می‌دهد و معیاری برای عدم قطعیت است.

37. **چگونه می‌توان توزیع پیش‌بینی‌ها را در رگرسیون احتمالی تحلیل کرد؟**

    **پاسخ**: با بررسی میانگین، واریانس، و بازه‌های اطمینان توزیع پیش‌بینی‌شده (مانند توزیع نرمال).

38. **چرا داده‌های آموزشی باید نماینده داده‌های واقعی باشند؟**

    **پاسخ**: اگر داده‌های آموزشی نماینده نباشند، مدل الگوهای نادرست یاد می‌گیرد و تعمیم‌پذیری ضعیفی خواهد داشت.

39. **مفهوم "افزایش داده" چیست و چگونه به تعمیم‌پذیری کمک می‌کند؟**

    **پاسخ**: افزایش داده با ایجاد داده‌های مصنوعی (مانند چرخش تصاویر) تنوع داده‌ها را افزایش می‌دهد و از بیش‌برازش جلوگیری می‌کند.

40. **تفاوت بین مدل‌های پارامتری و غیرپارامتری چیست؟**

    **پاسخ**: مدل‌های پارامتری (مانند رگرسیون خطی) تعداد محدودی پارامتر دارند، اما مدل‌های غیرپارامتری (مانند KNN) ساختار انعطاف‌پذیرتری دارند.

41. **رگرسیون خطی یک مدل پارامتری است یا غیرپارامتری؟ چرا؟**

    **پاسخ**: پارامتری است، زیرا تعداد محدودی پارامتر (ضرایب $\beta_i$) دارد و فرض خطی بودن را اعمال می‌کند.

42. **مفهوم "حداکثر درست‌نمایی" در رگرسیون احتمالی چیست؟**

    **پاسخ**: حداکثر درست‌نمایی روشی است برای یافتن پارامترهایی که احتمال مشاهده داده‌ها را بیشینه می‌کنند.

43. **چگونه می‌توان مدل رگرسیون را برای داده‌های نامتوازن تنظیم کرد؟**

    **پاسخ**: با استفاده از روش‌هایی مانند وزن‌دهی به داده‌ها، نمونه‌برداری مجدد (oversampling/undersampling)، یا مدل‌های قوی.

44. **مفهوم "گرادیان کاهشی تصادفی" چیست؟**

    **پاسخ**: گرادیان کاهشی تصادفی (SGD) ضرایب مدل را با استفاده از یک نمونه تصادفی در هر مرحله به‌روزرسانی می‌کند تا محاسبات سریع‌تر شود.

45. **تفاوت بین یادگیری برخط و یادگیری دسته‌ای چیست؟**

    **پاسخ**: یادگیری برخط مدل را با هر نمونه داده به‌روزرسانی می‌کند، اما یادگیری دسته‌ای از کل داده‌ها به‌صورت یکجا استفاده می‌کند.

46. **چگونه می‌توان مدل رگرسیون را برای داده‌های زمانی بهبود داد؟**

    **پاسخ**: با افزودن ویژگی‌های زمانی (مانند تأخیر)، استفاده از مدل‌های سری زمانی (مانند ARIMA)، یا شبکه‌های بازگشتی.

47. **مفهوم "رگرسیون قوی" چیست و در چه مواردی استفاده می‌شود؟**

    **پاسخ**: رگرسیون قوی روشی است که تأثیر داده‌های پرت را کاهش می‌دهد، مانند استفاده از تابع هزینه Huber، و در داده‌های پرنویز کاربرد دارد.

48. **چرا مدل‌های احتمالی در پزشکی کاربرد دارند؟**

    **پاسخ**: مدل‌های احتمالی با ارائه عدم قطعیت، به پزشکان کمک می‌کنند تا ریسک‌ها و احتمالات بیماری‌ها را بهتر ارزیابی کنند.

49. **چگونه می‌توان مدل رگرسیون را برای پیش‌بینی‌های چندمتغیره گسترش داد؟**

   **پاسخ**: با استفاده از رگرسیون چندمتغیره که چندین متغیر وابسته را به‌صورت همزمان مدل می‌کند.

50. **تفاوت بین پیش‌بینی نقطه‌ای و پیش‌بینی بازه‌ای چیست؟**

**پاسخ**: پیش‌بینی نقطه‌ای یک مقدار دقیق ارائه می‌دهد (مانند 500)، اما پیش‌بینی بازه‌ای یک بازه اطمینان (مانند 450-550) با سطح اطمینان مشخص می‌دهد.

---

### **6. منابع**

1.  کریستوفر ام. بیشاپ، *تشخیص الگو و یادگیری ماشین*.
2.  مهرداد سلیمانی باغشا، *یادگیری ماشین*.
3.  اندرو انگ و تنسور ما، *یادداشت‌های درس CS229*.
4.  تام میچل، *یادگیری ماشین*.
5.  یاسر ابومصطفی، مالک مگدون-اسماعیل و هسینگ-تی لین، *یادگیری از داده‌ها: دوره کوتاه*.

---

### **6. منابع**

1.  کریستوفر ام. بیشاپ، *تشخیص الگو و یادگیری ماشین*.
2.  مهرداد سلیمانی باغشا، *یادگیری ماشین*.
3.  اندرو انگ و تنسور ما، *یادداشت‌های درس CS229*.
4.  تام میچل، *یادگیری ماشین*.
5.  یاسر ابومصطفی، مالک مگدون-اسماعیل و هسینگ-تی لین، *یادگیری از داده‌ها: دوره کوتاه*.
### **6. منابع**

1.  کریستوفر ام. بیشاپ، *تشخیص الگو و یادگیری ماشین*.
2.  مهرداد سلیمانی باغشا، *یادگیری ماشین*.
3.  اندرو انگ و تنسور ما، *یادداشت‌های درس CS229*.
4.  تام میچل، *یادگیری ماشین*.
5.  یاسر ابومصطفی، مالک مگدون-اسماعیل و هسینگ-تی لین، *یادگیری از داده‌ها: دوره کوتاه*.

---

## 📌 ۵۰ سوال مهم مصاحبه‌ای همراه با پاسخ

### یادگیری ماشین - مفهومی، تکنیکی، پیاده‌سازی

1. تفاوت Bias و Variance چیست؟

   * Bias خطای ناشی از ساده بودن مدل است، Variance حساسیت مدل به داده‌های آموزشی.

2. چه زمانی از Regularization استفاده می‌کنیم؟

   * زمانی که مدل دچار Overfitting شود و نیاز به کاهش پیچیدگی داشته باشیم.

3. تفاوت L1 و L2 چیست؟

   * L1 باعث sparsity می‌شود (ویژگی‌هایی حذف می‌شوند)، ولی L2 همه وزن‌ها را کوچک می‌کند.

4. چگونه Overfitting را تشخیص دهیم؟

   * زمانی که خطای آموزش پایین و خطای تست بالا باشد.

5. راه‌های جلوگیری از Overfitting؟

   * Regularization، Dropout، استفاده از داده بیشتر، مدل ساده‌تر

6. تفاوت بین supervised و unsupervised learning؟

   * در supervised برچسب داریم، در unsupervised نه.

7. کاربرد رگرسیون خطی؟

   * پیش‌بینی قیمت‌ها، روندها، دما و هر داده پیوسته

8. مدل ساده‌ای برای پیش‌بینی پیوسته چیست؟

   * رگرسیون خطی

9. تعریف MSE؟

   * میانگین مربعات اختلاف بین پیش‌بینی و مقدار واقعی

10. تفاوت MAE و MSE؟

    * MAE خطا را به‌صورت خطی در نظر می‌گیرد، MSE خطاهای بزرگ را بیشتر جریمه می‌کند

11. گرادیان دیسنت چیست؟

    * الگوریتمی برای کمینه‌سازی تابع هزینه با استفاده از گرادیان

12. چه زمانی گرادیان دیسنت همگرا نمی‌شود؟

    * اگر نرخ یادگیری زیاد باشد یا تابع غیرمحدب باشد

13. Early stopping چیست؟

    * متوقف کردن آموزش قبل از Overfitting با مانیتور کردن خطای اعتبارسنجی

14. Batch size در آموزش چه تأثیری دارد؟

    * اندازه batch روی نوسان گرادیان، حافظه و سرعت یادگیری تأثیر دارد

15. در رگرسیون چه فرضی در مورد نویز داریم؟

    * نویز را معمولاً نرمال با میانگین صفر فرض می‌کنیم

16. تعریف log-likelihood؟

    * لگاریتم تابع درست‌نمایی برای ساده‌تر کردن مشتق‌گیری

17. چرا log-likelihood را بیشتر از likelihood استفاده می‌کنیم؟

    * چون ضرب به جمع تبدیل می‌شود و مشتق‌گیری ساده‌تر می‌شود

18. چرا مدل‌های پیچیده overfit می‌کنند؟

    * چون می‌توانند حتی نویز داده را یاد بگیرند

19. چه زمانی underfitting داریم؟

    * مدل ساده‌ است و نمی‌تواند داده‌ها را خوب یاد بگیرد

20. آیا کاهش MSE همیشه خوب است؟

    * نه، اگر فقط روی داده آموزش باشد ممکن است overfit کنیم

(ادامه سوالات در پیام بعدی...)

---


البته! در ادامه، سوالات مصاحبه‌ای شماره ۲۱ تا ۵۰ در حوزه یادگیری ماشین به‌همراه پاسخ آورده شده‌اند. این سوالات شامل مفاهیم پیشرفته‌تر، تحلیل مدل‌ها، رگرسیون، بهینه‌سازی، و پیاده‌سازی کد هستند:

---

### ادامه سوالات مصاحبه‌ای:

21. تفاوت مدل خطی و مدل غیرخطی چیست؟

* مدل خطی خروجی را به‌صورت ترکیب خطی از ورودی‌ها تولید می‌کند، در حالی که مدل‌های غیرخطی می‌توانند روابط پیچیده‌تری را مدل کنند.

22. چرا از Polynomial Regression استفاده می‌شود؟

* برای مدل‌سازی روابط غیرخطی بین متغیرهای ورودی و خروجی.

23. Regularization چگونه از overfitting جلوگیری می‌کند؟

* با اضافه کردن جریمه به وزن‌ها، مدل را وادار به یادگیری ساده‌تر می‌کند.

24. مفهوم Early Stopping چیست؟

* توقف آموزش زمانی که عملکرد روی داده اعتبارسنجی شروع به بدتر شدن می‌کند.

25. چه تفاوتی بین Validation و Test Set وجود دارد؟

* Validation برای تنظیم مدل است، Test برای ارزیابی نهایی عملکرد مدل.

26. تفاوت Ridge و Lasso چیست؟

* Ridge از L2 و Lasso از L1 استفاده می‌کند. Lasso ویژگی‌های غیرمفید را به صفر می‌رساند.

27. آیا L1 همیشه بهتر از L2 است؟

* نه. بسته به داده و هدف، L2 ممکن است عملکرد بهتری داشته باشد.

28. چرا از Cross-validation استفاده می‌کنیم؟

* برای ارزیابی مدل روی نمونه‌های مختلف و کاهش واریانس ارزیابی.

29. چند نوع Cross-validation داریم؟

* K-Fold, Leave-One-Out, Stratified K-Fold و غیره.

30. مزایای استفاده از K-Fold Cross-validation چیست؟

* استفاده مؤثر از داده، ارزیابی پایدارتر.

---

### سوالات تحلیلی/ریاضی:

31. چرا تابع MSE مشتق‌پذیر است و MAE نه؟

* MSE تابع مربعی است و مشتق‌پذیر در همه‌جا، ولی MAE در صفر مشتق ندارد.

32. چرا در MLE فرض می‌کنیم نویز نرمال است؟

* چون بسیاری از پدیده‌های طبیعی نویز نرمال دارند (طبق قضیه حد مرکزی).

33. در رگرسیون احتمالاتی چرا log-likelihood را بیشینه می‌کنیم؟

* معادل کمینه‌سازی SSE است و پیاده‌سازی راحت‌تر دارد.

34. چرا Bias^2 و Variance جمع می‌شوند؟

* چون خطای کلی مدل از دو منبع سیستماتیک (Bias) و تصادفی (Variance) می‌آید.

35. چگونه Bias بالا را کاهش دهیم؟

* با استفاده از مدل‌های پیچیده‌تر یا افزایش ویژگی‌ها

36. چگونه Variance بالا را کاهش دهیم؟

* با Regularization، استفاده از داده بیشتر، یا مدل ساده‌تر

37. تعریف دقیق Noise در Bias-Variance چیست؟

* بخشی از خطا که ناشی از تصادفی بودن داده‌ها است و قابل کاهش نیست.

38. چرا از Root Mean Squared Error استفاده می‌کنیم؟

* چون با واحد خروجی یکسان است و خطاهای بزرگ را بیشتر جریمه می‌کند.

---

### سوالات کدنویسی و کاربردی:

39. در scikit-learn چطور یک مدل Ridge می‌سازید؟

```python
from sklearn.linear_model import Ridge
model = Ridge(alpha=1.0)
model.fit(X_train, y_train)
```

40. چگونه می‌توان λ بهینه را پیدا کرد؟

* با استفاده از Grid Search یا Cross-validation.

41. اگر مدل شما در تست بد عمل می‌کند ولی در آموزش عالی است، چه مشکلی وجود دارد؟

* احتمالاً Overfitting اتفاق افتاده است.

42. اگر مدل ساده‌ای دارید و خطا هم بالا است، چه کاری باید بکنید؟

* مدل پیچیده‌تر یا ویژگی‌های جدید اضافه کنید.

43. در یادگیری ماشین، چه نوع تابع خطا برای طبقه‌بندی استفاده می‌شود؟

* Cross-entropy

44. اگر تابع هزینه به‌صورت غیرمحدب باشد چه مشکلی ایجاد می‌شود؟

* ممکن است در مینیمم محلی گیر کند.

45. چه زمانی از مدل‌های non-parametric استفاده می‌کنیم؟

* زمانی که نمی‌خواهیم فرض خاصی در مورد توزیع داده‌ها بزنیم.

46. مزایای مدل‌های احتمالاتی نسبت به مدل‌های قطعی چیست؟

* قابلیت مدل‌سازی عدم قطعیت و پیش‌بینی توزیع خروجی

47. در چه شرایطی Regularization به مدل آسیب می‌زند؟

* اگر مقدار λ بسیار بزرگ باشد و مدل را بیش از حد محدود کند.

48. چرا استفاده زیاد از ویژگی‌ها ممکن است عملکرد مدل را کاهش دهد؟

* به دلیل curse of dimensionality یا افزایش واریانس.

49. در کدام شرایط dropout مؤثرتر از L2 است؟

* در شبکه‌های عصبی با لایه‌های زیاد، Dropout بهتر عمل می‌کند.

50. اگر مدل شما دچار high variance است، چه راهکارهایی دارید؟

* استفاده از داده بیشتر، Regularization، ساده‌سازی مدل

* ---
  حتماً! 👌 با توجه به محتوای دقیق اسلایدهای دکتر شریفی زارعی در فایل «Linear Regression - Part 2»، در اینجا **۱۰ سوال بسیار پرکاربرد مصاحبه‌ای** همراه با **پاسخ‌های چندخطی و مفهومی** ارائه می‌دهم. تمرکز این سوالات بر مباحث: **تعمیم‌پذیری، Overfitting/Underfitting، Bias-Variance، Regularization، و رگرسیون احتمالاتی** است.

---

## ✅ ۱۰ سوال مهم مصاحبه‌ای براساس اسلایدهای دکتر شریفی زارعی

---

### 1. تفاوت بین **Training Error** و **Test Error** چیست و چرا Test Error مهم‌تر است؟

**پاسخ:**
Training Error، خطای مدل روی داده‌های آموزش است، در حالی که Test Error خطا روی داده‌هایی است که مدل قبلاً ندیده است. مدل ممکن است روی داده آموزش عملکرد فوق‌العاده داشته باشد (حتی خطای صفر)، اما اگر روی داده جدید خطا بالا برود، نشان از **عدم تعمیم‌پذیری مناسب** دارد. هدف در یادگیری ماشین، **حداقل‌سازی Test Error** است.

---

### 2. چگونه می‌توان تشخیص داد که مدل دچار **Overfitting** شده است؟

**پاسخ:**
در Overfitting، مدل روی داده آموزش بسیار خوب عمل می‌کند ولی روی داده تست عملکرد بدی دارد. یعنی:

* **Training Error پایین**
* **Test Error بالا**
  این اتفاق معمولاً زمانی رخ می‌دهد که مدل **بیش‌ازحد پیچیده** است یا ویژگی‌های زیادی دارد که باعث یادگیری نویز داده‌ها می‌شود.

---

### 3. Underfitting چیست و چه زمانی رخ می‌دهد؟

**پاسخ:**
Underfitting زمانی اتفاق می‌افتد که مدل آن‌قدر ساده است که حتی **داده آموزش را هم به خوبی یاد نمی‌گیرد**. در این حالت:

* **Training Error بالا**
* **Test Error بالا**
  علت اصلی معمولاً ساده بودن مدل یا نداشتن ظرفیت کافی برای مدل‌سازی رابطه‌ی بین ویژگی‌ها و خروجی است.

---

### 4. منظور از **Bias-Variance Tradeoff** چیست؟

**پاسخ:**
در یادگیری ماشین، خطای تعمیم‌پذیری به سه جزء تقسیم می‌شود:

* **Bias**: خطای ناشی از ساده بودن مدل
* **Variance**: نوسان مدل نسبت به تغییر داده آموزش
* **Noise**: خطای ذاتی داده
  Tradeoff یعنی افزایش پیچیدگی باعث کاهش Bias ولی افزایش Variance می‌شود. هنر طراحی مدل، رسیدن به **تعادل بهینه** بین این دو است.

---

### 5. Regularization چیست و چگونه از Overfitting جلوگیری می‌کند؟

**پاسخ:**
Regularization تکنیکی برای جلوگیری از Overfitting است. این کار با **اضافه کردن جریمه‌ای به وزن‌های بزرگ** در تابع هزینه انجام می‌شود:

* **L2 Regularization (Ridge)**: جریمه با مجموع مربعات وزن‌ها
* **L1 Regularization (Lasso)**: جریمه با مجموع قدرمطلق وزن‌ها
  این جریمه مدل را مجبور به ساده‌سازی می‌کند.

---

### 6. پارامتر λ در Regularization چه نقشی دارد؟

**پاسخ:**
پارامتر λ میزان تاثیر ترم Regularization را کنترل می‌کند:

* اگر λ خیلی بزرگ باشد → مدل بیش‌ازحد ساده می‌شود (Underfitting)
* اگر λ خیلی کوچک باشد → مدل آزادانه وزن‌ها را انتخاب می‌کند (Overfitting)
  انتخاب مناسب λ باعث رسیدن به **مدلی متعادل بین دقت و سادگی** می‌شود.

---

### 7. در مدل رگرسیون با دیدگاه احتمالاتی، چرا از توزیع نرمال برای نویز استفاده می‌شود؟

**پاسخ:**
توزیع نرمال به‌دلیل خواص ریاضی مناسب (تقارن، مشتق‌پذیری) و قضیه حد مرکزی انتخاب می‌شود. فرض می‌کنیم:

$$
y = f(x; w) + \epsilon,\ \ \epsilon \sim \mathcal{N}(0, \sigma^2)
$$

این فرض باعث می‌شود تخمین پارامترها با روش **Maximum Likelihood Estimation** به ساده‌سازی تابع هزینه منجر شود (معادل MSE).

---

### 8. چگونه نشان می‌دهیم که **Maximizing Log-Likelihood** معادل **Minimizing MSE** است؟

**پاسخ:**
اگر نویز نرمال با میانگین صفر و واریانس σ² فرض شود، تابع لگاریتم درست‌نمایی به شکل زیر درمی‌آید:

$$
\log L = -\frac{1}{2\sigma^2} \sum (y_i - f(x_i;w))^2 + \text{const}
$$

با حذف ثابت‌ها، بیشینه‌سازی log-likelihood معادل کمینه‌سازی **Sum of Squared Errors** (MSE) می‌شود.

---

### 9. چه زمانی از Polynomial Regression استفاده می‌کنیم و خطر آن چیست؟

**پاسخ:**
وقتی رابطه‌ی بین ورودی و خروجی **غیرخطی** است، از رگرسیون چندجمله‌ای استفاده می‌کنیم.
خطر آن در این است که **درجه بالا → Overfitting** چون مدل می‌تواند به راحتی روی نویز داده آموزش هم منطبق شود.

---

### 10. تعریف دقیق Expected Test Error چیست؟

**پاسخ:**
Expected Test Error یعنی میانگین خطای مدل روی داده‌های جدیدی که از همان توزیع $p(x,y)$ استخراج شده‌اند:

$$
J(w) = \mathbb{E}_{(x,y) \sim p}[(y - h_w(x))^2]
$$

از آنجا که توزیع اصلی را نداریم، این مقدار با داده‌های تست تخمین زده می‌شود.

---

حتماً! 👌 در ادامه، ۱۰ سؤال **مهم و پرکاربرد دیگر** مصاحبه‌ای همراه با پاسخ‌های **تحلیلی‌تر، مفهومی‌تر و دقیق‌تر** ارائه می‌دهم. این پرسش‌ها مستقیماً مرتبط با محتوای فایل PDF جلسه دوم هستند (تعمیم‌پذیری، رگرسیون احتمالاتی، Bias-Variance، Regularization و غیره).

---

## 🔟 سوال مصاحبه‌ای دیگر با پاسخ‌های کامل‌تر

---

### 11. چرا مدل‌های پیچیده با درجات بالای چندجمله‌ای (Polynomial Regression) معمولاً دچار Overfitting می‌شوند؟

**پاسخ کامل:**
در رگرسیون چندجمله‌ای با درجات بالا، مدل توانایی فوق‌العاده‌ای در منطبق شدن با داده آموزش دارد. این منطبق شدن شامل **نویزهای موجود در داده نیز می‌شود**. چون مدل بیش از حد انعطاف‌پذیر است، به جای درک الگوی کلی، وارد جزئیات و نوسانات تصادفی داده‌ها می‌شود. این باعث می‌شود که مدل **روی داده‌های جدید عملکرد ضعیفی** داشته باشد. راه‌حل‌هایی مانند Regularization یا کاهش درجه چندجمله‌ای برای کنترل این پدیده به کار می‌روند.

---

### 12. در تفسیر Bias و Variance، چرا نمی‌توان هردو را هم‌زمان به حداقل رساند؟

**پاسخ کامل:**
Bias و Variance دو مؤلفه‌ی متضاد هستند:

* مدل‌های ساده (مثلاً خطی) معمولاً **Bias بالا** دارند چون قادر به یادگیری الگوهای پیچیده نیستند.
* مدل‌های پیچیده (مثلاً شبکه‌های عمیق یا چندجمله‌ای درجه بالا) **Variance بالا** دارند چون نسبت به داده‌های آموزش حساس‌اند.

کاهش یکی، معمولاً منجر به افزایش دیگری می‌شود. بنابراین باید بین این دو یک **تعادل هوشمندانه** برقرار کرد که به آن **Bias-Variance Tradeoff** می‌گویند.

---

### 13. چگونه می‌توان Generalization Error را در عمل تخمین زد؟

**پاسخ کامل:**
گرچه Generalization Error (خطای واقعی روی داده‌های دیده‌نشده) به‌صورت تئوری به‌شکل $\mathbb{E}_{p(x,y)}[(y - h(x))^2]$ تعریف می‌شود، در عمل ما **داده تست مستقل** را از همان توزیع در نظر می‌گیریم و مقدار خطا را روی آن محاسبه می‌کنیم. به این مقدار، **Test Error** می‌گویند و تقریب مناسبی برای Generalization Error است.

---

### 14. Regularization چه تأثیری روی مقادیر وزن‌های مدل دارد؟

**پاسخ کامل:**
در Regularization، ما با افزودن یک جریمه به تابع هزینه، مدل را از داشتن وزن‌های بزرگ بازمی‌داریم.
در **L2 Regularization (Ridge)**:

* تابع جریمه: $\lambda \sum w_j^2$
* وزن‌ها به‌صورت پیوسته کاهش می‌یابند.

در **L1 Regularization (Lasso)**:

* تابع جریمه: $\lambda \sum |w_j|$
* برخی وزن‌ها به‌کلی صفر می‌شوند → **ویژگی‌گزینی (Feature Selection)**

در هر دو روش، تأثیر اصلی، **کاهش پیچیدگی مدل و افزایش تعمیم‌پذیری** است.

---

### 15. چرا در MLE فرض می‌شود نویز از توزیع نرمال با میانگین صفر می‌آید؟

**پاسخ کامل:**
این فرض چند دلیل دارد:

1. **قضیه حد مرکزی**: نویزهای ترکیبی از عوامل مختلف معمولاً توزیع نرمال دارند.
2. **سادگی ریاضیاتی**: توزیع نرمال مشتق‌پذیر و متقارن است و log-likelihood آن به راحتی محاسبه می‌شود.
3. **تحلیل آماری دقیق‌تر**: با این فرض، کمینه کردن SSE معادل بیشینه کردن Likelihood می‌شود.

البته، اگر نویز واقعاً نرمال نباشد، MLE ممکن است دچار خطا شود، و باید مدل نویز مناسب‌تری انتخاب کرد.

---

### 16. تفاوت L1 و L2 Regularization در نتایج نهایی چیست؟

**پاسخ کامل:**

* **L1 Regularization (Lasso)** تمایل دارد **برخی وزن‌ها را کاملاً صفر کند**، که به انتخاب ویژگی منجر می‌شود (Feature Selection).
* **L2 Regularization (Ridge)** وزن‌ها را کاهش می‌دهد اما به ندرت به صفر می‌رساند. مدل پیچیده را نرم‌تر می‌کند بدون حذف کامل ویژگی‌ها.

در مسائل با تعداد زیاد ویژگی (high-dimensional), اگر فکر می‌کنیم برخی ویژگی‌ها بی‌ارزش هستند، L1 مناسب‌تر است.

---

### 17. Root Mean Squared Error (RMSE) چه تفاوتی با MSE دارد و چه زمانی استفاده می‌شود؟

**پاسخ کامل:**

* **MSE** فقط میانگین مربعات خطا را گزارش می‌کند و واحد آن مربع واحد خروجی است.
* **RMSE** ریشه‌ی MSE است و واحد آن مثل خروجی اصلی است.

مثلاً اگر داریم قیمت خانه‌ها را پیش‌بینی می‌کنیم، RMSE در واحد «تومان» خواهد بود و **قابل تفسیرتر** است. بنابراین RMSE اغلب برای گزارش به کاربران یا ارزیابی عملکرد کاربردی ترجیح داده می‌شود.

---

### 18. چرا مدل‌های بسیار ساده (High Bias) حتی با داده زیاد هم عملکرد ضعیفی دارند؟

**پاسخ کامل:**
مدل‌های ساده دارای فرضیات محدودکننده‌ای هستند. مثلاً در رگرسیون خطی، ما فرض می‌کنیم رابطه بین ورودی و خروجی خطی است. اگر واقعیت پیچیده‌تر باشد، حتی اگر **حجم داده زیاد باشد**، این مدل قادر به یادگیری آن نخواهد بود.
این خطای سیستماتیک را **Bias** می‌گویند. داده بیشتر نمی‌تواند فرض غلط مدل را جبران کند.

---

### 19. آیا همیشه باید از مدل‌های پیچیده برای بهبود عملکرد استفاده کرد؟

**پاسخ کامل:**
خیر! مدل پیچیده لزوماً بهتر نیست. پیچیدگی بالا اگر با داده ناکافی یا تنظیمات نامناسب همراه شود، **Overfitting** ایجاد می‌کند.
برعکس، مدل ساده با انتخاب ویژگی مناسب، Regularization و تنظیم پارامتر صحیح می‌تواند عملکرد بهتری از مدل پیچیده داشته باشد.
اصل طلایی: مدل باید **به اندازه‌ی لازم پیچیده باشد، نه بیشتر**.

---

### 20. در چه شرایطی Regularization می‌تواند به مدل آسیب بزند؟

**پاسخ کامل:**
اگر مقدار λ (ضریب Regularization) بیش از حد زیاد باشد، مدل بیش از حد ساده می‌شود. این اتفاق باعث **Underfitting** می‌شود، یعنی مدل نمی‌تواند حتی داده آموزش را به خوبی یاد بگیرد.
در نتیجه، هم Training Error و هم Test Error افزایش می‌یابند.
بنابراین، **تنظیم دقیق λ** با استفاده از Cross-validation بسیار حیاتی است.

---
حتماً! 🙌 در ادامه، ۱۰ سؤال دیگر مصاحبه‌ای مهم و مفهومی همراه با پاسخ‌های کامل و کاربردی، کاملاً بر اساس مباحث مطرح‌شده در اسلاید جلسه دوم دکتر شریفی زارعی (رگرسیون خطی، تعمیم‌پذیری، Bias-Variance، Regularization، و Maximum Likelihood) ارائه می‌دهم:

---

## ✅ سوالات ۲۱ تا ۳۰ | پاسخ‌های تشریحی و حرفه‌ای

---

### 21. چه تفاوتی بین مدل Discriminative و Generative وجود دارد؟

**پاسخ کامل:**

* **مدل‌های Discriminative** مستقیم تابع شرطی $p(y|x)$ را یاد می‌گیرند. مثل: Logistic Regression.
* **مدل‌های Generative** توزیع مشترک $p(x,y)$ یا $p(x|y)$ و $p(y)$ را مدل می‌کنند. مثل: Naive Bayes.
  در رگرسیون و بسیاری از مدل‌های یادگیری ماشین، بیشتر از مدل‌های Discriminative استفاده می‌شود چون دقت بالاتری دارند.

---

### 22. هدف از Cross-Validation چیست و چرا مهم است؟

**پاسخ کامل:**
Cross-validation برای ارزیابی عملکرد مدل به شکلی **مستقل از داده آموزش و تست** استفاده می‌شود.
در K-Fold، داده به K قسمت تقسیم می‌شود و مدل روی K-1 قسمت آموزش می‌بیند و روی قسمت باقیمانده اعتبارسنجی می‌شود.
این کار باعث می‌شود بتوانیم **مقدار بهینه‌ی λ یا درجه‌ی مدل را انتخاب کنیم** بدون overfit شدن.

---

### 23. اگر داده‌ها نویزدار باشند، چه مشکلی برای مدل یادگیری پیش می‌آید؟

**پاسخ کامل:**
نویز باعث می‌شود مدل نتواند رابطه واقعی را به خوبی یاد بگیرد. اگر مدل بیش از حد پیچیده باشد، ممکن است نویز را نیز یاد بگیرد (Overfitting).
در این شرایط استفاده از:

* **Regularization**
* **مدل ساده‌تر**
* **جمع‌آوری داده بیشتر**
  می‌تواند به کاهش اثر نویز کمک کند.

---

### 24. چرا MSE نسبت به خطاهای بزرگ حساس‌تر است؟

**پاسخ کامل:**
چون در تعریف MSE از مربع خطا استفاده می‌شود، خطاهای بزرگ بیش از حد تقویت می‌شوند:

$$
MSE = \frac{1}{n} \sum (y_i - \hat{y}_i)^2
$$

در نتیجه اگر در داده‌های ما outlier وجود داشته باشد، MSE ممکن است گمراه‌کننده باشد. در چنین شرایطی استفاده از MAE یا Huber Loss توصیه می‌شود.

---

### 25. چه زمانی استفاده از MAE به جای MSE منطقی‌تر است؟

**پاسخ کامل:**
MAE = میانگین قدرمطلق خطاها.
در داده‌هایی که دارای **outlier (داده پرت)** هستند، MAE بهتر عمل می‌کند چون خطاها را خطی جریمه می‌کند. برخلاف MSE که به‌شدت از outlier تأثیر می‌گیرد.

---

### 26. مدل خطی چگونه می‌تواند با داده‌های غیرخطی کار کند؟

**پاسخ کامل:**
با استفاده از **پیش‌پردازش ویژگی‌ها (Feature Engineering)** یا **بسط ویژگی‌ها (Polynomial Features)** می‌توان داده غیرخطی را به فضای خطی‌تر منتقل کرد.
مثال:

```python
from sklearn.preprocessing import PolynomialFeatures
```

مدل همچنان خطی باقی می‌ماند ولی در فضایی با ویژگی‌های غیربدیهی کار می‌کند.

---

### 27. در تفسیر Root Mean Squared Error، چرا گفتیم واحد آن با خروجی برابر است؟

**پاسخ کامل:**
چون RMSE برابر است با:

$$
RMSE = \sqrt{MSE}
$$

از آنجایی که MSE دارای واحد **(خروجی)^2** است، گرفتن ریشه دوم باعث می‌شود **واحد RMSE با خروجی یکسان باشد** و قابل تفسیرتر باشد. مثلاً: "مدل ما به‌طور میانگین ۲ درجه خطا دارد."

---

### 28. چه ارتباطی بین Maximum Likelihood و Least Squares وجود دارد؟

**پاسخ کامل:**
اگر فرض کنیم نویز نرمال با واریانس ثابت است، آنگاه **بیشینه‌سازی تابع درست‌نمایی معادل کمینه‌سازی SSE (Sum of Squared Errors)** خواهد بود.
یعنی:

$$
\text{argmax}_{w} \log L(w) \equiv \text{argmin}_{w} \sum (y_i - f(x_i))^2
$$

این پیوند بین آمار و یادگیری ماشین، یکی از دلایل محبوبیت رگرسیون خطی است.

---

### 29. اگر مدل‌تان Bias بالا دارد، چه اقداماتی انجام می‌دهید؟

**پاسخ کامل:**
مدلی که Bias بالا دارد معمولاً خیلی ساده است و قادر به مدل‌سازی روابط داده نیست. برای کاهش Bias:

* افزایش پیچیدگی مدل (مثلاً درجه بالاتر در رگرسیون چندجمله‌ای)
* اضافه کردن ویژگی‌های جدید
* استفاده از مدل‌های غیرخطی (مثل درخت تصمیم یا شبکه عصبی)

---

### 30. اگر مدل‌تان Variance بالا دارد، چگونه با آن مقابله می‌کنید؟

**پاسخ کامل:**
مدل‌هایی با Variance بالا نسبت به تغییر داده‌های آموزشی بسیار حساس هستند. راهکارها:

* استفاده از **Regularization**
* افزایش حجم داده آموزشی
* ساده‌تر کردن مدل (مثلاً کاهش درجه چندجمله‌ای)
* استفاده از Cross-validation برای انتخاب مدل متعادل

---

اگر خواستی، می‌تونم همین ۳۰ سؤال و پاسخ رو با طراحی مرتب، توی فایل PDF یا به‌صورت فلش‌کارت مصاحبه‌ای برات آماده کنم.
✅ آیا بریم برای ۱۰ سؤال دیگه (۳۱ تا ۴۰)؟
یا دوست داری از همین‌ها یک فایل نهایی بسازیم؟




---

---

