
**مقدمه‌ای بر رگرسیون لجستیک (Logistic Regression)**


**مدرس:** علی شریفی-زارچی
**دپارتمان:** مهندسی کامپیوتر
**دانشگاه:** صنعتی شریف
**تاریخ:** 5 اکتبر 2024
**درس:** یادگیری ماشین (CE 40717)

---
**رگرسیون لجستیک: مباحث اولیه و پیش‌پردازش داده**

در جلسه گذشته، مروری بر تکنیک‌های دسته‌بندی (classification) انجام شد و برای اولین بار با مسئله دسته‌بندی آشنا شدیم. [cite_start]برخلاف مسئله رگرسیون که هدف، پیش‌بینی یک مقدار پیوسته بود، در دسته‌بندی هدف پیش‌بینی مجموعه‌ای از کلاس‌ها است[cite: 49]. این کلاس‌ها می‌توانند حالات مختلفی داشته باشند، مانند بیمار/سالم، سگ/گربه، فروش رفتن/نرفتن خانه، خوش‌حساب/بدحساب بودن مشتری، پرداخت وام/عدم پرداخت وام، اسپم بودن/نبودن ایمیل، یا حاوی محتوای توهین‌آمیز بودن/نبودن یک متن، و بسیاری موارد دیگر.

در جلسات قبلی، در ساده‌ترین مدل‌های دسته‌بندی، برچسب کلاس‌ها را منفی یک و یک در نظر می‌گرفتیم. [cite_start]اما در این جلسه، به خاطر سادگی و دلایل ریاضیاتی مدل، برچسب کلاس‌ها از این به بعد 0 و 1 در نظر گرفته می‌شود[cite: 57, 58, 59]. این یک تفاوت اولیه است که باید به آن توجه داشت.

**پرسش محوری:**
در جلسات قبل، با دسته‌بند "پرسپترون" آشنا شدیم که ساختار شبکه عصبی داشت. اما این مدل اشکالی داشت: خروجی آن شبیه یک تابع پله‌ای بود که از یک نقطه خاص (مثلاً صفر) به بعد، کلاس را 1 و قبل از آن، کلاس را منفی 1 در نظر می‌گرفت. [cite_start]عملاً از علامت (sign) استفاده می‌شد[cite: 81, 82]. واقعیت این است که در بسیاری از مواقع، شما یک "درجه اطمینان" دارید. به عنوان مثال، برای یک بیمار، ممکن است 100% مطمئن باشید که سرطان دارد، یا 100% مطمئن باشید که سالم است. اما اغلب اوقات، مقادیری بین این دو حالت وجود دارد. مثلاً، نه می‌توانید 100% مطمئن باشید که فرد سرطان دارد و نه 100% مطمئن باشید که سالم است؛ شاید 70% احتمال می‌دهید سرطان داشته باشد یا 80% احتمال می‌دهید سالم باشد.

**سوال این است که چگونه می‌توانیم این موضوع را مدل‌سازی کنیم؟** چگونه الگوریتم خود را توسعه دهیم تا بتواند یک نوع "احتمال" (مانند احتمال بیمار بودن یا سالم بودن) را به دست آورد؟ این رویکرد، بسیار متفاوت از تابع پله‌ای است که در جلسه قبل دیدیم. ما به دنبال تابعی هستیم که خروجی آن بین 0 و 1 باشد، به گونه‌ای که اگر ورودی در یک ناحیه خاص قرار گیرد، خروجی به 0 نزدیک باشد (مثلاً 100% سالم)، و اگر در ناحیه دیگر باشد، خروجی به 1 نزدیک باشد (مثلاً 100% بیمار). اما در نقاط میانی، خروجی باید مقادیر بین 0 و 1 را بگیرد (مثلاً 0.4 یا 0.6).

![image1](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/03-Logistic%20Regression/images/01.png)

**مشکل رگرسیون خطی برای مسائل دسته‌بندی:**
یک راه حل ساده این است که به سراغ رگرسیون خطی برویم، شبیه همان مدلی که قبلاً داشتیم. اگر داده‌هایی با برچسب 0 و 1 داشته باشیم، می‌توانیم یک خط به آنها برازش (fit) دهیم تا حداقل خطای مربعات را داشته باشد. اما مشکل اینجاست که اگر یک نقطه جدید (outlier) به داده‌ها اضافه شود، خط برازش یافته به شدت تغییر می‌کند. این تغییر می‌تواند باعث شود که بسیاری از نقاطی که قبلاً به درستی دسته‌بندی شده بودند، اکنون به اشتباه دسته‌بندی شوند (مثلاً همه نقاط را 1 یا 0 برچسب‌گذاری کند). این یک نمونه از اینکه چرا رگرسیون خطی برای مسائل دسته‌بندی مناسب نیست.
![image2](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/03-Logistic%20Regression/images/02.png)


**رگرسیون لجستیک:**
الگوریتمی معرفی خواهد شد که یکی از پرکاربردترین الگوریتم‌های دسته‌بندی است. این الگوریتم، رگرسیون لجستیک (Logistic Regression) نام دارد.

**قالب‌بندی داده‌ها (Data Format):**
فرض کنید یک جدول داده (table) داریم که شامل تعدادی "ویژگی" (features) است. تلاش می‌کنیم همه این ویژگی‌ها را به مقادیر عددی تبدیل کنیم. به عنوان مثال، اگر ستونی برای جنسیت (male/female) داریم، می‌توانیم آن را به 0 و 1 تبدیل کنیم که کاملاً قراردادی است.

**پیش‌پردازش داده (Data Preprocessing):**
ویژگی‌های عددی ممکن است مقیاس‌های (scales) بسیار متفاوتی داشته باشند. مثلاً، یک ویژگی ممکن است بین 0 تا 1 باشد (مثل جنسیت)، در حالی که دیگری ممکن است بین 150 تا 230 باشد (مثل قد). این دامنه‌های متفاوت باعث می‌شوند که ضرایب (weights) مدل (مثلاً در یک معادله خط ساده) مقیاس‌های بسیار متفاوتی داشته باشند. بنابراین، "مقیاس‌بندی" (scaling) تک‌تک ویژگی‌ها مهم است.
* **استانداردسازی (Standardization):** یک تکنیک این است که میانگین هر ویژگی را صفر و واریانس آن را یک کنیم. این کار به "نرمال‌سازی" یا "استانداردسازی" داده‌ها معروف است.
* **مقیاس‌بندی Min-Max (Min-Max Scaling):** روش دیگر این است که حداقل مقدار هر ویژگی را به صفر و حداکثر آن را به یک برسانیم.

پیش‌پردازش داده‌ها یک مرحله بسیار مهم در یادگیری ماشین است که قبل از قرار دادن داده‌ها در مدل باید انجام شود. در این مرحله، کارهایی مانند حذف داده‌های پرت (outliers)، بصری‌سازی (visualization) داده‌ها، و بررسی توزیع ویژگی‌های مختلف انجام می‌شود تا از کیفیت داده‌ها اطمینان حاصل شود. ممکن است لازم باشد برخی از ردیف‌ها (samples) یا ستون‌های داده (features) را حذف کنید زیرا نتایج مدل را تحت تأثیر قرار می‌دهند. این کار به "پیش‌پردازش داده" معروف است و در عمل یادگیری ماشین، اهمیت زیادی دارد.

در نهایت، یک ستون "برچسب" (label) نیز وجود دارد، مثلاً "اضافه وزن" (overweight) بودن یا نبودن، که هدف ما پیش‌بینی آن از روی ویژگی‌ها است.


![image](https://github.com/user-attachments/assets/b2a2474e-2769-4857-9e6a-cca7561a04a3)




---

**مبانی رگرسیون لجستیک: تابع سیگموئید و ویژگی‌های آن**


**1. نیاز به تابع احتمالاتی:**
* در رگرسیون لجستیک، ما به دنبال یک "تابع احتمال" هستیم. این تابع به صورت اولیه "سیگما" نامیده می‌شود.
* وظیفه این تابع این است که مقادیر ورودی (که می‌توانند از منفی بی‌نهایت تا مثبت بی‌نهایت باشند) را به بازه بین صفر تا یک تبدیل کند.
* مقدار احتمال همیشه بین صفر و یک است، بنابراین به چنین تابعی نیاز داریم.
* اگر ضرایب $w$ را در بردار ویژگی $x$ (که شامل $x_0=1, x_1, \dots, x_d$ است) ضرب کنیم (یعنی $w^T x$)، نتیجه می‌تواند هر عددی بین منفی بی‌نهایت تا مثبت بی‌نهایت باشد.
* تابع "سیگما" این مقدار را به بازه صفر تا یک مقیاس‌بندی می‌کند.
* برخلاف تابع پله‌ای (که مشتق‌ناپذیر است و خروجی‌های چکشی 0 یا 1 می‌دهد)، تابع سیگما رفتاری نرم (smooth) و مشتق‌پذیر دارد و امکان نمایش "درجه اطمینان" را فراهم می‌کند.
* هدف این است که خروجی تابع، احتمال بیمار بودن یا سالم بودن را نشان دهد، نه فقط یک دسته‌بندی قطعی.
* $P(y=1|x, w) = \sigma(w^T x)$ نشان‌دهنده احتمال اینکه کلاس برابر با 1 باشد (مثلاً بیمار باشد) با توجه به ورودی $x$ و پارامترهای $w$ است.
* $P(y=0|x, w) = 1 - \sigma(w^T x)$ نشان‌دهنده احتمال اینکه کلاس برابر با 0 باشد (مثلاً سالم باشد).

  
---


**2. تابع سیگموئید (Sigmoid Function) یا تابع لجستیک (Logistic Function):**


   
   
   * این تابع، شکل مناسبی برای تابع احتمالاتی است و "تابع سیگموئید" یا "تابع لجستیک" نام دارد.
   * به همین دلیل، الگوریتم دسته‌بندی ما "رگرسیون لجستیک" نامیده می‌شود، با وجود اینکه یک الگوریتم دسته‌بندی است، نه رگرسیون.
   * فرمول تابع سیگموئید: $\sigma(z) = \frac{1}{1 + e^{-z}}$
   * 2.1. ویژگی‌های تابع سیگموئید:
   * اگر $z$ به سمت مثبت بی‌نهایت میل کند، $\sigma(z)$ به سمت 1 میل می‌کند.
   * اگر $z$ به سمت منفی بی‌نهایت میل کند، $\sigma(z)$ به سمت 0 میل می‌کند.
   * این رفتار تابع، مطابق با انتظارات ما برای یک تابع احتمال است.
   *  اگر $z = 0$ باشد، $\sigma(0) = 0.5$.
   *  خروجی آن همواره بین 0 و 1 است.
   * به صورت "هموار" (smoothly) بین 0 و 1 تغییر می‌کند.
   * "مشتق‌پذیر" (differentiable) است.

   

   ![image3](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/03-Logistic%20Regression/images/03.png)

   * **مشتق تابع سیگموئید:**
      * مشتق $\sigma(z)$ نسبت به $z$， برابر است با $\sigma(z)(1 - \sigma(z))$.
       ![image](https://github.com/user-attachments/assets/714d9c2a-3e3a-42c6-b4ea-5d548bfeb7ab)

      * این ویژگی ریاضیاتی تابع سیگموئید، در محاسبات بعدی (مانند گرادیان) بسیار مفید خواهد بود و باعث سادگی محاسبات می‌شود.
      * نمودار مشتق سیگموئید نشان می‌دهد که مشتق در اطراف $z=0$ (که $\sigma(z)=0.5$ است) به حداکثر می‌رسد و در دورترین نقاط (نزدیک به 0 و 1) به 0 میل می‌کند.
    
      ![image4](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/03-Logistic%20Regression/images/04.png)


   * **تفسیر خروجی رگرسیون لجستیک:**
      * $\sigma(w^T x)$ نشان‌دهنده احتمال اینکه $y=1$ باشد، با توجه به ورودی $x$ و پارامترهای $w$ است: $P(y=1|x, w) = \sigma(w^T x)$.
      * احتمال اینکه $y=0$ باشد، برابر است با: $P(y=0|x, w) = 1 - \sigma(w^T x)$.
      * $w$ یک بردار شامل ضرایب $w_0, w_1, ..., w_d$ است و $x$ یک بردار ویژگی شامل $x_0=1, x_1, ..., x_d$ است.
      * $w^T x$ همان ضرب داخلی بردار ویژگی‌ها در بردار وزن‌ها است.
      * **مثال:** اگر $\sigma(w^T x) = 0.7$ باشد، به این معنی است که 70 درصد شانس برد در بازی بسکتبال وجود دارد.
    





**سطح تصمیم (Decision Surface) در رگرسیون لجستیک**

در رگرسیون لجستیک، با مفهوم "سطح تصمیم" (Decision Surface) آشنا می‌شویم. قبل از این، در دسته‌بندهای خطی مانند پرسپترون که در جلسه قبل دیدیم، یک خط وجود داشت که نقاط دارای برچسب‌های مختلف (مانند -1 و 1) را از یکدیگر جدا می‌کرد. در رگرسیون لجستیک نیز می‌توان همین را تصور کرد: خطی که نقاط با برچسب 0 را از نقاط با برچسب 1 جدا می‌کند.

اما تفاوت در این است که برخلاف دسته‌بند خطی پرسپترون که تابع آن به صورت "پله‌ای تیز" (sharp step function) بود (یعنی به طور ناگهانی از یک مقدار به مقدار دیگر تغییر می‌کرد), در رگرسیون لجستیک، تابع "بسیار هموارتر" (smoother) است و به صورت پیوسته تغییر می‌کند.
![image5](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/03-Logistic%20Regression/images/05.png)

**سطح تصمیم غیرخطی (Non-linear Decision Boundary) در رگرسیون لجستیک**

اگر نقاط داده به گونه‌ای باشند که با یک خط مستقیم قابل تفکیک نباشند و کلاس‌های 0 و 1 به صورت غیرخطی (مثلاً به شکل دایره‌ای) توزیع شده باشند، می‌توان از تکنیک "مهندسی ویژگی" (Feature Engineering) برای ایجاد یک مرز تصمیم غیرخطی استفاده کرد.

**روش کار:**
* **افزایش ابعاد ویژگی:** علاوه بر ویژگی‌های اصلی مانند $x_1$ و $x_2$， می‌توانیم ویژگی‌های مرتبه بالاتر مانند $x_1^2$ و $x_2^2$ را نیز به بردار ویژگی‌های ورودی اضافه کنیم.
* **ایجاد مرز تصمیم غیرخطی:** با اضافه کردن این ویژگی‌های جدید، رگرسیون لجستیک می‌تواند یک مرز تصمیم غیرخطی (مانند یک دایره) را یاد بگیرد که به بهترین شکل کلاس‌ها را از هم جدا کند.
* **مثال معادله مرز تصمیم دایره‌ای:** اگر مرز تصمیم یک دایره باشد، معادله آن می‌تواند به صورت $x_1^2 + x_2^2 - 1 = 0$ باشد. در این حالت، ضرایب (weights) مدل (بردار $w$) به گونه‌ای خواهند بود که برای $x_1^2$ و $x_2^2$ مقدار 1 و برای جمله ثابت (عرض از مبدأ) مقدار -1 را داشته باشند، و برای $x_1$ و $x_2$ مقادیر 0.
* **تفسیر خروجی:** در این مدل، رگرسیون لجستیک برای تمام نقاط داخل دایره، مقدار 0 و برای تمام نقاط خارج دایره، مقدار 1 را برمی‌گرداند. این شبیه به یک "چاله هموار" است که داخل آن 0 و بیرون آن 1 است.

**پارامترهای قابل یادگیری:**
تنها پارامترهایی که الگوریتم باید یاد بگیرد و به صورت خودکار محاسبه کند، همین مقادیر $w_0, w_1, w_2, w_3, w_4$ (شامل ضرایب ویژگی‌های اصلی، ویژگی‌های مرتبه بالاتر و عرض از مبدأ) هستند.
![image6](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/03-Logistic%20Regression/images/06.png)

---
یاداوری: احتمال 


![image7](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/03-Logistic%20Regression/images/07.png)


---

**تخمین پارامتر با استفاده از حداکثر درستنمایی (Maximum Likelihood Estimation - MLE)**

وقتی می‌خواهیم پارامترهای یک توزیع کلی را از روی داده‌های نمونه‌برداری شده تخمین بزنیم، این فرآیند را "استیمیشن" (Estimation) یا "تخمین" می‌نامیم. یکی از بهترین روش‌ها برای تخمین پارامتر، "تخمین حداکثر درستنمایی" (Maximum Likelihood Estimation - MLE) است.

**مثال: تخمین احتمال شیر آمدن سکه**

فرض کنید یک سکه را چندین بار پرتاب کرده‌اید و توالی زیر را مشاهده کرده‌اید: "1، 0، 1، 0، 1، 1، 1، 1، 0، 1، 1، 1، 1، 0، 1". در این مثال، 12 بار "یک" (شیر) و 4 بار "صفر" (خط) آمده است.

* **هدف:** می‌خواهیم احتمال شیر آمدن (برچسب 1) را برای این سکه تخمین بزنیم، که آن را با $P$ (پی کوچک) نشان می‌دهیم. (توجه داشته باشید که این $P$ با تابع احتمال که با $P$ بزرگ نشان داده می‌شود، تفاوت دارد).
* **احتمال وقوع 0:** احتمال خط آمدن نیز برابر است با $1 - P$.
* **احتمال مشاهده این توالی:** هر پرتاب سکه یک آزمایش برنولی است و مشاهده 12 شیر و 4 خط در 16 پرتاب، از توزیع دو جمله‌ای (Binomial Distribution) پیروی می‌کند.
    * فرمول احتمال مشاهده $k$ موفقیت در $n$ آزمایش با احتمال موفقیت $p$: $P(X=k) = \binom{n}{k} p^k (1-p)^{n-k}$
    * در مثال ما، احتمال مشاهده 12 شیر از 16 پرتاب برابر است با: $\binom{16}{12} P^{12} (1-P)^4$. این عبارت، "درستنمایی" (Likelihood) مشاهده این توالی داده‌ها با پارامتر $P$ است.

**فرایند تخمین حداکثر درستنمایی:**
MLE به دنبال یافتن مقداری برای پارامتر $P$ است که باعث شود احتمال مشاهده توالی داده‌های ما (یعنی درستنمایی) "بیشترین" مقدار ممکن را داشته باشد. این یعنی پیدا کردن:
$\arg \max_{P} \left[ \binom{16}{12} P^{12} (1-P)^4 \right]$

برای سادگی محاسبات، از ویژگی لگاریتم استفاده می‌کنیم: اگر یک تابع ماکسیمم شود، لگاریتم آن نیز ماکسیمم می‌شود. این به این دلیل است که لگاریتم یک تابع اکیداً صعودی است. با گرفتن لگاریتم از عبارت درستنمایی، حاصل‌ضرب‌ها به جمع تبدیل می‌شوند:
$\arg \max_{P} \left[ \log \left( P^{12} (1-P)^4 \right) \right] = \arg \max_{P} \left[ 12 \log P + 4 \log (1-P) \right]$

برای یافتن مقدار $P$ که این عبارت را حداکثر می‌کند، مشتق آن را نسبت به $P$ برابر با صفر قرار می‌دهیم:
$\frac{d}{dP} (12 \log P + 4 \log (1-P)) = 0$
$12 \cdot \frac{1}{P} + 4 \cdot \frac{-1}{1-P} = 0$
$\frac{12}{P} - \frac{4}{1-P} = 0$
$\frac{12}{P} = \frac{4}{1-P}$
$12(1-P) = 4P$
$12 - 12P = 4P$
$12 = 16P$
$P = \frac{12}{16} = \frac{3}{4} = 0.75$

**تفسیر نتیجه:**
مقدار تخمینی $P$ (که با $\hat{P}$ نشان داده می‌شود) برابر با $0.75$ است. این نتیجه با شهود ما مطابقت دارد: اگر 12 بار از 16 پرتاب شیر بیاید، محتمل‌ترین احتمال شیر آمدن سکه $12/16$ است.
MLE به همین سادگی است. این تکنیک می‌تواند برای تخمین پارامترهای توزیع‌های مختلف (مانند میانگین و واریانس در توزیع نرمال، یا پارامترهای توزیع بتا و پواسون) نیز به کار رود.

![image08](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/03-Logistic%20Regression/images/08.png)


---


برای پیدا کردن پارامترهای $w$ که تابع درستنمایی را حداکثر می‌کنند، هدف ما یافتن $P(y|x, w)$ است که در آن $w$ پارامترهای مدل هستند.

**تابع درستنمایی (Likelihood Function)**
* فرض می‌شود که نمونه‌های داده‌ای مستقل از هم (IID) هستند. این فرض به ما اجازه می‌دهد تا احتمال کلی مشاهده تمام نمونه‌ها را به صورت حاصل‌ضرب احتمالات هر نمونه بنویسیم.
* پس، $L(w) = \prod_{i=1}^{n} P(y^{(i)}|x^{(i)}, w)$.
    * در اینجا $P(y^{(i)}|x^{(i)}, w)$ برای دسته‌بندی باینری به صورت $\sigma(w^T x^{(i)})^{y^{(i)}}(1-\sigma(w^T x^{(i)}))^{(1-y^{(i)})}$ بیان می‌شود. این فرمول، روشی ریاضیاتی برای بیان شرط "اگر $y^{(i)}=1$ بود، از $\sigma$ استفاده کن و اگر $y^{(i)}=0$ بود، از $1-\sigma$ استفاده کن" است.

**تابع لگاریتم درستنمایی (Log-Likelihood Function)**
* برای ساده‌سازی محاسبات و جلوگیری از مشکلات عددی (مانند underflow که از حاصل‌ضرب اعداد کوچک به وجود می‌آید)، به جای تابع درستنمایی، لگاریتم آن را حداکثر می‌کنیم.
* از آنجایی که تابع لگاریتم یک تابع اکیداً صعودی است، حداکثر کردن لگاریتم درستنمایی معادل با حداکثر کردن خود درستنمایی است.
* با اعمال لگاریتم، حاصل‌ضرب‌ها به جمع تبدیل می‌شوند:
    * $\log L(w) = \sum_{i=1}^{n} \log P(y^{(i)}|x^{(i)}, w)$
    * $\log L(w) = \sum_{i=1}^{n} [y^{(i)} \log(\sigma(w^T x^{(i)})) + (1-y^{(i)}) \log(1-\sigma(w^T x^{(i)}))]$

**بهینه‌سازی پارامترها**
* این تابع (لگاریتم درستنمایی) را با $L(w)$ نمایش می‌دهیم.
* برای یافتن $w$ که $L(w)$ را حداکثر می‌کند، باید مشتق $L(w)$ نسبت به $w$ را محاسبه کرده و آن را برابر با صفر قرار دهیم.
* **محاسبه گرادیان:** مشتق $L(w)$ نسبت به $w$ به صورت زیر است:
    * $\nabla_w L(w) = \sum_{i=1}^{n} (y^{(i)} - \sigma(w^T x^{(i)})) x^{(i)}$
    * این گرادیان از مشتقات زنجیره‌ای تابع لگاریتم و تابع سیگموئید به دست می‌آید.
    * مشتق $\log(\sigma(z))$ نسبت به $z$ برابر است با $(1-\sigma(z))$ و مشتق $\log(1-\sigma(z))$ نسبت به $z$ برابر است با $-\sigma(z)$ (با استفاده از مشتق $\sigma(z)$ که $\sigma(z)(1-\sigma(z))$ است).
    * پس از ساده‌سازی، گرادیان به فرم $ \sum_{i=1}^{n} (y^{(i)} - \sigma(w^T x^{(i)})) x^{(i)}$ در می‌آید.
* **عدم وجود فرم بسته:** متاسفانه، برخلاف رگرسیون خطی، برای $\nabla_w L(w) = 0$ راه حل "فرم بسته" (closed-form solution) وجود ندارد. یعنی نمی‌توانیم $w$ را مستقیماً با یک فرمول جبری محاسبه کنیم.



![image9](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/03-Logistic%20Regression/images/09.png)

![image10](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/03-Logistic%20Regression/images/10.png)

![image11](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/03-Logistic%20Regression/images/11.png)

![image12](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/03-Logistic%20Regression/images/12.png)













**بررسی تابع هزینه و گرادیان در رگرسیون لجستیک**

**1. تابع هزینه (Cost Function) و ارتباط آن با خطای پیش‌بینی:**

* اگر به گرادیانی که برای رگرسیون لجستیک محاسبه کردیم (یعنی $\sum_{i=1}^{n} (\sigma(w^T x^{(i)}) - y^{(i)}) x^{(i)}$) دقت کنید، فرم آن شباهت زیادی به گرادیان در رگرسیون خطی دارد.
* در رگرسیون خطی، گرادیان شامل عبارت $(w^T x^{(i)} - y^{(i)})$ بود که نشان‌دهنده "خطا" یا تفاوت بین مقدار پیش‌بینی شده و مقدار واقعی بود.
* در رگرسیون لجستیک نیز، $\sigma(w^T x^{(i)})$ همان "پیش‌بینی" مدل است و $y^{(i)}$ "برچسب واقعی" است. بنابراین، عبارت $(\sigma(w^T x^{(i)}) - y^{(i)})$ همان "خطا" یا "ارور" مدل است.
* پس، گرادیان در رگرسیون لجستیک به سادگی از ضرب "خطا" در بردار ویژگی $x^{(i)}$ به دست می‌آید.
* این سادگی و زیبایی در فرم گرادیان، یکی از دلایل اصلی انتخاب تابع سیگموئید (با فرمول $1/(1+e^{-z})$) برای رگرسیون لجستیک است. اگر از توابع دیگری استفاده می‌شد، ممکن بود گرادیان به قدری پیچیده شود که حل آن از نظر محاسباتی غیرممکن باشد.
* تابع هزینه‌ای که برای رگرسیون لجستیک استفاده می‌شود، "Binary Cross-Entropy Loss" نام دارد. در حالت کلی (برای بیش از دو کلاس)، به آن "Cross-Entropy Loss" می‌گویند.
* نکته کلیدی در این تابع هزینه، وجود عبارت لگاریتمی است.
* 
* ![image13](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/03-Logistic%20Regression/images/13.png)


**2. محدب بودن (Convexity) تابع هزینه و تضمین همگرایی:**

* یکی از ویژگی‌های بسیار مهم و زیبای الگوریتم رگرسیون لجستیک این است که "تابع هزینه آن محدب (Convex) است".
* "محدب بودن" به این معنی است که تابع هزینه فقط یک "بهینه سراسری" (global optimum) دارد و هیچ "بهینه محلی" (local optima) در آن وجود ندارد.
* از نظر ریاضی، این ویژگی با بررسی مشتق دوم تابع هزینه اثبات می‌شود. مشتق دوم هر جمله از تابع هزینه (چه $y=1$ باشد و چه $y=0$) همواره مثبت است.
* همچنین، جمع تعدادی تابع محدب، یک تابع محدب خواهد بود. بنابراین، کل تابع هزینه رگرسیون لجستیک نیز محدب است.
* این محدب بودن تضمین می‌کند که الگوریتم‌های بهینه‌سازی مبتنی بر گرادیان، مانند "گرادیان کاهشی" (Gradient Descent)، همیشه به سمت بهترین جواب (بهینه سراسری) همگرا می‌شوند و در نقاط بهینه محلی گیر نمی‌کنند.
* این یک مزیت بزرگ نسبت به مدل‌هایی است که تابع هزینه نامحدب دارند (مانند استفاده از خطای مربعات برای رگرسیون لجستیک که منجر به توابع با "چال‌چوله" یا چندین بهینه محلی می‌شود).

**3. به‌روزرسانی پارامترها با گرادیان کاهشی:**

* هدف نهایی این است که پارامترهای مدل ($w$) را طوری پیدا کنیم که تابع هزینه حداقل شود.
* از آنجایی که نمی‌توانیم $w$ را با یک فرمول بسته پیدا کنیم، از گرادیان کاهشی استفاده می‌کنیم.
* در فرآیند بهینه‌سازی، مقدار پارامترها ($w$) در هر مرحله (iteration) بر اساس گرادیان تابع هزینه به‌روزرسانی می‌شود.
* "قانون به‌روزرسانی" (Update Rule) به این صورت است: $w_{جدید} = w_{قدیم} - \eta \times \text{گرادیان}$. در اینجا $\eta$ (اتا) "نرخ یادگیری" (learning rate) است که اندازه گام‌ها در جهت گرادیان را تعیین می‌کند.
* گرادیان محاسبه شده، جهت شیب تابع هزینه را نشان می‌دهد. در گرادیان کاهشی، در جهت "منفی" گرادیان حرکت می‌کنیم تا به حداقل تابع برسیم.

![image14](https://github.com/ZahraShahlaie/Introduction_to_Machine_Learning/raw/main/Lecture_Notes/Chapter_01_Supervised_Learning/03-Logistic%20Regression/images/14.png)


