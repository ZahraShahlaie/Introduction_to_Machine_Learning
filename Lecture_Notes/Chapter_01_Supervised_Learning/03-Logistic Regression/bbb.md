## رگرسیون لجستیک: خلاصه‌ای از مبانی و کاربردها

این جزوه به بررسی رگرسیون لجستیک می‌پردازد، که یکی از الگوریتم‌های پرکاربرد در مسائل طبقه‌بندی است.

### مقدمه ای بر طبقه‌بندی و رگرسیون لجستیک

برخلاف مسائل رگرسیون که هدف پیش‌بینی یک خروجی پیوسته است، طبقه‌بندی (Classification) به دنبال پیش‌بینی برچسب‌های کلاسی گسسته است. به عنوان مثال، دسته‌بندی یک ایمیل به عنوان هرزنامه یا غیر هرزنامه، تعیین جعلی یا معتبر بودن یک تراکنش آنلاین، یا تشخیص بدخیم یا خوش‌خیم بودن تومور، همگی از مسائل طبقه‌بندی محسوب می‌شوند. در طبقه‌بندی باینری (دودویی)، متغیر خروجی $y$ معمولاً به مجموعه $\{0, 1\}$ تعلق دارد، که 0 نشان‌دهنده "کلاس منفی" (مانند تومور خوش‌خیم) و 1 نشان‌دهنده "کلاس مثبت" (مانند تومور بدخیم) است.

استفاده از رگرسیون خطی برای مسائل طبقه‌بندی با چالش‌هایی همراه است، زیرا خروجی آن، $h_{\theta}(x)$، می‌تواند خارج از محدوده $[0, 1]$ قرار گیرد. این موضوع برای نمایش احتمال، مشکل‌ساز است. آنچه مورد نیاز است، تابعی است که خروجی را بین 0 و 1 محدود کند، درست مانند یک احتمال. اینجا همان جایی است که رگرسیون لجستیک وارد می‌شود.

در رگرسیون لجستیک، ما سعی می‌کنیم تابعی به نام $\sigma(w^T x)$ را پیدا کنیم که احتمالات پسین $P(y=1|x)$ را پیش‌بینی کند. به طور خاص:
* $P(y=1|x,w)=\sigma(w^T x)$
* $P(y=0|x,w)=1-\sigma(w^T x)$

تابع $\sigma(.)$ را **تابع فعال‌سازی** (activation function) می‌نامند. یک نامزد مناسب برای این تابع فعال‌سازی، **تابع سیگموئید (لجستیک)** است.

تابع سیگموئید به صورت زیر تعریف می‌شود:
$\sigma(z)=\frac{1}{1+e^{-z}}$

این تابع انتخاب خوبی است زیرا هر ورودی با مقدار حقیقی $z$ را به طور پیوسته به خروجی بین 0 و 1 تبدیل می‌کند. همچنین، این تابع مشتق‌پذیر است که یک ویژگی حیاتی برای بهینه‌سازی محسوب می‌شود. مشتق تابع سیگموئید نسبت به $z$ برابر است با $\sigma(z)(1 - \sigma(z))$.

در رگرسیون لجستیک، ورودی تابع سیگموئید، ضرب داخلی بردار ویژگی $x$ و بردار وزن $w$ است، یعنی $w^T x$. بردار ویژگی $x$ معمولاً با یک جمله بایاس $x_0=1$ گسترش می‌یابد، به طوری که $x=[x_0=1, x_1, \ldots, x_d]$ و $w=[w_0, w_1, \ldots, w_d]$. خروجی $\sigma(w^T x)$ نشان‌دهنده احتمال برآورد شده $y=1$ برای ورودی $x$ است.

### سطح تصمیم

**سطح تصمیم** (Decision surface) یا **مرز تصمیم** (decision boundary)، ناحیه‌ای در فضای مسئله است که برچسب خروجی طبقه‌بند در آن مبهم است. در طبقه‌بندی دودویی، این مرز جایی است که احتمال تعلق یک نمونه به هر یک از کلاس‌ها ($y=0$ یا $y=1$) برابر است.

برای رگرسیون لجستیک، سطح تصمیم با $\sigma(w^T x) = 0.5$ تعریف می‌شود. این بدان معنی است که $w^T x = 0$. بنابراین، سطوح تصمیم در رگرسیون لجستیک توابع خطی از $x$ هستند.

اگر $\sigma(w^T x)\ge0.5$ باشد، $\hat{y}=1$ پیش‌بینی می‌شود، در غیر این صورت $\hat{y}=0$ پیش‌بینی می‌شود. به طور معادل، اگر $w^T x \ge 0$ باشد، $\hat{y}=1$ تصمیم گرفته می‌شود، در غیر این صورت $\hat{y}=0$.

اگرچه رگرسیون لجستیک ذاتاً مرزهای تصمیم خطی ایجاد می‌کند، اما می‌تواند با اضافه کردن جملات مرتبه بالاتر از ویژگی‌ها به بردار ورودی $x$ (مانند $x_1^2, x_2^2$)، مرزهای تصمیم پیچیده‌تر (غیرخطی) را نیز یاد بگیرد.

### برآورد حداکثر احتمال (MLE)

هدف رگرسیون لجستیک، یافتن بردار وزن بهینه $w$ است که بهترین توصیف را از مسئله طبقه‌بندی ارائه می‌دهد. این امر با حداکثر کردن تابع درستنمایی (likelihood) مشاهده داده‌های آموزشی داده شده حاصل می‌شود. به طور خاص، ما قصد داریم حاصل‌ضرب احتمالات پسین را برای تمام نمونه‌ها حداکثر کنیم:

$\hat{w}=arg~max_{w}log\prod_{i=1}^{n}P(y^{(i)}|x^{(i)},w)$

برای طبقه‌بندی دودویی، احتمال پسین برای یک نمونه تکی $(x^{(i)}, y^{(i)})$ را می‌توان به صورت فشرده‌ای بیان کرد:
$P(y^{(i)}|x^{(i)},w)=\sigma(w^{T}x^{(i)})^{y^{(i)}}(1-\sigma(w^{T}x^{(i)}))^{(1-y^{(i)})}$

برای ساده‌سازی بهینه‌سازی، معمولاً به جای خود تابع درستنمایی، **لگاریتم درستنمایی** (log-likelihood) را حداکثر می‌کنیم. از آنجایی که لگاریتم یک تابع صعودی اکید است، حداکثر کردن لگاریتم درستنمایی معادل با حداکثر کردن درستنمایی است.

لگاریتم احتمال پسین برای یک نمونه تکی برابر است با:
$log~P(y^{(i)}|x^{(i)},w)=y^{(i)}log(\sigma(w^{T}x^{(i)}))+(1-y^{(i)})log(1-\sigma(w^{T}x^{(i)}))$

لگاریتم درستنمایی کلی برای کل مجموعه داده، مجموع لگاریتم درستنمایی برای نمونه‌های منفرد است:
$log\prod_{i=1}^{n}P(y^{(i)}|x^{(i)},w)=\sum_{i=1}^{n}log~P(y^{(i)}|x^{(i)},w)$
$= \sum_{i=1}^{n}[y^{(i)}log(\sigma(w^{T}x^{(i)}))+(1-y^{(i)})log(1-\sigma(w^{T}x^{(i)}))]$

### تابع هزینه (Cost Function)

در یادگیری ماشین، اغلب یک **تابع هزینه** (cost function) یا تابع زیان (loss function) را تعریف می‌کنیم که هدفمان حداقل کردن آن است. برای برآورد حداکثر احتمال، تابع هزینه $J(w)$ معمولاً منفی لگاریتم درستنمایی است:

$J(w)=-\sum_{i=1}^{n}log~P(y^{(i)}|x^{(i)},w)$
$=\sum_{i=1}^{n}-y^{(i)}log(\sigma(w^{T}x^{(i)}))-(1-y^{(i)})log(1-\sigma(w^{T}x^{(i)}))$

این تابع هزینه به عنوان **زیان آنتروپی متقاطع دودویی** (Binary Cross-Entropy Loss) نیز شناخته می‌شود.
یکی از ویژگی‌های مهم این تابع هزینه، **محدب بودن** (convexity) آن است. این امر حائز اهمیت است زیرا یک تابع محدب تنها یک حداقل سراسری دارد و تضمین می‌کند که الگوریتم‌های بهینه‌سازی مانند گرادیان کاهشی به راه حل بهینه همگرا می‌شوند و در حداقل‌های محلی گیر نمی‌کنند.

### گرادیان کاهشی (Gradient Descent)

از آنجایی که هیچ راه‌حل فرم بسته ای (closed-form solution) برای یافتن وزن‌های $w$ که $J(w)$ را با صفر قرار دادن گرادیان آن ($\nabla_w J(w) = 0$) حداقل می‌کنند وجود ندارد، از یک الگوریتم بهینه‌سازی تکراری مانند **گرادیان کاهشی** استفاده می‌کنیم.

قاعده به روزرسانی برای گرادیان کاهشی به صورت زیر است:
$w^{t+1}=w^{t}-\eta\nabla_{w}J(w^{t})$
که در آن $\eta$ نرخ یادگیری (learning rate) است.

گرادیان تابع هزینه $J(w)$ برای رگرسیون لجستیک نسبت به $w$ به طور شگفت‌آوری مشابه گرادیان مجموع مربعات خطا (SSE) در رگرسیون خطی است:
$\nabla_{w}J(w)=\sum_{i=1}^{n}(\sigma(w^{T}x^{(i)})-y^{(i)})x^{(i)}$

در اینجا، $(\sigma(w^{T}x^{(i)}) - y^{(i)})$ نشان‌دهنده خطای (احتمال پیش‌بینی شده منهای برچسب واقعی) برای $i$-امین نمونه است.

### رگرسیون لجستیک چندکلاسه

رگرسیون لجستیک را می‌توان برای مدیریت مسائل با بیش از دو کلاس نیز گسترش داد، که به آن **رگرسیون لجستیک چندکلاسه** (Multi-class Logistic Regression) گفته می‌شود. در این سناریو، ما $K$ کلاس داریم و هر نمونه تنها به یکی از کلاس‌ها تعلق دارد (برای سادگی).

برای هر کلاس $k$، تابعی به نام $\sigma_k(x;W)$، احتمال $P(y=k|x,W)$ را پیش‌بینی می‌کند.
مجموع احتمالات برای تمامی کلاس‌ها باید برابر با 1 باشد: $\sum_{k=1}^{K}P(y=k|x_{0},W)$.
$W$ یک ماتریس از بردارهای وزن $w_i$ است، که هر $w_i$ بردار وزن مربوط به کلاس $i$ است.
برای یک ورودی جدید $x$، برای پیش‌بینی، کلاسی را انتخاب می‌کنیم که $\sigma_k(x;W)$ را حداکثر کند.

در رگرسیون لجستیک چندکلاسه (زمانی که $K>2$ و $y\in\{1,2,...,K\}$)، از تابع **سافت‌مکس** (Softmax) به عنوان تابع فعال‌سازی استفاده می‌شود. این تابع، نسخه‌ای نرمال‌سازی شده از تابع نمایی است و احتمالات را برای هر کلاس تولید می‌کند:
$\sigma_{k}(x,W)=P(y=k|x)=\frac{exp(w_{k}^{T}x)}{\sum_{j=1}^{K}exp(w_{j}^{T}x)}$

تابع سافت‌مکس به طور پیوسته حداکثر احتمال را برجسته می‌کند و مشتق‌پذیر است. همچنین می‌تواند مقادیر منفی را نیز مدیریت کند زیرا از تابع نمایی استفاده می‌کند. مجموع خروجی‌های سافت‌مکس برای همه کلاس‌ها برابر با 1 است، که آن را به یک توزیع احتمال معتبر تبدیل می‌کند.

تابع هزینه در رگرسیون لجستیک چندکلاسه نیز به عنوان منفی لگاریتم درستنمایی تعریف می‌شود:
$J(W)=-log\prod_{i=1}^{n}P(y^{(i)}|x^{(i)},W)$
$=-log\prod_{i=1}^{n}\prod_{k=1}^{K}\sigma_{k}(x^{(i)};W)^{y_{k}}^{(0)}}$
$=-\sum_{i=1}^{n}\sum_{k=1}^{K}y_{k}^{(i)}log(\sigma_{k}(x^{(i)};\mathbb{W}))$

در اینجا $y_k^{(i)}$ نشان می‌دهد که آیا $i$-امین نمونه به کلاس $k$ تعلق دارد (1 اگر تعلق داشته باشد، 0 در غیر این صورت).
باز هم، هیچ راه‌حل فرم بسته‌ای برای یافتن $W$ وجود ندارد. از این رو، از گرادیان کاهشی برای بهینه‌سازی استفاده می‌کنیم. قاعده به‌روزرسانی برای بردار وزن کلاس $j$، $w_j^t$، در تکرار $t$ به صورت زیر است:
$w_{j}^{t+1}=w_{j}^{t}-\eta\nabla_{W}J(W^{t})$
$\nabla_{W_{j}}J(W)=\sum_{i=1}^{n}(\sigma_{j}(x^{(i)};W)-y_{j}^{(i)})x^{(i)}$

### خلاصه‌ی رگرسیون لجستیک

* رگرسیون لجستیک یک طبقه‌بند خطی است.
* مسئله بهینه‌سازی رگرسیون لجستیک با استفاده از حداکثر احتمال (Maximum Likelihood) به دست می‌آید.
* هیچ راه‌حل فرم بسته‌ای برای مسئله بهینه‌سازی آن وجود ندارد.
* اما تابع هزینه آن محدب است و می‌توان با استفاده از گرادیان صعودی (یا گرادیان کاهشی بر روی منفی تابع هزینه) به یکینه‌ی سراسری دست یافت.

### دیدگاه احتمالی در طبقه‌بندی

در یک مسئله طبقه‌بندی:
* هر ویژگی یک متغیر تصادفی است (مثلاً قد یک فرد).
* برچسب کلاس نیز یک متغیر تصادفی در نظر گرفته می‌شود (مثلاً یک فرد می‌تواند چاق یا غیر چاق باشد).
* ما مقادیر ویژگی‌ها را برای یک نمونه تصادفی مشاهده می‌کنیم و قصد داریم برچسب کلاس آن را پیدا کنیم.
* **شواهد**: بردار ویژگی $x$.
* **هدف**: برچسب کلاس.

**تعاریف**:
* **احتمال پسین (Posterior probability)**: احتمال یک برچسب کلاس $C_k$ به شرط یک نمونه $x$ است.
    $P(C_k|x)$
* **درستنمایی (Likelihood)** یا **احتمال شرطی کلاس (class conditional probability)**: تابع چگالی احتمال (PDF) بردار ویژگی $x$ برای نمونه‌های کلاس $C_k$ است.
    $P(x|C_k)$
* **احتمال پیشین (Prior probability)**: احتمال اینکه برچسب $C_k$ باشد.
    $P(C_k)$
* $P(x)$: تابع چگالی احتمال بردار ویژگی $x$.
    از قضیه احتمال کل (total probability theorem) داریم:
    $P(x)=\sum_{k=1}^{K}P(x|C_{k})P(C_{k})$

### طبقه‌بندهای احتمالی

رویکردهای احتمالی را می‌توان به دو دسته اصلی تقسیم کرد:
* **مدل‌های مولد (Generative Models)**:
    * تابع چگالی احتمال مشترک $P(x,C_k)$ را برای هر کلاس $C_k$ تخمین می‌زنند و سپس از آن برای یافتن $P(C_k|x)$ استفاده می‌کنند.
    * یا به طور متناوب، هر دو تابع چگالی احتمال $P(x|C_k)$ و $P(C_k)$ را برای یافتن $P(C_k|x)$ تخمین می‌زنند.
    * این مدل‌ها می‌توانند برای تولید جفت‌های $(x,y)$ محتمل نیز استفاده شوند.
    * مراحل:
        1.  **استنتاج (Inference)**: چگالی‌های شرطی کلاس $P(x|C_k)$ و پیشین‌ها $P(C_k)$ را تعیین کنید. سپس از قضیه بیز برای یافتن $P(C_k|x)$ استفاده کنید.
        2.  **تصمیم‌گیری (Decision)**: برای ورودی جدید، انتساب بهینه را انجام دهید (پس از یادگیری مدل در مرحله استنتاج). اگر $P(C_i|x)>P(C_j|x)\forall j\ne i$ باشد، کلاس $C_i$ را انتخاب کنید.

* **مدل‌های تمییزدهنده (Discriminative Models)**:
    * مستقیماً احتمال شرطی $P(C_k|x)$ را برای کلاس $C_k$ تخمین می‌زنند.
    * این مدل‌ها توزیع $P(y|x)$ را که توزیع طبیعی برای طبقه‌بندی یک نمونه $x$ به کلاس $y$ است، مدل می‌کنند.
    * رگرسیون لجستیک یک رویکرد تمییزدهنده است. ما مستقیماً می‌خواهیم برچسب کلاس را با $\sigma(w^T x)$ مشخص کنیم.
    * مراحل:
        1.  **استنتاج (Inference)**: احتمالات پسین کلاس $P(C_k|x)$ را مستقیماً تعیین کنید.
        2.  **تصمیم‌گیری (Decision)**: برای ورودی جدید، انتساب بهینه را انجام دهید (پس از یادگیری مدل در مرحله استنتاج). اگر $P(C_i|x)>P(C_j|x)\forall j\ne i$ باشد، کلاس $C_i$ را انتخاب کنید.

این خلاصه بر اساس اسلایدها و توضیحات ارائه شده در ویدیو تهیه شده است.
