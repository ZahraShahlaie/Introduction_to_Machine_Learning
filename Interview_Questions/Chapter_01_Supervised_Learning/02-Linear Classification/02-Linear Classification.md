---

## ✅ سوالات مصاحبه‌ای مهم از مبحث «طبقه‌بندی خطی» + پاسخ‌های مفهومی

---

### طبقه‌بندی و رگرسیون

**۱. تفاوت اساسی میان مسائل طبقه‌بندی (Classification) و رگرسیون (Regression) چیست؟ مثالی از هر کدام در دنیای واقعی ارائه دهید.**

تفاوت اصلی در نوع خروجی پیش‌بینی شده است:

* **رگرسیون:** خروجی یک مقدار پیوسته (real number) است.
    مثال: پیش‌بینی قیمت خانه، روند بازار سهام.
* **طبقه‌بندی:** خروجی یک برچسب گسسته (Binary یا Multi-class) است.
    مثال: تشخیص ایمیل اسپم، امتیازدهی اعتباری، پیش‌بینی ریزش مشتری.

---

**۲. در تعریف "Introduction to Classification"، منظور از "Training Set" به عنوان "A dataset D with N labeled instances" چیست؟ چرا "labeled instances" اهمیت دارند؟**

* **Training Set (مجموعه آموزشی):** مجموعه داده‌ای است به نام $D$ که شامل $N$ نمونه (instances) است. هر نمونه به صورت جفت $(x^{(i)}, y^{(i)})$ تعریف می‌شود که:
    * $x^{(i)}$ بردار ویژگی‌های نمونه $i$-ام است.
    * $y^{(i)}$ برچسب یا کلاس صحیح نمونه $i$-ام است.
* **اهمیت "Labeled Instances":** وجود برچسب‌ها حیاتی است چون مدل‌های طبقه‌بندی تحت یادگیری نظارت‌شده (Supervised Learning) آموزش می‌بینند. این برچسب‌ها به مدل امکان یادگیری رابطه میان ورودی‌ها و کلاس‌ها را می‌دهند و به آن کمک می‌کنند برای داده‌های جدید بدون برچسب پیش‌بینی انجام دهد.

---

### توابع تشخیص و مرز تصمیم

**۳. منظور از Discriminant Function چیست و چگونه در طبقه‌بندی استفاده می‌شود؟**

تابع تشخیص (Discriminant Function) یک تابع ریاضی است که به هر ورودی $x$ یک نمره $g(x)$ اختصاص می‌دهد. این نمره مشخص می‌کند $x$ به کدام کلاس تعلق دارد. در مسائل دودسته‌ای، اگر $g(x) \geq 0$ باشد کلاس اول و اگر $< 0$ باشد کلاس دوم را پیش‌بینی می‌کنیم. در حالت چندکلاسه، کلاس با بیشترین مقدار $g_i(x)$ انتخاب می‌شود.

---

**۴. در مبحث توابع تشخیص (Discriminant Functions)، "degree of confidence" به چه معناست؟ آیا این مفهوم به احتمال (probability) شباهت دارد؟**


**Degree of Confidence:** مقدار $g(x)$ است که مدل به ورودی $x$ تخصیص می‌دهد، نمایانگر میزان اطمینان مدل از تعلق $x$ به یک کلاس خاص است. مقدار بزرگ‌تر یعنی اطمینان بیشتر.

 **شباهت به احتمال:** تا حدی مشابه است اما تفاوت دارد. توابع تشخیص لزوماً مقادیر در بازه $[0,1]$ نمی‌دهند و می‌توانند هر عدد حقیقی باشند، در حالی که احتمال‌ها همواره بین ۰ و ۱ هستند. مدل‌هایی مانند رگرسیون لجستیک با استفاده از تابع سیگموید خروجی را به احتمال نگاشت می‌کنند.

---

**۵. در توابع تشخیص دودویی می‌توان به جای دو تابع $g_1(x)$ و $g_2(x)$ تنها از یک تابع $g(x)$ استفاده کرد و مرز تصمیم را با $g(x)=0$ تعریف کرد. چرا؟**

در طبقه‌بندی دودویی، می‌توان $g_1(x) = g(x)$ و $g_2(x) = -g(x)$ در نظر گرفت.
اگر $g_1(x) > g_2(x)$، آنگاه $g(x) > 0$ است و نمونه به کلاس اول اختصاص می‌یابد.
اگر $g_2(x) > g_1(x)$، آنگاه $g(x) < 0$ است و نمونه به کلاس دوم تعلق دارد.
بنابراین مرز تصمیم زمانی است که $g_1(x) = g_2(x)$ یعنی $g(x) = 0$.
این ساده‌سازی باعث می‌شود تنها لازم باشد یک تابع را بررسی کنیم و علامت آن را برای طبقه‌بندی استفاده کنیم.

---

**۶. مرز تصمیم (Decision Boundary) چیست؟ آیا یک طبقه‌بندی‌کننده خطی همیشه مرز تصمیم خطی ایجاد می‌کند؟ چگونه مرزهای غیرخطی بسازیم؟**

* مرز تصمیم: هایپرپلینی که کلاس‌ها را در فضای ویژگی‌ها جدا می‌کند.
* طبقه‌بندی‌کننده خطی معمولاً مرز تصمیم خطی دارد.
* برای مرزهای غیرخطی، ویژگی‌ها را به فضای بالاتری تبدیل می‌کنیم (**Feature Transformation**)؛
    مثال: افزودن $x_1^2$ و $x_2^2$ به بردار ویژگی‌ها مرزی غیرخطی در فضای اصلی ایجاد می‌کند.

---

### طبقه‌بندی خطی (Linear Classification)

**۷. در بخش "Linear Classifiers" به "Linearly separable data" اشاره شده است. این اصطلاح به چه معناست و چرا برای طبقه‌بندی‌کننده‌های خطی (مانند پرسپترون) اهمیت دارد؟**

"Linearly separable data" یعنی مجموعه‌ای از داده‌ها که می‌توان دقیقاً با یک مرز خطی (خط در دو بعد، صفحه در سه بعد، یا هایپرپلین در ابعاد بالاتر) آن‌ها را از هم جدا کرد.
اهمیت آن برای طبقه‌بندی‌کننده‌های خطی مثل پرسپترون این است که این مدل‌ها فقط می‌توانند چنین مرزهای خطی را یاد بگیرند. اگر داده‌ها خطی جداسازی‌پذیر نباشند، پرسپترون ساده نمی‌تواند همگرا شود و طبقه‌بندی دقیقی ارائه دهد.

---

**۸. چه شرایطی برای استفاده از یک Linear Classifier لازم است؟**

برای استفاده موفق از طبقه‌بند خطی، داده‌ها باید **به‌صورت خطی قابل تفکیک (linearly separable)** باشند؛ یعنی با یک خط (در فضای دو بعدی) یا هایپرپلین (در فضای چندبعدی) بتوان داده‌ها را از هم جدا کرد. اگر داده‌ها همپوشانی پیچیده یا غیرخطی داشته باشند، مدل خطی دقت مناسبی نخواهد داشت.

---

**۹. در طبقه‌بندی‌کننده‌های خطی، چرا "سادگی (Simplicity)"، "کارایی (Efficiency)" و "اثربخشی (Effectiveness)" به عنوان دلایل محبوبیت آن‌ها ذکر شده‌اند؟**

* **سادگی:** فرم ریاضی ساده و فهم آسان (مانند $w^T x + w_0$) و پیاده‌سازی آسان.
* **کارایی:** آموزش و پیش‌بینی سریع و کم‌هزینه محاسباتی، حتی برای داده‌های بزرگ.
* **اثربخشی:** در بسیاری مسائل، به‌خصوص داده‌های خطی جداسازی‌پذیر یا قابل تبدیل به خطی، عملکرد خوبی دارند و بهینه عمل می‌کنند.

---

**۱۰. چرا Linear Classifiers هنوز هم در صنعت کاربرد دارند با وجود شبکه‌های عصبی پیشرفته؟**

مدل‌های طبقه‌بند خطی، مثل Logistic Regression و Perceptron، بسیار **ساده، سریع و قابل تفسیر** هستند. در بسیاری از کاربردها مثل تشخیص اسپم، طبقه‌بندی سریع و سبک‌وزن نیاز است. مدل‌های خطی با **داده‌های زیاد اما ساده** بسیار خوب کار می‌کنند، به‌خصوص زمانی که محاسبه‌پذیری و سرعت مهم است. همچنین در بسیاری از صنایع (مثلاً پزشکی) نیاز به **شفافیت مدل** وجود دارد که در شبکه‌های عصبی فراهم نیست.

---

**۱۱. آیا یک Linear Classifier می‌تواند مرز تصمیم غیرخطی یاد بگیرد؟ چگونه؟**

خود مدل خطی ذاتاً نمی‌تواند مرز غیرخطی بسازد، اما با **تبدیل ویژگی‌ها** (Feature Transformation) یا **نگاشت به فضای با بعد بالاتر** می‌توان این محدودیت را دور زد. مثلاً با استفاده از ویژگی‌های جدید مانند $x^2$ یا $x_1 \cdot x_2$، فضای داده تغییر می‌کند و در فضای جدید، مرز تصمیم خطی خواهد بود که معادل مرز غیرخطی در فضای اولیه است. این رویکرد در Kernel Methods هم استفاده می‌شود.

---

**۱۲. چگونه می‌توان مدل‌های خطی را روی داده‌های غیرخطی استفاده کرد بدون تغییر الگوریتم اصلی؟**

با استفاده از **feature transformation**، یعنی اضافه کردن ویژگی‌های غیرخطی (مثل $x^2$، $x_1 x_2$) به ورودی‌ها. این کار، فضای داده را به شکلی تغییر می‌دهد که در آن، مرز تصمیم خطی شود. نکته مهم این است که الگوریتم همچنان خطی باقی می‌ماند ولی در فضای جدید کار می‌کند. این ایده، اساس کار kernel methods نیز هست.

---

**۱۳. چه زمانی باید از مدل خطی به سراغ مدل‌های غیرخطی برویم؟**

اگر:

* مدل خطی روی train و test هر دو عملکرد ضعیفی دارد (underfitting)
* داده‌ها دارای ساختارهای غیرخطی آشکار هستند (مثلاً توزیع دایره‌ای)
* تصمیم‌ها به‌وضوح با خط قابل جداسازی نیستند
در این شرایط، باید به سراغ مدل‌هایی با توانایی غیرخطی مثل kernel-SVM، MLP یا decision tree رفت.

---

### پرسپترون (Perceptron)

**۱۴. پرسپترون (Perceptron) چیست و اجزای اصلی آن کدامند؟ چگونه تصمیم دودویی می‌گیرد؟**

  پرسپترون: ساده‌ترین نورون مصنوعی، طبقه‌بندی‌کننده خطی.
  
  اجزا: ورودی‌ها $x_1, x_2, \ldots$، وزن‌ها، بایاس، و تابع فعال‌سازی (معمولاً تابع پله‌ای).

  تصمیم دودویی:



  

  $$ y = f(w^T x + w_0) $$

  اگر خروجی بزرگ‌تر از آستانه باشد، 1؛ در غیر این صورت 0.

---

**۱۵. در فرم ریاضی یک نورون منفرد $y = f(w^T x + w_0)$، نقش تابع فعال‌سازی $f$ چیست و چه نوع توابعی می‌توانند به عنوان $f$ استفاده شوند؟**

* **نقش تابع فعال‌سازی $f$:** تبدیل خروجی خطی $w^T x + w_0$ به خروجی نهایی نورون و معرفی غیرخطی‌بودن به مدل.
* **انواع توابع:**
    * تابع پله‌ای (Step function): خروجی ۰ یا ۱/−۱ بر اساس آستانه، مانند پرسپترون اولیه.
    * تابع سیگموید (Sigmoid): خروجی بین ۰ و ۱، در رگرسیون لجستیک.
    * توابع دیگر: ReLU، Tanh و ... در شبکه‌های عصبی مدرن.

---

**۱۶. آیا می‌توان تابع تصمیم را بدون تابع Activation استفاده کرد؟**

در مدل‌هایی مثل پرسپترون یا Logistic Regression، تابع تصمیم (مثل $w^T x + w_0$) فقط یک نمره خطی می‌دهد. برای اینکه این نمره به کلاس تبدیل شود، نیاز به **تابع Activation یا آستانه (threshold)** داریم، مثلاً:

* برای پرسپترون: تابع step یا sign
* برای Logistic: تابع sigmoid
  بدون این تابع، خروجی مدل یک عدد خام است که قابل تفسیر برای طبقه‌بندی نیست.

---

**۱۷. بردار نرمال $w$ و بایاس $w_0$ در تعیین مرز تصمیم چه تاثیری دارند؟**

* **بردار نرمال $w$:** جهت (Orientation) مرز تصمیم را تعیین می‌کند. این بردار عمود بر هایپرپلین مرز تصمیم است و جهت "شیب" آن را مشخص می‌کند.
* **بایاس $w_0$:** مکان (Location) مرز تصمیم را کنترل می‌کند. بدون bias، همه مرزهای تصمیم از مبدأ عبور می‌کنند، که محدودیت بزرگی است. Bias اجازه می‌دهد مرز تصمیم **در موقعیت دلخواه در فضا قرار گیرد**، نه فقط از مرکز مختصات. این پارامتر نقش مهمی در انعطاف‌پذیری مدل دارد.

---

**۱۸. آیا استفاده از تابع خطی بدون bias کافی است؟ چرا نه؟**

خیر. اگر bias را حذف کنیم، مرز تصمیم مدل **همیشه از مبدأ عبور خواهد کرد**. این محدودیت شدیدی در توانایی مدل ایجاد می‌کند، زیرا بسیاری از مسائل دنیای واقعی به چنین شرطی پایبند نیستند. وجود bias به مدل اجازه می‌دهد مرز تصمیم را **در هر جای فضای ویژگی‌ها قرار دهد**، و نه فقط از مبدا.

---

**۱۹. چرا پرسپترون نمی‌تواند مسأله XOR را حل کند؟**

مدل پرسپترون تنها قادر به یادگیری توابعی است که داده‌ها را به‌صورت خطی جدا می‌کنند. در مسأله XOR، هیچ خط مستقیمی نمی‌تواند داده‌های کلاس ۰ و ۱ را از هم جدا کند؛ بنابراین پرسپترون با یک لایه (single-layer) نمی‌تواند این مسأله را یاد بگیرد. برای حل این مشکل، نیاز به **پرسپترون چندلایه (MLP)** داریم.

---

**۲۰. چرا یک پرسپترون منفرد قادر به حل مسئله XOR نیست؟ چگونه می‌توان این محدودیت را برطرف کرد؟**

مسئله XOR خطی جداسازی‌پذیر نیست؛ پرسپترون منفرد فقط مرزهای خطی می‌تواند بسازد.
رفع محدودیت: استفاده از پرسپترون چندلایه (MLP) که چندین لایه نورونی دارد و قادر به یادگیری مرزهای غیرخطی است.

---

**۲۱. تفاوت بین Batch Perceptron و Single-Sample (Stochastic) Perceptron چیست؟**

در **Batch Perceptron**، وزن‌ها با استفاده از مجموع تمام نمونه‌های اشتباه در هر تکرار به‌روزرسانی می‌شوند. اما در **Single-Sample (SGD)**، بعد از مشاهده هر نمونه اشتباه، وزن‌ها بلافاصله آپدیت می‌شوند. نسخه SGD سریع‌تر و محاسباتی سبک‌تر است، به‌خصوص در داده‌های بزرگ. اما ممکن است نوسان بیشتری در همگرایی داشته باشد.

---

**۲۲. الگوریتم پرسپترون چگونه وزن‌ها را به‌روزرسانی می‌کند؟ قاعده به‌روزرسانی برای یک نمونه اشتباه طبقه‌بندی شده چیست؟**

برای یک نمونه اشتباه طبقه‌بندی شده $x^{(i)}$ با برچسب واقعی $y^{(i)}$، وزن‌ها به صورت زیر به‌روزرسانی می‌شوند:

$$w \leftarrow w + \eta y^{(i)} x^{(i)}$$

که در آن:

* $w$ بردار وزن‌ها
* $\eta$ نرخ یادگیری
* $y^{(i)}$ برچسب واقعی (+1 یا -1)
* $x^{(i)}$ بردار ویژگی‌ها
این به‌روزرسانی وزن‌ها را به سمتی هدایت می‌کند که امتیاز نمونه درست افزایش و امتیاز اشتباه کاهش یابد.

---

**۲۳. الگوریتم پرسپترون تک‌نمونه (Single-sample Perceptron) چگونه با Stochastic Gradient Descent (SGD) مرتبط است؟ مزیت اصلی SGD نسبت به Batch Gradient Descent چیست؟**

* **ارتباط با SGD:** پرسپترون تک‌نمونه به‌روزرسانی وزن‌ها را بعد از هر نمونه انجام می‌دهد که مشابه قاعده گرادیان تصادفی (SGD) است.
* **مزیت اصلی SGD:**
    * هزینه محاسباتی کمتر در هر تکرار (محاسبه گرادیان روی یک نمونه به جای کل داده).
    * همگرایی سریع‌تر به ویژه در داده‌های بزرگ، گرچه مسیر همگرایی ممکن است نوسانی‌تر باشد اما معمولاً سریع‌تر به منطقه بهینه می‌رسد.

---

**۲۴. الگوریتم پرسپترون تحت چه شرایطی همگرا می‌شود و چه زمانی نمی‌شود؟ راه‌حل عدم همگرایی چیست؟**

* **همگرایی:**
    اگر داده‌ها خطی جداسازی‌پذیر باشند، پرسپترون (دسته‌ای و تک‌نمونه) در تعداد مراحل محدود همگرا می‌شود.
* **عدم همگرایی:**
    اگر داده‌ها خطی جداسازی‌پذیر نباشند (مثلاً به دلیل نویز)، الگوریتم هیچگاه به راه‌حل پایدار نمی‌رسد و دائما وزن‌ها را تغییر می‌دهد.
* **راه‌حل:**
    الگوریتم **Pocket** که بهترین بردار وزن تا آن لحظه با کمترین خطا را ذخیره می‌کند و حتی در عدم همگرایی، بهترین وزن موجود را نگه می‌دارد.

---

**۲۵. چه مشکلی برای الگوریتم پرسپترون پیش می‌آید اگر داده‌ها قابل تفکیک نباشند؟**

در صورتی که داده‌ها به‌صورت خطی قابل تفکیک نباشند (مثلاً داده‌ها نویز داشته باشند)، الگوریتم پرسپترون هیچ‌وقت متوقف نمی‌شود و به همگرایی نمی‌رسد. چون همیشه نقاطی وجود دارد که اشتباه طبقه‌بندی شده‌اند و الگوریتم مدام سعی در اصلاح آن‌ها دارد. راه‌حل این مشکل استفاده از **الگوریتم Pocket** است که بهترین وزن دیده‌شده تا آن لحظه را حفظ می‌کند.

---

**۲۶. الگوریتم Pocket Algorithm چه زمانی استفاده می‌شود و چگونه مشکل عدم همگرایی پرسپترون را حل می‌کند؟**

* **زمان استفاده:** وقتی داده‌ها خطی جداسازی‌پذیر نیستند (مثلاً به دلیل نویز)، پرسپترون معمولی همگرا نمی‌شود.
* **حل مشکل:** الگوریتم Pocket بهترین وزن $w_{best}$ را که تاکنون کمترین خطا را داشته نگه می‌دارد و پس از هر به‌روزرسانی وزن‌ها، اگر وزن جدید عملکرد بهتری داشته باشد $w_{best}$ به‌روزرسانی می‌شود.
  این باعث می‌شود حتی در عدم همگرایی، بهترین راه‌حل مشاهده شده ذخیره و ارائه شود.

---

**۲۷. در چه شرایطی استفاده از الگوریتم Perceptron مناسب نیست؟**

زمانی که داده‌ها **قابل جداسازی خطی نباشند**، یعنی نتوان یک مرز تصمیم مستقیم بین کلاس‌ها ترسیم کرد، الگوریتم پرسپترون کارایی خود را از دست می‌دهد. همچنین پرسپترون به نویز حساس است و اگر داده‌ها دارای خطا یا outlier باشند، ممکن است **هیچ‌گاه همگرا نشود**. برای چنین مواردی، الگوریتم‌هایی مانند **SVM، Logistic Regression یا MLP** بهتر هستند.

---

**۲۸. اگر داده‌های شما noise زیادی داشته باشند، از چه مدلی استفاده می‌کنید؟ چرا؟**

مدل‌هایی مثل **Logistic Regression** یا **SVM با soft margin** برای داده نویزی مناسب‌تر از پرسپترون هستند. چون این مدل‌ها سعی می‌کنند خط تصمیمی پیدا کنند که تا حد امکان فاصله از مرز را حفظ کند، نه اینکه فقط درست/غلط را در نظر بگیرند. همچنین الگوریتم Pocket برای پرسپترون یک گزینه قابل قبول در محیط‌های نویزی است.

---

**۲۹. در چه مواقعی الگوریتم Pocket بهتر از پرسپترون معمولی عمل می‌کند؟**

الگوریتم Pocket برای داده‌هایی مناسب است که:

* **نویز دارند**
* **قابل تفکیک خطی نیستند**
  در این حالت، پرسپترون معمولی هیچ‌گاه همگرا نمی‌شود و دائم وزن‌ها را تغییر می‌دهد. اما Pocket بهترین وزن دیده‌شده تا آن لحظه را ذخیره می‌کند و در نهایت آن را بازمی‌گرداند. این باعث **پایداری و عملکرد بهتر** می‌شود.

---

### توابع هزینه (Cost Functions)

**۳۰. تابع هزینه‌ای که پرسپترون استفاده می‌کند چیست و چه ویژگی‌ای دارد؟**

تابع هزینه‌ی پرسپترون فقط روی نقاطی که اشتباه طبقه‌بندی شده‌اند تمرکز دارد:

$$J(w) = - \sum_{i \in M} y^{(i)} w^T x^{(i)}$$

در اینجا M مجموعه نقاط اشتباه است. این تابع، اگر نمونه‌ای به درستی طبقه‌بندی شود، تأثیری روی هزینه ندارد. هدف کاهش مجموع پیش‌بینی‌های اشتباه است. این ویژگی باعث سادگی و تمرکز مدل روی خطاها می‌شود.

---

**۳۱. در بخش "Cost Functions" اشاره شده که "Finding discriminant functions $(w^T, w_0)$ is framed as minimizing a cost function". چرا کمینه‌سازی تابع هزینه برای یافتن توابع تشخیص اهمیت دارد؟**

* **هدف مدل یادگیری ماشین:** یافتن پارامترهایی ($w$ و $w_0$) است که پیش‌بینی مدل را به برچسب‌های واقعی نزدیک‌تر کند.
* **نقش تابع هزینه:** تابع هزینه معیاری است برای اندازه‌گیری میزان اختلاف پیش‌بینی‌های مدل با برچسب‌های واقعی. هر چه این اختلاف کمتر باشد، عملکرد مدل بهتر است.
* **کمینه‌سازی:** با کمینه کردن تابع هزینه، پارامترهای مدل به نحوی تنظیم می‌شوند که خطا و اختلاف میان پیش‌بینی و واقعیت حداقل شود، در نتیجه توابع تشخیص بهینه و دقیق‌تری یاد گرفته می‌شوند.

---

**۳۲. چرا تابع هزینه "تعداد نمونه‌های اشتباه" مناسب برای یادگیری نیست؟**

تابع شمارش نمونه‌های اشتباه (Misclassification Count) یک تابع **قطعه‌ای و غیرمشتق‌پذیر** است. به همین دلیل نمی‌توان از روش‌هایی مثل Gradient Descent برای یادگیری استفاده کرد. مدل‌هایی مثل SVM یا Logistic، از توابع هزینه‌ای استفاده می‌کنند که **مشتق‌پذیر و نرم** هستند، مثل hinge loss یا log loss. این توابع اجازه می‌دهند الگوریتم‌های یادگیری مؤثرتر و قابل همگراتر طراحی شوند.

---

**۳۳. چرا استفاده از Sum of Squared Error (SSE) برای Classification ایده‌آل نیست؟**

در SSE خطاهای عددی بین خروجی واقعی و پیش‌بینی شده به‌صورت مربعی محاسبه می‌شوند. اما در Classification، خروجی‌ها فقط برچسب کلاس هستند، نه مقادیر عددی. بنابراین SSE ممکن است حتی برای پیش‌بینی‌های درست، ولی با مقادیر نزدیک (مثلاً 0.9 به جای 1)، خطا در نظر بگیرد. این باعث گمراهی الگوریتم یادگیری می‌شود.

---

**۳۴. چرا تابع هزینه مجموع مربعات خطا (SSE) برای مسائل طبقه‌بندی نامناسب است؟ چه جایگزین‌هایی برای آن پیشنهاد می‌شود؟**

 **نامناسب بودن SSE:**

   SSE بزرگی خطا را کمینه می‌کند که برای رگرسیون مناسب است، اما برای طبقه‌بندی که خروجی برچسب گسسته است، نامربوط است.
   اگر پیش‌بینی مدل نزدیک به کلاس واقعی باشد ولی دقیقاً 0 یا 1 نباشد، SSE خطای مثبت نشان می‌دهد حتی برای پیش‌بینی‌های درست.
   SSE مستعد بیش‌برازش داده‌های نویزی است.

  **جایگزین‌ها:**

   **تعداد اشتباه طبقه‌بندی شده:** تعداد نمونه‌هایی که مدل اشتباه طبقه‌بندی کرده است. ولی این تابع غیرقابل مشتق (non-differentiable) است و بهینه‌سازی با گرادیان مستقیم سخت است.

   **معیار پرسپترون:**

  $$J_p(w) = - \sum_{i \in M} y^{(i)} w^T x^{(i)}$$

   که $M$ مجموعه نقاط اشتباه است. این تابع قابل مشتق‌گیری بوده و برای بهینه‌سازی پرسپترون استفاده می‌شود.


---

**۳۵. در مورد Perceptron Algorithm، چرا بهینه کردن $J_p(w) = - \sum_{i \in M} y^{(i)} w^T x^{(i)}$ که فقط شامل نقاط اشتباه طبقه‌بندی شده است، منجر به یافتن یک مرز جداسازی می‌شود؟**

* تابع هزینه فقط روی نقاط اشتباه طبقه‌بندی شده تمرکز دارد و تلاش می‌کند مقدار $y^{(i)} w^T x^{(i)}$ را برای آن‌ها مثبت کند.
* اگر نمونه با برچسب +1 اشتباه طبقه‌بندی شده باشد (یعنی $w^T x^{(i)} \leq 0$)، الگوریتم سعی می‌کند $w^T x^{(i)}$ را افزایش دهد.
* اگر نمونه با برچسب −1 اشتباه طبقه‌بندی شده باشد (یعنی $w^T x^{(i)} \geq 0$)، الگوریتم سعی می‌کند $w^T x^{(i)}$ را کاهش دهد.
* با تکرار این روند، وزن‌ها به سمتی تنظیم می‌شوند که هیچ نمونه اشتباهی باقی نماند؛ در این حالت $J_p(w) = 0$ و الگوریتم همگرا می‌شود و مرز جداسازی پیدا می‌شود.

---

**۳۶. تفاوت hinge loss در SVM با خطای پرسپترون چیست؟**

در پرسپترون فقط نمونه‌هایی که **اشتباه طبقه‌بندی شده‌اند** در تابع هزینه وارد می‌شوند. ولی hinge loss حتی به نمونه‌هایی که درست طبقه‌بندی شده‌اند ولی با «فاصله کم» از مرز تصمیم هستند نیز جریمه می‌دهد. بنابراین hinge loss **سخت‌گیرتر و دقیق‌تر** است و کمک می‌کند SVM، مرز تصمیم بهینه‌تری بیاموزد.

---

### طبقه‌بندی چندکلاسه (Multi-Class Classification)

**۳۷. در طبقه‌بندی چندکلاسه، تفاوت بین روش One-vs-Rest و One-vs-One چیست؟**

در **One-vs-Rest (OvR)**، برای هر کلاس یک مدل ساخته می‌شود که آن کلاس را در برابر همه کلاس‌های دیگر قرار می‌دهد. مثلاً برای ۳ کلاس، ۳ مدل ساخته می‌شود. در **One-vs-One (OvO)**، برای هر زوج کلاس، یک مدل ساخته می‌شود. بنابراین برای K کلاس، $K(K−1)/2$ مدل ساخته می‌شود. OvR ساده‌تر است ولی ممکن است ابهام بیشتری داشته باشد. OvO دقت بالاتری دارد ولی محاسباتی سنگین‌تر است.

---

**۳۸. روش‌های اصلی حل مسائل طبقه‌بندی چندکلاسه چیست؟**

 **گسترش مستقیم الگوریتم:**
* 
    برای هر کلاس $C_i$، یک تابع تشخیص $g_i(x)$ تعریف شده و کلاس پیش‌بینی شده $\hat{y} = \arg\max_i g_i(x)$ است.
  
 **تبدیل به مسائل دودویی:**

   **One-vs-Rest (OvR) / One-vs-All (OvA):** هر طبقه‌بندی‌کننده، یک کلاس را مقابل همه کلاس‌های دیگر قرار می‌دهد.

   **One-vs-One (OvO):** طبقه‌بندی‌کننده‌هایی برای هر جفت کلاس ساخته می‌شوند.
    * این روش‌ها ممکن است منجر به مناطق مبهم در تصمیم‌گیری شوند.

---
**۳۹. الگوریتم پرسپترون چندکلاسه (Multi-Class Perceptron Algorithm) چگونه وزن‌های خود را به‌روزرسانی می‌کند تا یک نمونه اشتباه طبقه‌بندی شده را تصحیح کند؟**

در الگوریتم پرسپترون چندکلاسه، زمانی که یک نمونه $x^{(i)}$ اشتباه طبقه‌بندی می‌شود (یعنی کلاس واقعی $y^{(i)}$ با کلاس پیش‌بینی شده $\hat{y}^{(i)}$ متفاوت است)، وزن‌های مدل (ماتریس $W$) به صورت زیر به‌روزرسانی می‌شوند:


**کاهش وزن کلاس اشتباه پیش‌بینی شده:** بردار وزن مربوط به کلاسی که به اشتباه پیش‌بینی شده ($\hat{y}^{(i)}$) از ویژگی‌های نمونه کم می‌شود:

  $$w_{\hat{y}^{(i)}} \leftarrow w_{\hat{y}^{(i)}} - \eta x^{(i)}$$

**افزایش وزن کلاس واقعی:** بردار وزن مربوط به کلاس واقعی نمونه ($y^{(i)}$) به ویژگی‌های نمونه اضافه می‌شود:

  $$w_{y^{(i)}} \leftarrow w_{y^{(i)}} + \eta x^{(i)}$$

این به‌روزرسانی‌ها به مدل کمک می‌کنند تا در تکرارهای بعدی، امتیاز کلاس واقعی را برای آن نمونه افزایش و امتیاز کلاس اشتباه را کاهش دهد.


---

**۴۰. در طبقه‌بندی چندکلاسه، روش‌های One-vs-Rest (OvR) و One-vs-One (OvO) چه چالش‌هایی از نظر مناطق طبقه‌بندی مبهم (ambiguous regions) می‌توانند ایجاد کنند؟**

هر دو روش OvR و OvO می‌توانند منجر به
مناطق طبقه‌بندی مبهم (ambiguous regions)
شوند که در آن‌ها طبقه‌بندی نهایی نمونه‌های جدید نامشخص یا غیرقابل تعریف است.

* OvR: در این روش، برای هر کلاس یک طبقه‌بندی‌کننده دودویی آموزش داده می‌شود (مثلاً کلاس A در مقابل غیر-A). ممکن است نمونه‌ای در ناحیه‌ای قرار گیرد که توسط هیچ طبقه‌بندی‌کننده‌ای به عنوان "کلاس خودش" پیش‌بینی نشود (یعنی همه پیش‌بینی کنند "غیر-X")، یا برعکس، توسط چندین طبقه‌بندی‌کننده به عنوان "کلاس خودش" پیش‌بینی شود. این همپوشانی‌ها یا شکاف‌ها مناطق مبهم را ایجاد می‌کنند.

* OvO: در OvO، طبقه‌بندی‌کننده‌ها برای هر جفت کلاس آموزش می‌بینند. در این حالت نیز ممکن است یک نمونه جدید در ناحیه‌ای قرار گیرد که چندین طبقه‌بندی‌کننده جفتی نتیجه‌ی "برنده" را برای یک کلاس خاص اعلام کنند، که منجر به تداخل و عدم قطعیت در تصمیم نهایی می‌شود. (نمودار صفحه 45 PDF مناطق مبهم را در هر دو سناریو نشان می‌دهد).

---

**۴۱. مزایا و معایب استفاده از روش One-vs-Rest در چندکلاسه چیست؟**

**مزایا:** ساده و مقیاس‌پذیر برای تعداد زیاد کلاس. الگوریتم‌های موجود را می‌توان بدون تغییر استفاده کرد.
**معایب:** ممکن است هر مدل معیار متفاوتی برای تصمیم‌گیری داشته باشد و در مرزهای بین کلاس‌ها تعارض ایجاد شود. برای کلاس‌های با داده کمتر یا نامتوازن ممکن است عملکرد ناپایدار باشد.

---

**۴۲. در "Linear Machines" برای طبقه‌بندی چندکلاسه، مناطق تصمیم (decision regions) چه خصوصیاتی دارند؟ این خصوصیات چگونه به دست می‌آیند؟**

در "Linear Machines" برای طبقه‌بندی چندکلاسه (که هر کلاس دارای تابع تشخیص خطی خود است)، مناطق تصمیم دارای خصوصیات زیر هستند:


محدب (Convex): مناطق تصمیم محدب هستند. به این معنی که اگر دو نقطه درون یک منطقه تصمیم‌گیری قرار داشته باشند، تمام نقاط روی خط مستقیم بین آن دو نقطه نیز درون همان منطقه قرار خواهند گرفت. این ویژگی به دلیل ماهیت خطی توابع تشخیص و مرزهای تصمیم‌گیری (که مجموعه‌ای از هایپرپلین‌ها هستند) ایجاد می‌شود.


تک‌اتصالی (Singly Connected): این مناطق معمولاً پیوسته و بدون شکاف یا سوراخ هستند.

این خصوصیات باعث می‌شوند که این نوع طبقه‌بندی‌کننده‌ها برای مجموعه‌های داده‌ای که به طور خطی از هم قابل تفکیک هستند، بسیار کارآمد و قابل پیش‌بینی عمل کنند.

---

### ارزیابی مدل و اعتبارسنجی متقابل (Cross-Validation)

**۴۳. هدف استفاده از Cross-Validation در طبقه‌بندی چیست؟**

Cross-validation برای ارزیابی عملکرد مدل روی داده‌هایی که **در آموزش استفاده نشده‌اند** استفاده می‌شود. این کار باعث می‌شود تخمینی واقع‌بینانه از عملکرد مدل روی داده‌ی واقعی داشته باشیم و از overfitting جلوگیری کنیم. همچنین در تنظیم هایپرپارامترها مثل $\lambda$ در Regularization یا انتخاب مدل کمک می‌کند.

---

**۴۴. اعتبارسنجی متقابل (Cross-Validation) چیست و چرا مهم است؟ روش K-Fold Cross-Validation را توضیح دهید.**

* **تعریف و اهمیت:**
    روش ارزیابی که عملکرد مدل را روی داده‌های دیده‌نشده می‌سنجد و باعث کاهش بیش‌برازش می‌شود.
* **روش K-Fold Cross-Validation:**
    * داده‌ها به $K$ بخش تقسیم می‌شوند.
    * در هر تکرار، مدل با $K-1$ بخش آموزش داده شده و روی بخش باقی‌مانده اعتبارسنجی می‌شود.
    * این روند $K$ بار تکرار شده و هر بار یک بخش به عنوان تست است.
    * میانگین نتایج همه بخش‌ها امتیاز نهایی مدل است.

---

**۴۵. چگونه می‌توان عملکرد طبقه‌بندی را به‌طور واقع‌گرایانه اندازه‌گیری کرد؟**

استفاده از **Cross-validation** به‌خصوص **K-fold** روش مناسبی است. داده به K قسمت تقسیم می‌شود، و در هر مرحله، یک قسمت به عنوان تست در نظر گرفته می‌شود. سپس میانگین امتیازها گرفته می‌شود. این روش مانع Overfitting و Underfitting می‌شود و تخمینی واقع‌بینانه از عملکرد مدل در داده‌های واقعی ارائه می‌دهد.

---

**۴۶. در بخش "Cross-Validation for Choosing Regularization Term"، به پارامتر $\lambda$ در رگولاریزاسیون اشاره شده است. چگونه اعتبارسنجی متقابل به ما در انتخاب مقدار بهینه $\lambda$ کمک می‌کند؟**

اعتبارسنجی متقابل برای انتخاب مقدار بهینه $\lambda$ در رگولاریزاسیون (که میزان پیچیدگی مدل را کنترل می‌کند) به این صورت کمک می‌کند:

* تعریف محدوده $\lambda$: یک مجموعه از مقادیر مختلف برای $\lambda$ (مثلاً از خیلی کوچک تا خیلی بزرگ) انتخاب می‌شود.
* اجرای Cross-Validation: برای هر مقدار $\lambda$، فرآیند K-Fold Cross-Validation روی مجموعه داده انجام می‌شود.
* ارزیابی عملکرد: در هر fold از CV، عملکرد مدل (مثلاً دقت یا خطا) برای آن $\lambda$ خاص بر روی داده‌های اعتبارسنجی ارزیابی می‌شود.
* میانگین‌گیری و انتخاب: میانگین عملکرد (مثلاً میانگین خطا) برای هر مقدار $\lambda$ در تمام K-folds محاسبه می‌شود. مقدار
    $\lambda$
    که منجر به بهترین میانگین عملکرد در داده‌های اعتبارسنجی شود (یعنی بهترین تعادل بین Bias و Variance را فراهم کند و از بیش‌برازش جلوگیری کند)، به عنوان مقدار بهینه انتخاب می‌شود.

---

**۴۷. Leave-One-Out Cross-Validation (LOOCV) چیست؟ مزایا و معایب اصلی آن در مقایسه با K-Fold Cross-Validation کدامند؟**

 LOOCV: نوعی از اعتبارسنجی متقابل است که در آن
    $K$
    برابر با تعداد کل نقاط داده ($N$) در مجموعه داده است. در هر تکرار، یک نقطه داده واحد به عنوان مجموعه اعتبارسنجی و بقیه
    $N-1$
    نقطه به عنوان مجموعه آموزشی استفاده می‌شود. این فرآیند
    $N$
    بار تکرار می‌شود.

 مزایا:
     
عدم اتلاف داده (No Data Wastage): هر نقطه داده هم برای آموزش و هم برای اعتبارسنجی استفاده می‌شود، که در مجموعه‌های داده کوچک مفید است.
    
بایاس پایین (Low Bias): از آنجایی که هر مدل تقریباً بر روی کل مجموعه داده آموزش می‌بیند ($N-1$ نمونه)، برآورد بایاس (Bias) بسیار پایینی از خطای تعمیم‌پذیری دارد.

 معایب:

 هزینه محاسباتی بالا (Computationally Expensive): نیاز به آموزش مدل
        $N$
        بار برای
        $N$
        نقطه داده دارد، که آن را برای مجموعه‌های داده بزرگ بسیار کند می‌کند.

واریانس بالا (High Variance): اگرچه بایاس پایینی دارد، اما به دلیل اینکه هر مجموعه تست فقط شامل یک نمونه است، ارزیابی‌های عملکرد می‌توانند واریانس بالایی داشته باشند.

بهترین برای مجموعه‌های داده کوچک: به دلیل معایب محاسباتی، عمدتاً برای مجموعه‌های داده کوچک توصیه می‌شود.

---

**۴۸. چرا Leave-One-Out Cross-Validation (LOOCV) با وجود مزایای "No Data Wastage" و "Low Bias"، برای مجموعه‌های داده بزرگ توصیه نمی‌شود؟**

* **هزینه محاسباتی بالا:** در LOOCV، مدل باید $N$ بار (تعداد نمونه‌ها) آموزش داده شود که برای مجموعه‌های داده بزرگ این مقدار بسیار زیاد و زمان‌بر است.
* **دلیل:** در هر بار، فقط یک نمونه برای تست و بقیه $N-1$ نمونه برای آموزش استفاده می‌شوند، که تکرار این روند برای همه نمونه‌ها، منابع محاسباتی و زمان زیادی مصرف می‌کند.
* **نتیجه:** LOOCV بیشتر برای داده‌های کوچک کاربردی و مناسب است.

---

**۴۹. اگر مدل خطی شما به‌درستی طبقه‌بندی نمی‌کند ولی train accuracy بالاست، چه مشکلی وجود دارد؟**

احتمال زیاد مدل دچار **overfitting** شده است؛ یعنی بیش از حد روی داده‌های آموزش منطبق شده و روی داده‌های جدید عملکرد ضعیفی دارد. همچنین ممکن است مدل شما روی داده‌هایی با توزیع متفاوت از train آموزش دیده باشد. استفاده از **cross-validation** و بررسی **test error** کلید حل این مشکل است.

---

**۵۰. اگر مدل ما فقط روی یک کلاس خاص دقت خوبی دارد، مشکل کجاست؟**

این پدیده معمولاً به دلیل **عدم تعادل کلاس‌ها (Class Imbalance)** یا **بایاس مدل** است. مثلاً اگر ۹۰٪ داده‌ها از کلاس A باشند، مدل ممکن است همه چیز را A پیش‌بینی کند و باز هم دقت ظاهری بالا داشته باشد. راه‌حل‌ها:

* استفاده از معیارهایی مثل F1-score به جای Accuracy
* بازنمونه‌گیری (Oversampling / Undersampling)
* استفاده از الگوریتم‌هایی که حساس به عدم تعادل هستند

---

**۵۱. چه معیارهایی برای ارزیابی عملکرد طبقه‌بند چندکلاسه استفاده می‌شود؟**

در مسائل چندکلاسه، استفاده از **دقت کلی (Accuracy)** کافی نیست. باید از معیارهای تفکیکی مثل:

* Precision و Recall برای هر کلاس
* F1-score (میانگین هماهنگ Precision و Recall)
* Confusion Matrix برای نمایش جزئیات اشتباه‌ها
  همچنین استفاده از **Macro/Micro Averaging** برای ترکیب امتیازها در چندکلاسه متداول است.

---

**۵۲. چگونه می‌توان از مدل‌های طبقه‌بند خطی به‌عنوان Base Classifier در Ensembleها استفاده کرد؟**

مدل‌های خطی بسیار سریع و سبک هستند، بنابراین به‌خوبی به عنوان اجزای پایه (Base Classifier) در روش‌هایی مثل **Bagging یا Boosting** عمل می‌کنند. مثلاً می‌توان چند Logistic Regression با داده‌های متفاوت آموزش داد و خروجی‌ها را با رأی‌گیری ترکیب کرد. این کار به افزایش دقت و کاهش واریانس مدل نهایی کمک می‌کند.

---

**۵۳. فایل PDF مثال "Pima Indians Diabetes Dataset" را به عنوان یک مثال واقعی از طبقه‌بندی مطرح می‌کند. ویژگی‌های این مجموعه داده (مانند گلوکز، BMI، سن) چگونه به مدل طبقه‌بندی‌کننده خطی کمک می‌کنند؟**

* ویژگی‌های عددی مانند "Glucose"، "BMI"، "Age" و ... ورودی‌های مدل هستند که پس از نرمال‌سازی در ترکیب خطی $w^T x + w_0$ استفاده می‌شوند.
* مدل یاد می‌گیرد به هر ویژگی وزن خاصی تخصیص دهد که نشان‌دهنده اهمیت آن ویژگی برای پیش‌بینی دیابت است (مثلاً گلوکز وزن بالاتری می‌تواند داشته باشد).
* این ترکیب خطی، مرز تصمیم خطی در فضای ویژگی‌ها ایجاد می‌کند تا نمونه‌های مبتلا و غیرمبتلا را از هم جدا کند.
* در صورتی که ویژگی‌ها به خوبی با کلاس‌ها همبستگی داشته باشند، مدل خطی نتایج موثری ارائه خواهد داد.

---
