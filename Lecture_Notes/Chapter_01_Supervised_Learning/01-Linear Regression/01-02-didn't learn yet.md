

### ۱.۱۱. رگولاریزاسیون (Regularization)

#### هدف:

هدف از رگولاریزاسیون جلوگیری از **بیش‌برازش** (overfitting) با جریمه کردن وزن‌های بزرگ است. وقتی وزن‌ها خیلی بزرگ شوند، مدل تمایل دارد تا به جزئیات کوچک و نویز موجود در داده‌های آموزشی توجه کند، که این موجب بیش‌برازش می‌شود.

#### فرمول کلی تابع هزینه با رگولاریزاسیون:

$$
J_{\lambda}(w) = J(w) + \lambda R(w)
$$

* $J(w)$ تابع هزینه اصلی (مثلاً SSE).
* $R(w)$ ترم رگولاریزاسیون (تابع جریمه برای وزن‌ها).
* $\lambda$ (لامبدا) یک هایپرپارامتر است که تعادل بین تطابق مدل با داده‌ها و سادگی مدل را کنترل می‌کند.

#### رایج‌ترین رگولاریزه‌کننده‌ها:

* **L1 norm (Lasso):** جریمه‌ای بر اساس مجموع قدر مطلق وزن‌ها.
* **L2 norm (Ridge):** جریمه‌ای بر اساس مجموع مربعات وزن‌ها.

#### توضیحات اضافه:

رگولاریزاسیون مثل یه "تنبیه" برای مدل عمل می‌کند که اجازه نده وزن‌هاش خیلی بزرگ بشن. وزن‌های بزرگ معمولاً نشانه‌ی این هستن که مدل داره به شدت روی جزئیات کوچک داده‌های آموزشی (حتی نویز) تمرکز می‌کنه و بیش‌برازش اتفاق می‌افته.

---

### ۱.۱۲. تاثیر پارامتر رگولاریزاسیون $\lambda$

#### فرمول با L2 Regularization:

$$
J_{\lambda}(w) = J(w) + \lambda \sum_{j=1}^{m} w_j^2 = J(w) + \lambda w^T w
$$

#### تأثیر $\lambda$ بر پیچیدگی مدل:

* **$\lambda$ بزرگ:** وزن‌ها را مجبور به کوچک‌تر شدن می‌کند، پیچیدگی مدل را کاهش می‌دهد، بایاس را افزایش و واریانس را کاهش می‌دهد (مدل ساده‌تر و کم‌برازش‌تر می‌شود).
* **$\lambda$ کوچک:** به وزن‌ها اجازه می‌دهد بزرگ‌تر شوند، پیچیدگی مدل را افزایش می‌دهد، بایاس را کاهش و واریانس را افزایش می‌دهد (مدل پیچیده‌تر و مستعد بیش‌برازش می‌شود).

#### کنترل پیچیدگی:

پارامتر $\lambda$ به طور مؤثری پیچیدگی مدل را کنترل می‌کند و در نتیجه میزان بیش‌براش را تنظیم می‌کند. با افزایش $\lambda$، مدل ساده‌تر می‌شود و ویژگی‌های پیچیده‌تر کمتر تأثیرگذار خواهند بود.

#### مثال:

جدولی که در صفحه 24 PDF آمده، نشان می‌دهد که با افزایش $\ln \lambda$ (افزایش $\lambda$)، مقادیر وزن‌ها (به خصوص وزن‌های مربوط به ترم‌های با درجه بالاتر) به شدت کاهش می‌یابند و به صفر نزدیک می‌شوند. این یعنی مدل ساده‌تر شده و اثر ویژگی‌های پیچیده کمتر می‌شود.

#### نمودار:

نمودار (صفحه 25 PDF) نشان می‌دهد که با تغییر $\ln \lambda$، خطای آموزش و تست تغییر می‌کنند. معمولاً یک $\lambda$ بهینه وجود دارد که خطای تست را به حداقل می‌رساند.

---

### ۲. رگرسیون احتمالی (Probabilistic Regression)

#### ۲.۱. مقدمه‌ای بر رگرسیون (دیدگاه احتمالی)

**هدف:** مدل‌سازی رابطه بین ورودی $x$ و خروجی $y$.

**عدم قطعیت (Uncertainty):** خروجی $y$ دارای عدم قطعیت است که با یک توزیع احتمالی مدل‌سازی می‌شود. این بدان معناست که پیش‌بینی‌های ما همیشه دقیق نخواهند بود و شامل نویز یا خطای تصادفی هستند.

#### مثال:

$$
y = f(x; w) + \epsilon
$$

که در آن:

* $\epsilon \sim N(0, \sigma^2)$ به این معنی است که نویز $\epsilon$ از توزیع نرمال با میانگین صفر و واریانس $\sigma^2$ پیروی می‌کند.

**هدف نهایی:** یادگیری تابع $f(x; w)$ برای پیش‌بینی $y$.

#### توضیحات اضافه:

در رگرسیون احتمالی، فرض می‌کنیم داده‌های ما دقیق نیستند و همیشه مقداری "نویز" یا خطای تصادفی در اندازه‌گیری‌ها یا فرآیند تولید داده وجود دارد. هدف ما پیدا کردن بهترین تابع $f(x; w)$ است که میانگین رفتار داده‌ها را نشان دهد.

---

### ۲.۲. فیت کردن منحنی با نویز (Curve Fitting with Noise)

**واقعیت:** در سناریوهای واقعی، خروجی مشاهده‌شده $y$ معمولاً دارای نویز است.

**مدل:** خروجی واقعی برابر است با خروجی تابع $f(x; w)$ به علاوه نویز:

$$
y = f(x; w) + \epsilon
$$

**نویز:** نویز نشان‌دهنده عواملی است که در مدل‌سازی لحاظ نشده‌اند یا ناشناخته‌اند.

#### مثال:

پیش‌بینی قیمت خانه بر اساس ویژگی‌ها، که دارای عدم قطعیت ذاتی است.

---

### ۲.۳. مقدار مورد انتظار خروجی (Expected Value of Output)

**بهترین تخمین:** بهترین تخمین برای $y$ با داشتن $x$, امید ریاضی شرطی $y$ به شرط $x$ است:

$$
E[y | x] = f(x; w)
$$

**هدف:** یادگیری تابع $f(x; w)$ که میانگین رفتار داده‌ها را نشان می‌دهد.

**نکته کلیدی:** مدل، میانگین متغیر هدف را با داشتن ورودی $x$ ثبت می‌کند.

---

این بخش‌ها توضیحات جامع‌تری در خصوص رگرسیون احتمالی و رگولاریزاسیون می‌دهند که به شما کمک می‌کنند تا مدل‌های یادگیری ماشین را بهتر درک کنید و از آن‌ها به‌طور مؤثرتر استفاده کنید. اگر نیاز به توضیح یا مثال‌های بیشتری دارید، خوشحال می‌شوم کمک کنم!


### ۲.۴. برآورد بیشینه درست‌نمایی (Maximum Likelihood Estimation - MLE)

#### MLE: روشی برای تخمین پارامترهایی است که احتمال وقوع داده‌ها (likelihood) را به حداکثر می‌رساند.

**هدف:** با داشتن مجموعه داده $Z = \{ (x_i, y_i) \}_{i=1}^n$، MLE حاصل‌ضرب احتمالات را بیشینه می‌کند:

$$
L(Z; w, \sigma^2) = \prod_{i=1}^{n} p(y_i | x_i, w, \sigma^2)
$$

**یافتن پارامترها:** MLE پارامترهای $w$ و $\sigma^2$ را پیدا می‌کند که بهترین توضیح را برای داده‌ها ارائه می‌دهند.

---

### ۲.۵. برآورد بیشینه درست‌نمایی (ادامه)

#### لگاریتم درست‌نمایی:

به جای بیشینه‌سازی درست‌نمایی، اغلب بیشینه‌سازی لگاریتم درست‌نمایی آسان‌تر است:

$$
\log L(Z; w, \sigma^2) = \sum_{i=1}^{n} \log p(y_i | x_i, w, \sigma^2)
$$

**دلیل:** لگاریتم تابع رفتار آن را حفظ می‌کند (یعنی نقاط بیشینه آن‌ها یکسان است) و مشتق‌گیری از مجموع ترم‌ها آسان‌تر است.

---

### ۲.۶. مثال تابع خطی تک‌متغیره (Univariate Linear Function Example)

**فرض نویز گاوسی:** با فرض نویز گاوسی ($\epsilon \sim N(0, \sigma^2)$)، احتمال مشاهده خروجی واقعی $y$ به صورت زیر است:

$$
p(y | x, w, \sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp\left( -\frac{(y - f(x; w))^2}{2 \sigma^2} \right)
$$

برای مدل خطی ساده: اگر $f(x; w) = w_0 + w_1 x$ باشد، داریم:

$$
p(y | x, w, \sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp\left( -\frac{(y - w_0 - w_1 x)^2}{2 \sigma^2} \right)
$$

**مشاهده کلیدی:** نقاطی که از خط فیت شده فاصله زیادی دارند، مقدار درست‌نمایی (likelihood) پایینی خواهند داشت.

#### توضیحات اضافه:

این بخش نشان می‌دهد که چرا روش "مجموع مربعات خطا" (SSE) که در رگرسیون خطی استفاده می‌کنیم، از دیدگاه احتمالی بهترین روش است. وقتی فرض می‌کنیم نویز داده‌ها نرمال (گاوسی) است، بیشینه‌سازی درست‌نمایی دقیقاً معادل کمینه‌سازی SSE می‌شود.

---

### ۲.۷. لگاریتم درست‌نمایی و مجموع مربعات (Log-Likelihood and Sum of Squares)

با استفاده از لگاریتم درست‌نمایی داریم:

$$
\log L(Z; w, \sigma^2) = -n \log \sigma - \frac{n}{2} \log(2\pi) - \frac{1}{2\sigma^2} \sum_{i=1}^{n} (y^{(i)} - f(x^{(i)}; w))^2
$$

**حذف ثابت‌ها:** از آنجایی که هدف MLE بهینه‌سازی نسبت به متغیرهای تصادفی (پارامترهای مدل $w$ و $\sigma^2$) است، می‌توان ثابت‌ها (ترم‌هایی که شامل $w$ یا $\sigma^2$ نیستند) را حذف کرد:

$$
\log L(Z; w, \sigma^2) \sim - \frac{1}{2\sigma^2} \sum_{i=1}^{n} (y^{(i)} - f(x^{(i)}; w))^2
$$

**هم‌ارزی (Equivalence):** بیشینه‌سازی لگاریتم درست‌نمایی (در این حالت) معادل کمینه‌سازی مجموع مربعات خطا (Sum of Squared Errors - SSE) است:

$$
J(w) = \sum_{i=1}^{n} (y^{(i)} - f(x^{(i)}; w))^2
$$

#### توضیحات اضافه:

این بخش نشان می‌دهد که چرا MLE با فرض نویز گاوسی، منجر به همان تابع هزینه‌ی SSE می‌شود که در رگرسیون خطی استفاده می‌کنیم. این یک پایه آماری قوی برای SSE فراهم می‌کند.

---

### ۲.۸. تخمین $\sigma^2$ (Estimating $\sigma^2$)

**تخمین بیشینه درست‌نمایی واریانس نویز $\sigma^2$:**

$$
\hat{\sigma}^2 = \frac{1}{n} \sum_{i=1}^{n} (y^{(i)} - f(x^{(i)}; w))^2
$$

**تفسیر:** این مقدار همان **میانگین مربعات خطا** (Mean Squared Error - MSE) پیش‌بینی‌ها است.

**نکته:** $\sigma^2$ (واریانس نویز) سطح نویز در مشاهدات را منعکس می‌کند.

---

این بخش‌ها توضیحات جامعی درباره فرآیند تخمین بیشینه درست‌نمایی (MLE) و چگونگی استفاده از آن برای رگرسیون خطی با فرض نویز گاوسی ارائه می‌دهند. اگر سؤالات بیشتری دارید یا نیاز به جزئیات بیشتری دارید، خوشحال می‌شوم کمک کنم!


---

### ۱.۱۱. رگولاریزاسیون (Regularization)

**رگولاریزاسیون** یک تکنیک کلیدی در یادگیری ماشین است که با جریمه کردن وزن‌های بزرگ (large weights)، به جلوگیری از **بیش‌براش** (overfitting) کمک می‌کند. هدف اصلی آن، **کاهش پیچیدگی مدل** است تا بتواند بهتر به داده‌های دیده نشده تعمیم پیدا کند.

**فرمول کلی تابع هزینه با رگولاریزاسیون** به صورت:

$$
J_{\lambda}(w) = J(w) + \lambda R(w)
$$

تعریف می‌شود:

* **$J(w)$:** این همان تابع هزینه اصلی مدل است (مانند **Sum of Squared Errors** در رگرسیون خطی) که میزان تطابق مدل با داده‌ها را اندازه‌گیری می‌کند.

* **$R(w)$:** این ترم رگولاریزاسیون یا "تابع جریمه" برای وزن‌های مدل است. این ترم با افزایش بزرگی وزن‌ها، مقدار تابع هزینه کلی را افزایش می‌دهد.

* **$\lambda$ (لامبدا):** این یک **هایپرپارامتر** (hyperparameter) است که نقش حیاتی در کنترل تعادل بین تطابق با داده‌ها (برازش) و سادگی مدل دارد. مقدار بزرگ $\lambda$ به معنای جریمه‌ی بیشتر وزن‌های بزرگ و در نتیجه مدل ساده‌تر است، در حالی که $\lambda$ کوچک، جریمه کمتری اعمال می‌کند و مدل می‌تواند پیچیده‌تر شود.

رایج‌ترین رگولاریزه‌کننده‌ها عبارتند از:

* **L1 norm (Lasso):** باعث می‌شود برخی وزن‌ها به صفر برسند (انتخاب ویژگی).
* **L2 norm (Ridge):** وزن‌ها را کوچک نگه می‌دارد اما به ندرت آن‌ها را صفر می‌کند.

#### توضیحات اضافه:

رگولاریزاسیون مثل یه "تنبیه" برای مدل عمل می‌کنه که اجازه نده وزن‌هاش خیلی بزرگ بشن. وزن‌های خیلی بزرگ معمولاً نشانه‌ی این هستن که مدل داره به شدت روی جزئیات بی‌ربط یا نویز داده‌های آموزشی تمرکز می‌کنه و **بیش‌براش** اتفاق می‌افته. با رگولاریزاسیون، ما به مدل می‌گیم که "هم خوب پیش‌بینی کن، هم وزنهات خیلی بزرگ نشن".
$\lambda$ هم مثل "میزان سختگیری" این تنبیه است.

---

این مفاهیم به شما کمک می‌کند تا توانایی درک چالش‌های مدل‌سازی در یادگیری ماشین را پیدا کنید و روش‌هایی برای بهبود عملکرد مدل‌ها ایجاد کنید. اگر نیاز به توضیحات بیشتری دارید، در اختیارم باشید!


### ۱.۱۲. تاثیر پارامتر رگولاریزاسیون $\lambda$ (Effect of Regularization Parameter $\lambda$)

پارامتر رگولاریزاسیون $\lambda$ نقش کلیدی در **متعادل کردن برازش مدل با پیچیدگی آن** ایفا می‌کند.

#### **فرمول با L2 Regularization:**

یکی از رایج‌ترین فرم‌های رگولاریزاسیون، **L2 regularization** است که به صورت:

$$
J_{\lambda}(w) = J(w) + \lambda \sum_{j=1}^{m} w_j^2 = J(w) + \lambda w^T w
$$

به تابع هزینه اضافه می‌شود. این ترم مربع نرم اقلیدسی وزن‌ها را به تابع هزینه می‌افزاید.

* **$\lambda$ بزرگ:** زمانی که مقدار $\lambda$ بزرگ است، مدل به شدت وزن‌های بزرگ را جریمه می‌کند. این امر باعث می‌شود که وزن‌ها مجبور به کوچک‌تر شدن شوند. در نتیجه، پیچیدگی مدل کاهش می‌یابد، بایاس افزایش می‌یابد (زیرا مدل ساده‌تر می‌شود و نمی‌تواند تمام پیچیدگی‌های داده را بگیرد) و واریانس کاهش می‌یابد (زیرا مدل کمتر به نویز حساس می‌شود). در این حالت، مدل تمایل به **کم‌براش** پیدا می‌کند.

* **$\lambda$ کوچک:** در مقابل، وقتی $\lambda$ کوچک است (نزدیک به صفر)، جریمه بر روی وزن‌ها کم می‌شود و مدل اجازه پیدا می‌کند وزن‌های بزرگ‌تری داشته باشد. این به افزایش پیچیدگی مدل منجر می‌شود، بایاس کاهش می‌یابد (زیرا مدل می‌تواند جزئیات بیشتری را فیت کند) و واریانس افزایش می‌یابد (زیرا مدل به نویز حساس‌تر می‌شود). در این حالت، مدل مستعد **بیش‌براش** می‌شود.

#### **کنترل پیچیدگی:**

به این ترتیب، $\lambda$ به طور موثری پیچیدگی موثر مدل را کنترل می‌کند و در نتیجه، میزان بیش‌براش را تنظیم می‌نماید.

#### **مثال (صفحه 24 PDF):**

جدول ارائه‌شده به وضوح نشان می‌دهد که با افزایش $\ln(\lambda)$ (که معادل افزایش مقدار $\lambda$ است)، مقادیر وزن‌ها، به خصوص وزن‌های مربوط به ترم‌های با درجه بالاتر (مانند $w_9^*, w_8^*, \dots$) به شدت کاهش می‌یابند و به صفر نزدیک می‌شوند. این نشان‌دهنده آن است که مدل با $\lambda$ بزرگ‌تر، ساده‌تر شده و کمتر به ویژگی‌های پیچیده وابسته می‌شود.

#### **نمودار (صفحه 25 PDF):**

نمودار خطای ERMS در برابر $\ln(\lambda)$ نیز این تاثیر را تأیید می‌کند. با تغییر $\ln(\lambda)$، هم خطای آموزش (آبی) و هم خطای تست (قرمز) تغییر می‌کنند. معمولاً یک مقدار بهینه برای $\lambda$ وجود دارد که خطای تست را به حداقل می‌رساند و نشان‌دهنده بهترین تعادل بین بایاس و واریانس است.

---

### ۲. رگرسیون احتمالی (Probabilistic Regression)

بخش دوم این جزوه به **"رگرسیون احتمالی"** می‌پردازد که دیدگاهی عمیق‌تر و آماری‌تر به مسائل رگرسیون ارائه می‌دهد.

#### ۲.۱. مقدمه‌ای بر رگرسیون (دیدگاه احتمالی)

در دیدگاه احتمالی، هدف **رگرسیون**، مدل‌سازی رابطه بین یک ورودی $x$ و یک خروجی $y$ است. با این حال، در این دیدگاه، فرض می‌شود که خروجی $y$ دارای **عدم قطعیت (Uncertainty)** مرتبطی است که نمی‌توان آن را به طور کامل با یک تابع قطعی مدل کرد. این عدم قطعیت با یک **توزیع احتمالی** مدل‌سازی می‌شود. یک مثال رایج، فرض این است که خروجی مشاهده شده $y$ برابر است با یک تابع پایه از $x$ و وزن‌های مدل $f(x;w)$ به علاوه مقداری نویز $\epsilon$ که از یک توزیع نرمال (Normal/Gaussian distribution) با میانگین صفر و واریانس $\sigma^2$ پیروی می‌کند:

$$
y = f(x; w) + \epsilon, \quad \epsilon \sim N(0, \sigma^2)
$$

در نهایت، هدف اصلی در این رویکرد، **یادگیری تابع $f(x; w)$** برای پیش‌بینی $y$ است.

#### **توضیحات اضافه:**

در رگرسیون عادی، ما فقط یک خط یا منحنی پیدا می‌کردیم که از وسط داده‌ها رد شود. در رگرسیون احتمالی، فرض می‌کنیم که داده‌های واقعی ما دقیق نیستند و همیشه یک مقداری "خطای تصادفی" یا "نویز" در اندازه‌گیری‌ها یا فرآیند تولید داده وجود دارد. هدف ما پیدا کردن بهترین تابع $f(x; w)$ است که میانگین رفتار داده‌ها را نشان دهد و همچنین بتوانیم میزان "عدم قطعیت" یا "پراکندگی" حول این پیش‌بینی را هم مدل کنیم.

#### ۲.۲. فیت کردن منحنی با نویز (Curve Fitting with Noise)

در سناریوهای واقعی و کاربردی، خروجی مشاهده شده $y$ همواره **نویزی (noisy)** است. این بدان معناست که حتی اگر رابطه اصلی بین ورودی و خروجی کاملاً مشخص باشد، مقادیر مشاهده شده دارای انحرافات تصادفی هستند. مدل ریاضی این وضعیت به این صورت است که خروجی واقعی $y$ برابر است با خروجی تابع $f(x; w)$ به علاوه نویز $\epsilon$:

$$
y = f(x; w) + \epsilon
$$

این نویز نشان‌دهنده تمام **عوامل ناشناخته** یا مدل‌سازی نشده‌ای است که بر خروجی تأثیر می‌گذارند و نمی‌توان آن‌ها را به طور دقیق در تابع $f(x; w)$ گنجاند. به عنوان مثال، در پیش‌بینی قیمت خانه بر اساس ویژگی‌ها، حتی با داشتن تمام اطلاعات ممکن، همیشه مقداری **عدم قطعیت ذاتی** وجود دارد که نمی‌توان آن را به طور کامل پیش‌بینی کرد.

#### ۲.۳. مقدار مورد انتظار خروجی (Expected Value of Output)

در دیدگاه احتمالی، بهترین تخمین برای $y$ با داشتن $x$، همان **امید ریاضی شرطی** $y$ به شرط $x$ است:

$$
E[y \mid x] = f(x; w)
$$

این بدان معناست که تابع $f(x; w)$ که ما یاد می‌گیریم، در واقع میانگین رفتار متغیر هدف $y$ را با داشتن ورودی $x$ ثبت می‌کند. بنابراین، هدف اصلی ما در **رگرسیون احتمالی**، یادگیری تابعی $f(x; w)$ است که بتواند این میانگین شرطی را به بهترین شکل ممکن تقریب بزند.

---

این توضیحات به شما کمک می‌کند تا فهم دقیق‌تری از تکنیک‌های رگرسیون و نحوه مدل‌سازی عدم قطعیت در یادگیری ماشین پیدا کنید. در صورتی که سوالی دارید یا نیاز به توضیحات بیشتری هستید، خوشحال می‌شوم که کمک کنم!
### ۲.۴. **برآورد بیشینه درست‌نمایی (Maximum Likelihood Estimation - MLE)**

**برآورد بیشینه درست‌نمایی (MLE)** یک روش آماری بسیار قدرتمند و پرکاربرد برای تخمین پارامترهای یک مدل است. هدف MLE این است که پارامترهایی را پیدا کند که **احتمال وقوع داده‌های مشاهده شده (likelihood)** را به حداکثر برسانند. به عبارت دیگر، این روش پارامترهایی را انتخاب می‌کند که بیشترین احتمال را برای وقوع داده‌های واقعی فراهم می‌کنند.

فرض کنید مجموعه داده‌ها به صورت $Z = \{(x_i, y_i)\}_{i=1}^n$ داریم. MLE پارامترهایی مانند $w$ (وزن‌ها) و $\sigma^2$ (واریانس نویز) را پیدا می‌کند که حاصل‌ضرب احتمال‌های هر یک از نمونه‌ها را بیشینه کنند:

$$
L(Z; w, \sigma^2) = \prod_{i=1}^{n} p(y_i | x_i, w, \sigma^2)
$$

در واقع، **MLE** پارامترهای $w$ و $\sigma^2$ را پیدا می‌کند که بهترین توضیح را برای داده‌هایی که مشاهده کرده‌ایم، ارائه می‌دهند.

### ۲.۵. **برآورد بیشینه درست‌نمایی (ادامه)**

در عمل، به جای **بیشینه‌سازی مستقیم تابع درست‌نمایی** ($L(Z; w, \sigma^2)$)، معمولاً **بیشینه‌سازی لگاریتم درست‌نمایی (log-likelihood)** آسان‌تر است. دلایل استفاده از log-likelihood به شرح زیر است:

* **حفظ رفتار تابع:** تابع لگاریتم یک تابع صعودی یکنواخت است. این بدان معناست که نقاطی که تابع اصلی را بیشینه می‌کنند، لگاریتم آن تابع را نیز بیشینه می‌کنند. بنابراین، بیشینه‌سازی logL همان نتیجه را به همراه دارد که بیشینه‌سازی تابع اصلی داشته است.

* **تبدیل ضرب به جمع:** تابع درست‌نمایی شامل حاصل‌ضرب احتمالات تک‌تک نمونه‌ها است. لگاریتم این حاصل‌ضرب را به یک جمع تبدیل می‌کند:

$$
\log L(Z; w, \sigma^2) = \sum_{i=1}^{n} \log p(y_i | x_i, w, \sigma^2)
$$

این تبدیل، هم از نظر محاسباتی پایدارتر است (جلوگیری از Underflow در حاصل‌ضرب اعداد کوچک) و هم **مشتق‌گیری از مجموع ترم‌ها** بسیار آسان‌تر است که برای الگوریتم‌های بهینه‌سازی مبتنی بر گرادیان حیاتی است.

### ۲.۶. **مثال تابع خطی تک‌متغیره (Univariate Linear Function Example)**

برای درک چگونگی ارتباط **MLE** با **رگرسیون خطی**، یک مثال رایج این است که فرض کنیم **نویز** ($\epsilon$) از یک توزیع **گاوسی** (نرمال) با میانگین صفر و واریانس $\sigma^2$ پیروی می‌کند. در این صورت، احتمال مشاهده یک خروجی واقعی $y$ به شرط ورودی $x$، وزن‌های $w$ و واریانس نویز $\sigma^2$ به صورت زیر است:

$$
p(y | x, w, \sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp \left( -\frac{(y - f(x; w))^2}{2 \sigma^2} \right)
$$

برای یک مدل خطی ساده مانند $f(x; w) = w_0 + w_1 x$ (که یک تابع تک‌متغیره است)، فرمول بالا به صورت زیر در می‌آید:

$$
p(y | x, w, \sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp \left( -\frac{(y - w_0 - w_1 x)^2}{2 \sigma^2} \right)
$$

مشاهده کلیدی در این فرمول این است که **نقاطی که از خط فیت شده** ($f(x; w)$) **فاصله زیادی دارند، احتمال وقوع آن‌ها کم خواهد بود.** به عبارت دیگر، مدل‌هایی که انحرافات بزرگی از داده‌های واقعی دارند، کمتر محتمل به نظر می‌رسند.

#### **توضیحات اضافه:**

این بخش بسیار مهم است زیرا نشان می‌دهد که چگونه **MLE** (که یک روش آماری است) به روشی که ما در **رگرسیون خطی** استفاده می‌کنیم (کمینه‌سازی مجموع مربعات خطا) منتهی می‌شود. فرض "نویز گاوسی" در اینجا کلید است. اگر داده‌های شما نویز گاوسی داشته باشند، **بیشینه‌سازی احتمال** دقیقا همان چیزی است که شما با **کمینه‌سازی فاصله مربع (SSE)** انجام می‌دهید.

### ۲.۷. **لگاریتم درست‌نمایی و مجموع مربعات (Log-Likelihood and Sum of Squares)**

با استفاده از فرمول **لگاریتم درست‌نمایی** که در بخش قبلی به دست آوردیم (با فرض نویز گاوسی)، می‌توانیم رابطه آن را با **مجموع مربعات خطا** مشخص کنیم. لگاریتم درست‌نمایی به صورت:

$$
\log L(Z; w, \sigma^2) = -n \log \sigma - \frac{n}{2} \log(2 \pi) - \frac{1}{2 \sigma^2} \sum_{i=1}^{n} (y^{(i)} - f(x^{(i)}; w))^2
$$

از آنجایی که هدف **MLE** بهینه‌سازی پارامترهای مدل ($w$ و $\sigma^2$) است، می‌توان ترم‌های ثابتی را که شامل این پارامترها نیستند (مانند $-n \log \sigma$ و $- \frac{n}{2} \log(2 \pi)$ و همچنین $- \frac{1}{2 \sigma^2}$) از معادله حذف کرد، زیرا تاثیری در محل بهینه ندارند. بنابراین، لگاریتم درست‌نمایی متناسب با عبارت زیر می‌شود:

$$
\log L(Z; w, \sigma^2) \sim - \sum_{i=1}^{n} (y^{(i)} - f(x^{(i)}; w))^2
$$

#### **هم‌ارزی (Equivalence):**

این نشان‌دهنده یک هم‌ارزی کلیدی است: **بیشینه‌سازی لگاریتم درست‌نمایی** (با فرض نویز گاوسی) دقیقا معادل **کمینه‌سازی مجموع مربعات خطا (Sum of Squared Errors - SSE)** است. تابع هزینه **SSE** که در رگرسیون خطی استفاده می‌کنیم به صورت زیر تعریف می‌شود:

$$
J(w) = \sum_{i=1}^{n} (y^{(i)} - f(x^{(i)}; w))^2
$$

این هم‌ارزی، یک پایه آماری قوی برای استفاده از **SSE** به عنوان تابع هزینه در **رگرسیون خطی** فراهم می‌کند.

#### **توضیحات اضافه:**

این بخش نشان می‌دهد که چرا روشی که ما در **رگرسیون خطی** برای پیدا کردن بهترین خط استفاده می‌کنیم (کمینه‌سازی **SSE**)، از دیدگاه احتمالی، بهترین روش است. یعنی وقتی ما فرض می‌کنیم که خطاهای ما (نویز) به صورت نرمال توزیع شده‌اند، پیدا کردن خطی که کمترین مجموع مربعات خطا را داشته باشد، دقیقا معادل پیدا کردن خطی است که داده‌های مشاهده شده‌ی ما را با بالاترین احتمال توضیح دهد.

---

اگر نیاز به توضیحات بیشتر یا درک عمیق‌تر در هر بخش دارید، حتماً بپرسید!


### ۲.۸. **تخمین $\sigma^2$**

پس از اینکه وزن‌های بهینه مدل ($\hat{w}$) از طریق فرآیند **بیشینه‌سازی درست‌نمایی** (MLE) به دست آمدند و مدل بهترین تطابق را با داده‌ها پیدا کرد، می‌توانیم **واریانس نویز** $\sigma^2$ را نیز تخمین بزنیم.

تخمین **بیشینه درست‌نمایی** واریانس نویز $\sigma^2$ به صورت زیر تعریف می‌شود:

$$
\hat{\sigma}^2 = \frac{1}{n} \sum_{i=1}^{n} (y^{(i)} - f(x^{(i)}; \hat{w}))^2
$$

#### **تفسیر:**

این تخمین، همان **میانگین مربعات خطا** یا **Mean Squared Error (MSE)** پیش‌بینی‌های مدل بر روی داده‌های آموزشی است. به عبارت دیگر، این تخمین **میانگین مربع باقی‌مانده‌ها (residuals)** را نشان می‌دهد. باقی‌مانده‌ها به تفاوت بین مقادیر پیش‌بینی‌شده مدل و مقادیر واقعی داده‌ها اشاره دارند.

#### **نکته:**

مقدار $\sigma^2$ (واریانس نویز) در واقع **سطح نویز ذاتی** در مشاهدات ما را منعکس می‌کند. هرچه $\hat{\sigma}^2$ کوچکتر باشد، نشان‌دهنده این است که نقاط داده مشاهده شده به طور متوسط، نزدیک‌تر به **خط یا منحنی پیش‌بینی‌شده** مدل قرار دارند. یعنی مدل به خوبی داده‌ها را پیش‌بینی کرده و نویز یا خطای پیش‌بینی کمتر است.

#### **مثال:**

فرض کنید یک مدل رگرسیون خطی داریم و پس از بهینه‌سازی وزن‌ها ($\hat{w}$) از طریق MLE، تخمین واریانس نویز $\hat{\sigma}^2$ را می‌خواهیم. با استفاده از داده‌های آموزشی، می‌توانیم باقی‌مانده‌ها را محاسبه کرده و سپس مربع آن‌ها را میانگین بگیریم تا مقدار $\hat{\sigma}^2$ بدست آید. این مقدار به ما کمک می‌کند تا درک بهتری از دقت پیش‌بینی‌های مدل و میزان نویز در داده‌ها داشته باشیم.





