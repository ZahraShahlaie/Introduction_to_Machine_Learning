# 📘 جزوه کامل یادگیری ماشین: رگرسیون خطی، تعمیم‌پذیری و رگرسیون احتمالی

**از فایل اصلی : دکتر علی شریفی‌زارچی منتشر شده درتاریخ: ۲۱ سپتامبر ۲۰۲۴**

---

### **1. مقدمه (Introduction)**

در این بخش، به بررسی مفاهیم پایه‌ای یادگیری ماشین می‌پردازیم که به‌عنوان پیش‌نیاز برای درک موضوعات بعدی ضروری است.

#### **1.1. یادگیری ماشین چیست؟**

**پرسش:** یادگیری ماشین به چه معناست و چرا اهمیت دارد؟
**پاسخ:** یادگیری ماشین شاخه‌ای از هوش مصنوعی است که به سیستم‌ها امکان می‌دهد از داده‌ها یاد بگیرند و بدون برنامه‌ریزی صریح، عملکرد خود را بهبود دهند. این فناوری در کاربردهایی مانند تشخیص تصویر، پردازش زبان طبیعی، پیش‌بینی‌های مالی، و تحلیل داده‌های پزشکی نقش کلیدی دارد. یادگیری ماشین به ما کمک می‌کند تا الگوهای پنهان در داده‌ها را کشف کنیم و تصمیم‌گیری‌های هوشمندانه‌تری انجام دهیم.

#### **1.2. انواع یادگیری ماشین**

**پرسش:** چه نوع‌هایی از یادگیری ماشین وجود دارد؟
**پاسخ:** یادگیری ماشین به سه دسته اصلی تقسیم می‌شود:
* **یادگیری نظارت‌شده:** مدل با استفاده از داده‌های برچسب‌دار (ورودی و خروجی) آموزش می‌بیند. مثال: پیش‌بینی قیمت خانه بر اساس ویژگی‌هایی مانند متراژ و تعداد اتاق.
* **یادگیری بدون نظارت:** مدل روی داده‌های بدون برچسب کار می‌کند تا الگوها یا ساختارهای پنهان را کشف کند. مثال: خوشه‌بندی مشتریان برای بازاریابی هدفمند.
* **یادگیری تقویتی:** مدل از طریق آزمون و خطا و دریافت پاداش یا جریمه یاد می‌گیرد. مثال: آموزش ربات برای انجام وظایف خاص مانند حرکت در محیط.

---

### **2. رگرسیون خطی و مدل‌سازی**

رگرسیون خطی یکی از روش‌های پایه‌ای در یادگیری ماشین است که برای مدل‌سازی روابط خطی بین متغیرها استفاده می‌شود.

#### **2.1. رگرسیون خطی چیست؟**

**پرسش:** رگرسیون خطی چگونه کار می‌کند؟
**پاسخ:** رگرسیون خطی مدلی است که رابطه‌ای خطی بین متغیرهای مستقل (ویژگی‌ها) و متغیر وابسته (هدف) برقرار می‌کند. این مدل به‌صورت زیر تعریف می‌شود:
\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_n x_n + \epsilon
\]
که در آن $\beta_0$ عرض از مبدا، $\beta_i$ ضرایب مدل، $x_i$ ویژگی‌ها، و $\epsilon$ خطای مدل است. هدف، یافتن مقادیر بهینه $\beta_i$ است که خطای پیش‌بینی را کمینه کند.

#### **2.2. کاربردهای رگرسیون خطی**

**پرسش:** رگرسیون خطی در چه مواردی استفاده می‌شود؟
**پاسخ:** رگرسیون خطی برای پیش‌بینی مقادیر عددی در مسائل مختلف به کار می‌رود، از جمله:
* پیش‌بینی فروش محصولات بر اساس بودجه تبلیغات.
* تخمین مصرف انرژی یک ساختمان بر اساس دما و اندازه.
* تحلیل روابط اقتصادی، مانند تأثیر نرخ بهره بر رشد اقتصادی.
برای بهبود دقت، تکنیک‌هایی مانند نرمال‌سازی داده‌ها، انتخاب ویژگی‌های مناسب، و استفاده از روش‌های منظم‌سازی (مانند رگرسیون ریج یا لاسو) استفاده می‌شود.

#### **2.3. چالش‌های رگرسیون خطی**

**پرسش:** چه مشکلاتی در استفاده از رگرسیون خطی ممکن است پیش بیاید؟
**پاسخ:** برخی از چالش‌های اصلی عبارت‌اند از:
* **بیش‌برازش**: مدل ممکن است بیش از حد به داده‌های آموزشی وابسته شود و در داده‌های جدید عملکرد ضعیفی داشته باشد.
* **فرض خطی بودن**: اگر رابطه بین متغیرها غیرخطی باشد، مدل رگرسیون خطی مناسب نخواهد بود.
* **حساسیت به داده‌های پرت**: داده‌های پرت می‌توانند ضرایب مدل را به‌شدت تحت تأثیر قرار دهند.

---

### **3. تعمیم‌پذیری در یادگیری ماشین**

تعمیم‌پذیری یکی از مفاهیم کلیدی در یادگیری ماشین است که به توانایی مدل در عملکرد خوب روی داده‌های جدید اشاره دارد.

#### **3.1. تعمیم‌پذیری چیست؟**

**پرسش:** چرا تعمیم‌پذیری در یادگیری ماشین مهم است؟
**پاسخ:** تعمیم‌پذیری به این معناست که مدل نه‌تنها روی داده‌های آموزشی بلکه روی داده‌های جدید و نادیده (داده‌های آزمون) نیز عملکرد خوبی داشته باشد. هدف اصلی یادگیری ماشین، ساخت مدل‌هایی است که بتوانند الگوهای عمومی را از داده‌ها استخراج کنند، نه اینکه صرفاً داده‌های آموزشی را حفظ کنند. بدون تعمیم‌پذیری، مدل ممکن است دچار بیش‌برازش (overfitting) یا کم‌برازش (underfitting) شود.

#### **3.2. چگونه تعمیم‌پذیری را بهبود دهیم؟**

**پرسش:** چه روش‌هایی برای بهبود تعمیم‌پذیری وجود دارد؟
**پاسخ:** برای بهبود تعمیم‌پذیری می‌توان از تکنیک‌های زیر استفاده کرد:
* **تقسیم داده‌ها**: استفاده از مجموعه‌های آموزشی، اعتبارسنجی، و آزمون برای ارزیابی عملکرد مدل.
* **منظم‌سازی**: استفاده از روش‌هایی مانند رگرسیون ریج یا لاسو برای کاهش پیچیدگی مدل.
* **افزایش داده‌ها**: استفاده از تکنیک‌های افزایش داده (data augmentation) یا جمع‌آوری داده‌های متنوع‌تر.
* **اعتبارسنجی متقاطع**: استفاده از روش‌هایی مانند k-fold cross-validation برای اطمینان از عملکرد پایدار مدل.

#### **3.3. چالش‌های تعمیم‌پذیری**

**پرسش:** چه عواملی تعمیم‌پذیری را به خطر می‌اندازند؟
**پاسخ:** برخی از عوامل عبارت‌اند از:
* **داده‌های ناکافی**: اگر داده‌های آموزشی محدود یا غیرنماینده باشند، مدل نمی‌تواند الگوهای عمومی را یاد بگیرد.
* **پیچیدگی بیش از حد مدل**: مدل‌های بسیار پیچیده (مانند شبکه‌های عصبی عمیق) ممکن است به داده‌های آموزشی بیش‌برازش شوند.
* **نویز در داده‌ها**: داده‌های پر سر و صدا یا نادرست می‌توانند یادگیری الگوهای صحیح را مختل کنند.

---

### **4. رگرسیون احتمالی**

رگرسیون احتمالی رویکردی است که عدم قطعیت را در مدل‌سازی وارد می‌کند و به‌جای پیش‌بینی یک مقدار دقیق، توزیع احتمالی خروجی‌ها را مدل می‌کند.

#### **4.1. رگرسیون احتمالی چیست؟**

**پرسش:** تفاوت رگرسیون احتمالی با رگرسیون خطی چیست؟
**پاسخ:** در رگرسیون خطی، هدف پیش‌بینی یک مقدار عددی دقیق است، اما در رگرسیون احتمالی، مدل توزیع احتمالی خروجی‌ها را پیش‌بینی می‌کند. به‌عنوان مثال، به‌جای پیش‌بینی قیمت خانه به‌صورت یک عدد (مثلاً 500 میلیون تومان)، مدل یک توزیع نرمال با میانگین 500 میلیون و واریانس مشخص ارائه می‌دهد که عدم قطعیت را نیز نشان می‌دهد.

#### **4.2. مدل‌های رگرسیون احتمالی**

**پرسش:** چه مدل‌هایی در رگرسیون احتمالی استفاده می‌شوند؟
**پاسخ:** برخی از مدل‌های رایج عبارت‌اند از:
* **رگرسیون خطی بیزی**: از رویکرد بیزی برای مدل‌سازی توزیع ضرایب استفاده می‌کند.
* **رگرسیون گاوسی**: فرض می‌کند خروجی‌ها از یک توزیع نرمال پیروی می‌کنند.
* **مدل‌های ترکیبی**: مانند مدل‌های مخلوط گاوسی که برای داده‌های پیچیده‌تر استفاده می‌شوند.

#### **4.3. کاربردهای رگرسیون احتمالی**

**پرسش:** رگرسیون احتمالی در چه مواردی مفید است؟
**پاسخ:** رگرسیون احتمالی در سناریوهایی که عدم قطعیت مهم است، کاربرد دارد، از جمله:
* پیش‌بینی‌های مالی، مانند تخمین ریسک سرمایه‌گذاری.
* مدل‌سازی داده‌های پزشکی، مانند پیش‌بینی احتمال بیماری.
* تحلیل داده‌های علمی که نویز زیادی دارند.

---

# 🎓 جزوه آموزشی جلسه ۲

## موضوع: تعمیم‌پذیری (Generalization) و رگرسیون احتمالاتی (Probabilistic Regression)

مدرس: دکتر علی شریفی زارعی
دانشگاه صنعتی شریف – پاییز ۱۴۰۳

---

## بخش اول: تعمیم‌پذیری (Generalization)

### توضیح تکمیلی:

در یادگیری ماشین، مدل‌ها فقط نباید روی داده‌های آموزش خوب عمل کنند؛ بلکه باید بتوانند روی داده‌هایی که قبلاً ندیده‌اند نیز عملکرد خوبی داشته باشند. این توانایی، **تعمیم‌پذیری** نام دارد.

### محتوای اصلی:

* مدل خوب باید روی داده آموزش و همچنین داده تست عملکرد خوبی داشته باشد.
* تابع هزینه رایج:
  $J(w) = \sum_{i=1}^n (y^{(i)} - h_w(x^{(i)}))^2$

---

## بخش دوم: خطای مورد انتظار روی داده تست (Expected Test Error)

### توضیح تکمیلی:

چون در عمل به تمام داده‌های واقعی دنیا دسترسی نداریم، برای ارزیابی عملکرد مدل از داده‌های تست استفاده می‌کنیم که از همان توزیع داده‌های آموزش آمده‌اند.

### محتوای اصلی:

* هدف اصلی: کمینه کردن فاصله بین خطای آموزش و خطای تست.
* فرمول رسمی:
  $J(w) = \mathbb{E}_{p(x,y)}[(y - h_w(x))^2]$

---

## بخش سوم: Overfitting و Underfitting

### توضیح تکمیلی:

دو خطای متداول در یادگیری ماشین هستند که مانع از تعمیم‌پذیری مناسب مدل می‌شوند. در Overfitting مدل به داده‌های آموزش بیش از حد وابسته می‌شود. در Underfitting مدل آنقدر ساده است که نمی‌تواند الگوی داده را یاد بگیرد.

### محتوای اصلی:

| ویژگی     | Overfitting                                 | Underfitting                       |
| --------- | ------------------------------------------- | ---------------------------------- |
| تعریف     | مدل بسیار پیچیده و حفظ‌کننده‌ی نویز داده‌ها | مدل بسیار ساده و ناتوان در یادگیری |
| رابطه خطا | $J_{train} \ll J_{test}$                    | $J_{train} \approx J_{test} \gg 0$ |
| نتیجه     | عملکرد ضعیف روی داده‌های جدید               | عملکرد ضعیف روی همه داده‌ها        |

---

## بخش چهارم: تجزیه خطای تعمیم‌پذیری (Bias-Variance Tradeoff)

### توضیح تکمیلی:

یکی از مفاهیم کلیدی یادگیری ماشین، تجزیه‌ی خطای مدل به سه مؤلفه است: بایاس، واریانس و نویز. تعادل بین بایاس و واریانس می‌تواند عملکرد مدل را بهینه کند.

### محتوای اصلی:

* فرمول:

  $$
  \mathbb{E}[(y - h_w(x))^2] = Bias^2 + Variance + Noise
  $$
* بایاس بالا: مدل ساده
* واریانس بالا: مدل پیچیده
* نویز: خطای غیرقابل حذف

---

## بخش پنجم: منظم‌سازی (Regularization)

### توضیح تکمیلی:

برای جلوگیری از Overfitting، می‌توان از منظم‌سازی استفاده کرد تا مدل بیش از حد به داده‌های آموزش وابسته نشود. این کار با جریمه کردن وزن‌های بزرگ انجام می‌شود.

### محتوای اصلی:

* تابع هزینه جدید:
  $J_{\lambda}(w) = J(w) + \lambda R(w)$
* برای L2:
  $R(w) = ||w||_2^2$
* λ بزرگ: مدل ساده‌تر → واریانس کمتر، بایاس بیشتر
* λ کوچک: مدل پیچیده‌تر → بایاس کمتر، واریانس بیشتر

---

## بخش ششم: رگرسیون احتمالاتی (Probabilistic Regression)

### توضیح تکمیلی:

در این دیدگاه، خروجی مدل را به‌صورت یک متغیر تصادفی می‌نگریم که دارای نویز است. هدف یادگیری تابعی است که بتواند رفتار میانگین داده را توضیح دهد.

### محتوای اصلی:

* مدل پایه:
  $y = f(x; w) + \epsilon,\ \epsilon \sim \mathcal{N}(0, \sigma^2)$
* برآورد پارامترها با MLE (بیشینه‌سازی درست‌نمایی)
* معادل کمینه‌سازی مجموع مربعات خطا:
  $J(w) = \sum (y_i - f(x_i; w))^2$
* تخمین واریانس نویز:
  $\hat{\sigma}^2 = \frac{1}{n} \sum (y_i - \hat{f}(x_i))^2$

---

