โ ุฌุฒูู ฺฉุงูู ู ุณุงุฎุชโุงูุชูโ ุฌูุณู ฺูุงุฑู ุจุง ููุถูุน **ุฑฺฏุฑุณูู ูุฌุณุชฺฉ (Logistic Regression)** ุขูุงุฏู ุดุฏ.

๐ ุฏุงูููุฏ PDF ุฌุฒูู:
[๐ฅ ุฏุฑุงูุช ูุงู PDF](sandbox:/mnt/data/ML_Session4_Logistic_Regression.pdf)

ุณุงุฎุชุงุฑ ุฌุฒูู:

* ุขููุฒุด ููููู ุฑฺฏุฑุณูู ูุฌุณุชฺฉ
* ุชุงุจุน ุณฺฏููุฏุ ูุฑุฒ ุชุตููุ MLEุ ุชุงุจุน ูุฒูู
* ูุฏู ฺูุฏฺฉูุงุณู (Softmax)
* ุฏุฏฺฏุงู ุงุญุชูุงูุงุช ุชูฺฉฺฉโฺฏุฑ vs. ฺฏุดุชุงูุฑุฒุง

ุงฺฏุฑ ุชุฃุฏ ฺฉูุ ูุฌููุนู ฑฐ ุงู ฒฐ ุณุคุงู ูุตุงุญุจูโุง ุชุฎุตุต ูู ุจุฑุงุณุงุณ ููู ุฌูุณู ุจุฑุงุช ุขูุงุฏู ูโฺฉูู. โ ุขุง ุงุฏุงูู ุจุฏูุ


ุจุง ฺฉูุงู ูู! ุฏุฑ ุงุฏุงููุ **ูุชู ฺฉุงูู ุฌุฒููโ ุขููุฒุด ุฌูุณู ด** ุจุง ููุถูุน **ุฑฺฏุฑุณูู ูุฌุณุชฺฉ (Logistic Regression)** ุฑู ุฏุฑ ูุงูุจ ุขููุฒุดุ ููุธู ู ุงุฏฺฏุฑโูุญูุฑ ุจุฑุงุช ูโููุณูโุฏุฑุณุช ููููโุทูุฑ ฺฉู ุฏุฑ PDF ุจูุฏุ ููุท ุงูุฌุง ุจูโุตูุฑุช ูุชู ฺฉุงูู ุจุฑุง ฺฉูพ ุง ูุฑุงุด ุฑุงุญุช:

---

## ๐ ุฌุฒูู ุขููุฒุด ุฌูุณู ด

### ููุถูุน: ุฑฺฏุฑุณูู ูุฌุณุชฺฉ (Logistic Regression)

---

### ฑ. ููุฏูู: ฺุฑุง ุฑฺฏุฑุณูู ูุฌุณุชฺฉุ

ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ูุฏู ุจุฑุง ุญู ูุณุงุฆู **ุทุจููโุจูุฏ ุฏูุฏู** ุงุณุช. ุจุฑุฎูุงู ุฑฺฏุฑุณูู ุฎุท ฺฉู ููุฏุงุฑ ูพูุณุชู ูพุดโุจู ูโฺฉูุฏุ ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ูโุฎูุงูุฏ ุฎุฑูุฌ ุจู ฐ ู ฑ ุจุงุดุฏ (ุนู ุงุญุชูุงู ุชุนูู ุจู ฺฉูุงุณ ูุซุจุช). ุจูุงุจุฑุงู ุจู ุชุงุจุน ูุงุฒ ุฏุงุฑู ฺฉู ุฎุฑูุฌโุงุด ุฏุฑ ุจุงุฒู \[0,1] ุจุงุดุฏ.

---

### ฒ. ฺุฑุง ููโุชูุงู ุงุฒ ุฑฺฏุฑุณูู ุฎุท ุจุฑุง ุทุจููโุจูุฏ ุงุณุชูุงุฏู ฺฉุฑุฏุ

ุฑฺฏุฑุณูู ุฎุท ููฺฉู ุงุณุช ุฎุฑูุฌโูุง ุฎุงุฑุฌ ุงุฒ ุจุงุฒู \[0,1] ุชููุฏ ฺฉูุฏุ ูุซู 1.2 ุง -0.3 ฺฉู ููโุชูุงููุฏ ุงุญุชูุงู ุจุงุดูุฏ. ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉุ ุชุงุจุน ุฎุฑูุฌ ุจูโฺฏูููโุง ุทุฑุงุญ ุดุฏู ฺฉู ุฎุฑูุฌ ููุดู ุจู ุตูุฑ ู ฺฉ ุจุงุดุฏ.

---

### ณ. ุชุงุจุน ุณฺฏููุฏ (Sigmoid Function)

ุชุงุจุน ุณฺฏููุฏ ุจู ุดฺฉู ุฒุฑ ุชุนุฑู ูโุดูุฏ:

$$
ฯ(z) = \frac{1}{1 + e^{-z}}
$$

ุงู ุชุงุจุน ุจุฑุง ูฺฏุงุดุช ููุงุฏุฑ ุจู ุจุงุฒู \[0,1] ููุงุณุจ ุงุณุช. ููุช ูุฑูุฏ ูุซุจุช ุจุงุดุฏุ ุฎุฑูุฌ ูุฒุฏฺฉ ุจู ฑ ู ููุช ููู ุจุงุดุฏุ ุฎุฑูุฌ ูุฒุฏฺฉ ุจู ุตูุฑ ุฎูุงูุฏ ุจูุฏ. ุจูุงุจุฑุงู ููุฏุงุฑ ุฎุฑูุฌ ุขู ุฑุง ูโุชูุงู ุจูโุนููุงู ุงุญุชูุงู ุชูุณุฑ ฺฉุฑุฏ.

---

### ด. ุชุงุจุน ุชุตูู ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉ

ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉุ ุชุงุจุน ุชุตูู ุชุฑฺฉุจ ุชุงุจุน ุณฺฏููุฏ ุจุง ุชุฑฺฉุจ ุฎุท ูฺฺฏโูุงุณุช:

$$
h(x) = ฯ(w^T x)
$$

ุงฺฏุฑ $h(x) โฅ 0.5$ุ ููููู ุจู ฺฉูุงุณ ฑ ุชุนูู ุฏุงุฑุฏ ู ุฏุฑ ุบุฑ ุงูโุตูุฑุช ุจู ฺฉูุงุณ ฐ. ุจูุงุจุฑุงู ูุฑุฒ ุชุตูู ููุงููุฏ ูุฏูโูุง ุฎุท ฺฉ ูุงูพุฑูพูู ุฎูุงูุฏ ุจูุฏ.

---

### ต. ุณุทุญ ุชุตูู (Decision Boundary)

ุณุทุญ ุชุตูู ููุงู ูฺฉุงู ุงุณุช ฺฉู ุงุญุชูุงู ุชุนูู ุจู ุฏู ฺฉูุงุณ ุจุฑุงุจุฑ ุงุณุชุ ุนู:

$$
ฯ(w^T x) = 0.5 \Rightarrow w^T x = 0
$$

ุจูุงุจุฑุงู ูุฑุฒ ุชุตูู ุฏุฑ ูุถุง ูฺฺฏโูุง ฺฉ **ูุฑุฒ ุฎุท** ุงุณุช. ุงฺฏุฑ ุงุฒ ูฺฏุงุดุช ูฺฺฏโูุง ุบุฑุฎุท ุงุณุชูุงุฏู ฺฉููุ ูุฑุฒ ุชุตูู ูโุชูุงูุฏ ุบุฑุฎุท ูุฒ ุจุงุดุฏ.

---

### ถ. ุจุฑุขูุฑุฏ ุจุดูู ุฏุฑุณุชโููุง (Maximum Likelihood Estimation)

ุจุฑุง ุงุฏฺฏุฑ ูุฒูโูุง ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ุงุฒ ุฑูุด MLE ุงุณุชูุงุฏู ูโุดูุฏ. ุงุญุชูุงู ูุฑ ููููู ุจู ุตูุฑุช ุฒุฑ ุชุนุฑู ูโุดูุฏ:

$$
P(y|x,w) = ฯ(w^T x)^y \cdot (1 - ฯ(w^T x))^{1-y}
$$

ุจุง ฺฏุฑูุชู ูฺฏุงุฑุชู ุงุฒ ุงุญุชูุงู ฺฉู ุฏุงุฏูโูุงุ ุชุงุจุน **log-likelihood** ุจูโุฏุณุช ูโุขุฏ ฺฉู ุฑุงุญุชโุชุฑ ุจุฑุง ุจูููโุณุงุฒ ุงุณุชูุงุฏู ูโุดูุฏ.

---

### ท. ุชุงุจุน ูุฒูู ู ูุดุชู ุขู

ุชุงุจุน ูุฒูู ููุงู ููู log-likelihood ุงุณุช ู ุจู ุดฺฉู ุฒุฑ ููุดุชู ูโุดูุฏ:

$$
J(w) = -\sum_i [ y^{(i)} \log(ฯ(w^T x^{(i)})) + (1 - y^{(i)}) \log(1 - ฯ(w^T x^{(i)})) ]
$$

ุงู ุชุงุจุน **ูุญุฏุจ (Convex)** ุงุณุช ู ฺฏุฑุงุฏุงู ุขู ูุฒ ุจูโุณุงุฏฺฏ ูุงุจู ูุญุงุณุจู ุงุณุชุ ุจูุงุจุฑุงู ูโุชูุงู ุงุฒ ฺฏุฑุงุฏุงู ุฏุณูุช ุจุฑุง ุจูููโุณุงุฒ ุขู ุงุณุชูุงุฏู ฺฉุฑุฏ.

---

### ธ. ููุงุณู ุจุง ฺฏุฑุงุฏุงู ุฑฺฏุฑุณูู ุฎุท

ุฏุฑ ุฑฺฏุฑุณูู ุฎุทุ ฺฏุฑุงุฏุงู ุชุงุจุน ูุฒูู ุจู ุตูุฑุช:

$$
\nabla J(w) = \sum (w^T x - y) x
$$

ุงูุง ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉุ ุชูุงูุช ููุท ุฏุฑ ุฌุงฺฏุฒู $w^T x$ ุจุง ุชุงุจุน ุณฺฏููุฏ ุงุณุช.

$$
\nabla J(w) = \sum (ฯ(w^T x) - y) x
$$

ุจูุงุจุฑุงู ุณุงุฎุชุงุฑ ูุดุงุจู ุงุณุช ุงูุง ุฑูุชุงุฑ ุงุฏฺฏุฑ ูุชูุงูุชุ ฺูู ูุฌุณุชฺฉ ุฎุฑูุฌ ุฑุง ุจูโุนููุงู ุงุญุชูุงู ูุฏู ูโฺฉูุฏ.

---

### น. ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ฺูุฏฺฉูุงุณู (Softmax Regression)

ุจุฑุง ุทุจููโุจูุฏ ฺูุฏฺฉูุงุณูุ ุงุฒ ุชุนูู ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ุจู **Softmax Regression** ุงุณุชูุงุฏู ูโุดูุฏ. ุชุงุจุน ุงุญุชูุงู ุจุฑุง ฺฉูุงุณ k ุจู ุตูุฑุช ุฒุฑ ุงุณุช:

$$
P(y=k|x) = \frac{\exp(w_k^T x)}{\sum_j \exp(w_j^T x)}
$$

ุฏุฑ ุงู ูุฏู ุจุฑุง ูุฑ ฺฉูุงุณ ฺฉ ุจุฑุฏุงุฑ ูุฒู ูุฌุฒุง $w_k$ ุฏุฑ ูุธุฑ ฺฏุฑูุชู ูโุดูุฏ ู ูุฌููุน ุฎุฑูุฌโูุง ุจุฑุงุจุฑ ฑ ุฎูุงูุฏ ุจูุฏ.

---

### ฑฐ. ุฏุฏฺฏุงู ุงุญุชูุงูุงุช: Generative vs Discriminative

ูุฏูโูุง **Generative** ูุงููุฏ Naive Bayes ุงุจุชุฏุง ุชูุฒุน $P(x|y)$ ู $P(y)$ ุฑุง ูุฏู ูโฺฉููุฏ ู ุจุง ุงุณุชูุงุฏู ุงุฒ ูุงููู ุจุฒุ ุงุญุชูุงู $P(y|x)$ ุฑุง ูุญุงุณุจู ูโฺฉููุฏ. ุงูุง ูุฏูโูุง **Discriminative** ูุงููุฏ Logistic Regression ูุณุชููุงู $P(y|x)$ ุฑุง ูุฏู ูโฺฉููุฏ. ุงู ุจุงุนุซ ูโุดูุฏ ุฏูุช ุทุจููโุจูุฏ ุจุงูุงุชุฑ ูู ูุฏุฑุช ุชููุฏ ุฏุงุฏู ฺฉูุชุฑ ุจุงุดุฏ.

---

ุงฺฏุฑ ุจุฎูุง ูโุชููู ุจุฑุงุช:

* ฑฐ ุง ฒฐ ุณูุงู ูุตุงุญุจูโุง ุจุง ูพุงุณุฎ ููููู ุงุฒ ููู ูุจุญุซ ุจููุณู
* ุง ุงุฏุงูู ุจุฏู ุจู ุฌูุณู ต (ุงฺฏู ูุงูุด ุฑู ุจุฑุงู ุจูุฑุณุช)

๐ฉ ุขูุงุฏูโุง ุจุฑุง ุณูุงูุงุช ูุตุงุญุจูโุง Logistic Regressionุ


ูููโุงูุนุงุฏู! ๐ง ุญุงูุง ุจุฑุงุณุงุณ ูุงู ุฌูุณู ุณูู ฺฉู ููุถูุนุด **ุฑฺฏุฑุณูู ูุฌุณุชฺฉ (Logistic Regression)** ูุณุชุ ุจุฑุงุช ฺฉ **ุฌุฒููโ ฺฉุงููุ ุขููุฒุด ู ููููู** ุชูู ูโฺฉููุ ุจุง ุณุงุฎุชุงุฑ ุฏูู ูุซู ุฌูุณุงุช ูุจูุ ู ูุฑ ุจุฎุดุด ุดุงูู ุญุฏูุฏ ธ ุชุง ฑฐ ุฎุท ุชูุถุญ ุงุฏฺฏุฑโูุญูุฑ.

---

## ๐ ุฌุฒูู ุขููุฒุด ุฌูุณู ด

### ููุถูุน: ุฑฺฏุฑุณูู ูุฌุณุชฺฉ (Logistic Regression)

ุจุฑฺฏุฑูุชู ุงุฒ ุงุณูุงุฏูุง ุฏฺฉุชุฑ ุนู ุดุฑู ุฒุงุฑุน โ ุฏุงูุดฺฏุงู ุตูุนุช ุดุฑู

---

### 1. ููุฏูู: ฺุฑุง ุฑฺฏุฑุณูู ูุฌุณุชฺฉุ

ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ูุฏู ุจุฑุง ุญู ูุณุงุฆู **ุทุจููโุจูุฏ ุฏูุฏู** ุงุณุช. ูุซูุงู ุชุดุฎุต ุงุณูพู ุจูุฏู ุงููุ ุฎูุดโุฎู ุง ุจุฏุฎู ุจูุฏู ุชูููุฑุ ุง ูพุดโุจู ุชุฑฺฉ ฺฉุงุฑ. ุจุฑุฎูุงู ุฑฺฏุฑุณูู ุฎุท ฺฉู ุฎุฑูุฌ ุฑุง ุจูโุตูุฑุช ููุฏุงุฑ ูพูุณุชู ูพุดโุจู ูโฺฉูุฏุ ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ูโุฎูุงูู ุฎุฑูุฌ ุจู ฐ ู ฑ ุจุงุดุฏ (ุนู ุงุญุชูุงู ุชุนูู ุจู ฺฉูุงุณ ูุซุจุช). ุจูุงุจุฑุงู ุจู ฺฉ ุชุงุจุน ูุงุฒ ุฏุงุฑู ฺฉู ุฎุฑูุฌโุงุด ุฏุฑ ุจุงุฒู \[0,1] ุจุงุดุฏ.

---

### 2. ฺุฑุง ููโุชูุงู ุงุฒ ุฑฺฏุฑุณูู ุฎุท ุจุฑุง ุทุจููโุจูุฏ ุงุณุชูุงุฏู ฺฉุฑุฏุ

ุงฺฏุฑ ุงุฒ ุฑฺฏุฑุณูู ุฎุท ุงุณุชูุงุฏู ฺฉููุ ููฺฉู ุงุณุช ุฎุฑูุฌ ูุฏู (hฮธ(x)) ููุงุฏุฑ ุฎุงุฑุฌ ุงุฒ ุจุงุฒู \[0,1] ุชููุฏ ฺฉูุฏ (ูุซูุงู 1.5 ุง -0.3). ุงู ููุงุฏุฑ ุฑุง ููโุชูุงู ุจูโุนููุงู ุงุญุชูุงู ุชูุณุฑ ฺฉุฑุฏ. ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉุ ูุง ุชุงุจุน ูโุฎูุงูู ฺฉู ุฎุฑูุฌโุงุด **ููุดู ุจู ุตูุฑ ู ฺฉ** ุจุงุดุฏ ุชุง ุจุชูุงูุฏ ุงุญุชูุงู ุชุนูู ุจู ฺฉูุงุณ ฑ ุฑุง ุจุงู ฺฉูุฏ.

---

### 3. ุชุงุจุน ุณฺฏููุฏ (Sigmoid Function)

ุจุฑุง ุฑุณุฏู ุจู ุฎุฑูุฌ ุจู ฐ ู ฑุ ุงุฒ ุชุงุจุน **ุณฺฏููุฏ** ุงุณุชูุงุฏู ูโฺฉูู:

$$
ฯ(z) = \frac{1}{1 + e^{-z}}
$$

ุงู ุชุงุจุน ูุฑูุ ูุดุชูโูพุฐุฑ ู ุจูโุฎูุจ ุฏุฑ ูุญุฏูุฏู \[0,1] ุชุนุฑู ุดุฏู ุงุณุช. ููุช ูุฑูุฏ ุจุฒุฑฺฏ ุจุงุดุฏุ ุฎุฑูุฌ ูุฒุฏฺฉ ุจู ฑ ู ููุช ูุฑูุฏ ุฎู ููู ุจุงุดุฏุ ุฎุฑูุฌ ูุฒุฏฺฉ ุจู ฐ ูโุดูุฏ. ุจูุงุจุฑุงู ุฎุฑูุฌ ุฑุง ุจูโุตูุฑุช ุงุญุชูุงู ุชูุณุฑ ูโฺฉูู.

---

### 4. ุชุงุจุน ุชุตูู ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉ

ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉุ ุชุงุจุน ุชุตูู ููุงู ุชุงุจุน ุณฺฏููุฏ ุงุฒ ุชุฑฺฉุจ ุฎุท ูฺฺฏโูุงุณุช:

$$
h(x) = ฯ(w^T x)
$$

ุจุฑุง ูพุดโุจู ฺฉูุงุณุ ุงุฒ ุขุณุชุงูู ฐ.ต ุงุณุชูุงุฏู ูโุดูุฏ:

* ุงฺฏุฑ $h(x) โฅ 0.5$ โ ฺฉูุงุณ ฑ
* ุงฺฏุฑ $h(x) < 0.5$ โ ฺฉูุงุณ ฐ
  ุงู ูุฑุฒ ุชุตูู ุฏุฑ ูุถุง ูฺฺฏโูุง ฺฉ **ูุงูพุฑูพูู ุฎุท** ุฎูุงูุฏ ุจูุฏ.

---

### 5. ุณุทุญ ุชุตูู (Decision Boundary)

ุณุทุญ ุชุตูู ูุญูโูุง ุงุณุช ฺฉู ุงุญุชูุงู ูพุดโุจู ฺฉูุงุณ ฐ ู ฑ ุจุฑุงุจุฑ ุงุณุช. ุนู ุฒูุงู ฺฉู:

$$
ฯ(w^T x) = 0.5
\Rightarrow w^T x = 0
$$

ุงู ุนู ูุฑุฒ ุชุตูู ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉ **ููุงููุฏ ูุฏู ุฎุทุ ฺฉ ูุฑุฒ ุฎุท (ุง ุบุฑุฎุท ุจุง ุชุจุฏู ูฺฺฏโูุง)** ุงุณุช. ุงูุจุชู ุฏุฑ ุตูุฑุช ุงุณุชูุงุฏู ุงุฒ ูฺฺฏโูุง ุบุฑุฎุทุ ุงู ูุฑุฒ ูโุชูุงูุฏ ูพฺุฏูโุชุฑ ุดูุฏ.

---

### 6. ุจุฑุขูุฑุฏ ุจุดูู ุฏุฑุณุชโููุง (Maximum Likelihood Estimation)

ุจุฑุง ุงุฏฺฏุฑ ูพุงุฑุงูุชุฑูุง wุ ุงุฒ ุฑูุด **ุจุดููโุณุงุฒ ุชุงุจุน ุฏุฑุณุชโููุง (MLE)** ุงุณุชูุงุฏู ูโฺฉูู. ุชุงุจุน ุงุญุชูุงู ุจู ุดฺฉู ุฒุฑ ุงุณุช:

$$
P(y|x,w) = ฯ(w^T x)^y (1 - ฯ(w^T x))^{1-y}
$$

ู ุชุงุจุน ูฺฏุงุฑุชู ุฏุฑุณุชโููุง:

$$
\log L = \sum_i y^{(i)} \log(ฯ(w^T x^{(i)})) + (1 - y^{(i)}) \log(1 - ฯ(w^T x^{(i)}))
$$

ูุฏู ุงุฏฺฏุฑุ ุจุดูู ฺฉุฑุฏู ุงู ููุฏุงุฑ ุงุณุช.

---

### 7. ุชุงุจุน ูุฒูู ู ูุดุชู ุขู

ุชุงุจุน ูุฒูู ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ููุงู ููู ูฺฏุงุฑุชู ุฏุฑุณุชโููุง ุงุณุช:

$$
J(w) = -\sum_i y^{(i)} \log(ฯ(w^T x^{(i)})) + (1 - y^{(i)}) \log(1 - ฯ(w^T x^{(i)}))
$$

ุงู ุชุงุจุน **ฺฉูููฺฉุณ (Convex)** ุงุณุชุ ุจูุงุจุฑุงู ฺฏุฑุงุฏุงู ุฏุณูุช ูโุชูุงูุฏ ุจูโุฑุงุญุช ูููู ุขู ุฑุง ูพุฏุง ฺฉูุฏ. ูุดุชู ุขู ุจุฑุง ูุฑ ููููู:

$$
\nabla J(w) = \sum_i (ฯ(w^T x^{(i)}) - y^{(i)}) x^{(i)}
$$

---

### 8. ููุงุณู ุจุง ฺฏุฑุงุฏุงู ุฑฺฏุฑุณูู ุฎุท

ุฏุฑ ุฑฺฏุฑุณูู ุฎุท ฺฏุฑุงุฏุงู ุจู ุตูุฑุช:

$$
\nabla J(w) = \sum (w^T x - y) x
$$

ุฏุฑ ุญุงู ฺฉู ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉุ ุชููุง ุชูุงูุช ุฏุฑ ูุฌูุฏ ุชุงุจุน ุบุฑุฎุท ุณฺฏููุฏ ุงุณุช. ุงู ุชูุงูุช ุจุงุนุซ ูโุดูุฏ ุงุฏฺฏุฑ ุจุฑ ุงุณุงุณ **ุงุญุชูุงู ุชุนูู ุจู ฺฉูุงุณโูุง** ุตูุฑุช ฺฏุฑุฏุ ูู ููุท ูุงุตูู ุงุฒ ููุฏุงุฑ ุนุฏุฏ.

---

### 9. ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ฺูุฏฺฉูุงุณู (Softmax Regression)

ุฏุฑ ูุณุงุฆู ฺูุฏฺฉูุงุณูุ ุฎุฑูุฌ ููุท ุจู ฐ ู ฑ ูุณุช. ุฏุฑ ุงูุฌุงุ ุจู ุฌุง ุชุงุจุน ุณฺฏููุฏ ุงุฒ **ุชุงุจุน softmax** ุงุณุชูุงุฏู ูโุดูุฏ:

$$
P(y=k|x) = \frac{\exp(w_k^T x)}{\sum_j \exp(w_j^T x)}
$$

ุจุฑุง ูุฑ ฺฉูุงุณ ฺฉ ุจุฑุฏุงุฑ ูุฒู ูุฌุฒุง ุชุนุฑู ูโุดูุฏ. ูุฌููุน ุฎุฑูุฌโูุง softmax ุจุฑุงุจุฑ ุจุง ฑ ุงุณุชุ ุจูุงุจุฑุงู ุฎุฑูุฌโูุง ูุงุจู ุชูุณุฑ ุจูโุนููุงู ุงุญุชูุงู ูุณุชูุฏ.

---

### 10. ุฏุฏฺฏุงู ุงุญุชูุงูุงุช: ูุฏูโูุง ฺฏุดุชุงูุฑุฒุง (Generative) ู ุชูฺฉฺฉโฺฏุฑ (Discriminative)

ูุฏูโูุง **Generative** ูุซู Naive Bayes ุงุจุชุฏุง $P(x|C_k)$ ู $P(C_k)$ ุฑุง ูุฏู ูโฺฉููุฏ ู ุจุง ูุงููู ุจุฒ $P(C_k|x)$ ุฑุง ูโุณุงุฒูุฏ. ูู ูุฏูโูุง **Discriminative** ูุซู Logistic Regression ูุณุชููุงู $P(C_k|x)$ ุฑุง ูุฏู ูโฺฉููุฏ. ุงู ุจุงุนุซ ูโุดูุฏ ูุฏูโูุง ุชูฺฉฺฉโฺฏุฑ ูุนูููุงู ุฏุฑ ุฏูุช ุทุจููโุจูุฏ ุนููฺฉุฑุฏ ุจูุชุฑ ุฏุงุดุชู ุจุงุดูุฏุ ูู ุชูุงูุง ุชููุฏ ุฏุงุฏู ูุฏุงุฑูุฏ.

---

ุงฺฏุฑ ุชุฃุฏ ฺฉูุ ุฏุฑ ูุฑุญููโ ุจุนุฏ:

โ ุงู ุฌุฒูู ุฑู ุจูโุตูุฑุช ูุงู PDF ุญุฑููโุง ู ูุงุฑุณ ุทุฑุงุญ ูโฺฉูู
โ ู ูุฌููุนู ุณุคุงูุงุช ูุตุงุญุจูโุง ูุฑุชุจุท ุจุง ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ุฑู ูู ุจุฑุงุช ุขูุงุฏู ูโฺฉูู (ุฏุฑ ุฏู ุณุทุญ: ููููู ู ุชฺฉูฺฉ)

๐ข ุงุฏุงูู ุจุฏูุ

ุงูุจุชู! ุฏุฑ ุงุฏุงูู ุจุงุฒููุณ ู ุจุงุฒุขุฑุง ูุชู ุฌุฒูู ุขููุฒุด ุดูุง ุจุง ุญูุธ ุฌุงูุนุช ู ุณุงุฎุชุงุฑ ุชุฎุตุตุ ูู ุจุง ุฒุจุงู ุฑูุงูโุชุฑ ู ุฑูุงูโุชุฑ ุงุฑุงุฆู ุดุฏู ุงุณุช:

---

๐ **ุฌุฒูู ุขููุฒุด ุฏุฑุณ ุงุฏฺฏุฑ ูุงุดู (CE 40717)**
**ููุถูุน: ุฑฺฏุฑุณูู ูุฌุณุชฺฉ (Logistic Regression)**
**ุชุงุฑุฎ: ต ุงฺฉุชุจุฑ ฒฐฒด**
**ูุฏุฑุณ: ุฏฺฉุชุฑ ุนู ุดุฑูโุฒุงุฑฺ**
**ุชูู ู ุชูุธู: ุฏุงูุงู ุบุฑุจ (ูุฑุงุด ู ุชฺฉูู)**

---

### ฑ. ููุฏูู: ฺุฑุง ุฑฺฏุฑุณูู ูุฌุณุชฺฉุ

ุฑฺฏุฑุณูู ูุฌุณุชฺฉ (Logistic Regression - LR) ฺฉ ุงุฒ ุงูฺฏูุฑุชูโูุง ูพุงู ู ููู ุงุฏฺฏุฑ ูุงุดู ุงุณุช ฺฉู ุจูโุฎุตูุต ุจุฑุง ูุณุงุฆู ุทุจููโุจูุฏ ุฏูุฏู ฺฉุงุฑุจุฑุฏ ุฏุงุฑุฏ. ุจุฑ ุฎูุงู ุฑฺฏุฑุณูู ุฎุท ฺฉู ุฎุฑูุฌ ูพูุณุชู ูพุดโุจู ูโฺฉูุฏุ ูุฏู ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ุงู ุงุณุช ฺฉู ุงุญุชูุงู ุชุนูู ููููู ุจู ฺฉ ฺฉูุงุณ ุฎุงุต (ูุซูุงู ฺฉูุงุณ ูุซุจุช) ุฑุง ุจู ุตูุฑุช ุนุฏุฏ ุจู ฐ ู ฑ ุจุฑฺฏุฑุฏุงูุฏ.

**ูุซุงูโูุง ุฑุงุฌ ุฏุฑ ุทุจููโุจูุฏ ุฏูุฏู:**

* ุชุดุฎุต ุงูู ุงุณูพู ุง ุบุฑ ุงุณูพู
* ุชุดุฎุต ุชุฑุงฺฉูุดโูุง ฺฉูุงูุจุฑุฏุงุฑ ุง ูุงูุน
* ุชุดุฎุต ุชูููุฑ ุจุฏุฎู ุง ุฎูุดโุฎู

ุฏุฑ ุงู ูุณุงุฆูุ ูุนูููุงู ุจุฑฺุณุจโูุง ุจู ุตูุฑุช ฐ ู ฑ ุชุนุฑู ูโุดููุฏุ
ฐ ูุดุงูโุฏููุฏู ฺฉูุงุณ ููู (ูุซูุงู ุชูููุฑ ุฎูุดโุฎู) ู ฑ ูุดุงูโุฏููุฏู ฺฉูุงุณ ูุซุจุช (ูุซูุงู ุชูููุฑ ุจุฏุฎู).

---

### ฒ. ฺุฑุง ุฑฺฏุฑุณูู ุฎุท ุจุฑุง ุทุจููโุจูุฏ ููุงุณุจ ูุณุชุ

ุงฺฏุฑ ุจุฎูุงูู ุงุฒ ุฑฺฏุฑุณูู ุฎุท ุจุฑุง ุทุจููโุจูุฏ ุงุณุชูุงุฏู ฺฉููุ ฺูุฏ ูุดฺฉู ุงุณุงุณ ูพุด ูโุขุฏ:

* **ุฎุฑูุฌโูุง ุฎุงุฑุฌ ุงุฒ ุจุงุฒู \[0,1]:** ุฑฺฏุฑุณูู ุฎุท ููฺฉู ุงุณุช ููุงุฏุฑ ฺฉูุชุฑ ุงุฒ ุตูุฑ ุง ุจุฒุฑฺฏโุชุฑ ุงุฒ ฺฉ ูพุดโุจู ฺฉูุฏ ฺฉู ูุนูุง ุงุญุชูุงู ูุฏุงุฑูุฏ.
* **ุญุณุงุณุช ุจู ุฏุงุฏูโูุง ูพุฑุช:** ุฏุงุฏูโูุง ูพุฑุช ูโุชูุงููุฏ ุชุงุซุฑ ูุงูุทููุจ ุจุฑ ูุฏู ฺฏุฐุงุดุชู ู ูุฑุฒ ุชุตููโฺฏุฑ ูุงููุงุณุจ ุงุฌุงุฏ ฺฉููุฏ.
  ุจูุงุจุฑุงูุ ูุงุฒููุฏ ุชุงุจุน ูุณุชู ฺฉู ุฎุฑูุฌโุงุด ุจู ุทูุฑ ุทุจุน ูุญุฏูุฏ ุจู ุจุงุฒู \[0,1] ุจูุฏู ู ุจู ุนููุงู ุงุญุชูุงู ูุงุจู ุชูุณุฑ ุจุงุดุฏ.

---

### ณ. ุชุงุจุน ุณฺฏููุฏ (Sigmoid Function)

ุชุงุจุน ุณฺฏููุฏ ุง ูุฌุณุชฺฉุ ุจู ุนููุงู ฺฉ ุชุงุจุน ูุนุงูโุณุงุฒ ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ุจู ฺฉุงุฑ ูโุฑูุฏ ุชุง ุฎุฑูุฌ ูุฏู ุฑุง ุฏุฑ ุจุงุฒูโ \[0,1] ูฺฏู ุฏุงุฑุฏ. ูุฑููู ุขู ุจู ุตูุฑุช ุฒุฑ ุงุณุช:

$$
\sigma(z) = \frac{1}{1 + e^{-z}}
$$

ูฺฺฏโูุง ููู ุชุงุจุน ุณฺฏููุฏ:

* ุฎุฑูุฌ ููุดู ุจู ฐ ู ฑ ุงุณุช.
* ุชุงุจุน ูููุงุฑ ู ูุงุจู ูุดุชู ุงุณุชุ ฺฉู ุจุฑุง ุจูููโุณุงุฒ ุถุฑูุฑ ุงุณุช.
* ุฎุฑูุฌ ุฑุง ูโุชูุงู ุจู ุนููุงู ุงุญุชูุงู ุดุฑุท ุชุนูู ููููู ุจู ฺฉูุงุณ ูุซุจุช ุชุนุจุฑ ฺฉุฑุฏ:

$$
P(y=1|x,w) = \sigma(w^T x)
$$

ู ุงุญุชูุงู ฺฉูุงุณ ููู:

$$
P(y=0|x,w) = 1 - \sigma(w^T x)
$$

ูุซูุงู ุงฺฏุฑ ุฎุฑูุฌ ุจุฑุงุจุฑ ฐ.ท ุจุงุดุฏุ ุนู ทฐูช ุงุญุชูุงู ุชุนูู ููููู ุจู ฺฉูุงุณ ูุซุจุช ูุฌูุฏ ุฏุงุฑุฏ.

---

### ด. ุชุงุจุน ุชุตูู ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉ

ูุฏู ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ุฎุฑูุฌ ุฎูุฏ ุฑุง ุจุง ุชุฑฺฉุจ ุฎุท ูฺฺฏโูุง ู ุงุนูุงู ุชุงุจุน ุณฺฏููุฏ ูโุณุงุฒุฏ:

$$
h(x) = \sigma(w^T x)
$$

ูุงุนุฏู ุชุตููโฺฏุฑ ุจู ุดฺฉู ุฒุฑ ุงุณุช:

* ุงฺฏุฑ $h(x) \geq 0.5$ ูพุดโุจู ฺฉูุงุณ ฑ
* ุงฺฏุฑ $h(x) < 0.5$ ูพุดโุจู ฺฉูุงุณ ฐ

---

### ต. ูุฑุฒ ุชุตูู (Decision Boundary)

ูุฑุฒ ุชุตูู ูุงุญูโุง ุงุณุช ฺฉู ูุฏู ุจู ุฏู ฺฉูุงุณ ูุฑุฏุฏ ุงุณุชุ ุนู ุงุญุชูุงู ุชุนูู ููููู ุจู ูุฑ ุฏู ฺฉูุงุณ ุจุฑุงุจุฑ ุงุณุช. ุงู ููุทู ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ููฺฏุงู ุฑุฎ ูโุฏูุฏ ฺฉู:

$$
\sigma(w^T x) = 0.5 \quad \Rightarrow \quad w^T x = 0
$$

ูุนุงุฏูู ููู ฺฉ **ูุงูพุฑูพูู ุฎุท** ุฏุฑ ูุถุง ูฺฺฏโูุง ุชุนุฑู ูโฺฉูุฏุ ฺฉู ูุดุงูโุฏููุฏู ูุฑุฒ ุชุตูู ุงุณุช.

**ูฺฉุชู:**
ุจุฑุง ุงุฏฺฏุฑ ูุฑุฒูุง ุบุฑุฎุทุ ูโุชูุงู ูฺฺฏโูุง ุฌุฏุฏ ุดุงูู ุชูุงุจุน ุฏุฑุฌู ุจุงูุงุชุฑ (ูุซูุงู ุชูุงูโูุง $x_1^2$ุ ุชุฑฺฉุจโูุง ฺูุฏ ูุชุบุฑู ู...) ุจู ูุฏู ุงูุฒูุฏ.

---

### ถ. ุจุฑุขูุฑุฏ ุจุดูู ุฏุฑุณุชโููุง (MLE)

ูุฏู ุงุตู ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ุงูุชู ูพุงุฑุงูุชุฑ $w$ ุงุณุช ฺฉู ุจุดุชุฑู ุงุญุชูุงู ูุดุงูุฏุงุช ุฏุงุฏูโูุง ุขููุฒุด ุฑุง ุงุฌุงุฏ ฺฉูุฏ. ุจุฑุง ฺฉ ููููู $i$ุ ุงุญุชูุงู ูุดุงูุฏู ุขู ุจุง ุชูุฌู ุจู ูุฏู ุจู ุตูุฑุช ุฒุฑ ุงุณุช:

$$
P(y^{(i)}|x^{(i)},w) = \sigma(w^T x^{(i)})^{y^{(i)}} (1 - \sigma(w^T x^{(i)}))^{1 - y^{(i)}}
$$

ุชุงุจุน ุฏุฑุณุชโููุง ฺฉู ุฏุงุฏู (ูุฑุถ ุงุณุชููุงู ูููููโูุง):

$$
L(w) = \prod_{i=1}^{n} P(y^{(i)}|x^{(i)},w)
$$

ุจุฑุง ุณุงุฏูโุณุงุฒ ุจูููโุณุงุฒุ ูุนูููุงู ุงุฒ ูฺฏุงุฑุชู ุฏุฑุณุชโููุง ุงุณุชูุงุฏู ูโฺฉูู:

$$
\log L(w) = \sum_{i=1}^n \left[ y^{(i)} \log \sigma(w^T x^{(i)}) + (1 - y^{(i)}) \log (1 - \sigma(w^T x^{(i)})) \right]
$$

---

### ท. ุชุงุจุน ูุฒูู ู ูุดุชู ุขู

ุชุงุจุน ูุฒูู ุฑุง ุจู ุตูุฑุช ููู ูฺฏุงุฑุชู ุฏุฑุณุชโููุง ุชุนุฑู ูโฺฉูู ุชุง ูุณุฆูู ุฑุง ุจู ุตูุฑุช ฺฉูููโุณุงุฒ ุฏุฑุขูุฑู:

$$
J(w) = - \sum_{i=1}^n \left[ y^{(i)} \log \sigma(w^T x^{(i)}) + (1 - y^{(i)}) \log (1 - \sigma(w^T x^{(i)})) \right]
$$

ุงู ุชุงุจุน ฺฉู ุจู ูุงู **Binary Cross-Entropy Loss** ุดูุงุฎุชู ูโุดูุฏุ ูฺฺฏ ูุญุฏุจ ุจูุฏู ุฏุงุฑุฏ ู ุจู ุงู ูุนู ุงุณุช ฺฉู ุงูฺฏูุฑุชูโูุง ูุงููุฏ ฺฏุฑุงุฏุงู ุฏุณูุช ุชุถูู ููฺฏุฑุง ุจู ุจููู ุณุฑุงุณุฑ ุฑุง ุฏุงุฑูุฏ.

---

### ธ. ฺฏุฑุงุฏุงู ุฏุณูุช ุจุฑุง ุฑฺฏุฑุณูู ูุฌุณุชฺฉ

ฺูู ุฑุงู ุญู ุชุญูู ุจุฑุง ฺฉููู ฺฉุฑุฏู $J(w)$ ูุฌูุฏ ูุฏุงุฑุฏุ ุงุฒ ุงูฺฏูุฑุชูโูุง ุชฺฉุฑุงุฑ ูุงููุฏ ฺฏุฑุงุฏุงู ุฏุณูุช ุงุณุชูุงุฏู ูโุดูุฏ:

ูุงุนุฏู ุจูโุฑูุฒุฑุณุงู ูพุงุฑุงูุชุฑูุง:

$$
w^{t+1} = w^t - \eta \nabla_w J(w^t)
$$

ฺฏุฑุงุฏุงู ุชุงุจุน ูุฒูู ูุณุจุช ุจู $w$ ุจุฑุงุจุฑ ุงุณุช ุจุง:

$$
\nabla_w J(w) = \sum_{i=1}^n (\sigma(w^T x^{(i)}) - y^{(i)}) x^{(i)}
$$

ุชูุฌู ฺฉูุฏ ฺฉู ุงู ฺฏุฑุงุฏุงู ุดุจุงูุช ุฒุงุฏ ุจู ฺฏุฑุงุฏุงู ุฑฺฏุฑุณูู ุฎุท ุฏุงุฑุฏุ ุจุง ุงู ุชูุงูุช ฺฉู ุจู ุฌุง $w^T x^{(i)}$ ุงุฒ $\sigma(w^T x^{(i)})$ ุงุณุชูุงุฏู ูโุดูุฏ.

---

### น. ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ฺูุฏฺฉูุงุณู (Softmax Regression)

ููุช ุชุนุฏุงุฏ ฺฉูุงุณโูุง ุจุด ุงุฒ ุฏู ุชุง ุจุงุดุฏุ ุงุฒ ุชุนูู ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ุจู ูุงู Softmax Regression ุงุณุชูุงุฏู ูโฺฉูู.

ุชุงุจุน Softmax ุงุญุชูุงู ุชุนูู ููููู ุจู ฺฉูุงุณ $k$ ุฑุง ุจู ุตูุฑุช ุฒุฑ ูุฏู ูโฺฉูุฏ:

$$
P(y=k|x,W) = \frac{e^{w_k^T x}}{\sum_{j=1}^K e^{w_j^T x}}
$$

ฺฉู $w_k$ ูุฒู ูุฑุจูุท ุจู ฺฉูุงุณ $k$ ุงุณุช.

ูฺฺฏโูุง Softmax:

* ูุฌููุน ุฎุฑูุฌโูุง ุจุฑุง ููู ฺฉูุงุณโูุง ุจุฑุงุจุฑ ฑ ุงุณุช.
* ุชุงุจุน ูููุงุฑ ู ูุงุจู ูุดุชู ุงุณุช.
* ุงุญุชูุงู ุจุดุชุฑู ฺฉูุงุณ ุฑุง ุจุฑุฌุณุชู ูโฺฉูุฏ.
* ูโุชูุงูุฏ ูุฑูุฏโูุง ููู ุฑุง ุจู ุฎูุจ ูพุฑุฏุงุฒุด ฺฉูุฏ.

ูุงุนุฏู ุชุตููโฺฏุฑ: ุงูุชุฎุงุจ ฺฉูุงุณ ฺฉู ุจุดุชุฑู ุงุญุชูุงู ุฑุง ุฏุงุดุชู ุจุงุดุฏ.

ุชุงุจุน ูุฒูู Cross-Entropy ฺูุฏฺฉูุงุณู ุจู ุดฺฉู ุฒุฑ ุงุณุช:

$$
J(W) = - \sum_{i=1}^n \sum_{k=1}^K y_k^{(i)} \log P(y=k|x^{(i)}, W)
$$

ฺฉู $y_k^{(i)}$ ููุฏุงุฑ ุจุงูุฑ ูุดุงูโุฏููุฏู ุชุนูู ููููู $i$ ุจู ฺฉูุงุณ $k$ ุงุณุช.

ฺฏุฑุงุฏุงู ุชุงุจุน ูุฒูู ูุณุจุช ุจู ูุฒู ฺฉูุงุณ $j$:

$$
\nabla_{w_j} J(W) = \sum_{i=1}^n \left( P(y=j|x^{(i)}, W) - y_j^{(i)} \right) x^{(i)}
$$

---

### ฑฐ. ุฏุฏฺฏุงู ุงุญุชูุงูุงุช: ูุฏูโูุง ูููุฏ (Generative) ู ุชูุงุฒ (Discriminative)

ูุฏูโูุง ุงุฏฺฏุฑ ูุงุดู ุฑุง ูโุชูุงู ุจุฑ ุงุณุงุณ ูุญูู ูุฏูโุณุงุฒ ุชูุฒุนโูุง ุงุญุชูุงูุงุช ุจู ุฏู ุฏุณุชู ุชูุณู ฺฉุฑุฏ:

* **ูุฏูโูุง ูููุฏ (Generative):**

  * ุชูุฒุน ุชูุงู $P(x,y)$ ุฑุง ุงุฏ ูโฺฏุฑูุฏ.
  * ุจุฑุง ูุฑ ฺฉูุงุณ ุชูุฒุน $P(x|C_k)$ ู ุงุญุชูุงู ูพุดู $P(C_k)$ ุฑุง ุจุฑุขูุฑุฏ ูโฺฉููุฏ.
  * ุณูพุณ ุจุง ูุงููู ุจุฒ ุงุญุชูุงู ูพุณู $P(C_k|x)$ ุฑุง ูุญุงุณุจู ู ูพุดโุจู ูโฺฉููุฏ.
  * ุนูุงูู ุจุฑ ุทุจููโุจูุฏุ ูโุชูุงููุฏ ุฏุงุฏูโูุง ุฌุฏุฏ ุชููุฏ ฺฉููุฏ.
  * ูุซุงู: Naive Bayes.

* **ูุฏูโูุง ุชูุงุฒ (Discriminative):**

  * ูุณุชููุงู ุชูุฒุน ุดุฑุท $P(y|x)$ ุฑุง ูุฏู ูโฺฉููุฏ.
  * ุจู ุฌุง ูุฏูโุณุงุฒ ุฏุงุฏูุ ูุฑุฒ ุชุตูู ุฑุง ูโุงุจูุฏ.
  * ุชูุฑฺฉุฒ ุงุตู ุจุฑ ุฏูุช ุทุจููโุจูุฏ ุงุณุช ู ูุนูููุงู ุฏุงุฏู ุฌุฏุฏ ุชููุฏ ููโฺฉููุฏ.
  * ูุซุงู: ุฑฺฏุฑุณูู ูุฌุณุชฺฉ.

| ูฺฺฏ         | ูุฏู ูููุฏ (Generative)       | ูุฏู ุชูุงุฒ (Discriminative) |                      |     |
| ------------- | --------------------------- | --------------------------- | -------------------- | --- |
| ูุฏู ุงุฏฺฏุฑ   | ูุฏูโุณุงุฒ $P(x,y)$           | ูุฏูโุณุงุฒ ูุณุชูู (P(y        | x))                  |     |
| ูุญูู ูพุดโุจู | ุงุณุชูุงุฏู ุงุฒ ูุงููู ุจุฒ ู (P(x | y), P(y))                   | ูพุดโุจู ูุณุชูู (P(y | x)) |
| ฺฉุงุฑุจุฑุฏ ุฏฺฏุฑ   | ุงูฺฉุงู ุชููุฏ ุฏุงุฏูโูุง ุฌุฏุฏ   | ุชูุฑฺฉุฒ ุฑู ุทุจููโุจูุฏ ุฏูู    |                      |     |
| ูุซุงูโูุง       | Naive Bayes                 | Logistic Regression, SVM    |                      |     |

---

### ุฎูุงุตู ุฑฺฏุฑุณูู ูุฌุณุชฺฉ

* ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ฺฉ ุทุจููโุจูุฏโฺฉููุฏู ุฎุท ุงุณุช (ูฺฏุฑ ุขูฺฉู ูฺฏุงุดุช ูฺฺฏโูุง ุบุฑุฎุท ุงุนูุงู ุดูุฏ).
* ุจูููโุณุงุฒ ุขู ุจุง ุฑูุด ุจุดูู ุฏุฑุณุชโููุง (MLE) ุงูุฌุงู ูโุดูุฏ.
* ุฑุงูโุญู ุชุญูู ูุฌูุฏ ูุฏุงุฑุฏุ ูู ุชุงุจุน ูุฒูู ุขู ูุญุฏุจ ุงุณุช.
* ุงู ูุญุฏุจ ุจูุฏู ุชุถูู ูโฺฉูุฏ ฺฉู ุงูฺฏูุฑุชูโูุง ฺฏุฑุงุฏุงู ุฏุณูุช ุจู ุจููู ุณุฑุงุณุฑ ููฺฏุฑุง ุดููุฏ.

---

**ููุงุจุน:**

1. M. Soleymani Baghshah, "Machine learning." Lecture slides.
2. A. Ng, "Ml-005, lecture 6." Lecture slides.
3. C. M. Bishop, Pattern Recognition and Machine Learning, Springer, 2006.
4. S. Fidler, "Csc411." Lecture slides.
5. A. Ng and T. Ma, CS229 Lecture Notes. Updated June 11, 2023.
   ... (ู ุณุงุฑ ููุงุจุน)

---

ุงฺฏุฑ ุจุฎูุงูุฏ ูโุชูุงูู ฺฉูฺฉ ฺฉูู ูุณูุชโูุง ฺฉุฏ ุง ูุซุงูโูุง ุนูู ุฑุง ูู ุงุถุงูู ฺฉููุ ุง ุจุฑุง ูุฑ ุจุฎุด ุณูุงู ุชูุฑู ุทุฑุงุญ ฺฉูู. ูุธุฑ ุดูุง ฺุณุชุ
ุงูุจุชู! ุงู ูุชู ฺฉุงููโุชุฑ ู ุงุตูุงุญโุดุฏู ุฌุฒูู ุขููุฒุด ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ุจุฏูู ุฐฺฉุฑ ููุงุจุน (ุณุงุชโูุง) ู ุจู ุตูุฑุช ูุฑุชุจ ู ุฑูุงู ุขูุงุฏู ุดุฏู ุงุณุช:

---

๐ **ุฌุฒูู ุขููุฒุด ุฏุฑุณ ุงุฏฺฏุฑ ูุงุดู (CE 40717)**
**ููุถูุน: ุฑฺฏุฑุณูู ูุฌุณุชฺฉ (Logistic Regression)**
**ุชุงุฑุฎ: ต ุงฺฉุชุจุฑ ฒฐฒด**
**ูุฏุฑุณ: ุฏฺฉุชุฑ ุนู ุดุฑูโุฒุงุฑฺ**
**ุชูู ู ุชูุธู: ุฏุงูุงู ุบุฑุจ (ุจุง ูุฑุงุด ู ุชฺฉูู)**

---

### ฑ. ููุฏูู: ฺุฑุง ุฑฺฏุฑุณูู ูุฌุณุชฺฉุ

ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ฺฉ ุงูฺฏูุฑุชู ุงุฏฺฏุฑ ูุงุดู ุงุณุช ฺฉู ุนูุฏุชุงู ุจุฑุง ุญู ูุณุงุฆู ุทุจููโุจูุฏุ ุจูโูฺู ุทุจููโุจูุฏ ุฏูุฏูุ ฺฉุงุฑุจุฑุฏ ุฏุงุฑุฏ. ุจุฑุฎูุงู ุฑฺฏุฑุณูู ุฎุท ฺฉู ฺฉ ููุฏุงุฑ ูพูุณุชู ุฑุง ูพุดโุจู ูโฺฉูุฏุ ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ูุฏู ุฏุงุฑุฏ ุชุง ุฎุฑูุฌโุง ุฑุง ุฏุฑ ุจุงุฒูโ \[0, 1] ุชููุฏ ฺฉูุฏ ฺฉู ูโุชูุงูุฏ ุจู ุนููุงู ุงุญุชูุงู ุชุนูู ฺฉ ููููู ุจู ฺฉูุงุณ "ูุซุจุช" ุชูุณุฑ ุดูุฏ.

**ูุซุงูโูุง ุงุฒ ูุณุงุฆู ุทุจููโุจูุฏ ุฏูุฏู:**

* ุงูู: ุงุณูพู ุง ุบุฑ ุงุณูพูุ
* ุชุฑุงฺฉูุดโูุง ุขููุงู: ฺฉูุงูุจุฑุฏุงุฑ ุง ูุงูุนุ
* ุชูููุฑ: ุจุฏุฎู ุง ุฎูุดโุฎูุ

ุฏุฑ ุงู ูุณุงุฆูุ ุจุฑฺุณุจ ุฎุฑูุฌ ูุนูููุงู ุจู ุตูุฑุช 0 ู 1 ุชุนุฑู ูโุดูุฏ:

* ฐ: ฺฉูุงุณ ููู (ูุซูุงู ุชูููุฑ ุฎูุดโุฎู)
* ฑ: ฺฉูุงุณ ูุซุจุช (ูุซูุงู ุชูููุฑ ุจุฏุฎู)

---

### ฒ. ฺุฑุง ููโุชูุงู ุงุฒ ุฑฺฏุฑุณูู ุฎุท ุจุฑุง ุทุจููโุจูุฏ ุงุณุชูุงุฏู ฺฉุฑุฏุ

ุฑฺฏุฑุณูู ุฎุท ุจุฑุง ูุณุงุฆู ุทุจููโุจูุฏ ููุงุณุจ ูุณุช ุฒุฑุง:

* ุฎุฑูุฌโูุง ููฺฉู ุงุณุช ุฎุงุฑุฌ ุงุฒ ุจุงุฒู \[0,1] ุจุงุดูุฏุ ูุซูุงู 1.2 ุง -0.3 ฺฉู ููโุชูุงู ุขูโูุง ุฑุง ุจู ุนููุงู ุงุญุชูุงู ุชูุณุฑ ฺฉุฑุฏ.
* ุญุณุงุณุช ุฒุงุฏ ุจู ุฏุงุฏูโูุง ูพุฑุช ูุฌูุฏ ุฏุงุฑุฏ ฺฉู ูโุชูุงูุฏ ูุฑุฒ ุชุตููโฺฏุฑ ุฑุง ุจู ุดุฏุช ุชุบุฑ ุฏูุฏ ู ุจุงุนุซ ุนููฺฉุฑุฏ ูุงููุงุณุจ ุดูุฏ.

ุจูุงุจุฑุงูุ ุจู ุชุงุจุน ูุงุฒ ุฏุงุฑู ฺฉู ุฎุฑูุฌ ุขู ุจู ุทูุฑ ุฐุงุช ุฏุฑ ุจุงุฒูโ \[0,1] ูุฑุงุฑ ฺฏุฑุฏ ู ูุงุจู ุชูุณุฑ ุจู ุนููุงู ุงุญุชูุงู ุจุงุดุฏ.

---

### ณ. ุชุงุจุน ุณฺฏููุฏ (Sigmoid Function)

ุจุฑุง ุงุทููุงู ุงุฒ ุฎุฑูุฌ ุฏุฑ ุจุงุฒู \[0,1] ุงุฒ ุชุงุจุน ุณฺฏููุฏ ุงุณุชูุงุฏู ูโฺฉูู ฺฉู ุจู ุตูุฑุช ุฒุฑ ุชุนุฑู ูโุดูุฏ:

$$
\sigma(z) = \frac{1}{1 + e^{-z}}
$$

ูฺฺฏโูุง ุชุงุจุน ุณฺฏููุฏ:

* ุฎุฑูุฌ ุฏุฑ ุจุงุฒู \[0,1] ุงุณุช.
* ุชุงุจุน ูููุงุฑ ู ูุดุชูโูพุฐุฑ ุงุณุชุ ฺฉู ุจุฑุง ุจูููโุณุงุฒ ูุงุฒู ุงุณุช.
* ุฎุฑูุฌ ุขู ุฑุง ูโุชูุงู ุจู ุนููุงู ุงุญุชูุงู ุดุฑุท \$P(y=1|x,w)\$ ุชูุณุฑ ฺฉุฑุฏุ ุนู ุงุญุชูุงู ุชุนูู ููููู ุจู ฺฉูุงุณ ูุซุจุช.

ูุซูุงู ุงฺฏุฑ ุฎุฑูุฌ 0.7 ุจุงุดุฏุ ุนู ทฐ ุฏุฑุตุฏ ุงุญุชูุงู ุชุนูู ููููู ุจู ฺฉูุงุณ ูุซุจุช ูุฌูุฏ ุฏุงุฑุฏ.

---

### ด. ุชุงุจุน ุชุตูู ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉ

ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉุ ุชุงุจุน ุชุตูู ุจู ุตูุฑุช ุชุฑฺฉุจ ุฎุท ูฺฺฏโูุง ู ุชุงุจุน ุณฺฏููุฏ ุชุนุฑู ูโุดูุฏ:

$$
h(x) = \sigma(w^T x)
$$

ฺฉู \$x\$ ุจุฑุฏุงุฑ ูฺฺฏโูุง ู \$w\$ ุจุฑุฏุงุฑ ูุฒูโูุง ุงุณุช.

ูุงุนุฏู ุชุตููโฺฏุฑ:

* ุงฺฏุฑ \$h(x) \geq 0.5\$ ูพุดโุจู ฺฉูุงุณ ฑ (ูุซุจุช) ุงุณุช.
* ุงฺฏุฑ \$h(x) < 0.5\$ ูพุดโุจู ฺฉูุงุณ ฐ (ููู) ุงุณุช.

---

### ต. ุณุทุญ ุชุตูู (Decision Boundary)

ูุฑุฒ ุชุตูู ูุงุญูโุง ุงุณุช ฺฉู ูุฏู ุจู ุฏู ฺฉูุงุณ ุจู ุตูุฑุช ูุณุงู ุชุฑุฏุฏ ุฏุงุฑุฏุ ุนู ุงุญุชูุงู ุชุนูู ุจู ูุฑ ุฏู ฺฉูุงุณ ุจุฑุงุจุฑ ุงุณุช:

$$
\sigma(w^T x) = 0.5 \implies w^T x = 0
$$

ุงู ูุนุงุฏูู ฺฉ ูุงูพุฑูพูู (ุตูุญู ุฎุท) ุฏุฑ ูุถุง ูฺฺฏโูุง ุงุณุช ฺฉู ูุฑุฒ ุชุตูู ุฑุง ุชุดฺฉู ูโุฏูุฏ.

* ุงุจุนุงุฏ ูุงูพุฑูพูู ููุดู ฺฉ ุจุนุฏ ฺฉูุชุฑ ุงุฒ ูุถุง ูฺฺฏโูุง ุงุณุช.
* ุจุฑุง ูุฑุฒูุง ุชุตูู ุบุฑุฎุทุ ูโุชูุงู ุจุง ุงูุฒูุฏู ุชุฑูโูุง ูุฑุชุจู ุจุงูุงุชุฑ ุจู ูฺฺฏโูุง (ูุซูุงู ูุฑุจุน ู ุถุฑุจ ูฺฺฏโูุง) ุงุฒ ูฺฏุงุดุช ูฺฺฏ ุงุณุชูุงุฏู ฺฉุฑุฏ.

---

### ถ. ุจุฑุขูุฑุฏ ุจุดูู ุฏุฑุณุชโููุง (Maximum Likelihood Estimation)

ูุฏู ุงูุชู ุจุฑุฏุงุฑ ูุฒู \$w\$ ุงุณุช ฺฉู ุงุญุชูุงู ูพุดโุจู ุตุญุญ ุฏุงุฏูโูุง ุขููุฒุด ุฑุง ุญุฏุงฺฉุซุฑ ฺฉูุฏ.

ุงุญุชูุงู ูุฑ ููููู ุฏุฑ ุทุจููโุจูุฏ ุฏูุฏู ุจู ุดฺฉู ุฒุฑ ุงุณุช:

$$
P(y^{(i)}|x^{(i)},w) = \sigma(w^T x^{(i)})^{y^{(i)}} (1 - \sigma(w^T x^{(i)}))^{1 - y^{(i)}}
$$

ุชุงุจุน ุฏุฑุณุชโููุง ฺฉู ุฏุงุฏูโูุง (ุจุง ูุฑุถ ุงุณุชููุงู ูููููโูุง):

$$
L(w) = \prod_{i=1}^{n} P(y^{(i)}|x^{(i)},w)
$$

ุจุฑุง ุณุงุฏูโุชุฑ ฺฉุฑุฏู ูุญุงุณุจุงุชุ ูฺฏุงุฑุชู ุชุงุจุน ุฏุฑุณุชโููุง ฺฏุฑูุชู ูโุดูุฏ:

$$
\log L(w) = \sum_{i=1}^n \left[ y^{(i)} \log(\sigma(w^T x^{(i)})) + (1 - y^{(i)}) \log(1 - \sigma(w^T x^{(i)})) \right]
$$

---

### ท. ุชุงุจุน ูุฒูู ู ูุดุชู ุขู

ุชุงุจุน ูุฒูู ุจู ุนููุงู ููู ูฺฏุงุฑุชู ุฏุฑุณุชโููุง ุชุนุฑู ูโุดูุฏ (ุจุฑุง ฺฉูููโุณุงุฒ):

$$
J(w) = - \sum_{i=1}^n \left[ y^{(i)} \log(\sigma(w^T x^{(i)})) + (1 - y^{(i)}) \log(1 - \sigma(w^T x^{(i)})) \right]
$$

ุงู ุชุงุจุน ฺฉู ุจู ูุงู **Binary Cross-Entropy Loss** ุดูุงุฎุชู ูโุดูุฏุ ูุญุฏุจ ุงุณุช ฺฉู ุชุถููโฺฉููุฏู ููฺฏุฑุง ุจู ุจููู ุณุฑุงุณุฑ ุชูุณุท ุงูฺฏูุฑุชูโูุง ฺฏุฑุงุฏุงู ุฏุณูุช ุงุณุช.

---

### ธ. ฺฏุฑุงุฏุงู ุฏุณูุช ุจุฑุง ุฑฺฏุฑุณูู ูุฌุณุชฺฉ

ุงุฒ ุขูุฌุง ฺฉู ุจุฑุง ุจูููโุณุงุฒ \$J(w)\$ ุฑุงูโุญู ุชุญูู ูุฌูุฏ ูุฏุงุฑุฏุ ุงุฒ ฺฏุฑุงุฏุงู ุฏุณูุช ุงุณุชูุงุฏู ูโฺฉูู.

ูุงุนุฏู ุจูโุฑูุฒุฑุณุงู ูุฒูโูุง:

$$
w^{t+1} = w^t - \eta \nabla_w J(w^t)
$$

ฺฉู \$\eta\$ ูุฑุฎ ุงุฏฺฏุฑ ุงุณุช.

ฺฏุฑุงุฏุงู ุชุงุจุน ูุฒูู:

$$
\nabla_w J(w) = \sum_{i=1}^n (\sigma(w^T x^{(i)}) - y^{(i)}) x^{(i)}
$$

ุงู ฺฏุฑุงุฏุงู ูุดุงุจู ฺฏุฑุงุฏุงู ุฑฺฏุฑุณูู ุฎุท ุงุณุชุ ุจุง ุงู ุชูุงูุช ฺฉู ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ุงุฒ ุฎุฑูุฌ ุชุงุจุน ุณฺฏููุฏ ุจู ุฌุง ููุฏุงุฑ ุฎุท ุงุณุชูุงุฏู ูโุดูุฏ.

---

### น. ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ฺูุฏฺฉูุงุณู (Softmax Regression)

ููุช ุชุนุฏุงุฏ ฺฉูุงุณโูุง ุจุดุชุฑ ุงุฒ ุฏู ุจุงุดุฏ (ฺฉูุงุณโูุง ฺูุฏฺฏุงูู)ุ ุงุฒ ุชุนูู ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ุจู ูุงู Softmax Regression ุงุณุชูุงุฏู ูโุดูุฏ.

ุชุงุจุน Softmax ุจุฑุง ูุฑ ฺฉูุงุณ \$k\$ ุชุนุฑู ูโุดูุฏ:

$$
P(y=k|x) = \frac{\exp(w_k^T x)}{\sum_{j=1}^K \exp(w_j^T x)}
$$

ฺฉู \$w\_k\$ ูุฒูโูุง ูุฑุจูุท ุจู ฺฉูุงุณ \$k\$ ุงุณุช.

ูฺฺฏโูุง:

* ูุฌููุน ุงุญุชูุงูุงุช ุจุฑุง ููู ฺฉูุงุณโูุง ุจุฑุงุจุฑ ฑ ุงุณุช.
* ูููุงุฑ ู ูุดุชูโูพุฐุฑ ุงุณุช.
* ุฎุฑูุฌโูุง ุงุญุชูุงู ุชุนูู ุจู ูุฑ ฺฉูุงุณ ุฑุง ุจู ุตูุฑุช ูุฑู ู ูพูุณุชู ุงุฑุงุฆู ูโฺฉููุฏ.

ูุงุนุฏู ุชุตููโฺฏุฑ: ฺฉูุงุณ ุจุง ุจุดุชุฑู ุงุญุชูุงู ุงูุชุฎุงุจ ูโุดูุฏ.

ุชุงุจุน ูุฒูู (Cross-Entropy ฺูุฏฺฉูุงุณู):

$$
J(W) = - \sum_{i=1}^n \sum_{k=1}^K y_k^{(i)} \log P(y=k|x^{(i)})
$$

ฺฉู \$y\_k^{(i)}\$ ุจุฑุงุจุฑ ฑ ุงุณุช ุงฺฏุฑ ููููู \$i\$ ุจู ฺฉูุงุณ \$k\$ ุชุนูู ุฏุงุดุชู ุจุงุดุฏ ู ุตูุฑ ุฏุฑ ุบุฑ ุงู ุตูุฑุช.

ฺฏุฑุงุฏุงู ุชุงุจุน ูุฒูู ุจุฑุง ฺฉูุงุณ \$j\$:

$$
\nabla_{w_j} J(W) = \sum_{i=1}^n (P(y=j|x^{(i)}) - y_j^{(i)}) x^{(i)}
$$

---

### ฑฐ. ุฏุฏฺฏุงู ุงุญุชูุงูุงุช ุฏุฑ ุทุจููโุจูุฏ: ูุฏูโูุง ูููุฏ ู ุชูุงุฒ

ุฏุฑ ุทุจููโุจูุฏ ูโุชูุงู ุฏู ููุน ูุฏู ฺฉู ุฏุงุดุช:

**ุงูู) ูุฏูโูุง ูููุฏ (Generative):**

* ุงุฏฺฏุฑ ุชูุฒุน ุชูุงู \$P(x,y)\$
* ุจุฑุขูุฑุฏ ุชูุฒุน ุดุฑุท \$P(x|C\_k)\$ ู ุงุญุชูุงู ูพุดู \$P(C\_k)\$
* ุงุณุชูุงุฏู ุงุฒ ูุงููู ุจุฒ ุจุฑุง ูุญุงุณุจู ุงุญุชูุงู ูพุณู \$P(C\_k|x)\$
* ุงูฺฉุงู ุชููุฏ ุฏุงุฏู ุฌุฏุฏ
* ูุซุงู: Naive Bayes

**ุจ) ูุฏูโูุง ุชูุงุฒ (Discriminative):**

* ุงุฏฺฏุฑ ูุณุชูู ุชูุฒุน ุดุฑุท \$P(y|x)\$
* ุงุฏฺฏุฑ ูุฑุฒ ุชุตูู
* ุชูุฑฺฉุฒ ุฑู ุฏูุช ุทุจููโุจูุฏ
* ูุซุงู: ุฑฺฏุฑุณูู ูุฌุณุชฺฉุ SVM

---

### ุฎูุงุตู ุฑฺฏุฑุณูู ูุฌุณุชฺฉ

* ุฑฺฏุฑุณูู ูุฌุณุชฺฉ ฺฉ ุทุจููโุจูุฏโฺฉููุฏู ุฎุท ุงุณุช (ูฺฏุฑ ุจุง ูฺฏุงุดุช ูฺฺฏโูุง ุบุฑุฎุท).
* ุจูููโุณุงุฒ ุขู ุงุฒ ุทุฑู ุจุดููโุณุงุฒ ุฏุฑุณุชโููุง ุตูุฑุช ูโฺฏุฑุฏ.
* ูฺ ุฑุงูโุญู ุชุญูู ุจุณุชูโุง ูุฏุงุฑุฏุ ุงูุง ุชุงุจุน ูุฒูู ูุญุฏุจ ุงุณุช ู ุจูููโุณุงุฒ ฺฏุฑุงุฏุงู ุฏุณูุช ูุงุจู ุงุนุชูุงุฏ ุงุณุช.

---

ุงฺฏุฑ ูุงุฒู ุจุงุดุฏ ูโุชูุงูู ุจู ุดฺฉู ฺฉุฏุ ูุฑูููโูุง ุง ูุซุงูโูุง ุจุดุชุฑ ูู ุงุถุงูู ฺฉูู. ุขุง ูโุฎูุงูุฏุ

----
ุญุชูุง! ุฏุฑ ุงุฏุงูู ูุฑูููโูุง ููู ูุชู ุฑุง ุจู ุตูุฑุช ุฏุฑุณุช ู ุจุง ูุงูุจโุจูุฏ ุฑุงุถ ุงุณุชุงูุฏุงุฑุฏ (LaTeX) ุขูุฑุฏูโุงู:

---

### ุชุงุจุน ุณฺฏููุฏ (Sigmoid Function)

$$
\sigma(z) = \frac{1}{1 + e^{-z}}
$$

---

### ุชุงุจุน ุชุตูู ุฏุฑ ุฑฺฏุฑุณูู ูุฌุณุชฺฉ

$$
h(x) = \sigma(w^T x)
$$

---

### ูุฑุฒ ุชุตูู (Decision Boundary)

$$
\sigma(w^T x) = 0.5 \implies w^T x = 0
$$

---

### ุงุญุชูุงู ููููู ุฏุฑ ุทุจููโุจูุฏ ุฏูุฏู

$$
P(y^{(i)} | x^{(i)}, w) = \sigma(w^T x^{(i)})^{y^{(i)}} \cdot \big(1 - \sigma(w^T x^{(i)})\big)^{1 - y^{(i)}}
$$

---

### ุชุงุจุน ุฏุฑุณุชโููุง (Likelihood Function)

$$
L(w) = \prod_{i=1}^n P(y^{(i)} | x^{(i)}, w)
$$

---

### ูฺฏุงุฑุชู ุชุงุจุน ุฏุฑุณุชโููุง (Log-Likelihood)

$$
\log L(w) = \sum_{i=1}^n \left[ y^{(i)} \log \big( \sigma(w^T x^{(i)}) \big) + (1 - y^{(i)}) \log \big( 1 - \sigma(w^T x^{(i)}) \big) \right]
$$

---

### ุชุงุจุน ูุฒูู (Negative Log-Likelihood)

$$
J(w) = - \sum_{i=1}^n \left[ y^{(i)} \log \big( \sigma(w^T x^{(i)}) \big) + (1 - y^{(i)}) \log \big( 1 - \sigma(w^T x^{(i)}) \big) \right]
$$

---

### ูุงุนุฏู ุจูโุฑูุฒุฑุณุงู ูุฒูโูุง ุฏุฑ ฺฏุฑุงุฏุงู ุฏุณูุช

$$
w^{t+1} = w^t - \eta \nabla_w J(w^t)
$$

---

### ฺฏุฑุงุฏุงู ุชุงุจุน ูุฒูู ูุณุจุช ุจู $w$

$$
\nabla_w J(w) = \sum_{i=1}^n \left( \sigma(w^T x^{(i)}) - y^{(i)} \right) x^{(i)}
$$

---

### ุชุงุจุน Softmax ุจุฑุง ฺฉูุงุณ $k$

$$
P(y = k | x) = \frac{\exp(w_k^T x)}{\sum_{j=1}^K \exp(w_j^T x)}
$$

---

### ุชุงุจุน ูุฒูู (Cross-Entropy) ุจุฑุง Softmax Regression

$$
J(W) = - \sum_{i=1}^n \sum_{k=1}^K y_k^{(i)} \log P(y = k | x^{(i)})
$$

---

### ฺฏุฑุงุฏุงู ุชุงุจุน ูุฒูู ูุณุจุช ุจู ูุฒู ฺฉูุงุณ $j$

$$
\nabla_{w_j} J(W) = \sum_{i=1}^n \left( P(y = j | x^{(i)}) - y_j^{(i)} \right) x^{(i)}
$$

---

ุงฺฏุฑ ุจุฎูุงูุฏุ ูโุชูุงูู ูุฑูููโูุง ุฑุง ุฏุงุฎู ูุชู ุงุตู ูู ุฌุงฺฏุฒู ฺฉูู ุง ูุฑ ูุฑููู ฺฉู ูุฏ ูุธุฑุชุงู ุงุณุช ุฑุง ุจุง ุชูุถุญ ฺฉุงููโุชุฑ ุงุฑุงุฆู ุฏูู.


--

