
---

### الگوریتم Pocket:

 برای داده‌هایی که به دلیل نویز یا غیرخطی بودن **خطی جداسازی‌پذیر نیستند**، الگوریتم Pocket بهترین وزن $w$ که تا کنون کمترین خطا را داشته، ذخیره می‌کند.

 این الگوریتم وزن‌ها را به‌روزرسانی می‌کند و همزمان بهترین وزن را که کمترین خطا را دارد در "جیب" نگه می‌دارد.

*حتی اگر همگرایی کامل اتفاق نیفتد، بهترین راه‌حل ممکن در دسترس خواهد بود.

---

## ۶. اعتبارسنجی متقابل (Cross Validation)

### انتخاب مدل از طریق اعتبارسنجی متقابل (Model Selection via Cross Validation):

 **هدف:**
  تکنیکی برای ارزیابی میزان تعمیم‌پذیری مدل روی داده‌های جدید و نادیده (unseen data).

---

### چگونگی کارکرد (K-Fold Cross Validation):

 داده‌ها به $K$ بخش مساوی (fold) تقسیم می‌شوند.

 مدل روی $K-1$ بخش آموزش داده می‌شود و روی بخش باقی‌مانده برای اعتبارسنجی (تست) ارزیابی می‌شود.

 این فرآیند $K$ بار تکرار می‌شود، به طوری که هر بار یک بخش متفاوت به عنوان بخش تست انتخاب می‌شود.

 امتیاز نهایی مدل میانگین امتیازهای به دست آمده در هر بار اعتبارسنجی است.

---

### مزایا:

 کاهش ریسک **بیش‌برازش** (overfitting) مدل.

 ارائه برآورد قابل اعتمادتر و واقعی‌تر از عملکرد مدل روی داده‌های جدید.

---

### توضیح ساده:

کراس‌ولیدیشن مثل این است که شما چند امتحان از یک درس می‌دهید. هر بار بخشی از کتاب را کنار می‌گذارید تا در امتحان از آن سوال بیاید، بقیه را می‌خوانید. به این ترتیب اطمینان حاصل می‌کنید که فقط حفظ نکردید بلکه واقعاً موضوع را یاد گرفته‌اید.

---

## اعتبارسنجی متقابل «ترک یک نمونه» (Leave-One-Out Cross-Validation - LOOCV):

 **چگونگی کارکرد:**
  در هر بار، یک نمونه به عنوان داده اعتبارسنجی انتخاب می‌شود و باقی نمونه‌ها برای آموزش استفاده می‌شوند. این روند برای تمام نمونه‌ها به صورت جداگانه تکرار می‌شود.

 اگر مجموعه داده $N$ نمونه داشته باشد، مدل $N$ بار آموزش داده می‌شود.

---

### خواص LOOCV:

 **عدم اتلاف داده:**
  هر نمونه هم برای آموزش و هم برای اعتبارسنجی استفاده می‌شود.

 **واریانس بالا و بایاس پایین:**
  مدل با تقریباً تمام داده‌ها آموزش می‌بیند (بایاس کم) اما چون مجموعه تست فقط یک نمونه است، ارزیابی می‌تواند واریانس بالایی داشته باشد.

 **هزینه محاسباتی بالا:**
  برای مجموعه‌های بزرگ، آموزش مدل $N$ بار بسیار زمان‌بر است.

 **مناسب برای مجموعه‌های داده کوچک:**
  به دلیل ویژگی‌های بالا، بیشتر برای داده‌های کم‌حجم کاربرد دارد.

---

## اعتبارسنجی متقابل برای انتخاب عبارت رگولاریزاسیون (Regularization Term):

از CV برای پیدا کردن بهترین مقدار هایپرپارامترهایی مانند $\lambda$ در رگولاریزاسیون استفاده می‌شود که کنترل‌کننده پیچیدگی مدل است.

تأثیر مقدار $\lambda$:

   $\lambda$ بزرگ → مدل ساده‌تر و کم‌برازش (underfitting).

   $\lambda$ متوسط → تعادل بهینه بین برازش و پیچیدگی.

   $\lambda$ کوچک → مدل پیچیده‌تر و ممکن است بیش‌برازش (overfitting) رخ دهد.

---

## اعتبارسنجی متقابل برای انتخاب پیچیدگی مدل:

 با استفاده از CV می‌توان مدل‌هایی با پیچیدگی‌های متفاوت (مثلاً رگرسیون چندجمله‌ای با درجات مختلف) را مقایسه کرد و بهترین مدل را انتخاب نمود.

 مثال: مقایسه مدل‌های درجه مختلف در صفحه 42 PDF.

---








۷. طبقه‌بندی چندکلاسه (Multi-Category Classification)

### راه‌حل‌ها برای مسئله طبقه‌بندی چندکلاسه:

۱. **گسترش الگوریتم یادگیری برای پشتیبانی از چندکلاسه:**
برای هر کلاس $C_i$، یک تابع تشخیص $g_i$ تعریف می‌شود.
سپس ورودی $x$ به کلاسی $C_i$ تخصیص داده می‌شود که مقدار تابع تشخیص آن بزرگ‌تر از سایر کلاس‌ها باشد، یعنی:

$$
\hat{y} = \arg\max_{i=1,\ldots,c} g_i(x)
$$

۲. **تبدیل مسئله به مجموعه‌ای از مسائل دو-دسته (Two-categorical problems):**

 روش **One-vs-Rest (OvR)** یا **One-vs-All (OvA):**
  برای هر کلاس، یک طبقه‌بندی‌کننده دودویی آموزش داده می‌شود که آن کلاس را از بقیه کلاس‌ها جدا می‌کند (مثلاً کلاس 1 در برابر کلاس‌های 2، 3 و 4).

 روش **One-vs-One (OvO):**
  برای هر جفت کلاس، یک طبقه‌بندی‌کننده دودویی آموزش داده می‌شود (مثلاً کلاس 1 در برابر کلاس 2، کلاس 1 در برابر کلاس 3، و ...).

---

### توضیحات اضافه:

وقتی بیش از دو کلاس دارید، دو راه اصلی برای طبقه‌بندی وجود دارد:

 یا الگوریتم را از ابتدا برای چندکلاسه بودن طراحی کنید (مثل Softmax Regression)،

 یا مسئله چندکلاسه را به چند مسئله دودویی ساده‌تر تقسیم کنید و برای هر کدام طبقه‌بندی‌کننده‌ای آموزش دهید.

---

### ابهام در طبقه‌بندی چندکلاسه (Ambiguity):

روش‌های OvR و OvO ممکن است مناطقی ایجاد کنند که طبقه‌بندی در آن‌ها نامشخص است (مناطق مبهم). (تصاویر صفحه ۴۵ PDF این مناطق مبهم را نشان می‌دهند)

---

### ماشین‌های خطی (Linear Machines) برای طبقه‌بندی چندکلاسه:

جایگزینی برای روش‌های OvR و OvO که در آن هر کلاس با یک تابع تشخیص $g_i(x)$ نمایش داده می‌شود.

 قاعده تصمیم:

$$
\hat{y} = \arg\max_{i=1,\ldots,c} g_i(x)
$$

مرز تصمیم بین کلاس‌های $i$ و $j$ جایی است که:

$$
g_i(x) = g_j(x) \implies (w_i - w_j)^T x + (w_{0i} - w_{0j}) = 0
$$

* **خواص مناطق تصمیم:** مناطق تصمیم این توابع محدب (convex) و تک‌اتصالی (singly connected) هستند؛ یعنی اگر دو نقطه از یک منطقه انتخاب شوند، خط واصل آن‌ها نیز کاملاً داخل همان منطقه است.

---

### الگوریتم پرسپترون چندکلاسه (Multi-Class Perceptron Algorithm):

* **بردار وزن‌ها:**
  یک ماتریس وزن $W \in \mathbb{R}^{m \times K}$ داریم که $m$ تعداد ویژگی‌ها و $K$ تعداد کلاس‌ها است.
  هر ستون $w_k$ بردار وزن کلاس $k$ است.

* **قاعده پیش‌بینی:**

$$
\hat{y} = \arg\max_{i=1,\ldots,c} w_i^T x
$$

* **تابع هزینه:**
  معیار پرسپترون روی نقاط اشتباه طبقه‌بندی شده تمرکز دارد:

$$
J_p(W) = - \sum_{i \in M} (w_{y^{(i)}} - w_{\hat{y}^{(i)}})^T x^{(i)}
$$

که $M$ مجموعه نقاط اشتباه است.

---

### الگوریتم به‌روزرسانی (صفحه ۴۹ PDF):

اگر نمونه $x^{(i)}$ اشتباه طبقه‌بندی شد (یعنی $y^{(i)} \neq \hat{y}^{(i)}$):

* وزن کلاس اشتباه کاهش می‌یابد:

$$
w_{\hat{y}^{(i)}} \leftarrow w_{\hat{y}^{(i)}} - \eta x^{(i)}
$$

* وزن کلاس واقعی افزایش می‌یابد:

$$
w_{y^{(i)}} \leftarrow w_{y^{(i)}} + \eta x^{(i)}
$$

این به‌روزرسانی‌ها وزن‌ها را به گونه‌ای تغییر می‌دهند که امتیاز کلاس واقعی افزایش و امتیاز کلاس اشتباه کاهش یابد.

---







































