**K-نزدیکترین همسایه (K-Nearest Neighbors - KNN): الگوریتمی غیرپارامتریک و نمونه‌محور**

در این جلسه، قصد داریم درباره یک الگوریتم جدید به نام K-نزدیکترین همسایه (KNN) صحبت کنیم. این الگوریتم هم در رگرسیون و هم در دسته‌بندی کاربرد دارد.

**روش‌های پارامتریک در مقابل روش‌های ناپارامتریک:**
در یادگیری ماشین، به طور کلی دو گروه از روش‌ها وجود دارد:
* **روش‌های پارامتریک (Parametric Methods):** این روش‌ها شامل پارامترهایی هستند که در طول فرآیند یادگیری (training) مدل، آن‌ها را "یاد می‌گیریم" یا "بهینه‌سازی می‌کنیم". مانند وزن‌ها (weights) در رگرسیون خطی یا پرسپترون. فرآیند تصمیم‌گیری (چه رگرسیون باشد چه دسته‌بندی) بر اساس این پارامترهای یادگرفته شده انجام می‌شود.
* **روش‌های ناپارامتریک (Non-Parametric Methods):** این روش‌ها، برخلاف روش‌های پارامتریک، دارای پارامترهایی مانند وزن‌ها نیستند که نیاز به یادگیری در مرحله آموزش داشته باشند.
    * **مزایای روش‌های ناپارامتریک:**
        * **سادگی و سرعت:** فرآیند یادگیری یا آموزش (training) ندارند. این باعث می‌شود که بتوانیم خیلی سریع‌تر کار با آن‌ها را شروع کنیم.
        * **کاربرد در داده‌های کم:** زمانی که حجم داده‌های آموزشی (training data) کم است و نمی‌توان پارامترهای زیادی را به طور قابل اعتماد یاد گرفت، روش‌های ناپارامتریک مفید هستند.
    * **مثال در آمار:** در آمار نیز آزمون‌هایی مانند T-test وجود دارند که فرض می‌کنند داده‌ها از یک توزیع خاص (مثلاً توزیع نرمال) آمده‌اند (این‌ها آزمون‌های پارامتریک هستند). در مقابل، آزمون‌های ناپارامتریک چنین فرضیاتی درباره توزیع داده‌ها ندارند و فرض می‌کنند که داده‌ها می‌توانند هر توزیعی داشته باشند. KNN یکی از جدی‌ترین الگوریتم‌های ناپارامتریک در یادگیری ماشین است که کاربرد فراوانی دارد.

**روش‌های مبتنی بر حافظه (Memory-Based) در مقابل روش‌های مبتنی بر نمونه (Instance-Based):**
همچنین می‌توان الگوریتم‌ها را از منظر دیگری دسته‌بندی کرد:
* **روش‌های مبتنی بر حافظه (Memory-Based Methods):** این روش‌ها نیاز دارند که "الگوهایی" را از داده‌های قبلی یا تجربیات پیشین به خاطر بسپارند. این خاطرات یا الگوها، همان پارامترهای مدل (مانند وزن‌ها) هستند که بر اساس بهترین عملکرد روی داده‌های آموزشی تنظیم شده‌اند.
* **روش‌های مبتنی بر نمونه (Instance-Based Methods):** این روش‌ها، نمونه‌محور هستند. یعنی در زمان تصمیم‌گیری، مدل به جای استفاده از پارامترهای یادگرفته شده، مستقیماً از "نمونه‌های آموزشی" (که برچسب‌های آن‌ها مشخص است) استفاده می‌کند.

**الگوریتم K-نزدیکترین همسایه (K-Nearest Neighbors - KNN):**
الگوریتم KNN بسیار شبیه به این شعر سعدی است: "تو اول بگو با کیان زیستی، من آنگه بگویم که تو کیستی." به عبارت دیگر، "دوستان نزدیکت را به من نشان بده تا بتوانم حدس بزنم تو کی هستی."

**نحوه عملکرد KNN:**
وقتی یک نمونه جدید داریم که می‌خواهیم وضعیت آن را مشخص کنیم (مثلاً سالم است یا سرطانی، قیمت خانه چقدر است، سگ است یا گربه، رقم تصویر 0 است یا 1، ایمیل اسپم است یا خیر، یا فیلمی را به کاربر پیشنهاد دهیم یا خیر)، KNN به صورت زیر عمل می‌کند:

1.  **انتخاب K:** ابتدا یک عدد صحیح K را مشخص می‌کنیم (مثلاً K=5).
2.  **یافتن نزدیکترین همسایه‌ها:** برای نمونه جدید (که به آن "نمونه تست" یا "نمونه ارزیابی" می‌گوییم)، K تا از "نزدیکترین" نمونه‌ها را از بین تمام داده‌های آموزشی (training data) پیدا می‌کنیم. نزدیکی بین نمونه‌ها بر اساس یک معیار فاصله (مثلاً فاصله اقلیدسی) تعیین می‌شود.
    * به عنوان مثال، برای توصیه فیلم، می‌توان نزدیکی دو کاربر را بر اساس درصد فیلم‌های مشترکی که دیده‌اند، تعیین کرد. اگر 90% فیلم‌های دیده شده توسط دو کاربر مشترک باشد، یعنی سلیقه فیلمی مشابهی دارند.
3.  **تصمیم‌گیری (برای دسته‌بندی):** بر اساس وضعیت این K همسایه نزدیک:
   
    * **رأی اکثریت (Majority Vote):** در مسائل دسته‌بندی، کلاس نمونه جدید بر اساس رأی اکثریت کلاس‌های K همسایه نزدیک تعیین می‌شود.
    * **مثال:** اگر 4 تا از 5 همسایه نزدیک نمونه جدید، "بیمار" باشند و فقط 1 همسایه "سالم" باشد، مدل پیش‌بینی می‌کند که نمونه جدید "بیمار" است.
    *
    * ![image](https://github.com/user-attachments/assets/91e439e7-c41f-4034-b2ae-965908be20eb)

    * **انتخاب K فرد:** معمولاً K را به صورت یک عدد فرد انتخاب می‌کنند تا از حالت تساوی در رأی‌گیری جلوگیری شود.

**خلاصه کلی KNN:**
KNN یک الگوریتم بسیار ساده و در عین حال قدرتمند است که پیچیدگی ریاضیاتی زیادی ندارد. تنها کاری که انجام می‌دهد این است که:
1.  برای هر نمونه جدیدی که می‌خواهیم پیش‌بینی روی آن انجام دهیم (بدون نیاز به فاز آموزش اولیه و پیدا کردن پارامترهایی مانند وزن‌ها).
2.  K تا از نزدیکترین نمونه‌ها را از مجموعه داده آموزشی (که تجربیات قبلی ما هستند و برچسب‌هایشان معلوم است) پیدا می‌کند.
3.  سپس، بر اساس کلاس‌هایی که در این K همسایه نزدیک بیشتر تکرار شده‌اند، کلاس نمونه جدید را پیش‌بینی می‌کند.
    * **مثال:** اگر از بین K همسایه، دو نمونه از کلاس 1، یک نمونه از کلاس 2، یک نمونه از کلاس 5 و یک نمونه از کلاس 4 باشند، نمونه جدید به کلاس 1 نسبت داده می‌شود، زیرا کلاس 1 بیشترین تکرار را در بین همسایگان نزدیک دارد.
  
**K-نزدیکترین همسایه (KNN): ویژگی‌ها و ملاحظات**

یکی از مزیت‌های مهم الگوریتم K-نزدیکترین همسایه (KNN) این است که می‌تواند مرزهای تصمیم‌گیری "غیرخطی" (non-linear) را ایجاد کند. این برخلاف الگوریتم‌هایی است که تا کنون بررسی شده‌اند، مانند رگرسیون خطی، پرسپترون، و رگرسیون لجستیک، که همگی با مدل‌های خطی کار می‌کنند.

**مرز تصمیم‌گیری غیرخطی در KNN:**
مدل‌های خطی نمی‌توانند به خوبی داده‌هایی که به صورت غیرخطی تفکیک‌پذیر هستند را جدا کنند، مگر با افزودن ویژگی‌های جدید. اما KNN می‌تواند به راحتی این کلاس‌ها را تفکیک کند. مرز تصمیم‌گیری در KNN می‌تواند بسیار پیچیده و غیرخطی باشد؛ این الگوریتم شکل هر یک از کلاس‌ها را در فضا شناسایی کرده و در اطراف آن‌ها مرزهایی را ترسیم می‌کند.

**اثر K بر مرز تصمیم‌گیری (Effect of K):**
تغییر مقدار K (تعداد همسایگان نزدیک) تأثیر قابل توجهی بر شکل مرز تصمیم‌گیری و عملکرد مدل دارد.

* **K=1 (1-Nearest Neighbor):**
    * در این حالت، کلاس یک نقطه جدید تنها بر اساس نزدیکترین همسایه آن تعیین می‌شود.
    * مرزهای تصمیم‌گیری بسیار "پیچیده" و "بریده‌بریده" می‌شوند.
    * این حالت به "Voronoi Tessellation" (تکه‌بندی ورونوی) منجر می‌شود. در تکه‌بندی ورونوی، فضا به سلول‌هایی تقسیم می‌شود که هر سلول شامل تمام نقاطی است که به یک نقطه آموزشی خاص (نسبت به سایر نقاط آموزشی) نزدیک‌ترند.
    * ![image](https://github.com/user-attachments/assets/57ded919-fb41-4243-bdd0-d53a42dbe6c6)

    * K=1 به شدت مستعد "بیش‌برازش" (Overfitting) و حساس به "نویز" (noise) یا داده‌های پرت (outliers) است. یک نقطه نویز می‌تواند بخش بزرگی از فضا را به اشتباه طبقه‌بندی کند.

* **افزایش K (K > 1):**
    * با افزایش K، مدل "هموارتر" (smoother) می‌شود و حساسیت آن به نویز و نقاط پرت کاهش می‌یابد.
    * با افزایش K، مدل از "بیش‌برازش" فاصله گرفته و به سمت "کم‌برازش" (Underfitting) میل می‌کند.
    * **کاهش واریانس و افزایش بایاس:** افزایش K باعث "کاهش واریانس" (variance) مدل می‌شود (مدل کمتر به نویزها حساس است)، اما در عین حال می‌تواند "بایاس" (bias) آن را "افزایش" دهد (مدل ممکن است پیچیدگی واقعی داده‌ها را نادیده بگیرد و دچار خطا شود). این پدیده به "موازنه بایاس-واریانس" (Bias-Variance Trade-off) معروف است.
        * **K خیلی کم (واریانس بالا):** مدل بیش‌برازش می‌کند، به نویز حساس است، و عملکرد روی داده‌های دیده نشده ممکن است ضعیف باشد.
        * **K خیلی زیاد (بایاس بالا):** مدل کم‌برازش می‌کند، پیچیدگی واقعی داده‌ها را نادیده می‌گیرد و ممکن است نتواند الگوهای مهم را تشخیص دهد.







![image](https://github.com/user-attachments/assets/36705d4f-2854-4a12-811b-5957332e1c29)

![image](https://github.com/user-attachments/assets/01c1452b-e38b-40c5-b7ca-b0c1de03ae8b)
![image](https://github.com/user-attachments/assets/ba8f13ef-2a46-46a6-a944-7b7562729084)




**KNN: معیارهای فاصله و رگرسیون**

**1. معیارهای فاصله (Distance Measures):**
برای تعیین "نزدیکترین همسایگان" در KNN، نیاز به معیاری برای اندازه‌گیری فاصله بین نقاط داریم. انتخاب معیار فاصله مناسب بر عملکرد مدل تأثیرگذار است.

* **فاصله اقلیدسی (Euclidean Distance):**
    * این رایج‌ترین معیار فاصله است.
    * فاصله بین دو نقطه $x = (x_1, \dots, x_d)$ و $x' = (x_1', \dots, x_d')$ در فضای $d$ بعدی به صورت زیر محاسبه می‌شود:
        $d(x, x') = \sqrt{(x_1 - x_1')^2 + (x_2 - x_2')^2 + \dots + (x_d - x_d')^2}$
    * این فاصله، همان ریشه دوم مجموع مربعات اختلاف مؤلفه‌های متناظر دو بردار است.

* **فاصله اقلیدسی وزن‌دار (Weighted Euclidean Distance):**
    * در این حالت، به هر یک از ابعاد (ویژگی‌ها) یک وزن (w) اختصاص داده می‌شود.
    * این وزن‌ها می‌توانند اهمیت نسبی هر ویژگی را در محاسبه فاصله نشان دهند.
    * $d_w(x, x') = \sqrt{w_1(x_1 - x_1')^2 + \dots + w_d(x_d - x_d')^2}$
    * **مثال:** در پیش‌بینی قیمت خانه، اگر "متراژ" (ویژگی $x_1$) تأثیرگذارتر از "تعداد طبقات" (ویژگی $x_2$) باشد، می‌توان وزن $w_1$ را بیشتر از $w_2$ در نظر گرفت. این وزن‌ها می‌توانند از طریق تجربه یا با استفاده از روش‌های یادگیری (distance learning methods) تعیین شوند.

* **فاصله مینکوفسکی (Minkowski Distance):**
    * یک فرم عمومی‌تر از فواصل اقلیدسی و منهتن است.
    * برای $p \ge 1$: $d(x, x') = \left(\sum_{i=1}^{d} |x_i - x_i'|^p\right)^{1/p}$
    * اگر $p=1$ باشد، به "فاصله منهتن" (Manhattan Distance) تبدیل می‌شود (جمع قدر مطلق اختلاف‌ها).
    * اگر $p=2$ باشد، همان "فاصله اقلیدسی" است.

* **نرم‌های LP (Lp-Norms):**
    * این نرم‌ها با فاصله مینکوفسکی ارتباط نزدیک دارند. نرم $L_p$ یک بردار $x$ به صورت $||x||_p = \left(\sum_{i=1}^{d} |x_i|^p\right)^{1/p}$ تعریف می‌شود.
    * **نرم $L_1$ (Manhattan Norm):** $||x||_1 = \sum_{i=1}^{d} |x_i|$
    * **نرم $L_2$ (Euclidean Norm):** $||x||_2 = \sqrt{\sum_{i=1}^{d} x_i^2}$
    * **نرم $L_\infty$ (Chebyshev Norm):** $||x||_\infty = \max\{|x_1|, |x_2|, \dots, |x_d|\}$ (این نرم وقتی $p$ به بی‌نهایت میل می‌کند، به دست می‌آید، زیرا بزرگترین مؤلفه، سایر مؤلفه‌ها را تحت‌الشعاع قرار می‌دهد).

* **فاصله کسینوسی (Cosine Distance) / شباهت کسینوسی (Cosine Similarity):**
    * این معیار، شباهت بین دو بردار را بر اساس زاویه بین آن‌ها اندازه‌گیری می‌کند. اگر دو بردار هم‌جهت باشند (زاویه صفر)، شباهت کسینوسی 1 خواهد بود.
    * شباهت کسینوسی (Cosine Similarity): $\text{similarity}(x, x') = \frac{x \cdot x'}{||x||_2 ||x'||_2} = \frac{\sum_{i=1}^{d} x_i x_i'}{\sqrt{\sum_{i=1}^{d} x_i^2} \sqrt{\sum_{i=1}^{d} (x_i')^2}}$
    * فاصله کسینوسی (Cosine Distance) به صورت $1 - \text{cosine similarity}$ تعریف می‌شود.
    * این معیار، بیشتر در کاربردهایی مانند پردازش زبان طبیعی و سیستم‌های توصیه‌گر استفاده می‌شود، جایی که جهت بردارها (محتوا) مهم‌تر از اندازه آن‌ها است.

**2. تعیین مقدار K (تعداد همسایگان):**
* انتخاب مقدار بهینه K یک "هایپرپارامتر" (hyperparameter) است.
* برای تعیین K، از مجموعه داده "ولیدیشن" (validation set) استفاده می‌شود.
* مدل با مقادیر مختلف K (مثلاً از 1، 2، 3 و ...) روی داده‌های آموزشی، آموزش داده می‌شود و سپس عملکرد آن روی داده‌های ولیدیشن ارزیابی می‌گردد.
* مقداری از K که بهترین عملکرد را روی مجموعه ولیدیشن ارائه دهد، به عنوان K بهینه انتخاب می‌شود.

**3. رگرسیون KNN (KNN Regression):**
* در مسائل رگرسیون، هدف پیش‌بینی یک مقدار پیوسته است.
* **روش پیش‌بینی:** برای یک نقطه جدید $x$， ابتدا $K$ نزدیکترین همسایه آن ($x'^{(1)}, \dots, x'^{(k)}$) از داده‌های آموزشی پیدا می‌شوند. سپس، مقدار پیش‌بینی شده $\hat{y}$ برای $x$، میانگین مقادیر برچسب این $K$ همسایه است:
    $\hat{y} = \frac{1}{k} \sum_{j=1}^{k} y'^{(j)}$
* **مشکلات و ملاحظات در رگرسیون KNN:**
    * **K=1:** مدل دارای "واریانس بالا" (high variance) است و تمایل به "بیش‌برازش" (overfitting) دارد. خط رگرسیون بسیار پرنوسان و حساس به نویز است.
    * **افزایش K:** با افزایش K، مدل "هموارتر" (smoother) می‌شود و واریانس آن کاهش می‌یابد. اما اگر K خیلی بزرگ شود، مدل به سمت "کم‌برازش" (underfitting) متمایل می‌شود و "بایاس" (bias) آن افزایش می‌یابد. این بدان معناست که مدل الگوهای اصلی را به خوبی یاد نمی‌گیرد و ممکن است خط رگرسیون از واقعیت منحرف شود (مثلاً صاف‌تر از حد لزوم شود).
    * **موازنه بایاس-واریانس (Bias-Variance Trade-off):** انتخاب K مناسب، یک موازنه بین بایاس و واریانس ایجاد می‌کند. K کوچک منجر به واریانس بالا و K بزرگ منجر به بایاس بالا می‌شود. هدف پیدا کردن Kی است که مجموع بایاس و واریانس (و نویز غیرقابل کاهش) را حداقل کند تا کمترین خطای کلی را داشته باشیم.
 
* <img width="902" height="549" alt="image" src="https://github.com/user-attachments/assets/2b11b692-a013-44b2-a642-4f4ffe422612" />




**K-نزدیکترین همسایه (KNN): معیارهای فاصله و رگرسیون**

برای تعیین "نزدیکترین همسایگان" در KNN، نیاز به معیاری برای اندازه‌گیری فاصله بین نقاط داریم. انتخاب معیار فاصله مناسب بر عملکرد مدل تأثیرگذار است.

* **فاصله اقلیدسی (Euclidean Distance):**
    * این رایج‌ترین معیار فاصله است.
    * فاصله بین دو نقطه $x = (x_1, \dots, x_d)$ و $x' = (x_1', \dots, x_d')$ در فضای $d$ بعدی به صورت زیر محاسبه می‌شود:
        $d(x, x') = \sqrt{(x_1 - x_1')^2 + (x_2 - x_2')^2 + \dots + (x_d - x_d')^2}$
    * این فاصله، همان ریشه دوم مجموع مربعات اختلاف مؤلفه‌های متناظر دو بردار است.

* **فاصله اقلیدسی وزن‌دار (Weighted Euclidean Distance):**
    * در این حالت، به هر یک از ابعاد (ویژگی‌ها) یک وزن (w) اختصاص داده می‌شود.
    * این وزن‌ها می‌توانند اهمیت نسبی هر ویژگی را در محاسبه فاصله نشان دهند.
    * $d_w(x, x') = \sqrt{w_1(x_1 - x_1')^2 + \dots + w_d(x_d - x_d')^2}$
    * **مثال:** در پیش‌بینی قیمت خانه، اگر "متراژ" (ویژگی $x_1$) تأثیرگذارتر از "تعداد طبقات" (ویژگی $x_2$) باشد، می‌توان وزن $w_1$ را بیشتر از $w_2$ در نظر گرفت. این وزن‌ها می‌توانند از طریق تجربه یا با استفاده از روش‌های یادگیری (distance learning methods) تعیین شوند.

* **فاصله مینکوفسکی (Minkowski Distance):**
    * یک فرم عمومی‌تر از فواصل اقلیدسی و منهتن است.
    * برای $p \ge 1$: $d(x, x') = \left(\sum_{i=1}^{d} |x_i - x_i'|^p\right)^{1/p}$
    * اگر $p=1$ باشد، به "فاصله منهتن" (Manhattan Distance) تبدیل می‌شود (جمع قدر مطلق اختلاف‌ها).
    * اگر $p=2$ باشد، همان "فاصله اقلیدسی" است.

* **نرم‌های LP (Lp-Norms):**
    * این نرم‌ها با فاصله مینکوفسکی ارتباط نزدیک دارند. نرم $L_p$ یک بردار $x$ به صورت $||x||_p = \left(\sum_{i=1}^{d} |x_i|^p\right)^{1/p}$ تعریف می‌شود.
    * **نرم $L_1$ (Manhattan Norm):** $||x||_1 = \sum_{i=1}^{d} |x_i|$
    * **نرم $L_2$ (Euclidean Norm):** $||x||_2 = \sqrt{\sum_{i=1}^{d} x_i^2}$
    * **نرم $L_\infty$ (Chebyshev Norm):** $||x||_\infty = \max\{|x_1|, |x_2|, \dots, |x_d|\}$ (این نرم وقتی $p$ به بی‌نهایت میل می‌کند، به دست می‌آید، زیرا بزرگترین مؤلفه، سایر مؤلفه‌ها را تحت‌الشعاع قرار می‌دهد).

* **فاصله کسینوسی (Cosine Distance) / شباهت کسینوسی (Cosine Similarity):**
    * این معیار، شباهت بین دو بردار را بر اساس زاویه بین آن‌ها اندازه‌گیری می‌کند. اگر دو بردار هم‌جهت باشند (زاویه صفر)، شباهت کسینوسی 1 خواهد بود.
    * شباهت کسینوسی (Cosine Similarity): $\text{similarity}(x, x') = \frac{x \cdot x'}{||x||_2 ||x'||_2} = \frac{\sum_{i=1}^{d} x_i x_i'}{\sqrt{\sum_{i=1}^{d} x_i^2} \sqrt{\sum_{i=1}^{d} (x_i')^2}}$
    * فاصله کسینوسی (Cosine Distance) به صورت $1 - \text{cosine similarity}$ تعریف می‌شود.
    * این معیار، بیشتر در کاربردهایی مانند پردازش زبان طبیعی و سیستم‌های توصیه‌گر استفاده می‌شود، جایی که جهت بردارها (محتوا) مهم‌تر از اندازه آن‌ها است.

**2. تعیین مقدار K (تعداد همسایگان):**
* انتخاب مقدار بهینه K یک "هایپرپارامتر" (hyperparameter) است.
* برای تعیین K، از مجموعه داده "ولیدیشن" (validation set) استفاده می‌شود.
* مدل با مقادیر مختلف K (مثلاً از 1، 2، 3 و ...) روی داده‌های آموزشی، آموزش داده می‌شود و سپس عملکرد آن روی داده‌های ولیدیشن ارزیابی می‌گردد.
* مقداری از K که بهترین عملکرد را روی مجموعه ولیدیشن ارائه دهد، به عنوان K بهینه انتخاب می‌شود.

**3. رگرسیون KNN (KNN Regression):**
* در مسائل رگرسیون، هدف پیش‌بینی یک مقدار پیوسته است.
* **روش پیش‌بینی:** برای یک نقطه جدید $x$، ابتدا $K$ نزدیکترین همسایه آن ($x'^{(1)}, \dots, x'^{(k)}$) از داده‌های آموزشی پیدا می‌شوند. سپس، مقدار پیش‌بینی شده $\hat{y}$ برای $x$، میانگین مقادیر برچسب این $K$ همسایه است:
    * $\hat{y} = \frac{1}{k} \sum_{j=1}^{k} y'^{(j)}$
* **مشکلات و ملاحظات در رگرسیون KNN:**
    * **ناپیوستگی (Discontinuities):** تابع تخمین زده شده توسط KNN می‌تواند دارای ناپیوستگی باشد.
    * **برازش نویز (Noise-fitting) در K=1:** مانند دسته‌بندی، در K=1، مدل به شدت به نویز حساس است و نویزهای داده را برازش می‌دهد.
    * **هموارسازی نویز و مشکلات دیگر در K > 1:** در K > 1، KNN نویز را هموار می‌کند، اما ممکن است مشکلات دیگری مانند "تخت کردن انتهای منحنی" (flats the ends) را ایجاد کند، به خصوص اگر K خیلی بزرگ باشد.
    * **مثال:** در یک مدل رگرسیون برای داده‌های سینوسی با نویز، با افزایش K، منحنی پیش‌بینی شده هموارتر می‌شود، اما اگر K خیلی بزرگ باشد، ممکن است از شکل واقعی منحنی منحرف شود و به سمت یک خط مستقیم میل کند.

---
**ارزیابی عملکرد مدل (Performance Metrics)**

برای ارزیابی عملکرد یک مدل دسته‌بندی، تنها استفاده از دقت (Accuracy) کافی نیست، به خصوص در مجموعه داده‌های نامتوازن (imbalanced datasets).

**1. دقت (Accuracy):**
* ساده‌ترین و رایج‌ترین معیار ارزیابی عملکرد.
* **تعریف:** نسبت نمونه‌های صحیح پیش‌بینی شده به کل نمونه‌ها.
    * $Accuracy = \frac{\text{True Positives} + \text{True Negatives}}{\text{Total Samples}}$
* **مشکلات:** دقت به تنهایی می‌تواند گمراه‌کننده باشد، به ویژه در مجموعه داده‌های نامتوازن.
    * **مثال: تشخیص سرطان:**
        * تصور کنید 1000 بیمار دارید: 10 نفر سرطان دارند (کلاس مثبت) و 990 نفر سالم هستند (کلاس منفی).
        * یک دسته‌بند که همیشه پیش‌بینی می‌کند "هیچ‌کس سرطان ندارد" (یعنی همیشه منفی پیش‌بینی می‌کند).
        * **ماتریس درهم‌ریختگی (Confusion Matrix) برای این مدل:**
            * **Actual Negative, Predicted Negative (TN):** 990 (تشخیص صحیح عدم سرطان)
            * **Actual Positive, Predicted Negative (FN):** 10 (عدم تشخیص سرطان در بیماران واقعی)
            * **Actual Negative, Predicted Positive (FP):** 0 (پیش‌بینی اشتباه سرطان در افراد سالم)
            * **Actual Positive, Predicted Positive (TP):** 0 (تشخیص صحیح سرطان در بیماران واقعی)
        * **دقت مدل:** $Accuracy = \frac{990 + 0}{1000} = 99\%$
        * با وجود دقت 99%، این مدل عملاً هیچ بیمار سرطانی واقعی را تشخیص نداده است و در دنیای واقعی کاملاً بی‌فایده است.
    * این مثال نشان می‌دهد که در داده‌های نامتوازن، مدلی که فقط کلاس اکثریت را پیش‌بینی کند، می‌تواند دقت بالایی داشته باشد اما عملکرد واقعی ضعیفی دارد. بنابراین، به معیارهای دیگری نیاز داریم.

**2. معیارهای عملکرد مبتنی بر ماتریس درهم‌ریختگی (Confusion Matrix-based Metrics):**
* **ماتریس درهم‌ریختگی:** جدولی است که برای ارزیابی عملکرد یک مدل دسته‌بندی استفاده می‌شود.
    * این ماتریس مقادیر واقعی (برچسب‌های واقعی) را با مقادیر پیش‌بینی شده توسط مدل مقایسه می‌کند.
    * هر ردیف ماتریس نشان‌دهنده کلاس واقعی و هر ستون نشان‌دهنده کلاس پیش‌بینی شده است.
    * این ماتریس به ما کمک می‌کند تا علاوه بر درستی پیش‌بینی‌ها، نوع اشتباهات مدل را نیز درک کنیم.
* **تعاریف اساسی در ماتریس درهم‌ریختگی (برای مسائل باینری):**
    * **True Positive (TP):** مدل به درستی کلاس مثبت را پیش‌بینی کرده است. (مثال: دزد حاضر است، آژیر به درستی زنگ می‌زند).
    * **True Negative (TN):** مدل به درستی کلاس منفی را پیش‌بینی کرده است. (مثال: دزد حاضر نیست، آژیر به درستی زنگ نمی‌زند).
    * **False Positive (FP - Type I Error):** مدل به اشتباه کلاس مثبت را پیش‌بینی کرده است (خطای نوع اول). (مثال: دزد حاضر نیست، آژیر به اشتباه زنگ می‌زند - آژیر کاذب).
    * **False Negative (FN - Type II Error):** مدل به اشتباه کلاس منفی را پیش‌بینی کرده است (خطای نوع دوم). (مثال: دزد حاضر است، آژیر به اشتباه زنگ نمی‌زند - آژیر به صدا در نیامده).

* **معیارهای ارزیابی مهم:**
    * **حساسیت (Sensitivity) / بازخوانی (Recall):**
        * تعریف: توانایی مدل در شناسایی صحیح موارد مثبت واقعی. (چند درصد از موارد مثبت واقعی را به درستی تشخیص داده‌ایم).
        * فرمول: $Sensitivity = Recall = \frac{TP}{TP + FN}$
        * **مثال (سیستم دزدگیر):** از 100 باری که دزد واقعاً آمده، دزدگیر چند بار زنگ زده است؟ (TP: دزد آمد و آژیر زد، FN: دزد آمد و آژیر نزد).
    * **ویژگی (Specificity):**
        * تعریف: توانایی مدل در شناسایی صحیح موارد منفی واقعی. (چند درصد از موارد منفی واقعی را به درستی تشخیص داده‌ایم).
        * فرمول: $Specificity = \frac{TN}{TN + FP}$
        * **مثال (سیستم دزدگیر):** از 100 باری که دزد نیامده، دزدگیر چند بار زنگ نزده است؟ (TN: دزد نیامد و آژیر نزد، FP: دزد نیامد و آژیر زد).
    * **دقت (Precision):**
        * تعریف: دقت پیش‌بینی‌های مثبت مدل. (از تمام دفعاتی که مدل "مثبت" پیش‌بینی کرده، چند درصدش واقعاً مثبت بوده است).
        * فرمول: $Precision = \frac{TP}{TP + FP}$
        * **مثال (سیستم دزدگیر):** از تمام دفعاتی که آژیر زنگ زده، چند درصدش درست بوده و واقعاً دزد آمده است؟

* **معیار ترکیبی F1 Score:**
    * **هدف:** ادغام Precision و Recall در یک معیار واحد برای ارزیابی جامع‌تر، به خصوص در داده‌های نامتوازن.
    * **فرمول:** F1 Score میانگین هارمونیک Precision و Recall است: $F1 = \frac{2 \times Precision \times Recall}{Precision + Recall}$
    * **چرا میانگین هارمونیک؟** میانگین هارمونیک برای نرخ‌ها مناسب‌تر است. این میانگین به عملکرد ضعیف در هر یک از Precision یا Recall "تنبیه" بیشتری می‌دهد، در حالی که میانگین حسابی ممکن است عملکرد ضعیف یک معیار را با عملکرد خوب معیار دیگر جبران کند.

**3. ارزیابی چندکلاسه و ماتریس درهم‌ریختگی (Multi-class Evaluation and Confusion Matrix)**

* **ماتریس درهم‌ریختگی برای بیش از دو کلاس:**
    * اگر بیش از دو کلاس (مثلاً K کلاس) داشته باشیم, ماتریس درهم‌ریختگی به صورت یک جدول KxK گسترش می‌یابد.
    * **سطرها:** کلاس‌های واقعی (Actual Classes).
    * **ستون‌ها:** کلاس‌های پیش‌بینی شده (Predicted Classes).
    * **سلول‌ها:** تعداد نمونه‌هایی که واقعاً در کلاس سطر بوده‌اند و مدل آن‌ها را در کلاس ستون پیش‌بینی کرده است.
    * **مثال:** در تشخیص تصویر گربه، سگ و اسب، سلول $C_{Cat, Dog}$ تعداد گربه‌هایی را نشان می‌دهد که مدل به اشتباه "سگ" پیش‌بینی کرده است.
    * **تشخیص خطاها:** ماتریس درهم‌ریختگی به وضوح نشان می‌دهد که مدل در کدام کلاس‌ها و در چه نوع خطاهایی (مثلاً اشتباه گرفتن گربه با سگ) بیشتر دچار مشکل می‌شود. این اطلاعات برای بهبود مدل بسیار ارزشمند است (مثلاً برای جمع‌آوری داده‌های بیشتر از کلاس‌های خاص).

* **محاسبه معیارهای عملکرد برای هر کلاس در حالت چندکلاسه:**
    * **Recall (برای کلاس $i$):** $Recall_i = \frac{C_{ii}}{\sum_j C_{ij}}$ (عناصر قطری / جمع سطر مربوطه)
    * **Precision (برای کلاس $i$):** $Precision_i = \frac{C_{ii}}{\sum_j C_{ji}}$ (عناصر قطری / جمع ستون مربوطه)
    * **Accuracy:** $Accuracy = \frac{\sum_i C_{ii}}{\sum_j \sum_i C_{ij}}$ (جمع عناصر قطری / کل نمونه‌ها)

**4. میانگین‌گیری برای ارزیابی کلی (Averaging for Overall Evaluation)**

* پس از محاسبه معیارهایی مانند F1 Score برای هر کلاس، برای به دست آوردن یک عدد واحد که عملکرد کلی مدل را نشان دهد، از روش‌های میانگین‌گیری استفاده می‌شود:
    * **Macro-averaging:**
        * معیار عملکرد (مثلاً F1 Score) برای "هر کلاس" به صورت جداگانه محاسبه می‌شود.
        * سپس، میانگین این مقادیر برای همه کلاس‌ها گرفته می‌شود.
        * این روش به همه کلاس‌ها، بدون توجه به تعداد نمونه‌هایشان، وزن یکسانی می‌دهد.
    * **Micro-averaging:**
        * ابتدا تصمیمات (TP, FP, FN) را برای "تمام کلاس‌ها" به صورت تجمیعی جمع‌آوری می‌شوند.
        * سپس، معیار عملکرد مورد نظر (مثلاً F1 Score) بر اساس این مقادیر تجمیع شده محاسبه می‌گردد.
        * این روش بیشتر تحت تأثیر عملکرد مدل روی "کلاس‌های پرتکرار" (کلاس‌هایی با تعداد نمونه بیشتر) قرار می‌گیرد.

**5. AUC-ROC (Area Under the Receiver Operating Characteristic Curve):**
* **ROC Curve (Receiver Operating Characteristic):** یک نمایش گرافیکی از عملکرد یک مدل دسته‌بندی باینری است.
    * این منحنی، نرخ مثبت واقعی (True Positive Rate - TPR یا همان Sensitivity) را در مقابل نرخ مثبت کاذب (False Positive Rate - FPR) در آستانه‌های مختلف طبقه‌بندی رسم می‌کند.
    * **FPR (False Positive Rate):** $FPR = \frac{FP}{FP + TN}$ (همان 1 - Specificity).
* **AUC (Area Under the Curve):** مساحت زیر منحنی ROC است.
    * **تفسیر:**
        * امتیاز AUC بالا نشان‌دهنده توانایی "تفکیک" خوب مدل است. یعنی مدل می‌تواند به طور موثر بین نمونه‌های مثبت و منفی در آستانه‌های مختلف تمایز قائل شود.
        * امتیاز AUC پایین‌تر نشان می‌دهد که مدل در تمایز بین دو کلاس مشکل دارد.
        * AUC از 0 تا 1 متغیر است.
        * AUC = 0.5 نشان‌دهنده عملکرد تصادفی (random guessing) است (مدل هیچ توانایی در تمایز ندارد).
        * AUC = 1 نشان‌دهنده یک دسته‌بند کامل و بدون نقص است.
    * AUC-ROC به ما اجازه می‌دهد که عملکرد مدل‌ها را فارغ از آستانه خاصی که برای دسته‌بندی انتخاب شده، مقایسه کنیم. این به ویژه زمانی مفید است که نیاز به توازنی بین حساسیت و ویژگی داریم.
---




---
---
---
نگران نباشید! مفاهیم مربوط به ارزیابی عملکرد مدل‌ها در دسته‌بندی، به خصوص در ابتدا، ممکن است کمی گیج‌کننده باشند. این کاملاً طبیعی است. [cite_start]دلیل اصلی پیچیدگی این مفاهیم، نیاز به نگاه دقیق‌تر به انواع خطاهایی است که یک مدل دسته‌بندی می‌تواند مرتکب شود، فراتر از صرفاً "درست" یا "غلط" بودن پیش‌بینی‌ها[cite: 808].

بیایید این مفاهیم را به صورت ساده و گام به گام مرور کنیم تا دیگر آن‌ها را با هم قاطی نکنید:

---

**مفاهیم اساسی در ارزیابی مدل‌های دسته‌بندی**

**1. ماتریس درهم‌ریختگی (Confusion Matrix)**
[cite_start]این ابزار، پایه و اساس درک عملکرد مدل شماست[cite: 805]. [cite_start]ماتریس درهم‌ریختگی یک جدول است که پیش‌بینی‌های مدل را در برابر واقعیت (برچسب‌های واقعی) مقایسه می‌کند[cite: 806].

* **ساختار ماتریس (برای دو کلاس: مثبت و منفی):**
    * **True Positive (TP):** نمونه‌هایی که واقعاً "مثبت" بودند و مدل نیز آن‌ها را به درستی "مثبت" پیش‌بینی کرده است.
        * [cite_start]**مثال:** سیستم دزدگیر زنگ می‌زند و **دزد واقعاً حضور دارد**. [cite: 662]
    * **True Negative (TN):** نمونه‌هایی که واقعاً "منفی" بودند و مدل نیز آن‌ها را به درستی "منفی" پیش‌بینی کرده است.
        * [cite_start]**مثال:** سیستم دزدگیر زنگ نمی‌زند و **دزد واقعاً حضور ندارد**. [cite: 663]
    * [cite_start]**False Positive (FP) - خطای نوع I:** نمونه‌هایی که واقعاً "منفی" بودند، اما مدل آن‌ها را به اشتباه "مثبت" پیش‌بینی کرده است (هشدار کاذب). [cite: 664]
        * [cite_start]**مثال:** سیستم دزدگیر زنگ می‌زند، اما **دزد حضور ندارد** (آژیر کاذب). [cite: 664]
    * [cite_start]**False Negative (FN) - خطای نوع II:** نمونه‌هایی که واقعاً "مثبت" بودند، اما مدل آن‌ها را به اشتباه "منفی" پیش‌بینی کرده است (عدم تشخیص). [cite: 665]
        * [cite_start]**مثال:** سیستم دزدگیر زنگ نمی‌زند، اما **دزد واقعاً حضور دارد** (دزد تشخیص داده نشده). [cite: 665]

[cite_start]**نکته کلیدی:** عبارت "True" یا "False" به **درستی پیش‌بینی مدل** اشاره دارد، و "Positive" یا "Negative" به **کلاسی که مدل پیش‌بینی کرده** اشاره دارد. [cite: 603, 633]

---

**2. معیارهای عملکرد اصلی (مشتق شده از ماتریس درهم‌ریختگی)**

حالا که انواع پیش‌بینی‌ها را شناختیم، می‌توانیم معیارهای دقیق‌تری را تعریف کنیم:

* **دقت (Accuracy):**
    * [cite_start]**تعریف:** نسبت تعداد کل پیش‌بینی‌های **صحیح** (TP و TN) به کل نمونه‌ها. [cite: 603]
    * [cite_start]**فرمول:** $Accuracy=\frac{True~Positives+True~Negatives}{Total~Samples}$ [cite: 603]
    * [cite_start]**چه زمانی گمراه کننده است؟** در مجموعه داده‌های **نامتوازن** (imbalanced datasets) که تعداد نمونه‌های یک کلاس (معمولاً کلاس منفی/اکثریت) بسیار بیشتر از کلاس دیگر است. [cite: 604, 646]
        * **مثال تشخیص سرطان:** اگر از 1000 بیمار، فقط 10 نفر سرطان داشته باشند، و مدل همه را "سالم" پیش‌بینی کند، دقت آن 99% خواهد بود. [cite_start]این مدل هیچ بیمار سرطانی را تشخیص نداده، اما دقت بالایی دارد! [cite: 634, 635]

* **بازخوانی (Recall) / حساسیت (Sensitivity):**
    * **تمرکز:** این معیار بر روی **مثبت‌های واقعی** تمرکز دارد.
    * [cite_start]**تعریف:** نسبت True Positives به **کل مثبت‌های واقعی** (نمونه‌هایی که واقعاً مثبت بودند). [cite: 680, 683]
    * [cite_start]**فرمول:** $Recall = Sensitivity = \frac{TP}{TP+FN}$ [cite: 680]
    * [cite_start]**به زبان ساده:** از تمام دزدانی که واقعاً آمدند، دزدگیر شما چند درصد را تشخیص داد (زنگ زد)؟ [cite: 683]
    * **کاربرد:** وقتی که از دست دادن موارد مثبت (False Negative) بسیار پرهزینه است. (مثلاً در تشخیص بیماری‌های جدی، نمی‌خواهیم بیماری را از دست بدهیم).

* **دقت (Precision):**
    * **تمرکز:** این معیار بر روی **مثبت‌های پیش‌بینی شده** توسط مدل تمرکز دارد.
    * [cite_start]**تعریف:** نسبت True Positives به **کل مواردی که مدل "مثبت" پیش‌بینی کرده است** (اعم از درست یا غلط). [cite: 690, 691]
    * [cite_start]**فرمول:** $Precision=\frac{TP}{TP+FP}$ [cite: 690]
    * [cite_start]**به زبان ساده:** از تمام دفعاتی که دزدگیر شما زنگ زد، چند درصد از آن زنگ‌ها واقعاً به خاطر وجود دزد بود؟ [cite: 691]
    * **کاربرد:** وقتی که هشدارهای کاذب (False Positive) بسیار پرهزینه است. (مثلاً در سیستم‌های امنیتی که هشدارهای کاذب زیاد، باعث نارضایتی می‌شود).

* **ویژگی (Specificity):**
    * **تمرکز:** این معیار بر روی **منفی‌های واقعی** تمرکز دارد.
    * [cite_start]**تعریف:** نسبت True Negatives به **کل منفی‌های واقعی** (نمونه‌هایی که واقعاً منفی بودند). [cite: 686, 687]
    * [cite_start]**فرمول:** $Specificity=\frac{TN}{TN+FP}$ [cite: 686]
    * [cite_start]**به زبان ساده:** از تمام دفعاتی که دزد واقعاً نیامده بود، دزدگیر شما چند درصد را به درستی تشخیص داد (زنگ نزد)؟ [cite: 687]
    * **تفاوت با Precision:** Precision به دقت پیش‌بینی‌های مثبت می‌پردازد، در حالی که Specificity به دقت پیش‌بینی‌های منفی واقعی می‌پردازد.

---

**3. معیارهای ترکیبی و جامع**

* **F1 Score:**
    * [cite_start]**هدف:** میانگین‌گیری از Precision و Recall برای ارائه یک معیار واحد و متعادل. [cite: 714]
    * [cite_start]**فرمول:** $F=\frac{1}{\frac{1}{2P}+\frac{1}{2R}}=\frac{2PR}{P+R}$ (میانگین هارمونیک) [cite: 717]
    * **چرا میانگین هارمونیک؟**
        * [cite_start]این میانگین یک نوع "حداقل هموار" (smooth minimum) است[cite: 762, 775].
        * به شدت به عملکرد ضعیف در هر یک از Precision یا Recall واکنش نشان می‌دهد. [cite_start]اگر یکی از این دو مقدار خیلی پایین باشد، F1 Score هم پایین می‌آید. [cite: 760]
        * [cite_start]میانگین حسابی ساده در مواقعی که یک معیار بسیار خوب و دیگری بسیار بد است، می‌تواند گمراه‌کننده باشد. [cite: 759]

* **AUC-ROC (Area Under the Receiver Operating Characteristic Curve):**
    * [cite_start]**ROC Curve:** نموداری است که True Positive Rate (TPR = Recall) را در مقابل False Positive Rate (FPR = 1 - Specificity) در آستانه‌های مختلف طبقه‌بندی رسم می‌کند. [cite: 927]
    * [cite_start]**AUC:** مساحت زیر منحنی ROC است. [cite: 925, 933]
    * **تفسیر:**
        * AUC بالا (نزدیک به 1) نشان‌دهنده توانایی "تفکیک" خوب مدل است. [cite_start]یعنی مدل می‌تواند به خوبی بین کلاس‌های مثبت و منفی تمایز قائل شود. [cite: 949]
        * [cite_start]AUC پایین (نزدیک به 0.5) نشان‌دهنده عملکرد تصادفی مدل است (مثل پرتاب سکه). [cite: 952, 934]
        * [cite_start]AUC بین 0 تا 1 متغیر است. [cite: 952]
    * **مزیت:** AUC یک معیار جامع است که عملکرد مدل را در **تمام آستانه‌های ممکن** ارزیابی می‌کند، نه فقط در یک آستانه خاص. این ویژگی آن را برای مقایسه مدل‌ها بسیار مفید می‌سازد.

**خلاصه برای جلوگیری از قاطی کردن:**

* **ماتریس درهم‌ریختگی:** تصویر کاملی از انواع پیش‌بینی‌های درست و غلط.
* **Accuracy (دقت):** ساده‌ترین، اما برای داده‌های نامتوازن، ناکافی.
* **Recall (کامل بودن):** چقدر از "مثبت‌های واقعی" را پیدا کردیم (اهمیت به FN کم).
* **Precision (صحت پیش‌بینی مثبت):** چقدر از "پیش‌بینی‌های مثبت" ما واقعاً درست بود (اهمیت به FP کم).
* **Specificity (دقت در منفی):** چقدر از "منفی‌های واقعی" را به درستی تشخیص دادیم.
* **F1 Score:** توازن بین Recall و Precision، برای داده‌های نامتوازن کاربردی‌تر.
* **AUC-ROC:** معیار جامع برای ارزیابی توانایی تفکیک مدل در آستانه‌های مختلف.

امیدوارم این تفکیک و مثال‌ها به شما کمک کند تا این مفاهیم را بهتر درک کرده و کمتر دچار اشتباه شوید!

---
---














































**ساختار اصلی یک یادگیرنده مبتنی بر نمونه (Instance-based Learner):**
برای ساخت یک یادگیرنده مبتنی بر نمونه مانند KNN، سه عنصر اصلی مورد نیاز است:
1.  **معیار فاصله (Distance Metric):** برای اندازه‌گیری نزدیکی بین نمونه‌ها.
    * **فاصله اقلیدسی (Euclidean Distance):** رایج‌ترین معیار فاصله. $d(x, x') = \sqrt[2]{||x-x'||_2^2} = \sqrt[2]{(x_1-x_1')^2 + \dots + (x_d-x_d')^2}$.
    * **فاصله اقلیدسی وزن‌دار (Weighted Euclidean Distance):** به ویژگی‌های خاص وزن می‌دهد. $d_w(x, x') = \sqrt[2]{w_1(x_1-x_1')^2 + \dots + w_d(x_d-x_d')^2}$.
    * **فاصله مینکوفسکی (Minkowski Distance):** یک حالت کلی از فواصل اقلیدسی و منهتن.
        * $d(x, x') = (\sum_{i=1}^{n}|x_i-x_i'|^p)^{1/p}$ برای $p \ge 1$.
        * وقتی $p=2$， فاصله اقلیدسی است.
        * این فاصله با نرم $L^p$ بردار $(x-x')$ برابر است.
    * **فاصله کسینوسی (Cosine Distance):** برای اندازه‌گیری زاویه بین بردارها استفاده می‌شود و به جای اندازه بردارها، به جهت آن‌ها اهمیت می‌دهد.
        * $d(x,x')=1 - \text{cosine similarity}(x,x')$.
        * $\text{cosine similarity}(x,x') = \frac{x \cdot x'}{||x||_2 ||x'||_2} = \frac{\sum_{i=1}^{d}x_i x_i'}{\sqrt{\sum_{i=1}^{d}x_i^2}\sqrt{\sum_{i=1}^{d}{x_i'^2}}}$.
2.  **تعداد همسایگان نزدیک (K):** تعداد نزدیکترین همسایگانی که برای تصمیم‌گیری در نظر گرفته می‌شوند.
3.  **تابع وزن‌دهی (اختیاری) (Weighting Function):** (اختیاری) برای اختصاص وزن‌های متفاوت به همسایگان بر اساس فاصله‌شان (همسایگان نزدیک‌تر وزن بیشتری دارند).
4.  **نحوه تعیین خروجی (Output Determination):** چگونه خروجی نهایی بر اساس همسایگان تعیین می‌شود.

**KNN برای رگرسیون (KNN Regression):**
در مسائل رگرسیون، KNN برای پیش‌بینی یک مقدار پیوسته استفاده می‌شود.
* **روش پیش‌بینی:** اگر $x'^{(1)}, \dots, x'^{(k)}$ K نزدیکترین همسایه به نمونه جدید $x$ باشند و $y'^{(1)}, \dots, y'^{(k)}$ مقادیر برچسب آن‌ها باشند، مقدار پیش‌بینی شده $\hat{y}$ به صورت میانگین مقادیر برچسب همسایگان محاسبه می‌شود:
    * $\hat{y} = \frac{1}{k} \sum_{j=1}^{k} y'^{(j)}$.
* **مشکلات KNN در رگرسیون:**
    * **ناپیوستگی (Discontinuities):** تابع تخمین زده شده توسط KNN می‌تواند دارای ناپیوستگی باشد.
    * **برازش نویز (Noise-fitting) در K=1:** مانند دسته‌بندی، در K=1، مدل به شدت به نویز حساس است و نویزهای داده را برازش می‌دهد.
    * **هموارسازی نویز و مشکلات دیگر در K > 1:** در K > 1، KNN نویز را هموار می‌کند، اما ممکن است مشکلات دیگری مانند "تخت کردن انتهای منحنی" (flats the ends) را ایجاد کند، به خصوص اگر K خیلی بزرگ باشد.
    * **مثال:** در یک مدل رگرسیون برای داده‌های سینوسی با نویز، با افزایش K، منحنی پیش‌بینی شده هموارتر می‌شود، اما اگر K خیلی بزرگ باشد، ممکن است از شکل واقعی منحنی منحرف شود و به سمت یک خط مستقیم میل کند.
