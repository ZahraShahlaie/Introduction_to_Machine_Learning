

# جزوه آموزشی درس یادگیری ماشین (CE 40477)

**موضوع:** تعمیم (Generalization) و رگرسیون احتمالی (Probabilistic Regression)
**تاریخ:** ۳۰ سپتامبر ۲۰۲۴
**مدرس:** دکتر علی شریفی‌زارچی

---

## ۱. تعمیم (Generalization)

### ۱.۱. مروری بر تعمیم (Generalization Overview)

 **ایده اصلی:**
 
  توانایی یک مدل برای عملکرد خوب روی داده‌هایی که در فرایند آموزش ندیده است (داده‌های unseen).

 **مجموعه آموزشی (Training Set):**
 
  مجموعه‌ای از داده‌های برچسب‌دار که مدل برای یادگیری الگوها از آن استفاده می‌کند:
  $D = \{(x_i, y_i)\}_{i=1}^n$

 **مجموعه تست (Test Set):**
 
  داده‌هایی که مدل در طول آموزش ندیده و برای ارزیابی تعمیم مدل استفاده می‌شوند.

 **تابع هزینه (Cost Function):**
  
  تابعی که میزان تطابق مدل با داده‌ها را اندازه می‌گیرد. در رگرسیون معمولاً از مجموع مربعات خطا (Sum of Squared Errors - SSE) استفاده می‌شود:

$$
J(w) = \sum_{i=1}^n (y^{(i)} - h_w(x^{(i)}))^2
$$

**هدف:**
  کمینه‌سازی تابع هزینه روی داده‌های دیده نشده، یعنی کمینه کردن خطای تعمیم (generalization error).



**پس به صورت کلی می توان گفت:**


**تعمیم** در واقع به معنای توانایی یک مدل یادگیری ماشین برای عملکرد موثر و پیش‌بینی دقیق بر روی داده‌های دیده نشده (unseen data) است. این مفهوم، هدف نهایی و سنگ محک موفقیت یک مدل یادگیری ماشین محسوب می‌شود. برای دستیابی به این هدف، ما از مجموعه‌ای از داده‌های برچسب‌دار به نام **مجموعه آموزشی (Training Set)** استفاده می‌کنیم. این مجموعه، که به صورت $D = \{ (x_i, y_i) \}_{i=1}^n$ نمایش داده می‌شود، همان داده‌هایی هستند که مدل برای یادگیری الگوها، روابط و ساختار پنهان بین ویژگی‌های ورودی $x_i$ و برچسب‌های خروجی $y_i$ از آن‌ها استفاده می‌کند.

پس از آموزش، برای ارزیابی واقعی عملکرد مدل، آن را بر روی **مجموعه تست (Test Set)** اعمال می‌کنیم. مجموعه تست شامل داده‌های کاملاً جدیدی است که مدل هرگز در طول فرآیند آموزش آن‌ها را ندیده و به این ترتیب، عملکرد مدل را در دنیای واقعی و در مواجهه با ورودی‌های ناشناخته می‌سنجد.

برای اندازه‌گیری میزان "خوبیِ" تطابق مدل با داده‌ها، از یک **تابع هزینه (Cost Function)** استفاده می‌شود. در مسائل رگرسیون، یکی از رایج‌ترین توابع هزینه، **مجموع مربعات خطا (Sum of Squared Errors - SSE)** است که به صورت:

$$
J(w) = \sum_{i=1}^{n} (y^{(i)} - h_w(x^{(i)}))^2
$$

تعریف می‌شود. در این فرمول، $y^{(i)}$ مقدار واقعی و $h_w(x^{(i)})$ مقدار پیش‌بینی شده توسط مدل برای نمونه $i$-ام است. هدف نهایی در فرآیند آموزش مدل، کمینه‌سازی این تابع هزینه بر روی داده‌های دیده نشده است؛ این همان چیزی است که به آن **خطای تعمیم (generalization error)** می‌گوییم و نشان‌دهنده توانایی مدل در تعمیم آموخته‌های خود به داده‌های جدید است.




**توضیحات اضافه برای درک بهتر:**
تصور کنید شما در حال آماده شدن برای یک امتحان مهم هستید. کتاب درسی و نمونه سؤالات گذشته‌ای که مطالعه می‌کنید، حکم مجموعه آموزشی شما را دارند. شما تمام تلاش خود را می‌کنید تا این مطالب را به خوبی یاد بگیرید (مدل آموزش می‌بیند). هدف اصلی شما چیست؟ این است که در امتحان واقعی (که سؤالات آن را قبلاً ندیده‌اید و نقش مجموعه تست را دارد) نمره‌ی خوبی بگیرید. اگر شما فقط سؤالات نمونه را "حفظ" کنید و در امتحان واقعی با سؤالات جدید نتوانید آن‌ها را حل کنید، این یعنی توانایی تعمیم‌پذیری خوبی ندارید. تابع هزینه در اینجا مانند نمره‌ی شما در امتحانات تمرینی است که نشان می‌دهد چقدر خوب داده‌های آموزشی را پیش‌بینی کرده‌اید. اما در نهایت، موفقیت شما با نمره‌تان در امتحان اصلی (داده‌های دیده نشده) سنجیده می‌شود.



---

### ۱.۲. خطای مورد انتظار تست (Expected Test Error)
خطای مورد انتظار تست به معنای عملکرد مورد انتظار مدل بر روی داده‌های دیده نشده است. این معیار، یک رویکرد ایده‌آل‌گرایانه را در نظر می‌گیرد که فرض می‌کند داده‌های تست از همان توزیع احتمالی $p(x, y)$ که داده‌های آموزشی از آن نمونه‌برداری شده‌اند، گرفته می‌شوند. به عبارت دیگر، ما فرض می‌کنیم که داده‌های آینده از همان الگوهای آماری گذشته پیروی خواهند کرد.

فرمول ریاضی این خطای مورد انتظار به صورت:

$$
J(w) = \mathbb{E}_{p(x,y)} \left[ (y - h_w(x))^2 \right]
$$

بیان می‌شود. این نشان‌دهنده میانگین مربعات خطا بر روی تمام داده‌های ممکن (نه فقط مجموعه تست محدود ما) با توجه به توزیع واقعی داده‌ها است.

از آنجایی که در عمل دسترسی به توزیع کامل $p(x, y)$ غیرممکن است، ما معمولاً این خطای مورد انتظار را با استفاده از مجموعه تست خود تخمین می‌زنیم. این تخمین با علامت $\hat{J}(w)$ نشان داده می‌شود.

**خطای تعمیم (Generalization error)** در واقع به عنوان شکاف یا تفاوت بین عملکرد مدل بر روی داده‌های آموزشی و داده‌های تست تعریف می‌شود. هرچه این شکاف بزرگتر باشد، نشان‌دهنده این است که مدل کمتر قادر به تعمیم آموخته‌های خود به داده‌های جدید و ناشناخته است.

**توضیحات اضافه:**
خطای مورد انتظار تست مثل این است که ما بخواهیم بدانیم یک دانش‌آموز در "همه‌ی" امتحانات ممکن در آینده چه نمره‌ای می‌گیرد، با فرض اینکه سؤالات آینده هم از همان منبع و با همان سختی سؤالات قبلی باشند. چون این کار عملی نیست، ما از یک "آزمون آزمایشی" (مجموعه تست) برای تخمین این نمره استفاده می‌کنیم. اگر دانش‌آموز در امتحانات تمرینی (آموزش) خیلی خوب باشد، ولی در آزمون آزمایشی (تست) بد باشد، یعنی "شکافی" بین عملکرد او وجود دارد که نشان می‌دهد توانایی تعمیم‌پذیری‌اش پایین است.

![image](https://github.com/user-attachments/assets/a561039e-02d5-4a4f-8b81-3f4ef63d437d)


---

### ۱.۳. خطای آموزش در مقابل خطای تست (Training vs. Test Error)
در یادگیری ماشین، تمایز بین **خطای آموزش (Training error)** و **خطای تست (Test error)** یک مفهوم کلیدی و بنیادین است.

* **خطای آموزش**، همانطور که از نامش پیداست، میزان تطابق و برازش مدل را با داده‌های شناخته‌شده یا همان مجموعه آموزشی اندازه‌گیری می‌کند. این خطا به صورت:

$$
J_{\text{train}}(w) = \frac{1}{n} \sum_{i=1}^n (y^{(i)} - h_w(x^{(i)}))^2
$$

محاسبه می‌شود.

* در مقابل، **خطای تست** میزان تطابق مدل را با داده‌های کاملاً جدید و دیده نشده ارزیابی می‌کند. این خطا با فرمول:

$$
J_{\text{test}}(w) = \frac{1}{m} \sum_{i=1}^m (y_{\text{test}}^{(i)} - h_w(x_{\text{test}}^{(i)}))^2
$$

تعریف می‌شود.

**هدف نهایی** و اصلی در توسعه مدل‌های یادگیری ماشین، **کمینه‌سازی خطای تست** است. این هدف به معنای دستیابی به بهترین توانایی تعمیم‌پذیری مدل است تا بتواند در سناریوهای واقعی و با داده‌های جدید، به طور موثر عمل کند.

**توضیحات اضافه:**
تصور کنید یک ورزشکار برای مسابقه‌ی مهمی تمرین می‌کند. عملکرد او در تمرینات (مثل دویدن سریع‌تر از حد نرمال در تمرین) همان خطای آموزش است – چقدر خوب روی داده‌های "شناخته‌شده" عمل می‌کند. اما عملکرد او در روز مسابقه، در شرایط جدید و با رقبای ناشناخته، همان خطای تست است. هدف واقعی، نه فقط خوب بودن در تمرین، بلکه درخشش در مسابقه اصلی است.

![image](https://github.com/user-attachments/assets/c71fa299-7d8a-4612-a0ac-fe14e313e290)

---

### ۱.۴. تعریف بیش‌برازش (Overfitting)

 **مفهوم:** مدل داده‌های آموزشی را بسیار دقیق یاد می‌گیرد اما روی داده‌های جدید عملکرد ضعیف دارد.

 **نشانه:**

$$
J_{\text{train}}(w) \ll J_{\text{test}}(w)
$$

 **علل و نتیجه:**  این اتفاق معمولاً زمانی رخ می‌دهد که مدل بیش از حد پیچیده باشد. به عنوان مثال، استفاده از تعداد زیادی ویژگی (ورودی) یا انتخاب یک مدل با درجه بالا (مانند چندجمله‌ای با درجه بسیار زیاد) می‌تواند منجر به این وضعیت شود. پیچیدگی بیش از حد مدل، باعث می‌شود که مدل حتی **نویز (Noise)** موجود در داده‌های آموزشی را نیز یاد بگیرد و نه فقط الگوهای اصلی را. در نتیجه، این مدل‌ها بر روی داده‌های جدید و دیده نشده، با شکست مواجه می‌شوند و نمی‌توانند به درستی تعمیم پیدا کنند.


**توضیح اضافه:** فرض کنید فقط سوالات سال‌های قبل را حفظ کنید. نمره شما در آن سوالات (خطای آموزش) عالی است ولی در سوالات جدید (داده تست) نمره بدی می‌گیرید. این همان بیش‌برازش است. یا مثل اینه که شما برای امتحان، نه تنها مطالب اصلی رو می‌خونید، بلکه جزئیات بی‌اهمیت، مثل حاشیه‌نویسی‌های اشتباه یا غلط املایی کتاب رو هم "حفظ" می‌کنید. وقتی سؤالات جدید در امتحان (داده‌ی تست) می‌آد، چون شما فقط جزئیات بی‌ربط رو حفظ کردید، نمی‌تونید جواب درست رو بدید و نمره‌تون (خطای تست) بد میشه، در حالی که تو سؤالای تمرینی (داده‌ی آموزش) عالی بودید. مدل اینجا به جای یادگیری، "کپی‌برداری" از نویز کرده.


![image](https://github.com/user-attachments/assets/fd891e55-af07-48b5-b42d-e8b1a5329911)

---

### ۱.۵. تعریف کم‌برازش (Underfitting Definition)

در مقابل **بیش‌برازش (Overfitting)**، **کم‌برازش (Underfitting)** حالتی است که در آن مدل بیش از حد ساده است و نمی‌تواند ساختار واقعی و الگوهای اساسی داده‌ها را به درستی تشخیص دهد. نشانه‌ی کم‌برازش این است که **خطای آموزش** $J_{\text{train}}(w)$ تقریباً برابر با **خطای تست** $J_{\text{test}}(w)$ است، اما هر دو مقدار نسبتاً زیادی دارند و به صفر نزدیک نیستند ($J_{\text{train}}(w) \approx J_{\text{test}}(w) \gg 0$).



$$
J_{\text{train}}(w) \approx J_{\text{test}}(w) \gg 0
$$


 **علل:** این وضعیت معمولاً ناشی از **کمبود پیچیدگی در مدل** است؛ مثلاً استفاده از تعداد بسیار کمی ویژگی یا انتخاب یک مدل با درجه خیلی پایین که قدرت لازم برای مدل‌سازی پیچیدگی‌های داده را ندارد. نتیجه‌ی کم‌برازش، **عملکرد ضعیف هم بر روی داده‌های آموزشی و هم بر روی داده‌های تست** است، زیرا مدل حتی قادر به یادگیری الگوهای ساده‌تر نیز نشده است که منجر به بایاس (Bias) بالا می‌شود.


 **نتیجه:**  عملکرد ضعیف هم بر روی داده‌های آموزشی و هم بر روی داده‌های تست.

**توضیح اضافه:**

کم‌برازش مثل اینه که شما برای امتحان، فقط مقدمه‌ی کتاب رو می‌خونید و کلاً وارد جزئیات و مطالب اصلی نمیشید. در این صورت، نه سؤالات تمرینی (داده‌ی آموزش) رو خوب پاسخ میدید (خطای آموزش بالا)، و نه سؤالات امتحان (داده‌ی تست) رو. مدل اینجا حتی نتونسته الگوهای ساده رو هم یاد بگیره، چون ابزار لازم (پیچیدگی) رو برای این کار نداشته.
![image](https://github.com/user-attachments/assets/df9e90ee-6cf7-4156-b357-64b5f9d1b68f)

---


### ۱.۶. تعمیم: رگرسیون چندجمله‌ای (Generalization: Polynomial Regression)

 **با افزایش درجه چندجمله‌ای مدل (افزایش پیچیدگی)**، مدل بهتر روی داده‌های آموزشی فیت می‌شود:

   **درجه 1:** مدل خطی، ممکن است دچار کم‌برازش باشد (خط صاف).
  
   **درجه 3:** مدل پیچیده‌تر، فیت بهتری روی داده‌های آموزشی دارد.
  
   **درجه 5 و 7:** مدل‌های بسیار پیچیده، که می‌توانند منجر به بیش‌برازش شوند. منحنی‌ها "پیچ و خم" زیادی پیدا می‌کنند تا از تمام نقاط آموزشی عبور کنند، حتی نویز.
![image](https://github.com/user-attachments/assets/da9861bc-fcca-443f-adaf-bb2149f3c721)
![image](https://github.com/user-attachments/assets/791e28e2-78f9-469f-918e-075f1b4fdc28)
![image](https://github.com/user-attachments/assets/70782ac1-fde0-4f56-8f01-c48802e66b16)
![image](https://github.com/user-attachments/assets/52a5e261-6f59-45d9-a7cb-c4cb4a3b8b16)


#### خطای جذر میانگین مربعات (Root Mean Squared Error - ERMS):

$$
ERMS = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y^{(i)} - f(x^{(i)}; w))^2}
$$

این معیار برای سنجش خطا در رگرسیون استفاده می‌شود.

#### نمودار ERMS:

نمودار ERMS نشان می‌دهد که با افزایش پیچیدگی مدل (درجه $M$)، خطای آموزش (آبی) کاهش می‌یابد، اما خطای تست (قرمز) پس از یک نقطه بهینه، شروع به افزایش می‌کند که نشان‌دهنده بیش‌برازش است.

![image](https://github.com/user-attachments/assets/52f4bd16-646c-4678-901c-ddcc043d7301)

**توضیح اضافه:**

این مثال رگرسیون چندجمله‌ای به وضوح رابطه‌ی پیچیدگی مدل با کم‌برازش و بیش‌برازش را نشان می‌دهد. با یک مدل خیلی ساده، داده‌ها را نمی‌توانید خوب مدل کنید (کم‌برازش). با افزایش پیچیدگی، مدل بهتر می‌شود، اما اگر خیلی پیچیده شود، شروع به حفظ کردن نویز می‌کند (بیش‌برازش).


---

### ۱.۷. تجزیه بایاس-واریانس (Bias-Variance Decomposition)

**تجزیه بایاس-واریانس** یک چارچوب تحلیلی قدرتمند است که **خطای مورد انتظار مربع خطا (Expected Squared Error)** را به سه مؤلفه اصلی تقسیم می‌کند. این تجزیه به ما کمک می‌کند تا منابع خطای مدل را بهتر درک کنیم:

$$
E[(y - h_w(x))^2] = (\text{Bias})^2 + \text{Variance} + \text{Noise}
$$

در این فرمول:

* **بایاس (Bias):** این مؤلفه نشان‌دهنده‌ی خطای ناشی از فرض‌های ساده‌کننده در مدل است. به عنوان مثال، اگر داده‌ها واقعاً یک رابطه‌ی غیرخطی داشته باشند اما ما از یک مدل خطی استفاده کنیم، مدل هرگز نمی‌تواند رابطه واقعی را به طور کامل ثبت کند و همیشه یک "تعصب" سیستماتیک در پیش‌بینی‌هایش خواهد داشت. بایاس بالا معمولاً نشان‌دهنده **کم‌برازش (Underfitting)** است. به صورت ریاضی، بایاس برای یک نقطه $x$ به صورت:

$$
\text{Bias}(x) = E[h_w(x)] - f(x)
$$

تعریف می‌شود، که تفاوت بین میانگین پیش‌بینی‌های مدل و تابع واقعی (زمینه‌ی حقیقی) را نشان می‌دهد.

* **واریانس (Variance):** این مؤلفه حساسیت مدل به تغییرات در داده‌های آموزشی را نشان می‌دهد. واریانس بالا به این معنی است که اگر مجموعه داده آموزشی کمی تغییر کند (مثلاً نمونه‌های متفاوتی برای آموزش انتخاب شوند)، مدل خروجی‌های بسیار متفاوتی تولید خواهد کرد. واریانس بالا معمولاً نشان‌دهنده **بیش‌برازش (Overfitting)** است. به صورت ریاضی، واریانس برای یک نقطه $x$ به صورت:

$$
\text{Variance}(x) = E[(h_w(x) - E[h_w(x)])^2]
$$

تعریف می‌شود، که میزان پراکندگی پیش‌بینی‌های مدل حول میانگین پیش‌بینی‌های آن را نشان می‌دهد.

* **نویز (Noise) یا خطای غیرقابل کاهش (Irreducible Error):** این مؤلفه نشان‌دهنده‌ی خطایی است که به دلیل تصادفی بودن ذاتی داده‌ها ایجاد می‌شود. حتی اگر مدل ما کامل‌ترین مدل ممکن باشد و داده‌های آموزشی نامحدود در اختیار داشته باشیم، باز هم به دلیل وجود نویز (مثل خطاهای اندازه‌گیری یا عوامل ناشناخته)، همیشه یک حداقل خطا وجود خواهد داشت که نمی‌توان آن را با هیچ مدل یادگیری ماشینی کاهش داد. این خطا به صورت $\sigma^2$ (واریانس نویز) نمایش داده می‌شود.

* 

![image](https://github.com/user-attachments/assets/8c23000f-3992-4552-8bf3-12af9c130d77)
![image](https://github.com/user-attachments/assets/3045da42-bdda-4636-9db6-a5ca442164b9)
در مدل رگرسیون، تابع اصلی به صورت سبز و آبی نمایش داده می‌شود. پیش‌بینی‌ها برای داده‌های مختلف با رنگ‌های زرد و آبی نشان داده می‌شوند و در نهایت، میانگین پیش‌بینی‌ها به صورت قرمز نمایش داده می‌شود. سپس، اختلاف بین پیش‌بینی‌ها و مقادیر واقعی (یعنی 
𝑓
(
𝑥
)
f(x) واقعی) محاسبه می‌شود تا خطاها و بایاس مدل بررسی شوند.

این خطاها می‌توانند شامل بایاس و واریانس باشند. بایاس به میزان انحراف پیش‌بینی‌ها از مقادیر واقعی اشاره دارد، در حالی که واریانس نشان‌دهنده تنوع پیش‌بینی‌ها بر اساس داده‌های مختلف است. به‌طور کلی، هرچه درجه چندجمله‌ای بیشتر باشد، مدل می‌تواند پیچیده‌تر و انعطاف‌پذیرتر باشد. این امر باعث افزایش واریانس می‌شود و احتمال overfitting (بیش‌برازش) را بالا می‌برد.

در این شرایط، ممکن است مدل به خوبی نتواند عملکرد مطلوبی داشته باشد، زیرا در تلاش برای به دست آوردن بهترین پیش‌بینی برای داده‌های آموزش، بیش از حد به جزئیات داده‌ها توجه می‌کند و خطای زیادی نسبت به داده‌های واقعی ایجاد می‌شود. به عبارت دیگر، مدل نمی‌تواند به درستی داده‌های جدید را پیش‌بینی کند، زیرا به ویژگی‌های جزئی و نویز داده‌های آموزشی بیش از حد حساس است.

بایاس به‌طور مستقیم تحت تأثیر درجه چندجمله‌ای قرار دارد. برای مثال، در یک مدل درجه 3 ممکن است پیش‌بینی‌ها دقیق باشند، اما با افزایش درجه و پیچیدگی مدل، بایاس کاهش می‌یابد، اما واریانس بیشتر می‌شود. هرچه تعداد پارامترهای مدل بیشتر شود، احتمال افزایش واریانس نیز بیشتر می‌شود.

در نهایت، این تغییرات نشان‌دهنده این است که پیچیدگی بیشتر مدل (از طریق افزایش تعداد پارامترها یا درجه چندجمله‌ای) می‌تواند باعث افزایش واریانس و در نتیجه افزایش خطر overfitting شود.


### اثبات تجزیه بایاس-واریانس (صفحات 15 تا 17 PDF)

فایل PDF مراحل اثبات این تجزیه را با جزئیات ریاضی نشان می‌دهد. فرض می‌شود که خروجی مشاهده شده $y$ یک مشاهده نویزی از تابع واقعی $f(x)$ است:

$$
y = f(x) + \epsilon
$$

که $\epsilon$ نویز گاوسی با میانگین صفر و واریانس $\sigma^2$ است. با بسط دادن عبارت **خطای مربع مورد انتظار** $E_{\text{data}}[(f(x) - y)^2]$ و استفاده از خواص امید ریاضی و استقلال نویز از تابع، می‌توان نشان داد که این عبارت به سه ترم $\text{Variance} + (\text{Bias})^2 + \sigma^2$ تجزیه می‌شود.


### توضیحات اضافه:

این یک مفهوم کلیدی و شاید کمی دشوار اما بسیار مهم در یادگیری ماشین است. تصور کنید که در حال هدف‌گیری هستید:

* **بایاس بالا:** تیرهای شما همیشه به یک سمت خاصی از هدف می‌خورند (مثلاً همیشه کمی به چپ). این ناشی از یک مشکل سیستماتیک در تنظیم تفنگ یا نحوه‌ی نشانه‌گیری شماست. در مدل، این یعنی مدل ما از ابتدا یک فرض اشتباه (مثلاً خطی بودن) را در مورد داده‌ها دارد.

* **واریانس بالا:** تیرهای شما در هر بار شلیک به نقاط بسیار پراکنده و متفاوتی در اطراف هدف می‌خورند (بعضی خیلی راست، بعضی خیلی چپ، بعضی بالا، بعضی پایین). این ناشی از ناپایداری در دست شما یا تفنگ است. در مدل، این یعنی مدل ما بیش از حد به جزئیات کوچک مجموعه داده آموزشی حساس است و با کمی تغییر در داده‌های آموزشی، خروجی‌های بسیار متفاوتی می‌دهد.

* **نویز:** حتی بهترین تیرانداز هم در بهترین شرایط، تیرش دقیقاً روی نقطه‌ی مرکزی هدف نمی‌خورد؛ همیشه یک پراکندگی بسیار جزئی و غیرقابل کنترل (مثلاً به خاطر باد، لرزش دست) وجود دارد. این همان خطای غیرقابل کاهش در داده‌هاست.

---

### ۱.۸. بایاس بالا در مدل‌های ساده (High Bias in Simple Models)

مدل‌های ساده، مانند **رگرسیون خطی ساده** (که به صورت $h_w(x) = w_0 + w_1 x$ نمایش داده می‌شود)، اغلب دچار **کم‌برازش (Underfit)** می‌شوند. این پدیده به این دلیل رخ می‌دهد که چنین مدل‌هایی، با وجود سادگی، توانایی کافی برای ثبت پیچیدگی‌های موجود در داده‌های واقعی را ندارند. نشانه اصلی **بایاس بالا** این است که **مؤلفه بایاس مربع** $(\text{Bias})^2$ به طور قابل توجهی بزرگ‌تر از واریانس می‌شود $(\text{Bias}^2 \gg \text{Variance})$. این بدان معناست که منبع اصلی خطای مدل، فرض‌های ساده‌کننده‌ی آن است. در نتیجه، حتی با فراهم آوردن **داده‌های نامحدود برای آموزش**، این مدل‌ها همچنان قادر به یادگیری رابطه واقعی نخواهند بود و **خطای تعمیم** (Generalization Error) آن‌ها بالا باقی می‌ماند.
![image](https://github.com/user-attachments/assets/65d1feb3-fcbc-4ca4-899a-b01a2e9d6a52)


---

### ۱.۹. واریانس بالا در مدل‌های پیچیده (High Variance in Complex Models)

در مقابل مدل‌های ساده، مدل‌های پیچیده مانند **رگرسیون چندجمله‌ای با درجه بالا** (که به صورت $h_w(x) = w_0 + w_1 x + w_2 x^2 + \dots + w_m x^m$ نمایش داده می‌شود)، تمایل زیادی به **بیش‌برازش (Overfitting)** دارند. این مدل‌ها به دلیل پیچیدگی بالای خود، می‌توانند به دقت بسیار زیادی بر روی داده‌های آموزشی منطبق شوند، اما این تطابق بیش از حد شامل **نویز** موجود در داده‌های آموزشی نیز می‌شود. نشانه‌ی **واریانس بالا** این است که:

$$
\text{Variance} \gg \text{Bias}
$$

نتیجه‌ی این رفتار، **عملکرد ضعیف بر روی داده‌های دیده نشده** (یعنی خطای تست بالا) است، زیرا مدل الگوهای عمومی را یاد نگرفته، بلکه جزئیات خاص مجموعه آموزشی را حفظ کرده است.

![image](https://github.com/user-attachments/assets/17e8c8e4-5eaa-456b-bb23-0290c27a020d)

---


### ۱.۱۰. داد و ستد بایاس-واریانس (Bias-Variance Tradeoff)

**داد و ستد بایاس-واریانس** (Bias-Variance Tradeoff) یک مفهوم کلیدی و بنیادین در یادگیری ماشین است که به معنای لزوم برقراری تعادل میان **بایاس** و **واریانس** برای دستیابی به **عملکرد بهینه مدل** است. این دو مؤلفه معمولاً **رابطه معکوسی** با یکدیگر دارند:

* **مدل با پیچیدگی پایین:** منجر به **بایاس بالا** و **واریانس پایین** می‌شود. چنین مدلی ساده است و قادر به ثبت تمام جزئیات داده‌ها نیست (بایاس بالا)، اما در عین حال، به تغییرات کوچک در داده‌های آموزشی حساس نیست (واریانس پایین) و از این رو دچار **کم‌برازش** می‌شود.

* **مدل با پیچیدگی بالا:** منجر به **بایاس پایین** و **واریانس بالا** می‌شود. این مدل قادر به ثبت پیچیدگی‌های بیشتری از داده‌ها است (بایاس پایین)، اما در مقابل به نویز موجود در داده‌های آموزشی بیش از حد حساس شده و به شدت به داده‌های آموزشی خود وابسته می‌شود (واریانس بالا) و در نتیجه دچار **بیش‌برازش** می‌شود.

هدف از این داد و ستد، یافتن **نقطه بهینه** در طیف پیچیدگی مدل است، جایی که مجموع $\text{Bias}^2 + \text{Variance}$ (به علاوه نویز) به کمترین مقدار خود برسد. این نقطه همان جایی است که مدل **بهترین تعمیم‌پذیری** را به داده‌های جدید نشان می‌دهد.


* بایاس بالا: مدل ساده
* واریانس بالا: مدل پیچیده
* نویز: خطای غیرقابل حذف

![image](https://github.com/user-attachments/assets/0d543534-c13c-44cb-b325-7916676d7c60)

---





#### **منابع:**

1. C. M., *Pattern Recognition and Machine Learning*. Information Science and Statistics, New York, NY: Springer, 1st ed., Aug. 2006.
2. M. Soleymani Baghshah, “Machine learning." Lecture slides.
3. A. Ng and T. Ma, *CS229 Lecture Notes*.
4. T. Mitchell, *Machine Learning*. McGraw-Hill series in computer science, New York, NY: McGraw-Hill Professional, Mar. 1997.
5. Y. S. Abu-Mostafa, M. Magdon-Ismail, and H.-T. Lin, *Learning From Data: A Short Course*. New York, NY: AMLBook, 2012.
6. S. Goel, H. Bansal, S. Bhatia, R. A. Rossi, V. Vinay, and A. Grover, "CyCLIP: Cyclic Contrastive Language-Image Pretraining," ArXiv, vol. abs/2205.14459, May 2022.

---

