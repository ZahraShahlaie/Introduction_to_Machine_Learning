با کمال میل!
در ادامه، بخش ابتدایی و توضیحات کامل جزوه‌ی آموزشی بر اساس فایل PDF "01-Linear Regression-part 2.pdf" به زبان فارسی آمده است. این متن شامل تعاریف، مفاهیم کلیدی و توضیحات اضافه برای درک بهتر است.

---

# جزوه آموزشی درس یادگیری ماشین (CE 40477)

**موضوع:** تعمیم (Generalization) و رگرسیون احتمالی (Probabilistic Regression)
**تاریخ:** ۳۰ سپتامبر ۲۰۲۴
**مدرس:** دکتر علی شریفی‌زارچی
**تهیه و تنظیم:** عرشیا غارونی، ماهان بیاهقی (با ویرایش و تکمیل)

---

## ۱. تعمیم (Generalization)

### ۱.۱. مروری بر تعمیم (Generalization Overview)

* **ایده اصلی:**
  توانایی یک مدل برای عملکرد خوب روی داده‌هایی که در فرایند آموزش ندیده است (داده‌های unseen).

* **مجموعه آموزشی (Training Set):**
  مجموعه‌ای از داده‌های برچسب‌دار که مدل برای یادگیری الگوها از آن استفاده می‌کند:
  $D = \{(x_i, y_i)\}_{i=1}^n$

* **مجموعه تست (Test Set):**
  داده‌هایی که مدل در طول آموزش ندیده و برای ارزیابی تعمیم مدل استفاده می‌شوند.

* **تابع هزینه (Cost Function):**
  تابعی که میزان تطابق مدل با داده‌ها را اندازه می‌گیرد. در رگرسیون معمولاً از مجموع مربعات خطا (Sum of Squared Errors - SSE) استفاده می‌شود:

$$
J(w) = \sum_{i=1}^n (y^{(i)} - h_w(x^{(i)}))^2
$$

* **هدف:**
  کمینه‌سازی تابع هزینه روی داده‌های دیده نشده، یعنی کمینه کردن خطای تعمیم (generalization error).

---

**توضیح اضافه:**
فرض کنید برای یک امتحان کتابی مطالعه می‌کنید (مجموعه آموزشی). هدف این است که در امتحان واقعی که سؤالات جدید دارد (مجموعه تست)، نمره خوبی کسب کنید. اگر فقط سؤالات کتاب را حفظ کنید و در مواجهه با سؤالات جدید ناکام بمانید، یعنی مدل شما تعمیم‌پذیری خوبی ندارد. تابع هزینه مانند نمره آزمون است که نشان می‌دهد مدل چقدر خوب پیش‌بینی کرده است.

---

### ۱.۲. خطای مورد انتظار تست (Expected Test Error)

* **تعریف:**
  میانگین خطای پیش‌بینی مدل روی داده‌های دیده نشده، که به عنوان معیار واقعی عملکرد مدل است.

* **مبنای نظری:**
  فرض می‌شود داده‌های تست و آموزش از یک توزیع احتمالی $p(x,y)$ نمونه‌برداری شده‌اند.

* **فرمول:**

$$
J(w) = \mathbb{E}_{p(x,y)} \left[ (y - h_w(x))^2 \right]
$$

* **تقریب:**
  در عمل به جای این مقدار انتزاعی، از خطای محاسبه شده روی مجموعه تست (نمونه محدود) استفاده می‌کنیم:

$$
\hat{J}(w)
$$

* **خطای تعمیم:**
  شکاف بین عملکرد مدل روی داده‌های آموزشی و تست است. هرچه این شکاف بزرگ‌تر باشد، مدل کمتر تعمیم‌پذیر است.

---

**توضیح اضافه:**
خطای مورد انتظار تست ایده‌آل‌ترین معیار است زیرا همه داده‌های ممکن را در نظر می‌گیرد. در عمل، چون تمام داده‌ها در دسترس نیست، با نمونه‌های تست محدود این خطا را تقریب می‌زنیم.

---

### ۱.۳. خطای آموزش در مقابل خطای تست (Training vs. Test Error)

* **خطای آموزش (Empirical error):**

$$
J_{\text{train}}(w) = \frac{1}{n} \sum_{i=1}^n (y^{(i)} - h_w(x^{(i)}))^2
$$

* **خطای تست:**

$$
J_{\text{test}}(w) = \frac{1}{m} \sum_{i=1}^m (y_{\text{test}}^{(i)} - h_w(x_{\text{test}}^{(i)}))^2
$$

* **هدف:**
  کمینه‌سازی خطای تست، که همان تعمیم‌پذیری است.

---

**توضیح اضافه:**
اگر خطای آموزش پایین ولی خطای تست بالا باشد، مدل احتمالاً دچار بیش‌برازش شده است (یعنی فقط داده‌های آموزشی را به خوبی یاد گرفته ولی روی داده‌های جدید عملکرد ضعیفی دارد).

---

### ۱.۴. تعریف بیش‌برازش (Overfitting)

* **مفهوم:**
  مدل داده‌های آموزشی را بسیار دقیق یاد می‌گیرد اما روی داده‌های جدید عملکرد ضعیف دارد.

* **نشانه:**

$$
J_{\text{train}}(w) \ll J_{\text{test}}(w)
$$

* **علل:**
  مدل خیلی پیچیده است (مثلاً تعداد زیاد ویژگی یا مدل با درجه بالا) و نویز داده‌ها را نیز یاد می‌گیرد.

* **نتیجه:**
  مدل به جای یادگیری الگوهای کلی، نویز داده‌های آموزشی را یاد می‌گیرد و روی داده‌های جدید به خوبی کار نمی‌کند.

---

**توضیح اضافه:**
فرض کنید فقط سوالات سال‌های قبل را حفظ کنید. نمره شما در آن سوالات (خطای آموزش) عالی است ولی در سوالات جدید (داده تست) نمره بدی می‌گیرید. این همان بیش‌برازش است.

---

اگر مایلید، می‌توانم بخش‌های بعدی جزوه یا تمرین‌ها و مثال‌ها را هم برایتان آماده کنم.




### ۱.۵. تعریف کم‌برازش (Underfitting Definition)

#### مفهوم:

کم‌برازش به حالتی اطلاق می‌شود که مدل داده‌های آموزشی را به خوبی مدل نمی‌کند و نمی‌تواند ساختار واقعی داده‌ها را به درستی تشخیص دهد.

#### نشانه:

$$
J_{\text{train}}(w) \approx J_{\text{test}}(w) \gg 0
$$

در این حالت، خطای آموزش تقریباً برابر با خطای تست است، اما هر دو مقدار زیادی دارند و به صفر نزدیک نیستند.

#### علل:

مدل فاقد پیچیدگی لازم است (مثلاً از تعداد کمی ویژگی یا یک مدل با درجه خیلی پایین استفاده شده است)، که منجر به بایاس (Bias) بالا می‌شود.

#### نتیجه:

عملکرد ضعیف هم بر روی داده‌های آموزشی و هم بر روی داده‌های تست.

#### توضیحات اضافه:

در مثال مطالعه برای امتحان، کم‌برازش مثل این است که شما فقط مقدمه‌ی کتاب را بخوانید. در این صورت، نه سؤالات کتاب را خوب پاسخ می‌دهید (خطای آموزش بالا)، و نه سؤالات امتحان را (خطای تست بالا). مدل آنقدر ساده است که حتی نتوانسته الگوهای ساده را هم یاد بگیرد.

---

### ۱.۶. تعمیم: رگرسیون چندجمله‌ای (Generalization: Polynomial Regression)

* **با افزایش درجه چندجمله‌ای مدل (افزایش پیچیدگی)**، مدل بهتر روی داده‌های آموزشی فیت می‌شود:

  * **درجه 1:** مدل خطی، ممکن است دچار کم‌برازش باشد (خط صاف).
  * **درجه 3:** مدل پیچیده‌تر، فیت بهتری روی داده‌های آموزشی دارد.
  * **درجه 5 و 7:** مدل‌های بسیار پیچیده، که می‌توانند منجر به بیش‌برازش شوند. منحنی‌ها "پیچ و خم" زیادی پیدا می‌کنند تا از تمام نقاط آموزشی عبور کنند، حتی نویز.

#### خطای جذر میانگین مربعات (Root Mean Squared Error - ERMS):

$$
ERMS = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y^{(i)} - f(x^{(i)}; w))^2}
$$

این معیار برای سنجش خطا در رگرسیون استفاده می‌شود.

#### نمودار ERMS:

نمودار ERMS نشان می‌دهد که با افزایش پیچیدگی مدل (درجه $M$)، خطای آموزش (آبی) کاهش می‌یابد، اما خطای تست (قرمز) پس از یک نقطه بهینه، شروع به افزایش می‌کند که نشان‌دهنده بیش‌برازش است.

#### توضیحات اضافه:

این مثال رگرسیون چندجمله‌ای به وضوح رابطه‌ی پیچیدگی مدل با کم‌برازش و بیش‌برازش را نشان می‌دهد. با یک مدل خیلی ساده، داده‌ها را نمی‌توانید خوب مدل کنید (کم‌برازش). با افزایش پیچیدگی، مدل بهتر می‌شود، اما اگر خیلی پیچیده شود، شروع به حفظ کردن نویز می‌کند (بیش‌برازش).

---

### ۱.۷. تجزیه بایاس-واریانس (Bias-Variance Decomposition)

* **تجزیه خطای تعمیم:**
  خطای مورد انتظار مربع خطا (Expected Squared Error) را می‌توان به سه مؤلفه تقسیم کرد:

$$
E[(y - h_w(x))^2] = (\text{Bias})^2 + \text{Variance} + \text{Noise}
$$

* **بایاس (Bias):**
  خطایی است که به دلیل فرض‌های ساده‌کننده در مدل (مثلاً استفاده از مدل خطی برای داده‌های غیرخطی) ایجاد می‌شود. بایاس بالا به معنای کم‌براش است.

$$
\text{Bias}(x) = E[h_w(x)] - f(x)
$$

(تفاوت بین میانگین پیش‌بینی‌های مدل و تابع واقعی)

* **واریانس (Variance):**
  حساسیت مدل به تغییرات در داده‌های آموزشی است. واریانس بالا به معنای بیش‌براش است.

$$
\text{Variance}(x) = E[(h_w(x) - E[h_w(x)])^2]
$$

(میزان پراکندگی پیش‌بینی‌های مدل حول میانگین پیش‌بینی‌های آن)

* **نویز (Noise) یا خطای غیرقابل کاهش (Irreducible Error):**
  خطایی است که به دلیل تصادفی بودن ذاتی داده‌ها ایجاد می‌شود و نمی‌توان آن را با هیچ مدل یادگیری ماشینی کاهش داد.

#### توضیحات اضافه:

این یک مفهوم بسیار اساسی در یادگیری ماشین است. فکر کنید دارید هدف‌گیری می‌کنید:

* **بایاس بالا:** تیرها همیشه به یک سمت مشخص هدف (مثلاً سمت چپ) می‌خورند، حتی اگر هر بار شلیک کنید. این به خاطر ایراد در تفنگ یا نحوه‌ی نشانه‌گیری شماست (ایراد در مدل).
* **واریانس بالا:** تیرها خیلی پراکنده می‌خورند، بعضی خیلی راست، بعضی خیلی چپ، بعضی بالا، بعضی پایین. حتی اگر میانگین آن‌ها به هدف نزدیک باشد، پراکندگی زیاد است (مدل بیش از حد به جزئیات داده‌ها حساس است).
* **نویز:** حتی اگر شما یک تیرانداز بی‌نقص باشید و تفنگ هم هیچ ایرادی نداشته باشد، همیشه یک پراکندگی بسیار کوچک و غیرقابل کنترل در اثر باد، ضربان قلب و... وجود دارد. این همان نویز داده است که قابل کاهش نیست.

---

### ۱.۸. بایاس بالا در مدل‌های ساده (High Bias in Simple Models)

* **توضیح:**
  مدل‌های ساده، مانند رگرسیون خطی ساده ($h_w(x) = w_0 + w_1 x$), اغلب دچار کم‌براش (underfit) می‌شوند.

* **نشانه:**
  مؤلفه بایاس مربع ($(\text{Bias})^2$) بسیار بزرگ‌تر از واریانس می‌شود ($(\text{Bias})^2 \gg \text{Variance}$).

* **نتیجه:**
  این مدل‌ها به دلیل ناتوانی در ثبت پیچیدگی‌های داده، حتی با داده‌های نامحدود، همچنان بایاس بالایی دارند و منجر به خطای تعمیم بالا می‌شوند.

---

### ۱.۹. واریانس بالا در مدل‌های پیچیده (High Variance in Complex Models)

* **توضیح:**
  مدل‌های پیچیده، مانند رگرسیون چندجمله‌ای با درجه بالا ($h_w(x) = w_0 + w_1 x + w_2 x^2 + \dots + w_m x^m$), تمایل به بیش‌براش (overfit) دارند.

* **نشانه:**
  واریانس بسیار بزرگ‌تر از بایاس می‌شود ($\text{Variance} \gg \text{Bias}$).

* **نتیجه:**
  این مدل‌ها نویز موجود در داده‌های آموزشی را نیز "حفظ" می‌کنند و در نتیجه عملکرد ضعیفی بر روی داده‌های دیده نشده دارند و منجر به خطای تست بالا می‌شوند.

---

### ۱.۱۰. داد و ستد بایاس-واریانس (Bias-Variance Tradeoff)

* **داد و ستد:**
  متعادل کردن بایاس و واریانس برای دستیابی به عملکرد بهینه مدل بسیار کلیدی است.

* **پیچیدگی پایین مدل:**
  منجر به بایاس بالا و واریانس پایین می‌شود (کم‌براش).

* **پیچیدگی بالای مدل:**
  منجر به بایاس پایین و واریانس بالا می‌شود (بیش‌براش).

* **هدف:**
  پیدا کردن نقطه بهینه که در آن مجموع $(\text{Bias})^2 + \text{Variance}$ (و نویز) کمینه شود.

#### توضیحات اضافه:

این یک مفهوم مرکزی در یادگیری ماشین است. همیشه یک مصالحه بین این دو وجود دارد. مدل خیلی ساده، تعصب زیادی دارد (بایاس بالا) اما خیلی ثابت و غیرحساس است (واریانس پایین). مدل خیلی پیچیده، تعصب کمی دارد (بایاس پایین) اما خیلی ناپایدار و حساس به داده‌هاست (واریانس بالا). هدف ما پیدا کردن یک مدل با پیچیدگی مناسب است که در نمودار ERMS پایین‌ترین نقطه خطای تست را داشته باشد.

---

اگر نیاز به توضیحات بیشتر یا مثال‌های بیشتری دارید، می‌توانم ادامه دهم.
### ۱.۱۱. رگولاریزاسیون (Regularization)

#### هدف:

هدف از رگولاریزاسیون جلوگیری از **بیش‌برازش** (overfitting) با جریمه کردن وزن‌های بزرگ است. وقتی وزن‌ها خیلی بزرگ شوند، مدل تمایل دارد تا به جزئیات کوچک و نویز موجود در داده‌های آموزشی توجه کند، که این موجب بیش‌برازش می‌شود.

#### فرمول کلی تابع هزینه با رگولاریزاسیون:

$$
J_{\lambda}(w) = J(w) + \lambda R(w)
$$

* $J(w)$ تابع هزینه اصلی (مثلاً SSE).
* $R(w)$ ترم رگولاریزاسیون (تابع جریمه برای وزن‌ها).
* $\lambda$ (لامبدا) یک هایپرپارامتر است که تعادل بین تطابق مدل با داده‌ها و سادگی مدل را کنترل می‌کند.

#### رایج‌ترین رگولاریزه‌کننده‌ها:

* **L1 norm (Lasso):** جریمه‌ای بر اساس مجموع قدر مطلق وزن‌ها.
* **L2 norm (Ridge):** جریمه‌ای بر اساس مجموع مربعات وزن‌ها.

#### توضیحات اضافه:

رگولاریزاسیون مثل یه "تنبیه" برای مدل عمل می‌کند که اجازه نده وزن‌هاش خیلی بزرگ بشن. وزن‌های بزرگ معمولاً نشانه‌ی این هستن که مدل داره به شدت روی جزئیات کوچک داده‌های آموزشی (حتی نویز) تمرکز می‌کنه و بیش‌برازش اتفاق می‌افته.

---

### ۱.۱۲. تاثیر پارامتر رگولاریزاسیون $\lambda$

#### فرمول با L2 Regularization:

$$
J_{\lambda}(w) = J(w) + \lambda \sum_{j=1}^{m} w_j^2 = J(w) + \lambda w^T w
$$

#### تأثیر $\lambda$ بر پیچیدگی مدل:

* **$\lambda$ بزرگ:** وزن‌ها را مجبور به کوچک‌تر شدن می‌کند، پیچیدگی مدل را کاهش می‌دهد، بایاس را افزایش و واریانس را کاهش می‌دهد (مدل ساده‌تر و کم‌برازش‌تر می‌شود).
* **$\lambda$ کوچک:** به وزن‌ها اجازه می‌دهد بزرگ‌تر شوند، پیچیدگی مدل را افزایش می‌دهد، بایاس را کاهش و واریانس را افزایش می‌دهد (مدل پیچیده‌تر و مستعد بیش‌برازش می‌شود).

#### کنترل پیچیدگی:

پارامتر $\lambda$ به طور مؤثری پیچیدگی مدل را کنترل می‌کند و در نتیجه میزان بیش‌براش را تنظیم می‌کند. با افزایش $\lambda$، مدل ساده‌تر می‌شود و ویژگی‌های پیچیده‌تر کمتر تأثیرگذار خواهند بود.

#### مثال:

جدولی که در صفحه 24 PDF آمده، نشان می‌دهد که با افزایش $\ln \lambda$ (افزایش $\lambda$)، مقادیر وزن‌ها (به خصوص وزن‌های مربوط به ترم‌های با درجه بالاتر) به شدت کاهش می‌یابند و به صفر نزدیک می‌شوند. این یعنی مدل ساده‌تر شده و اثر ویژگی‌های پیچیده کمتر می‌شود.

#### نمودار:

نمودار (صفحه 25 PDF) نشان می‌دهد که با تغییر $\ln \lambda$، خطای آموزش و تست تغییر می‌کنند. معمولاً یک $\lambda$ بهینه وجود دارد که خطای تست را به حداقل می‌رساند.

---

### ۲. رگرسیون احتمالی (Probabilistic Regression)

#### ۲.۱. مقدمه‌ای بر رگرسیون (دیدگاه احتمالی)

**هدف:** مدل‌سازی رابطه بین ورودی $x$ و خروجی $y$.

**عدم قطعیت (Uncertainty):** خروجی $y$ دارای عدم قطعیت است که با یک توزیع احتمالی مدل‌سازی می‌شود. این بدان معناست که پیش‌بینی‌های ما همیشه دقیق نخواهند بود و شامل نویز یا خطای تصادفی هستند.

#### مثال:

$$
y = f(x; w) + \epsilon
$$

که در آن:

* $\epsilon \sim N(0, \sigma^2)$ به این معنی است که نویز $\epsilon$ از توزیع نرمال با میانگین صفر و واریانس $\sigma^2$ پیروی می‌کند.

**هدف نهایی:** یادگیری تابع $f(x; w)$ برای پیش‌بینی $y$.

#### توضیحات اضافه:

در رگرسیون احتمالی، فرض می‌کنیم داده‌های ما دقیق نیستند و همیشه مقداری "نویز" یا خطای تصادفی در اندازه‌گیری‌ها یا فرآیند تولید داده وجود دارد. هدف ما پیدا کردن بهترین تابع $f(x; w)$ است که میانگین رفتار داده‌ها را نشان دهد.

---

### ۲.۲. فیت کردن منحنی با نویز (Curve Fitting with Noise)

**واقعیت:** در سناریوهای واقعی، خروجی مشاهده‌شده $y$ معمولاً دارای نویز است.

**مدل:** خروجی واقعی برابر است با خروجی تابع $f(x; w)$ به علاوه نویز:

$$
y = f(x; w) + \epsilon
$$

**نویز:** نویز نشان‌دهنده عواملی است که در مدل‌سازی لحاظ نشده‌اند یا ناشناخته‌اند.

#### مثال:

پیش‌بینی قیمت خانه بر اساس ویژگی‌ها، که دارای عدم قطعیت ذاتی است.

---

### ۲.۳. مقدار مورد انتظار خروجی (Expected Value of Output)

**بهترین تخمین:** بهترین تخمین برای $y$ با داشتن $x$, امید ریاضی شرطی $y$ به شرط $x$ است:

$$
E[y | x] = f(x; w)
$$

**هدف:** یادگیری تابع $f(x; w)$ که میانگین رفتار داده‌ها را نشان می‌دهد.

**نکته کلیدی:** مدل، میانگین متغیر هدف را با داشتن ورودی $x$ ثبت می‌کند.

---

این بخش‌ها توضیحات جامع‌تری در خصوص رگرسیون احتمالی و رگولاریزاسیون می‌دهند که به شما کمک می‌کنند تا مدل‌های یادگیری ماشین را بهتر درک کنید و از آن‌ها به‌طور مؤثرتر استفاده کنید. اگر نیاز به توضیح یا مثال‌های بیشتری دارید، خوشحال می‌شوم کمک کنم!


### ۲.۴. برآورد بیشینه درست‌نمایی (Maximum Likelihood Estimation - MLE)

#### MLE: روشی برای تخمین پارامترهایی است که احتمال وقوع داده‌ها (likelihood) را به حداکثر می‌رساند.

**هدف:** با داشتن مجموعه داده $Z = \{ (x_i, y_i) \}_{i=1}^n$، MLE حاصل‌ضرب احتمالات را بیشینه می‌کند:

$$
L(Z; w, \sigma^2) = \prod_{i=1}^{n} p(y_i | x_i, w, \sigma^2)
$$

**یافتن پارامترها:** MLE پارامترهای $w$ و $\sigma^2$ را پیدا می‌کند که بهترین توضیح را برای داده‌ها ارائه می‌دهند.

---

### ۲.۵. برآورد بیشینه درست‌نمایی (ادامه)

#### لگاریتم درست‌نمایی:

به جای بیشینه‌سازی درست‌نمایی، اغلب بیشینه‌سازی لگاریتم درست‌نمایی آسان‌تر است:

$$
\log L(Z; w, \sigma^2) = \sum_{i=1}^{n} \log p(y_i | x_i, w, \sigma^2)
$$

**دلیل:** لگاریتم تابع رفتار آن را حفظ می‌کند (یعنی نقاط بیشینه آن‌ها یکسان است) و مشتق‌گیری از مجموع ترم‌ها آسان‌تر است.

---

### ۲.۶. مثال تابع خطی تک‌متغیره (Univariate Linear Function Example)

**فرض نویز گاوسی:** با فرض نویز گاوسی ($\epsilon \sim N(0, \sigma^2)$)، احتمال مشاهده خروجی واقعی $y$ به صورت زیر است:

$$
p(y | x, w, \sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp\left( -\frac{(y - f(x; w))^2}{2 \sigma^2} \right)
$$

برای مدل خطی ساده: اگر $f(x; w) = w_0 + w_1 x$ باشد، داریم:

$$
p(y | x, w, \sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp\left( -\frac{(y - w_0 - w_1 x)^2}{2 \sigma^2} \right)
$$

**مشاهده کلیدی:** نقاطی که از خط فیت شده فاصله زیادی دارند، مقدار درست‌نمایی (likelihood) پایینی خواهند داشت.

#### توضیحات اضافه:

این بخش نشان می‌دهد که چرا روش "مجموع مربعات خطا" (SSE) که در رگرسیون خطی استفاده می‌کنیم، از دیدگاه احتمالی بهترین روش است. وقتی فرض می‌کنیم نویز داده‌ها نرمال (گاوسی) است، بیشینه‌سازی درست‌نمایی دقیقاً معادل کمینه‌سازی SSE می‌شود.

---

### ۲.۷. لگاریتم درست‌نمایی و مجموع مربعات (Log-Likelihood and Sum of Squares)

با استفاده از لگاریتم درست‌نمایی داریم:

$$
\log L(Z; w, \sigma^2) = -n \log \sigma - \frac{n}{2} \log(2\pi) - \frac{1}{2\sigma^2} \sum_{i=1}^{n} (y^{(i)} - f(x^{(i)}; w))^2
$$

**حذف ثابت‌ها:** از آنجایی که هدف MLE بهینه‌سازی نسبت به متغیرهای تصادفی (پارامترهای مدل $w$ و $\sigma^2$) است، می‌توان ثابت‌ها (ترم‌هایی که شامل $w$ یا $\sigma^2$ نیستند) را حذف کرد:

$$
\log L(Z; w, \sigma^2) \sim - \frac{1}{2\sigma^2} \sum_{i=1}^{n} (y^{(i)} - f(x^{(i)}; w))^2
$$

**هم‌ارزی (Equivalence):** بیشینه‌سازی لگاریتم درست‌نمایی (در این حالت) معادل کمینه‌سازی مجموع مربعات خطا (Sum of Squared Errors - SSE) است:

$$
J(w) = \sum_{i=1}^{n} (y^{(i)} - f(x^{(i)}; w))^2
$$

#### توضیحات اضافه:

این بخش نشان می‌دهد که چرا MLE با فرض نویز گاوسی، منجر به همان تابع هزینه‌ی SSE می‌شود که در رگرسیون خطی استفاده می‌کنیم. این یک پایه آماری قوی برای SSE فراهم می‌کند.

---

### ۲.۸. تخمین $\sigma^2$ (Estimating $\sigma^2$)

**تخمین بیشینه درست‌نمایی واریانس نویز $\sigma^2$:**

$$
\hat{\sigma}^2 = \frac{1}{n} \sum_{i=1}^{n} (y^{(i)} - f(x^{(i)}; w))^2
$$

**تفسیر:** این مقدار همان **میانگین مربعات خطا** (Mean Squared Error - MSE) پیش‌بینی‌ها است.

**نکته:** $\sigma^2$ (واریانس نویز) سطح نویز در مشاهدات را منعکس می‌کند.

---

این بخش‌ها توضیحات جامعی درباره فرآیند تخمین بیشینه درست‌نمایی (MLE) و چگونگی استفاده از آن برای رگرسیون خطی با فرض نویز گاوسی ارائه می‌دهند. اگر سؤالات بیشتری دارید یا نیاز به جزئیات بیشتری دارید، خوشحال می‌شوم کمک کنم!


---



### ۱. تعمیم (Generalization)

بخش اول این جزوه به مفهوم حیاتی **"تعمیم" (Generalization)** در یادگیری ماشین می‌پردازد. این بخش توضیح می‌دهد که چرا توانایی یک مدل برای عملکرد خوب بر روی داده‌هایی که قبلاً ندیده است، هدف اصلی در این حوزه محسوب می‌شود.

#### ۱.۱. مروری بر تعمیم (Generalization Overview)

**تعمیم** در واقع به معنای توانایی یک مدل یادگیری ماشین برای عملکرد موثر و پیش‌بینی دقیق بر روی داده‌های دیده نشده (unseen data) است. این مفهوم، هدف نهایی و سنگ محک موفقیت یک مدل یادگیری ماشین محسوب می‌شود. برای دستیابی به این هدف، ما از مجموعه‌ای از داده‌های برچسب‌دار به نام **مجموعه آموزشی (Training Set)** استفاده می‌کنیم. این مجموعه، که به صورت $D = \{ (x_i, y_i) \}_{i=1}^n$ نمایش داده می‌شود، همان داده‌هایی هستند که مدل برای یادگیری الگوها، روابط و ساختار پنهان بین ویژگی‌های ورودی $x_i$ و برچسب‌های خروجی $y_i$ از آن‌ها استفاده می‌کند.

پس از آموزش، برای ارزیابی واقعی عملکرد مدل، آن را بر روی **مجموعه تست (Test Set)** اعمال می‌کنیم. مجموعه تست شامل داده‌های کاملاً جدیدی است که مدل هرگز در طول فرآیند آموزش آن‌ها را ندیده و به این ترتیب، عملکرد مدل را در دنیای واقعی و در مواجهه با ورودی‌های ناشناخته می‌سنجد.

برای اندازه‌گیری میزان "خوبیِ" تطابق مدل با داده‌ها، از یک **تابع هزینه (Cost Function)** استفاده می‌شود. در مسائل رگرسیون، یکی از رایج‌ترین توابع هزینه، **مجموع مربعات خطا (Sum of Squared Errors - SSE)** است که به صورت:

$$
J(w) = \sum_{i=1}^{n} (y^{(i)} - h_w(x^{(i)}))^2
$$

تعریف می‌شود. در این فرمول، $y^{(i)}$ مقدار واقعی و $h_w(x^{(i)})$ مقدار پیش‌بینی شده توسط مدل برای نمونه $i$-ام است. هدف نهایی در فرآیند آموزش مدل، کمینه‌سازی این تابع هزینه بر روی داده‌های دیده نشده است؛ این همان چیزی است که به آن **خطای تعمیم (generalization error)** می‌گوییم و نشان‌دهنده توانایی مدل در تعمیم آموخته‌های خود به داده‌های جدید است.

**توضیحات اضافه برای درک بهتر:**
تصور کنید شما در حال آماده شدن برای یک امتحان مهم هستید. کتاب درسی و نمونه سؤالات گذشته‌ای که مطالعه می‌کنید، حکم مجموعه آموزشی شما را دارند. شما تمام تلاش خود را می‌کنید تا این مطالب را به خوبی یاد بگیرید (مدل آموزش می‌بیند). هدف اصلی شما چیست؟ این است که در امتحان واقعی (که سؤالات آن را قبلاً ندیده‌اید و نقش مجموعه تست را دارد) نمره‌ی خوبی بگیرید. اگر شما فقط سؤالات نمونه را "حفظ" کنید و در امتحان واقعی با سؤالات جدید نتوانید آن‌ها را حل کنید، این یعنی توانایی تعمیم‌پذیری خوبی ندارید. تابع هزینه در اینجا مانند نمره‌ی شما در امتحانات تمرینی است که نشان می‌دهد چقدر خوب داده‌های آموزشی را پیش‌بینی کرده‌اید. اما در نهایت، موفقیت شما با نمره‌تان در امتحان اصلی (داده‌های دیده نشده) سنجیده می‌شود.

---

#### ۱.۲. خطای مورد انتظار تست (Expected Test Error)

خطای مورد انتظار تست به معنای عملکرد مورد انتظار مدل بر روی داده‌های دیده نشده است. این معیار، یک رویکرد ایده‌آل‌گرایانه را در نظر می‌گیرد که فرض می‌کند داده‌های تست از همان توزیع احتمالی $p(x, y)$ که داده‌های آموزشی از آن نمونه‌برداری شده‌اند، گرفته می‌شوند. به عبارت دیگر، ما فرض می‌کنیم که داده‌های آینده از همان الگوهای آماری گذشته پیروی خواهند کرد.

فرمول ریاضی این خطای مورد انتظار به صورت:

$$
J(w) = \mathbb{E}_{p(x,y)} \left[ (y - h_w(x))^2 \right]
$$

بیان می‌شود. این نشان‌دهنده میانگین مربعات خطا بر روی تمام داده‌های ممکن (نه فقط مجموعه تست محدود ما) با توجه به توزیع واقعی داده‌ها است.

از آنجایی که در عمل دسترسی به توزیع کامل $p(x, y)$ غیرممکن است، ما معمولاً این خطای مورد انتظار را با استفاده از مجموعه تست خود تخمین می‌زنیم. این تخمین با علامت $\hat{J}(w)$ نشان داده می‌شود.

**خطای تعمیم (Generalization error)** در واقع به عنوان شکاف یا تفاوت بین عملکرد مدل بر روی داده‌های آموزشی و داده‌های تست تعریف می‌شود. هرچه این شکاف بزرگتر باشد، نشان‌دهنده این است که مدل کمتر قادر به تعمیم آموخته‌های خود به داده‌های جدید و ناشناخته است.

**توضیحات اضافه:**
خطای مورد انتظار تست مثل این است که ما بخواهیم بدانیم یک دانش‌آموز در "همه‌ی" امتحانات ممکن در آینده چه نمره‌ای می‌گیرد، با فرض اینکه سؤالات آینده هم از همان منبع و با همان سختی سؤالات قبلی باشند. چون این کار عملی نیست، ما از یک "آزمون آزمایشی" (مجموعه تست) برای تخمین این نمره استفاده می‌کنیم. اگر دانش‌آموز در امتحانات تمرینی (آموزش) خیلی خوب باشد، ولی در آزمون آزمایشی (تست) بد باشد، یعنی "شکافی" بین عملکرد او وجود دارد که نشان می‌دهد توانایی تعمیم‌پذیری‌اش پایین است.

---

#### ۱.۳. خطای آموزش در مقابل خطای تست (Training vs. Test Error)

در یادگیری ماشین، تمایز بین **خطای آموزش (Training error)** و **خطای تست (Test error)** یک مفهوم کلیدی و بنیادین است.

* **خطای آموزش**، همانطور که از نامش پیداست، میزان تطابق و برازش مدل را با داده‌های شناخته‌شده یا همان مجموعه آموزشی اندازه‌گیری می‌کند. این خطا به صورت:

$$
J_{\text{train}}(w) = \frac{1}{n} \sum_{i=1}^n (y^{(i)} - h_w(x^{(i)}))^2
$$

محاسبه می‌شود.

* در مقابل، **خطای تست** میزان تطابق مدل را با داده‌های کاملاً جدید و دیده نشده ارزیابی می‌کند. این خطا با فرمول:

$$
J_{\text{test}}(w) = \frac{1}{m} \sum_{i=1}^m (y_{\text{test}}^{(i)} - h_w(x_{\text{test}}^{(i)}))^2
$$

تعریف می‌شود.

**هدف نهایی** و اصلی در توسعه مدل‌های یادگیری ماشین، **کمینه‌سازی خطای تست** است. این هدف به معنای دستیابی به بهترین توانایی تعمیم‌پذیری مدل است تا بتواند در سناریوهای واقعی و با داده‌های جدید، به طور موثر عمل کند.

**توضیحات اضافه:**
تصور کنید یک ورزشکار برای مسابقه‌ی مهمی تمرین می‌کند. عملکرد او در تمرینات (مثل دویدن سریع‌تر از حد نرمال در تمرین) همان خطای آموزش است – چقدر خوب روی داده‌های "شناخته‌شده" عمل می‌کند. اما عملکرد او در روز مسابقه، در شرایط جدید و با رقبای ناشناخته، همان خطای تست است. هدف واقعی، نه فقط خوب بودن در تمرین، بلکه درخشش در مسابقه اصلی است.

---

#### ۱.۴. تعریف بیش‌برازش (Overfitting Definition)

**بیش‌برازش (Overfitting)** یک مفهوم مهم و چالش‌برانگیز در یادگیری ماشین است که به حالتی اشاره دارد که یک مدل، داده‌های آموزشی را به خوبی مدل می‌کند، اما بر روی مجموعه تست عملکرد ضعیفی از خود نشان می‌دهد. نشانه‌ی واضح بیش‌برازش این است که **خطای آموزش** ($J_{\text{train}}(w)$) به طور قابل توجهی از **خطای تست** ($J_{\text{test}}(w)$) کمتر است ($J_{\text{train}}(w) \ll J_{\text{test}}(w)$).

این اتفاق معمولاً زمانی رخ می‌دهد که مدل بیش از حد پیچیده باشد. به عنوان مثال، استفاده از تعداد زیادی ویژگی (ورودی) یا انتخاب یک مدل با درجه بالا (مانند چندجمله‌ای با درجه بسیار زیاد) می‌تواند منجر به این وضعیت شود. پیچیدگی بیش از حد مدل، باعث می‌شود که مدل حتی **نویز (Noise)** موجود در داده‌های آموزشی را نیز یاد بگیرد و نه فقط الگوهای اصلی را. در نتیجه، این مدل‌ها بر روی داده‌های جدید و دیده نشده، با شکست مواجه می‌شوند و نمی‌توانند به درستی تعمیم پیدا کنند. این پ


دیده به دلیل **واریانس (Variance)** بالای مدل اتفاق می‌افتد، به این معنی که مدل به جزئیات خاص مجموعه داده آموزشی بیش از حد حساس شده است.

**توضیحات اضافه:**
بیش‌برازش مثل اینه که شما برای امتحان، نه تنها مطالب اصلی رو می‌خونید، بلکه جزئیات بی‌اهمیت، مثل حاشیه‌نویسی‌های اشتباه یا غلط املایی کتاب رو هم "حفظ" می‌کنید. وقتی سؤالات جدید در امتحان (داده‌ی تست) می‌آد، چون شما فقط جزئیات بی‌ربط رو حفظ کردید، نمی‌تونید جواب درست رو بدید و نمره‌تون (خطای تست) بد میشه، در حالی که تو سؤالای تمرینی (داده‌ی آموزش) عالی بودید. مدل اینجا به جای یادگیری، "کپی‌برداری" از نویز کرده.

---

اگر بخواهید بخش‌های بعدی را هم مرور کنیم یا به جزئیات بیشتری پرداخته شود، خوشحال می‌شوم که کمک کنم.


### ۱.۵. تعریف کم‌برازش (Underfitting Definition)

در مقابل **بیش‌برازش (Overfitting)**، **کم‌برازش (Underfitting)** حالتی است که در آن مدل بیش از حد ساده است و نمی‌تواند ساختار واقعی و الگوهای اساسی داده‌ها را به درستی تشخیص دهد. نشانه‌ی کم‌برازش این است که **خطای آموزش** $J_{\text{train}}(w)$ تقریباً برابر با **خطای تست** $J_{\text{test}}(w)$ است، اما هر دو مقدار نسبتاً زیادی دارند و به صفر نزدیک نیستند ($J_{\text{train}}(w) \approx J_{\text{test}}(w) \gg 0$).

این وضعیت معمولاً ناشی از **کمبود پیچیدگی در مدل** است؛ مثلاً استفاده از تعداد بسیار کمی ویژگی یا انتخاب یک مدل با درجه خیلی پایین که قدرت لازم برای مدل‌سازی پیچیدگی‌های داده را ندارد. نتیجه‌ی کم‌برازش، **عملکرد ضعیف هم بر روی داده‌های آموزشی و هم بر روی داده‌های تست** است، زیرا مدل حتی قادر به یادگیری الگوهای ساده‌تر نیز نشده است. این پدیده به دلیل **بایاس (Bias)** بالای مدل اتفاق می‌افتد، به این معنی که مدل از ابتدا دارای فرض‌های ساده‌کننده‌ی قوی بوده که از یادگیری رابطه واقعی جلوگیری کرده است.

**توضیحات اضافه:**
کم‌برازش مثل اینه که شما برای امتحان، فقط مقدمه‌ی کتاب رو می‌خونید و کلاً وارد جزئیات و مطالب اصلی نمیشید. در این صورت، نه سؤالات تمرینی (داده‌ی آموزش) رو خوب پاسخ میدید (خطای آموزش بالا)، و نه سؤالات امتحان (داده‌ی تست) رو. مدل اینجا حتی نتونسته الگوهای ساده رو هم یاد بگیره، چون ابزار لازم (پیچیدگی) رو برای این کار نداشته.

---

### ۱.۶. تعمیم: رگرسیون چندجمله‌ای (Generalization: Polynomial Regression)

**رگرسیون چندجمله‌ای** یک مثال عالی برای درک پدیده‌های کم‌برازش و بیش‌برازش در بحث تعمیم است. در این نوع رگرسیون، با **افزایش درجه چندجمله‌ای مدل** (که به معنای افزایش پیچیدگی مدل است)، مدل قابلیت بیشتری برای تطابق با داده‌های آموزشی پیدا می‌کند.

#### درجه 1:

اگر از یک مدل خطی ساده (چندجمله‌ای درجه 1) استفاده کنیم، ممکن است مدل دچار **کم‌برازش** شود. در این حالت، یک خط صاف سعی می‌کند از میان داده‌ها عبور کند که ممکن است نتواند انحنا یا الگوی واقعی داده‌ها را به خوبی ثبت کند.

#### درجه 3:

با افزایش پیچیدگی به یک مدل چندجمله‌ای درجه 3، مدل فیت (تطابق) بهتری با داده‌های آموزشی پیدا می‌کند و می‌تواند انحناهای بیشتری را مدل‌سازی کند.

#### درجه 5 و 7:

اما اگر درجه چندجمله‌ای را بیش از حد افزایش دهیم (مثلاً به درجه 5 یا 7)، مدل **بیش از حد پیچیده** می‌شود و می‌تواند منجر به **بیش‌برازش** شود. در این حالت، منحنی‌های مدل "پیچ و خم"‌های زیادی پیدا می‌کنند تا از تمام نقاط آموزشی عبور کنند، حتی اگر آن نقاط صرفاً **نویز** باشند. این باعث می‌شود مدل در برابر داده‌های جدید حساس و ناپایدار عمل کند.

برای سنجش خطای مدل در رگرسیون، از معیاری به نام **خطای جذر میانگین مربعات (Root Mean Squared Error - RMSE)** استفاده می‌شود که به صورت:

$$
E_{\text{RMS}} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y^{(i)} - f(x^{(i)};w))^2}
$$

تعریف می‌شود.

**نمودار ERMS** (که در صفحه 13 PDF نشان داده شده است) به وضوح رابطه‌ی بین پیچیدگی مدل و خطاهای آموزش و تست را به نمایش می‌گذارد. در این نمودار، با افزایش پیچیدگی مدل (که توسط درجه $M$ چندجمله‌ای نشان داده می‌شود)، **خطای آموزش** (خط آبی) به طور پیوسته کاهش می‌یابد. این طبیعی است، زیرا مدل پیچیده‌تر می‌تواند بهتر روی داده‌های دیده‌شده فیت شود. اما، **خطای تست** (خط قرمز) پس از رسیدن به یک نقطه بهینه (معمولاً در یک درجه متوسط از پیچیدگی)، شروع به افزایش می‌کند. این افزایش خطای تست در حالی که خطای آموزش همچنان پایین است، نشان‌دهنده وقوع **بیش‌برازش** است.

**توضیحات اضافه:**
این مثال، کل داستان تعمیم را به وضوح بیان می‌کند. یک مدل خیلی ساده مثل یه خط راست (درجه 1) نمی‌تونه انحناهای داده رو بگیره (کم‌برازش). وقتی مدل رو پیچیده‌تر می‌کنیم (درجه 3)، بهتر میشه. اما اگه خیلی پیچیده شه (درجه 5 یا 7)، شروع می‌کنه به حفظ کردن جزئیات بی‌ربط و نویز، که باعث میشه رو داده‌ی جدید بد عمل کنه (بیش‌برازش). نمودار ERMS هم مثل یه راهنماست که بهترین درجه پیچیدگی (نقطه بهینه) رو نشون میده که هم خطای آموزش پایین باشه و هم خطای تست.

---

این مطالب به شما کمک می‌کند تا تفاوت‌ها و اثرات پیچیدگی مدل‌های یادگیری ماشین را در فرآیند **تعمیم** و **رگرسیون چندجمله‌ای** به طور واضح درک کنید. اگر بخواهید جزئیات بیشتری در مورد هر بخش داشته باشید، خوشحال می‌شوم که بیشتر توضیح دهم!




### ۱.۷. تجزیه بایاس-واریانس (Bias-Variance Decomposition)

**تجزیه بایاس-واریانس** یک چارچوب تحلیلی قدرتمند است که **خطای مورد انتظار مربع خطا (Expected Squared Error)** را به سه مؤلفه اصلی تقسیم می‌کند. این تجزیه به ما کمک می‌کند تا منابع خطای مدل را بهتر درک کنیم:

$$
E[(y - h_w(x))^2] = (\text{Bias})^2 + \text{Variance} + \text{Noise}
$$

در این فرمول:

* **بایاس (Bias):** این مؤلفه نشان‌دهنده‌ی خطای ناشی از فرض‌های ساده‌کننده در مدل است. به عنوان مثال، اگر داده‌ها واقعاً یک رابطه‌ی غیرخطی داشته باشند اما ما از یک مدل خطی استفاده کنیم، مدل هرگز نمی‌تواند رابطه واقعی را به طور کامل ثبت کند و همیشه یک "تعصب" سیستماتیک در پیش‌بینی‌هایش خواهد داشت. بایاس بالا معمولاً نشان‌دهنده **کم‌برازش (Underfitting)** است. به صورت ریاضی، بایاس برای یک نقطه $x$ به صورت:

$$
\text{Bias}(x) = E[h_w(x)] - f(x)
$$

تعریف می‌شود، که تفاوت بین میانگین پیش‌بینی‌های مدل و تابع واقعی (زمینه‌ی حقیقی) را نشان می‌دهد.

* **واریانس (Variance):** این مؤلفه حساسیت مدل به تغییرات در داده‌های آموزشی را نشان می‌دهد. واریانس بالا به این معنی است که اگر مجموعه داده آموزشی کمی تغییر کند (مثلاً نمونه‌های متفاوتی برای آموزش انتخاب شوند)، مدل خروجی‌های بسیار متفاوتی تولید خواهد کرد. واریانس بالا معمولاً نشان‌دهنده **بیش‌برازش (Overfitting)** است. به صورت ریاضی، واریانس برای یک نقطه $x$ به صورت:

$$
\text{Variance}(x) = E[(h_w(x) - E[h_w(x)])^2]
$$

تعریف می‌شود، که میزان پراکندگی پیش‌بینی‌های مدل حول میانگین پیش‌بینی‌های آن را نشان می‌دهد.

* **نویز (Noise) یا خطای غیرقابل کاهش (Irreducible Error):** این مؤلفه نشان‌دهنده‌ی خطایی است که به دلیل تصادفی بودن ذاتی داده‌ها ایجاد می‌شود. حتی اگر مدل ما کامل‌ترین مدل ممکن باشد و داده‌های آموزشی نامحدود در اختیار داشته باشیم، باز هم به دلیل وجود نویز (مثل خطاهای اندازه‌گیری یا عوامل ناشناخته)، همیشه یک حداقل خطا وجود خواهد داشت که نمی‌توان آن را با هیچ مدل یادگیری ماشینی کاهش داد. این خطا به صورت $\sigma^2$ (واریانس نویز) نمایش داده می‌شود.

---

### اثبات تجزیه بایاس-واریانس (صفحات 15 تا 17 PDF)

فایل PDF مراحل اثبات این تجزیه را با جزئیات ریاضی نشان می‌دهد. فرض می‌شود که خروجی مشاهده شده $y$ یک مشاهده نویزی از تابع واقعی $f(x)$ است:

$$
y = f(x) + \epsilon
$$

که $\epsilon$ نویز گاوسی با میانگین صفر و واریانس $\sigma^2$ است. با بسط دادن عبارت **خطای مربع مورد انتظار** $E_{\text{data}}[(f(x) - y)^2]$ و استفاده از خواص امید ریاضی و استقلال نویز از تابع، می‌توان نشان داد که این عبارت به سه ترم $\text{Variance} + (\text{Bias})^2 + \sigma^2$ تجزیه می‌شود.

---

### توضیحات اضافه:

این یک مفهوم کلیدی و شاید کمی دشوار اما بسیار مهم در یادگیری ماشین است. تصور کنید که در حال هدف‌گیری هستید:

* **بایاس بالا:** تیرهای شما همیشه به یک سمت خاصی از هدف می‌خورند (مثلاً همیشه کمی به چپ). این ناشی از یک مشکل سیستماتیک در تنظیم تفنگ یا نحوه‌ی نشانه‌گیری شماست. در مدل، این یعنی مدل ما از ابتدا یک فرض اشتباه (مثلاً خطی بودن) را در مورد داده‌ها دارد.

* **واریانس بالا:** تیرهای شما در هر بار شلیک به نقاط بسیار پراکنده و متفاوتی در اطراف هدف می‌خورند (بعضی خیلی راست، بعضی خیلی چپ، بعضی بالا، بعضی پایین). این ناشی از ناپایداری در دست شما یا تفنگ است. در مدل، این یعنی مدل ما بیش از حد به جزئیات کوچک مجموعه داده آموزشی حساس است و با کمی تغییر در داده‌های آموزشی، خروجی‌های بسیار متفاوتی می‌دهد.

* **نویز:** حتی بهترین تیرانداز هم در بهترین شرایط، تیرش دقیقاً روی نقطه‌ی مرکزی هدف نمی‌خورد؛ همیشه یک پراکندگی بسیار جزئی و غیرقابل کنترل (مثلاً به خاطر باد، لرزش دست) وجود دارد. این همان خطای غیرقابل کاهش در داده‌هاست.

---

### ۱.۸. بایاس بالا در مدل‌های ساده (High Bias in Simple Models)

مدل‌های ساده، مانند **رگرسیون خطی ساده** (که به صورت $h_w(x) = w_0 + w_1 x$ نمایش داده می‌شود)، اغلب دچار **کم‌برازش (Underfit)** می‌شوند. این پدیده به این دلیل رخ می‌دهد که چنین مدل‌هایی، با وجود سادگی، توانایی کافی برای ثبت پیچیدگی‌های موجود در داده‌های واقعی را ندارند. نشانه اصلی **بایاس بالا** این است که **مؤلفه بایاس مربع** $(\text{Bias})^2$ به طور قابل توجهی بزرگ‌تر از واریانس می‌شود $(\text{Bias}^2 \gg \text{Variance})$. این بدان معناست که منبع اصلی خطای مدل، فرض‌های ساده‌کننده‌ی آن است. در نتیجه، حتی با فراهم آوردن **داده‌های نامحدود برای آموزش**، این مدل‌ها همچنان قادر به یادگیری رابطه واقعی نخواهند بود و **خطای تعمیم** (Generalization Error) آن‌ها بالا باقی می‌ماند.

---

این مفاهیم به شما کمک می‌کند تا بهتر درک کنید که چگونه مدل‌ها با پیچیدگی‌های مختلف می‌توانند در مواجهه با داده‌ها واکنش نشان دهند و چگونه می‌توان با تنظیم مدل، به بهبود عملکرد آن دست یافت. اگر نیاز به توضیحات بیشتری دارید، من در خدمت شما هستم!
### ۱.۹. واریانس بالا در مدل‌های پیچیده (High Variance in Complex Models)

در مقابل مدل‌های ساده، مدل‌های پیچیده مانند **رگرسیون چندجمله‌ای با درجه بالا** (که به صورت $h_w(x) = w_0 + w_1 x + w_2 x^2 + \dots + w_m x^m$ نمایش داده می‌شود)، تمایل زیادی به **بیش‌برازش (Overfitting)** دارند. این مدل‌ها به دلیل پیچیدگی بالای خود، می‌توانند به دقت بسیار زیادی بر روی داده‌های آموزشی منطبق شوند، اما این تطابق بیش از حد شامل **نویز** موجود در داده‌های آموزشی نیز می‌شود. نشانه‌ی **واریانس بالا** این است که:

$$
\text{Variance} \gg \text{Bias}
$$

نتیجه‌ی این رفتار، **عملکرد ضعیف بر روی داده‌های دیده نشده** (یعنی خطای تست بالا) است، زیرا مدل الگوهای عمومی را یاد نگرفته، بلکه جزئیات خاص مجموعه آموزشی را حفظ کرده است.

### ۱.۱۰. داد و ستد بایاس-واریانس (Bias-Variance Tradeoff)

**داد و ستد بایاس-واریانس** (Bias-Variance Tradeoff) یک مفهوم کلیدی و بنیادین در یادگیری ماشین است که به معنای لزوم برقراری تعادل میان **بایاس** و **واریانس** برای دستیابی به **عملکرد بهینه مدل** است. این دو مؤلفه معمولاً **رابطه معکوسی** با یکدیگر دارند:

* **مدل با پیچیدگی پایین:** منجر به **بایاس بالا** و **واریانس پایین** می‌شود. چنین مدلی ساده است و قادر به ثبت تمام جزئیات داده‌ها نیست (بایاس بالا)، اما در عین حال، به تغییرات کوچک در داده‌های آموزشی حساس نیست (واریانس پایین) و از این رو دچار **کم‌برازش** می‌شود.

* **مدل با پیچیدگی بالا:** منجر به **بایاس پایین** و **واریانس بالا** می‌شود. این مدل قادر به ثبت پیچیدگی‌های بیشتری از داده‌ها است (بایاس پایین)، اما در مقابل به نویز موجود در داده‌های آموزشی بیش از حد حساس شده و به شدت به داده‌های آموزشی خود وابسته می‌شود (واریانس بالا) و در نتیجه دچار **بیش‌برازش** می‌شود.

هدف از این داد و ستد، یافتن **نقطه بهینه** در طیف پیچیدگی مدل است، جایی که مجموع $\text{Bias}^2 + \text{Variance}$ (به علاوه نویز) به کمترین مقدار خود برسد. این نقطه همان جایی است که مدل **بهترین تعمیم‌پذیری** را به داده‌های جدید نشان می‌دهد.

#### توضیحات اضافه:

این یک مفهوم مرکزی و بسیار مهم در یادگیری ماشین است. تصور کنید یک **کماندار** هستید و دارید به **سیبل تیراندازی** می‌کنید:

* **مدل خیلی ساده (پیچیدگی پایین):** تیرهای شما همیشه کمی به چپ هدف می‌خورند (بایاس بالا). اما این تیرها خیلی نزدیک به هم می‌خورند و پراکندگی کمی دارند (واریانس پایین). شما همیشه اشتباه می‌کنید، اما همیشه به یک شکل مشخص. این می‌شود **کم‌برازش**.

* **مدل خیلی پیچیده (پیچیدگی بالا):** تیرهای شما به طور متوسط به مرکز هدف می‌خورند (بایاس پایین). اما هر تیر در یک جای متفاوت می‌خورد، یکی خیلی راست، یکی خیلی چپ، یکی بالا و یکی پایین (واریانس بالا). شما به طور متوسط خوبید، اما ناپایدارید. این می‌شود **بیش‌برازش**.

داد و ستد یعنی پیدا کردن بهترین تنظیمات برای **کمان (مدل)** تا مجموع اشتباهات سیستمی (بایاس) و پراکندگی (واریانس) به حداقل برسد و بیشترین امتیاز را بگیرید.

---

### ۱.۱۱. رگولاریزاسیون (Regularization)

**رگولاریزاسیون** یک تکنیک کلیدی در یادگیری ماشین است که با جریمه کردن وزن‌های بزرگ (large weights)، به جلوگیری از **بیش‌براش** (overfitting) کمک می‌کند. هدف اصلی آن، **کاهش پیچیدگی مدل** است تا بتواند بهتر به داده‌های دیده نشده تعمیم پیدا کند.

**فرمول کلی تابع هزینه با رگولاریزاسیون** به صورت:

$$
J_{\lambda}(w) = J(w) + \lambda R(w)
$$

تعریف می‌شود:

* **$J(w)$:** این همان تابع هزینه اصلی مدل است (مانند **Sum of Squared Errors** در رگرسیون خطی) که میزان تطابق مدل با داده‌ها را اندازه‌گیری می‌کند.

* **$R(w)$:** این ترم رگولاریزاسیون یا "تابع جریمه" برای وزن‌های مدل است. این ترم با افزایش بزرگی وزن‌ها، مقدار تابع هزینه کلی را افزایش می‌دهد.

* **$\lambda$ (لامبدا):** این یک **هایپرپارامتر** (hyperparameter) است که نقش حیاتی در کنترل تعادل بین تطابق با داده‌ها (برازش) و سادگی مدل دارد. مقدار بزرگ $\lambda$ به معنای جریمه‌ی بیشتر وزن‌های بزرگ و در نتیجه مدل ساده‌تر است، در حالی که $\lambda$ کوچک، جریمه کمتری اعمال می‌کند و مدل می‌تواند پیچیده‌تر شود.

رایج‌ترین رگولاریزه‌کننده‌ها عبارتند از:

* **L1 norm (Lasso):** باعث می‌شود برخی وزن‌ها به صفر برسند (انتخاب ویژگی).
* **L2 norm (Ridge):** وزن‌ها را کوچک نگه می‌دارد اما به ندرت آن‌ها را صفر می‌کند.

#### توضیحات اضافه:

رگولاریزاسیون مثل یه "تنبیه" برای مدل عمل می‌کنه که اجازه نده وزن‌هاش خیلی بزرگ بشن. وزن‌های خیلی بزرگ معمولاً نشانه‌ی این هستن که مدل داره به شدت روی جزئیات بی‌ربط یا نویز داده‌های آموزشی تمرکز می‌کنه و **بیش‌براش** اتفاق می‌افته. با رگولاریزاسیون، ما به مدل می‌گیم که "هم خوب پیش‌بینی کن، هم وزنهات خیلی بزرگ نشن".
$\lambda$ هم مثل "میزان سختگیری" این تنبیه است.

---

این مفاهیم به شما کمک می‌کند تا توانایی درک چالش‌های مدل‌سازی در یادگیری ماشین را پیدا کنید و روش‌هایی برای بهبود عملکرد مدل‌ها ایجاد کنید. اگر نیاز به توضیحات بیشتری دارید، در اختیارم باشید!


### ۱.۱۲. تاثیر پارامتر رگولاریزاسیون $\lambda$ (Effect of Regularization Parameter $\lambda$)

پارامتر رگولاریزاسیون $\lambda$ نقش کلیدی در **متعادل کردن برازش مدل با پیچیدگی آن** ایفا می‌کند.

#### **فرمول با L2 Regularization:**

یکی از رایج‌ترین فرم‌های رگولاریزاسیون، **L2 regularization** است که به صورت:

$$
J_{\lambda}(w) = J(w) + \lambda \sum_{j=1}^{m} w_j^2 = J(w) + \lambda w^T w
$$

به تابع هزینه اضافه می‌شود. این ترم مربع نرم اقلیدسی وزن‌ها را به تابع هزینه می‌افزاید.

* **$\lambda$ بزرگ:** زمانی که مقدار $\lambda$ بزرگ است، مدل به شدت وزن‌های بزرگ را جریمه می‌کند. این امر باعث می‌شود که وزن‌ها مجبور به کوچک‌تر شدن شوند. در نتیجه، پیچیدگی مدل کاهش می‌یابد، بایاس افزایش می‌یابد (زیرا مدل ساده‌تر می‌شود و نمی‌تواند تمام پیچیدگی‌های داده را بگیرد) و واریانس کاهش می‌یابد (زیرا مدل کمتر به نویز حساس می‌شود). در این حالت، مدل تمایل به **کم‌براش** پیدا می‌کند.

* **$\lambda$ کوچک:** در مقابل، وقتی $\lambda$ کوچک است (نزدیک به صفر)، جریمه بر روی وزن‌ها کم می‌شود و مدل اجازه پیدا می‌کند وزن‌های بزرگ‌تری داشته باشد. این به افزایش پیچیدگی مدل منجر می‌شود، بایاس کاهش می‌یابد (زیرا مدل می‌تواند جزئیات بیشتری را فیت کند) و واریانس افزایش می‌یابد (زیرا مدل به نویز حساس‌تر می‌شود). در این حالت، مدل مستعد **بیش‌براش** می‌شود.

#### **کنترل پیچیدگی:**

به این ترتیب، $\lambda$ به طور موثری پیچیدگی موثر مدل را کنترل می‌کند و در نتیجه، میزان بیش‌براش را تنظیم می‌نماید.

#### **مثال (صفحه 24 PDF):**

جدول ارائه‌شده به وضوح نشان می‌دهد که با افزایش $\ln(\lambda)$ (که معادل افزایش مقدار $\lambda$ است)، مقادیر وزن‌ها، به خصوص وزن‌های مربوط به ترم‌های با درجه بالاتر (مانند $w_9^*, w_8^*, \dots$) به شدت کاهش می‌یابند و به صفر نزدیک می‌شوند. این نشان‌دهنده آن است که مدل با $\lambda$ بزرگ‌تر، ساده‌تر شده و کمتر به ویژگی‌های پیچیده وابسته می‌شود.

#### **نمودار (صفحه 25 PDF):**

نمودار خطای ERMS در برابر $\ln(\lambda)$ نیز این تاثیر را تأیید می‌کند. با تغییر $\ln(\lambda)$، هم خطای آموزش (آبی) و هم خطای تست (قرمز) تغییر می‌کنند. معمولاً یک مقدار بهینه برای $\lambda$ وجود دارد که خطای تست را به حداقل می‌رساند و نشان‌دهنده بهترین تعادل بین بایاس و واریانس است.

---

### ۲. رگرسیون احتمالی (Probabilistic Regression)

بخش دوم این جزوه به **"رگرسیون احتمالی"** می‌پردازد که دیدگاهی عمیق‌تر و آماری‌تر به مسائل رگرسیون ارائه می‌دهد.

#### ۲.۱. مقدمه‌ای بر رگرسیون (دیدگاه احتمالی)

در دیدگاه احتمالی، هدف **رگرسیون**، مدل‌سازی رابطه بین یک ورودی $x$ و یک خروجی $y$ است. با این حال، در این دیدگاه، فرض می‌شود که خروجی $y$ دارای **عدم قطعیت (Uncertainty)** مرتبطی است که نمی‌توان آن را به طور کامل با یک تابع قطعی مدل کرد. این عدم قطعیت با یک **توزیع احتمالی** مدل‌سازی می‌شود. یک مثال رایج، فرض این است که خروجی مشاهده شده $y$ برابر است با یک تابع پایه از $x$ و وزن‌های مدل $f(x;w)$ به علاوه مقداری نویز $\epsilon$ که از یک توزیع نرمال (Normal/Gaussian distribution) با میانگین صفر و واریانس $\sigma^2$ پیروی می‌کند:

$$
y = f(x; w) + \epsilon, \quad \epsilon \sim N(0, \sigma^2)
$$

در نهایت، هدف اصلی در این رویکرد، **یادگیری تابع $f(x; w)$** برای پیش‌بینی $y$ است.

#### **توضیحات اضافه:**

در رگرسیون عادی، ما فقط یک خط یا منحنی پیدا می‌کردیم که از وسط داده‌ها رد شود. در رگرسیون احتمالی، فرض می‌کنیم که داده‌های واقعی ما دقیق نیستند و همیشه یک مقداری "خطای تصادفی" یا "نویز" در اندازه‌گیری‌ها یا فرآیند تولید داده وجود دارد. هدف ما پیدا کردن بهترین تابع $f(x; w)$ است که میانگین رفتار داده‌ها را نشان دهد و همچنین بتوانیم میزان "عدم قطعیت" یا "پراکندگی" حول این پیش‌بینی را هم مدل کنیم.

#### ۲.۲. فیت کردن منحنی با نویز (Curve Fitting with Noise)

در سناریوهای واقعی و کاربردی، خروجی مشاهده شده $y$ همواره **نویزی (noisy)** است. این بدان معناست که حتی اگر رابطه اصلی بین ورودی و خروجی کاملاً مشخص باشد، مقادیر مشاهده شده دارای انحرافات تصادفی هستند. مدل ریاضی این وضعیت به این صورت است که خروجی واقعی $y$ برابر است با خروجی تابع $f(x; w)$ به علاوه نویز $\epsilon$:

$$
y = f(x; w) + \epsilon
$$

این نویز نشان‌دهنده تمام **عوامل ناشناخته** یا مدل‌سازی نشده‌ای است که بر خروجی تأثیر می‌گذارند و نمی‌توان آن‌ها را به طور دقیق در تابع $f(x; w)$ گنجاند. به عنوان مثال، در پیش‌بینی قیمت خانه بر اساس ویژگی‌ها، حتی با داشتن تمام اطلاعات ممکن، همیشه مقداری **عدم قطعیت ذاتی** وجود دارد که نمی‌توان آن را به طور کامل پیش‌بینی کرد.

#### ۲.۳. مقدار مورد انتظار خروجی (Expected Value of Output)

در دیدگاه احتمالی، بهترین تخمین برای $y$ با داشتن $x$، همان **امید ریاضی شرطی** $y$ به شرط $x$ است:

$$
E[y \mid x] = f(x; w)
$$

این بدان معناست که تابع $f(x; w)$ که ما یاد می‌گیریم، در واقع میانگین رفتار متغیر هدف $y$ را با داشتن ورودی $x$ ثبت می‌کند. بنابراین، هدف اصلی ما در **رگرسیون احتمالی**، یادگیری تابعی $f(x; w)$ است که بتواند این میانگین شرطی را به بهترین شکل ممکن تقریب بزند.

---

این توضیحات به شما کمک می‌کند تا فهم دقیق‌تری از تکنیک‌های رگرسیون و نحوه مدل‌سازی عدم قطعیت در یادگیری ماشین پیدا کنید. در صورتی که سوالی دارید یا نیاز به توضیحات بیشتری هستید، خوشحال می‌شوم که کمک کنم!
### ۲.۴. **برآورد بیشینه درست‌نمایی (Maximum Likelihood Estimation - MLE)**

**برآورد بیشینه درست‌نمایی (MLE)** یک روش آماری بسیار قدرتمند و پرکاربرد برای تخمین پارامترهای یک مدل است. هدف MLE این است که پارامترهایی را پیدا کند که **احتمال وقوع داده‌های مشاهده شده (likelihood)** را به حداکثر برسانند. به عبارت دیگر، این روش پارامترهایی را انتخاب می‌کند که بیشترین احتمال را برای وقوع داده‌های واقعی فراهم می‌کنند.

فرض کنید مجموعه داده‌ها به صورت $Z = \{(x_i, y_i)\}_{i=1}^n$ داریم. MLE پارامترهایی مانند $w$ (وزن‌ها) و $\sigma^2$ (واریانس نویز) را پیدا می‌کند که حاصل‌ضرب احتمال‌های هر یک از نمونه‌ها را بیشینه کنند:

$$
L(Z; w, \sigma^2) = \prod_{i=1}^{n} p(y_i | x_i, w, \sigma^2)
$$

در واقع، **MLE** پارامترهای $w$ و $\sigma^2$ را پیدا می‌کند که بهترین توضیح را برای داده‌هایی که مشاهده کرده‌ایم، ارائه می‌دهند.

### ۲.۵. **برآورد بیشینه درست‌نمایی (ادامه)**

در عمل، به جای **بیشینه‌سازی مستقیم تابع درست‌نمایی** ($L(Z; w, \sigma^2)$)، معمولاً **بیشینه‌سازی لگاریتم درست‌نمایی (log-likelihood)** آسان‌تر است. دلایل استفاده از log-likelihood به شرح زیر است:

* **حفظ رفتار تابع:** تابع لگاریتم یک تابع صعودی یکنواخت است. این بدان معناست که نقاطی که تابع اصلی را بیشینه می‌کنند، لگاریتم آن تابع را نیز بیشینه می‌کنند. بنابراین، بیشینه‌سازی logL همان نتیجه را به همراه دارد که بیشینه‌سازی تابع اصلی داشته است.

* **تبدیل ضرب به جمع:** تابع درست‌نمایی شامل حاصل‌ضرب احتمالات تک‌تک نمونه‌ها است. لگاریتم این حاصل‌ضرب را به یک جمع تبدیل می‌کند:

$$
\log L(Z; w, \sigma^2) = \sum_{i=1}^{n} \log p(y_i | x_i, w, \sigma^2)
$$

این تبدیل، هم از نظر محاسباتی پایدارتر است (جلوگیری از Underflow در حاصل‌ضرب اعداد کوچک) و هم **مشتق‌گیری از مجموع ترم‌ها** بسیار آسان‌تر است که برای الگوریتم‌های بهینه‌سازی مبتنی بر گرادیان حیاتی است.

### ۲.۶. **مثال تابع خطی تک‌متغیره (Univariate Linear Function Example)**

برای درک چگونگی ارتباط **MLE** با **رگرسیون خطی**، یک مثال رایج این است که فرض کنیم **نویز** ($\epsilon$) از یک توزیع **گاوسی** (نرمال) با میانگین صفر و واریانس $\sigma^2$ پیروی می‌کند. در این صورت، احتمال مشاهده یک خروجی واقعی $y$ به شرط ورودی $x$، وزن‌های $w$ و واریانس نویز $\sigma^2$ به صورت زیر است:

$$
p(y | x, w, \sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp \left( -\frac{(y - f(x; w))^2}{2 \sigma^2} \right)
$$

برای یک مدل خطی ساده مانند $f(x; w) = w_0 + w_1 x$ (که یک تابع تک‌متغیره است)، فرمول بالا به صورت زیر در می‌آید:

$$
p(y | x, w, \sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp \left( -\frac{(y - w_0 - w_1 x)^2}{2 \sigma^2} \right)
$$

مشاهده کلیدی در این فرمول این است که **نقاطی که از خط فیت شده** ($f(x; w)$) **فاصله زیادی دارند، احتمال وقوع آن‌ها کم خواهد بود.** به عبارت دیگر، مدل‌هایی که انحرافات بزرگی از داده‌های واقعی دارند، کمتر محتمل به نظر می‌رسند.

#### **توضیحات اضافه:**

این بخش بسیار مهم است زیرا نشان می‌دهد که چگونه **MLE** (که یک روش آماری است) به روشی که ما در **رگرسیون خطی** استفاده می‌کنیم (کمینه‌سازی مجموع مربعات خطا) منتهی می‌شود. فرض "نویز گاوسی" در اینجا کلید است. اگر داده‌های شما نویز گاوسی داشته باشند، **بیشینه‌سازی احتمال** دقیقا همان چیزی است که شما با **کمینه‌سازی فاصله مربع (SSE)** انجام می‌دهید.

### ۲.۷. **لگاریتم درست‌نمایی و مجموع مربعات (Log-Likelihood and Sum of Squares)**

با استفاده از فرمول **لگاریتم درست‌نمایی** که در بخش قبلی به دست آوردیم (با فرض نویز گاوسی)، می‌توانیم رابطه آن را با **مجموع مربعات خطا** مشخص کنیم. لگاریتم درست‌نمایی به صورت:

$$
\log L(Z; w, \sigma^2) = -n \log \sigma - \frac{n}{2} \log(2 \pi) - \frac{1}{2 \sigma^2} \sum_{i=1}^{n} (y^{(i)} - f(x^{(i)}; w))^2
$$

از آنجایی که هدف **MLE** بهینه‌سازی پارامترهای مدل ($w$ و $\sigma^2$) است، می‌توان ترم‌های ثابتی را که شامل این پارامترها نیستند (مانند $-n \log \sigma$ و $- \frac{n}{2} \log(2 \pi)$ و همچنین $- \frac{1}{2 \sigma^2}$) از معادله حذف کرد، زیرا تاثیری در محل بهینه ندارند. بنابراین، لگاریتم درست‌نمایی متناسب با عبارت زیر می‌شود:

$$
\log L(Z; w, \sigma^2) \sim - \sum_{i=1}^{n} (y^{(i)} - f(x^{(i)}; w))^2
$$

#### **هم‌ارزی (Equivalence):**

این نشان‌دهنده یک هم‌ارزی کلیدی است: **بیشینه‌سازی لگاریتم درست‌نمایی** (با فرض نویز گاوسی) دقیقا معادل **کمینه‌سازی مجموع مربعات خطا (Sum of Squared Errors - SSE)** است. تابع هزینه **SSE** که در رگرسیون خطی استفاده می‌کنیم به صورت زیر تعریف می‌شود:

$$
J(w) = \sum_{i=1}^{n} (y^{(i)} - f(x^{(i)}; w))^2
$$

این هم‌ارزی، یک پایه آماری قوی برای استفاده از **SSE** به عنوان تابع هزینه در **رگرسیون خطی** فراهم می‌کند.

#### **توضیحات اضافه:**

این بخش نشان می‌دهد که چرا روشی که ما در **رگرسیون خطی** برای پیدا کردن بهترین خط استفاده می‌کنیم (کمینه‌سازی **SSE**)، از دیدگاه احتمالی، بهترین روش است. یعنی وقتی ما فرض می‌کنیم که خطاهای ما (نویز) به صورت نرمال توزیع شده‌اند، پیدا کردن خطی که کمترین مجموع مربعات خطا را داشته باشد، دقیقا معادل پیدا کردن خطی است که داده‌های مشاهده شده‌ی ما را با بالاترین احتمال توضیح دهد.

---

اگر نیاز به توضیحات بیشتر یا درک عمیق‌تر در هر بخش دارید، حتماً بپرسید!








































# 📘 جزوه کامل یادگیری ماشین: رگرسیون خطی، تعمیم‌پذیری و رگرسیون احتمالی

**از فایل اصلی : دکتر علی شریفی‌زارچی منتشر شده درتاریخ: ۲۱ سپتامبر ۲۰۲۴**

---

### **1. مقدمه (Introduction)**

در این بخش، به بررسی مفاهیم پایه‌ای یادگیری ماشین می‌پردازیم که به‌عنوان پیش‌نیاز برای درک موضوعات بعدی ضروری است.

#### **1.1. یادگیری ماشین چیست؟**

**پرسش:** یادگیری ماشین به چه معناست و چرا اهمیت دارد؟
**پاسخ:** یادگیری ماشین شاخه‌ای از هوش مصنوعی است که به سیستم‌ها امکان می‌دهد از داده‌ها یاد بگیرند و بدون برنامه‌ریزی صریح، عملکرد خود را بهبود دهند. این فناوری در کاربردهایی مانند تشخیص تصویر، پردازش زبان طبیعی، پیش‌بینی‌های مالی، و تحلیل داده‌های پزشکی نقش کلیدی دارد. یادگیری ماشین به ما کمک می‌کند تا الگوهای پنهان در داده‌ها را کشف کنیم و تصمیم‌گیری‌های هوشمندانه‌تری انجام دهیم.

#### **1.2. انواع یادگیری ماشین**

**پرسش:** چه نوع‌هایی از یادگیری ماشین وجود دارد؟
**پاسخ:** یادگیری ماشین به سه دسته اصلی تقسیم می‌شود:
* **یادگیری نظارت‌شده:** مدل با استفاده از داده‌های برچسب‌دار (ورودی و خروجی) آموزش می‌بیند. مثال: پیش‌بینی قیمت خانه بر اساس ویژگی‌هایی مانند متراژ و تعداد اتاق.
* **یادگیری بدون نظارت:** مدل روی داده‌های بدون برچسب کار می‌کند تا الگوها یا ساختارهای پنهان را کشف کند. مثال: خوشه‌بندی مشتریان برای بازاریابی هدفمند.
* **یادگیری تقویتی:** مدل از طریق آزمون و خطا و دریافت پاداش یا جریمه یاد می‌گیرد. مثال: آموزش ربات برای انجام وظایف خاص مانند حرکت در محیط.

---

### **2. رگرسیون خطی و مدل‌سازی**

رگرسیون خطی یکی از روش‌های پایه‌ای در یادگیری ماشین است که برای مدل‌سازی روابط خطی بین متغیرها استفاده می‌شود.

#### **2.1. رگرسیون خطی چیست؟**

**پرسش:** رگرسیون خطی چگونه کار می‌کند؟
**پاسخ:** رگرسیون خطی مدلی است که رابطه‌ای خطی بین متغیرهای مستقل (ویژگی‌ها) و متغیر وابسته (هدف) برقرار می‌کند. این مدل به‌صورت زیر تعریف می‌شود:
\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_n x_n + \epsilon
\]
که در آن $\beta_0$ عرض از مبدا، $\beta_i$ ضرایب مدل، $x_i$ ویژگی‌ها، و $\epsilon$ خطای مدل است. هدف، یافتن مقادیر بهینه $\beta_i$ است که خطای پیش‌بینی را کمینه کند.

#### **2.2. کاربردهای رگرسیون خطی**

**پرسش:** رگرسیون خطی در چه مواردی استفاده می‌شود؟
**پاسخ:** رگرسیون خطی برای پیش‌بینی مقادیر عددی در مسائل مختلف به کار می‌رود، از جمله:
* پیش‌بینی فروش محصولات بر اساس بودجه تبلیغات.
* تخمین مصرف انرژی یک ساختمان بر اساس دما و اندازه.
* تحلیل روابط اقتصادی، مانند تأثیر نرخ بهره بر رشد اقتصادی.
برای بهبود دقت، تکنیک‌هایی مانند نرمال‌سازی داده‌ها، انتخاب ویژگی‌های مناسب، و استفاده از روش‌های منظم‌سازی (مانند رگرسیون ریج یا لاسو) استفاده می‌شود.

#### **2.3. چالش‌های رگرسیون خطی**

**پرسش:** چه مشکلاتی در استفاده از رگرسیون خطی ممکن است پیش بیاید؟
**پاسخ:** برخی از چالش‌های اصلی عبارت‌اند از:
* **بیش‌برازش**: مدل ممکن است بیش از حد به داده‌های آموزشی وابسته شود و در داده‌های جدید عملکرد ضعیفی داشته باشد.
* **فرض خطی بودن**: اگر رابطه بین متغیرها غیرخطی باشد، مدل رگرسیون خطی مناسب نخواهد بود.
* **حساسیت به داده‌های پرت**: داده‌های پرت می‌توانند ضرایب مدل را به‌شدت تحت تأثیر قرار دهند.

---

### **3. تعمیم‌پذیری در یادگیری ماشین**

تعمیم‌پذیری یکی از مفاهیم کلیدی در یادگیری ماشین است که به توانایی مدل در عملکرد خوب روی داده‌های جدید اشاره دارد.

#### **3.1. تعمیم‌پذیری چیست؟**

**پرسش:** چرا تعمیم‌پذیری در یادگیری ماشین مهم است؟
**پاسخ:** تعمیم‌پذیری به این معناست که مدل نه‌تنها روی داده‌های آموزشی بلکه روی داده‌های جدید و نادیده (داده‌های آزمون) نیز عملکرد خوبی داشته باشد. هدف اصلی یادگیری ماشین، ساخت مدل‌هایی است که بتوانند الگوهای عمومی را از داده‌ها استخراج کنند، نه اینکه صرفاً داده‌های آموزشی را حفظ کنند. بدون تعمیم‌پذیری، مدل ممکن است دچار بیش‌برازش (overfitting) یا کم‌برازش (underfitting) شود.

#### **3.2. چگونه تعمیم‌پذیری را بهبود دهیم؟**

**پرسش:** چه روش‌هایی برای بهبود تعمیم‌پذیری وجود دارد؟
**پاسخ:** برای بهبود تعمیم‌پذیری می‌توان از تکنیک‌های زیر استفاده کرد:
* **تقسیم داده‌ها**: استفاده از مجموعه‌های آموزشی، اعتبارسنجی، و آزمون برای ارزیابی عملکرد مدل.
* **منظم‌سازی**: استفاده از روش‌هایی مانند رگرسیون ریج یا لاسو برای کاهش پیچیدگی مدل.
* **افزایش داده‌ها**: استفاده از تکنیک‌های افزایش داده (data augmentation) یا جمع‌آوری داده‌های متنوع‌تر.
* **اعتبارسنجی متقاطع**: استفاده از روش‌هایی مانند k-fold cross-validation برای اطمینان از عملکرد پایدار مدل.

#### **3.3. چالش‌های تعمیم‌پذیری**

**پرسش:** چه عواملی تعمیم‌پذیری را به خطر می‌اندازند؟
**پاسخ:** برخی از عوامل عبارت‌اند از:
* **داده‌های ناکافی**: اگر داده‌های آموزشی محدود یا غیرنماینده باشند، مدل نمی‌تواند الگوهای عمومی را یاد بگیرد.
* **پیچیدگی بیش از حد مدل**: مدل‌های بسیار پیچیده (مانند شبکه‌های عصبی عمیق) ممکن است به داده‌های آموزشی بیش‌برازش شوند.
* **نویز در داده‌ها**: داده‌های پر سر و صدا یا نادرست می‌توانند یادگیری الگوهای صحیح را مختل کنند.

---

### **4. رگرسیون احتمالی**

رگرسیون احتمالی رویکردی است که عدم قطعیت را در مدل‌سازی وارد می‌کند و به‌جای پیش‌بینی یک مقدار دقیق، توزیع احتمالی خروجی‌ها را مدل می‌کند.

#### **4.1. رگرسیون احتمالی چیست؟**

**پرسش:** تفاوت رگرسیون احتمالی با رگرسیون خطی چیست؟
**پاسخ:** در رگرسیون خطی، هدف پیش‌بینی یک مقدار عددی دقیق است، اما در رگرسیون احتمالی، مدل توزیع احتمالی خروجی‌ها را پیش‌بینی می‌کند. به‌عنوان مثال، به‌جای پیش‌بینی قیمت خانه به‌صورت یک عدد (مثلاً 500 میلیون تومان)، مدل یک توزیع نرمال با میانگین 500 میلیون و واریانس مشخص ارائه می‌دهد که عدم قطعیت را نیز نشان می‌دهد.

#### **4.2. مدل‌های رگرسیون احتمالی**

**پرسش:** چه مدل‌هایی در رگرسیون احتمالی استفاده می‌شوند؟
**پاسخ:** برخی از مدل‌های رایج عبارت‌اند از:
* **رگرسیون خطی بیزی**: از رویکرد بیزی برای مدل‌سازی توزیع ضرایب استفاده می‌کند.
* **رگرسیون گاوسی**: فرض می‌کند خروجی‌ها از یک توزیع نرمال پیروی می‌کنند.
* **مدل‌های ترکیبی**: مانند مدل‌های مخلوط گاوسی که برای داده‌های پیچیده‌تر استفاده می‌شوند.

#### **4.3. کاربردهای رگرسیون احتمالی**

**پرسش:** رگرسیون احتمالی در چه مواردی مفید است؟
**پاسخ:** رگرسیون احتمالی در سناریوهایی که عدم قطعیت مهم است، کاربرد دارد، از جمله:
* پیش‌بینی‌های مالی، مانند تخمین ریسک سرمایه‌گذاری.
* مدل‌سازی داده‌های پزشکی، مانند پیش‌بینی احتمال بیماری.
* تحلیل داده‌های علمی که نویز زیادی دارند.

---

# 🎓 جزوه آموزشی جلسه ۲

## موضوع: تعمیم‌پذیری (Generalization) و رگرسیون احتمالاتی (Probabilistic Regression)

مدرس: دکتر علی شریفی زارعی
دانشگاه صنعتی شریف – پاییز ۱۴۰۳

---

## بخش اول: تعمیم‌پذیری (Generalization)

### توضیح تکمیلی:

در یادگیری ماشین، مدل‌ها فقط نباید روی داده‌های آموزش خوب عمل کنند؛ بلکه باید بتوانند روی داده‌هایی که قبلاً ندیده‌اند نیز عملکرد خوبی داشته باشند. این توانایی، **تعمیم‌پذیری** نام دارد.

### محتوای اصلی:

* مدل خوب باید روی داده آموزش و همچنین داده تست عملکرد خوبی داشته باشد.
* تابع هزینه رایج:
  $J(w) = \sum_{i=1}^n (y^{(i)} - h_w(x^{(i)}))^2$

---

## بخش دوم: خطای مورد انتظار روی داده تست (Expected Test Error)

### توضیح تکمیلی:

چون در عمل به تمام داده‌های واقعی دنیا دسترسی نداریم، برای ارزیابی عملکرد مدل از داده‌های تست استفاده می‌کنیم که از همان توزیع داده‌های آموزش آمده‌اند.

### محتوای اصلی:

* هدف اصلی: کمینه کردن فاصله بین خطای آموزش و خطای تست.
* فرمول رسمی:
  $J(w) = \mathbb{E}_{p(x,y)}[(y - h_w(x))^2]$

---

## بخش سوم: Overfitting و Underfitting

### توضیح تکمیلی:

دو خطای متداول در یادگیری ماشین هستند که مانع از تعمیم‌پذیری مناسب مدل می‌شوند. در Overfitting مدل به داده‌های آموزش بیش از حد وابسته می‌شود. در Underfitting مدل آنقدر ساده است که نمی‌تواند الگوی داده را یاد بگیرد.

### محتوای اصلی:

| ویژگی     | Overfitting                                 | Underfitting                       |
| --------- | ------------------------------------------- | ---------------------------------- |
| تعریف     | مدل بسیار پیچیده و حفظ‌کننده‌ی نویز داده‌ها | مدل بسیار ساده و ناتوان در یادگیری |
| رابطه خطا | $J_{train} \ll J_{test}$                    | $J_{train} \approx J_{test} \gg 0$ |
| نتیجه     | عملکرد ضعیف روی داده‌های جدید               | عملکرد ضعیف روی همه داده‌ها        |

---

## بخش چهارم: تجزیه خطای تعمیم‌پذیری (Bias-Variance Tradeoff)

### توضیح تکمیلی:

یکی از مفاهیم کلیدی یادگیری ماشین، تجزیه‌ی خطای مدل به سه مؤلفه است: بایاس، واریانس و نویز. تعادل بین بایاس و واریانس می‌تواند عملکرد مدل را بهینه کند.

### محتوای اصلی:

* فرمول:

  $$
  \mathbb{E}[(y - h_w(x))^2] = Bias^2 + Variance + Noise
  $$
* بایاس بالا: مدل ساده
* واریانس بالا: مدل پیچیده
* نویز: خطای غیرقابل حذف

---

## بخش پنجم: منظم‌سازی (Regularization)

### توضیح تکمیلی:

برای جلوگیری از Overfitting، می‌توان از منظم‌سازی استفاده کرد تا مدل بیش از حد به داده‌های آموزش وابسته نشود. این کار با جریمه کردن وزن‌های بزرگ انجام می‌شود.

### محتوای اصلی:

* تابع هزینه جدید:
  $J_{\lambda}(w) = J(w) + \lambda R(w)$
* برای L2:
  $R(w) = ||w||_2^2$
* λ بزرگ: مدل ساده‌تر → واریانس کمتر، بایاس بیشتر
* λ کوچک: مدل پیچیده‌تر → بایاس کمتر، واریانس بیشتر

---

## بخش ششم: رگرسیون احتمالاتی (Probabilistic Regression)

### توضیح تکمیلی:

در این دیدگاه، خروجی مدل را به‌صورت یک متغیر تصادفی می‌نگریم که دارای نویز است. هدف یادگیری تابعی است که بتواند رفتار میانگین داده را توضیح دهد.

### محتوای اصلی:

* مدل پایه:
  $y = f(x; w) + \epsilon,\ \epsilon \sim \mathcal{N}(0, \sigma^2)$
* برآورد پارامترها با MLE (بیشینه‌سازی درست‌نمایی)
* معادل کمینه‌سازی مجموع مربعات خطا:
  $J(w) = \sum (y_i - f(x_i; w))^2$
* تخمین واریانس نویز:
  $\hat{\sigma}^2 = \frac{1}{n} \sum (y_i - \hat{f}(x_i))^2$

---

