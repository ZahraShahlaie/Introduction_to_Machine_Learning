

**یادگیری ماشین چیست و چه تفاوتی با برنامه‌نویسی سنتی دارد؟**

**پاسخ**: یادگیری ماشین شاخه‌ای از هوش مصنوعی است که به سیستم‌ها امکان می‌دهد از داده‌ها یاد بگیرند و عملکردشان را بدون برنامه‌نویسی صریح بهبود دهند. در برنامه‌نویسی سنتی، قوانین به‌صورت دستی کد می‌شوند، اما در یادگیری ماشین، مدل از داده‌ها الگوها را استخراج می‌کند.

---


**تعریف تام میچل از یادگیری ماشین چیست؟**

**پاسخ**: یک برنامه از تجربه $E$ نسبت به وظیفه $T$ و معیار عملکرد $P$ یاد می‌گیرد، اگر عملکردش در $T$، که با $P$ اندازه‌گیری می‌شود، با $E$ بهبود یابد.

---


**سوال:** در تعریف تام ام. میچل از یادگیری ماشین، سه‌گانه $(T, P, E)$ را توضیح دهید. چگونه این سه جزء با یکدیگر ارتباط برقرار می‌کنند تا نشان دهند که یک برنامه یاد می‌گیرد؟

**پاسخ:**

سه‌گانه $(T, P, E)$ اجزای اصلی یک مسئله یادگیری را تشکیل می‌دهند:

* **وظیفه (Task - T):** کاری که برنامه کامپیوتری باید انجام دهد.
* **معیار عملکرد (Performance Measure - P):** معیاری برای اندازه‌گیری میزان خوب بودن عملکرد برنامه در انجام وظیفه $T$.
* **تجربه (Experience - E):** داده‌ها یا اطلاعاتی که برنامه برای یادگیری از آن‌ها استفاده می‌کند.

**ارتباط:** یک برنامه یاد می‌گیرد اگر عملکرد آن در وظایف $T$، که با $P$ اندازه‌گیری می‌شود، با افزایش تجربه $E$ بهبود یابد. این بدان معناست که با مشاهده داده‌های بیشتر یا با تعاملات مکرر (تجربه)، برنامه باید بتواند وظیفه محوله را با کیفیت بالاتری (عملکرد بهتر) انجام دهد.

---
**چند کاربرد عملی یادگیری ماشین را نام ببرید.**

**پاسخ**: پیش‌بینی رفتار مشتریان، کنترل کیفیت کارخانه، تحلیل تصاویر پزشکی.

---

### چه نوع‌هایی از یادگیری ماشین وجود دارد؟

**پاسخ:**
یادگیری ماشین به سه نوع اصلی تقسیم می‌شود:

* **یادگیری نظارت‌شده:** مدل با استفاده از داده‌های برچسب‌دار (ورودی و خروجی) آموزش می‌بیند. مثلاً پیش‌بینی قیمت خانه بر اساس ویژگی‌هایی مانند متراژ و تعداد اتاق.
* **یادگیری بدون نظارت:** مدل با استفاده از داده‌های بدون برچسب برای کشف الگوها یا ساختارهای پنهان در داده‌ها آموزش می‌بیند. مثلاً خوشه‌بندی مشتریان برای بازاریابی هدفمند.
* **یادگیری تقویتی:** مدل از طریق آزمون و خطا و با دریافت پاداش یا جریمه یاد می‌گیرد. مثلاً آموزش یک ربات برای انجام وظایف خاص مانند حرکت در محیط.

---

**تفاوت بین یادگیری نظارت‌شده و بدون نظارت چیست؟**

**پاسخ**: در یادگیری نظارت‌شده، داده‌ها برچسب دارند (ورودی و خروجی مشخص)، اما در یادگیری بدون نظارت، داده‌ها بدون برچسب هستند و مدل الگوهای پنهان را کشف می‌کند.

---


### تفاوت بین supervised و unsupervised learning؟

**پاسخ**:
در **supervised learning** مدل با **برچسب‌های آموزشی** آموزش داده می‌شود، اما در **unsupervised learning** داده‌ها بدون برچسب هستند و مدل باید ساختار یا الگوهای پنهان در داده‌ها را کشف کند.

---

**یادگیری تحت نظارت چیست؟**

**پاسخ**: یادگیری با داده‌های برچسب‌دار که شامل ورودی ($x$) و خروجی ($y$) است برای پیش‌بینی خروجی‌های جدید.

---


**تفاوت رگرسیون و طبقه‌بندی چیست؟**

**پاسخ**: رگرسیون برای پیش‌بینی مقادیر پیوسته (مثل قیمت) و طبقه‌بندی برای پیش‌بینی دسته‌های گسسته (مثل اسپم/غیراسپم) است.

---


**رگرسیون خطی چیست و چگونه کار می‌کند؟**

**پاسخ**: رگرسیون خطی مدلی است که رابطه خطی بین متغیرهای مستقل و وابسته را مدل‌سازی می‌کند. معادله آن به‌صورت زیر است:

$$
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_n x_n + \epsilon
$$

هدف کمینه کردن خطا با یافتن ضرایب بهینه است.
---

###  رگرسیون خطی؟

**پاسخ**:
**رگرسیون خطی** برای پیش‌بینی داده‌های پیوسته مانند قیمت‌ها، روندها و دما استفاده می‌شود.

---

### مدل ساده‌ای برای پیش‌بینی پیوسته چیست؟

**پاسخ**:
**رگرسیون خطی** یک مدل ساده برای پیش‌بینی **داده‌های پیوسته** است که رابطه‌ای خطی بین ورودی‌ها و خروجی برقرار می‌کند.

---

**فرمول فرضیه رگرسیون خطی چیست؟**

**پاسخ**:

$$
h_w(x) = w_0 + w_1x_1 + \dots + w_Dx_D = w^T x
$$

---

**معادله رگرسیون خطی را بنویسید و اجزای آن را توضیح دهید.**

**پاسخ**: معادله:

$$
y = \beta_0 + \beta_1 x_1 + \dots + \beta_n x_n + \epsilon
$$

* $y$: متغیر وابسته (هدف).
* $\beta_0$: عرض از مبدا.
* $\beta_i$: ضرایب ویژگی‌ها.
* $x_i$: متغیرهای مستقل (ویژگی‌ها).
* $\epsilon$: خطای مدل.

---

**نقش $w_0$ در رگرسیون خطی چیست؟**

**پاسخ**: $w_0$ بایاس است که امکان پیش‌بینی مقادیر غیرصفر را حتی در صورت صفر بودن ویژگی‌ها فراهم می‌کند.

---

**هدف اصلی رگرسیون خطی چیست؟**

**پاسخ**: کمینه کردن فاصله بین پیش‌بینی ($h_w(x)$) و مقدار واقعی ($y$).

---

**تابع هزینه چیست؟**

**پاسخ**: معیاری برای سنجش دقت مدل، مثل مجموع مربعات خطاها (SSE).

---

**تابع هزینه در رگرسیون خطی چیست و چگونه محاسبه می‌شود؟**

**پاسخ**: تابع هزینه معمولاً میانگین مربعات خطا (MSE) است:

$$
J(\beta) = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2
$$

که $y_i$ مقدار واقعی و $\hat{y}_i$ مقدار پیش‌بینی‌شده است.

---


**فرمول MSE چیست؟**

**پاسخ**:

$$
J(w) = \frac{1}{n} \sum_{i=1}^{n} (y^{(i)} - h_w(x^{(i)}))^2
$$

---

**چرا از MSE به‌عنوان تابع هزینه استفاده می‌شود؟**

**پاسخ**: چون خطاهای بزرگ را بیشتر جریمه می‌کند و محاسباتش ساده است.

---

**روش تحلیلی در رگرسیون خطی چیست؟**

**پاسخ**: استفاده از معادلات نرمال برای محاسبه مستقیم

$$
w = (X^T X)^{-1} X^T y
$$

---



**مزیت روش تحلیلی چیست؟**

**پاسخ**: دقیق است و نیازی به تکرار ندارد.

---

**محدودیت‌های روش معادلات نرمال چیست؟**

**پاسخ**: محاسبات سنگین برای داده‌های بزرگ و نیاز به معکوس‌پذیری $X^T X$.

---








**گرادیان نزولی چیست؟**

**پاسخ**: روشی عددی برای کمینه کردن تابع هزینه با به‌روزرسانی وزن‌ها در جهت مخالف گرادیان.

---

**فرمول به‌روزرسانی گرادیان نزولی چیست؟**

**پاسخ**:

$$
w_{t+1} = w_t - \eta \nabla J(w_t)
$$

---

**نرخ یادگیری ($\eta$) چیست؟**

**پاسخ**: پارامتری که اندازه قدم‌های به‌روزرسانی وزن‌ها را تعیین می‌کند.

---

**اگر نرخ یادگیری خیلی بزرگ باشد چه اتفاقی می‌افتد؟**

**پاسخ**: الگوریتم ممکن است واگرا شود و به نقطه بهینه نرسد.

---

**اگر نرخ یادگیری خیلی کوچک باشد چه می‌شود؟**

**پاسخ**: همگرایی کند می‌شود و زمان زیادی طول می‌کشد.

---

**تفاوت Batch GD و Stochastic GD چیست؟**

**پاسخ**: Batch GD از کل داده‌ها و Stochastic GD از یک نمونه در هر مرحله استفاده می‌کند.

---

**Mini-batch GD چیست؟**

**پاسخ**: استفاده از زیرمجموعه‌ای از داده‌ها برای به‌روزرسانی وزن‌ها، تعادل بین دقت و سرعت.

---

**چرا نرمال‌سازی داده‌ها در گرادیان نزولی مهم است؟**

**پاسخ**: باعث می‌شود گرادیان‌ها در مقیاس مشابه باشند و همگرایی سریع‌تر شود.

---

**رگرسیون چندجمله‌ای چیست؟**

**پاسخ**: مدلی که روابط غیرخطی را با استفاده از ویژگی‌های چندجمله‌ای مدل می‌کند.

---

**فرمول فرضیه رگرسیون چندجمله‌ای چیست؟**

**پاسخ**:

$$
h(x) = w_0 + w_1x + w_2x^2 + \dots + w_mx^m
$$

---



**مزیت رگرسیون چندجمله‌ای نسبت به رگرسیون خطی چیست؟**

**پاسخ**: توانایی مدل‌سازی روابط غیرخطی.

---

**چرا رگرسیون چندجمله‌ای ممکن است بیش‌برازش کند؟**

**پاسخ**: چون با افزایش درجه، مدل ممکن است نویز داده‌ها را هم یاد بگیرد.

---

**Underfitting چیست؟**

**پاسخ**: وقتی مدل بیش‌ازحد ساده است و نمی‌تواند الگوهای داده را خوب یاد بگیرد.

---

**Overfitting چیست؟**

**پاسخ**: وقتی مدل بیش‌ازحد پیچیده است و نویز داده‌ها را هم یاد می‌گیرد.

---


**چگونه می‌توان از بیش‌برازش جلوگیری کرد؟**

**پاسخ**: استفاده از تنظیم‌سازی (Regularization)، داده‌های اعتبارسنجی، و Cross-Validation.

---


**بیش‌برازش چیست و چگونه می‌توان از آن جلوگیری کرد؟**

**پاسخ**: بیش‌برازش زمانی رخ می‌دهد که مدل بیش از حد به داده‌های آموزشی وابسته شود و روی داده‌های جدید ضعیف عمل کند. برای جلوگیری: منظم‌سازی (ریج، لاسو)، افزایش داده، و اعتبارسنجی متقاطع.

---

---

### چگونه Overfitting را تشخیص دهیم؟

**پاسخ**:
**Overfitting** زمانی رخ می‌دهد که **خطای آموزش پایین** و **خطای تست بالا** باشد، زیرا مدل فقط به داده‌های آموزش مناسب شده است و توانایی تعمیم به داده‌های جدید را ندارد.

---

### راه‌های جلوگیری از Overfitting؟

**پاسخ**:
برای جلوگیری از **overfitting** می‌توان از روش‌هایی مانند:

* **Regularization**
* **Dropout**
* **استفاده از داده‌های بیشتر**
* **مدل ساده‌تر** استفاده کرد.

---



**تفاوت بین بیش‌برازش و کم‌برازش چیست؟**

**پاسخ**: بیش‌برازش: مدل بیش از حد به داده‌های آموزشی وابسته است و روی داده‌های جدید ضعیف عمل می‌کند.
کم‌برازش: مدل الگوهای داده‌های آموزشی را به‌خوبی یاد نمی‌گیرد و عملکرد ضعیفی دارد.

---

**داده‌های اعتبارسنجی چه نقشی دارند؟**

**پاسخ**: برای انتخاب مدلی که نه خیلی ساده و نه خیلی پیچیده باشد.
---

**چرا MSE خطاهای بزرگ را بیشتر جریمه می‌کند؟**

**پاسخ**: چون خطاها را به توان 2 می‌رساند، تأثیر خطاهای بزرگ بیشتر می‌شود.

---

**چه زمانی از Batch GD استفاده می‌کنیم؟**

**پاسخ**: وقتی داده‌ها کم باشند و دقت بالا مهم باشد.

---

**چه زمانی Stochastic GD مناسب است؟**

**پاسخ**: برای داده‌های بزرگ یا مسائل آنلاین که سرعت مهم است.

---

**مزیت Mini-batch GD چیست؟**

**پاسخ**: تعادل بین سرعت Stochastic GD و دقت Batch GD.

---

**چگونه نرخ یادگیری مناسب انتخاب می‌شود؟**

**پاسخ**: با آزمایش مقادیر مختلف یا استفاده از روش‌های تطبیقی مثل Adam.

---

**چرا $X^T X$ ممکن است معکوس‌پذیر نباشد؟**

**پاسخ**: به دلیل هم‌خطی ویژگی‌ها یا تعداد کم نمونه‌ها.

---

**گرادیان چیست؟**

**پاسخ**: مشتق تابع هزینه نسبت به پارامترها که جهت بهینه‌سازی را نشان می‌دهد.

---


**نقش بایاس در رگرسیون چیست؟**

**پاسخ**: امکان جابجایی مدل برای تطابق بهتر با داده‌ها.

---




**چرا نرمال‌سازی داده‌ها در رگرسیون خطی مهم است؟**

**پاسخ**: نرمال‌سازی مقیاس ویژگی‌ها را یکسان می‌کند تا تأثیر متغیرهای با مقیاس بزرگ‌تر بر مدل کاهش یابد و گرادیان کاهشی سریع‌تر همگرا شود.
---


**چگونه می‌توان مدل رگرسیون را ارزیابی کرد؟**

**پاسخ**: با معیارهایی مثل MSE، RMSE، یا $R^2$ روی داده‌های تست.

---

**تفاوت داده‌های آموزشی و اعتبارسنجی چیست؟**

**پاسخ**: داده‌های آموزشی برای یادگیری مدل و اعتبارسنجی برای ارزیابی آن استفاده می‌شوند.

---

**چگونه درجه مناسب در رگرسیون چندجمله‌ای انتخاب میشود؟**


**پاسخ**: با استفاده از داده‌های اعتبارسنجی و بررسی خطای تست.

---

**چرا رگرسیون خطی برای داده‌های غیرخطی مناسب نیست؟**

**پاسخ**: چون فرض می‌کند رابطه بین ورودی و خروجی خطی است.

---

**تفاوت MSE و RMSE چیست؟**

**پاسخ**: RMSE ریشه دوم MSE است و مقیاسش با داده‌ها یکسان است.



---


